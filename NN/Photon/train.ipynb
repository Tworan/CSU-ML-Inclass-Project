{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os, sys \n",
    "import numpy as np \n",
    "import cupy as cp \n",
    "from tensorflow.keras.datasets.mnist import load_data as load_mnist\n",
    "from tensorflow.keras.datasets.cifar10 import load_data as load_cifar\n",
    "sys.path.append('/home/oneran/机器学习课设/cifar-10/Photon')\n",
    "from layers import * \n",
    "from ResidualModel import * \n",
    "from Model import * \n",
    "from DenseNet import *\n",
    "from optimizers import * \n",
    "from utils import * \n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Mnist数据集"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = load_mnist()\n",
    "print(X_train.shape, Y_train.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(60000, 28, 28) (60000,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def to_category(labels, classes=10):\n",
    "    categories = np.zeros((len(labels), classes)) \n",
    "    for i in range(len(categories)):\n",
    "        categories[i, labels[i]] = 1\n",
    "    return categories\n",
    "if X_train.shape[0] == 50000:\n",
    "    data = X_train / 255.\n",
    "    label = to_category(Y_train, 10)\n",
    "else:\n",
    "    data = np.expand_dims(X_train / 255., axis=-1)\n",
    "    label = to_category(Y_train, 10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "model = ResNet(datasets='mnist', opt='sgd')\n",
    "model.datas = [data, label]\n",
    "model.train(15)\n",
    "plt.plot(np.arange(len(model.history)), model.history)\n",
    "plt.show()\n",
    "np.savetxt('/home/oneran/Downloads/sgd_mnist_ResNet_history.txt', model.history)\n",
    "model.save_model('/home/oneran/机器学习课设/cifar-10/Photon/sgd_mnist_ResNet.pkl')\n",
    "score, pred = model.score(X_train, Y_train)\n",
    "score, pred = model.score(X_test, Y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 0 Step: 1 Loss: 2.3019419383383175\n",
      "Epoch: 0 Step: 11 Loss: 2.261711845925751\n",
      "Epoch: 0 Step: 21 Loss: 2.3231911992476233\n",
      "Epoch: 0 Step: 31 Loss: 2.2857642643068523\n",
      "Epoch: 0 Step: 41 Loss: 2.331355085573133\n",
      "Epoch: 0 Step: 51 Loss: 2.2948519532193137\n",
      "Epoch: 0 Step: 61 Loss: 2.1362192986396416\n",
      "Epoch: 0 Step: 71 Loss: 2.1693232011560477\n",
      "Epoch: 0 Step: 81 Loss: 2.171362853905099\n",
      "Epoch: 0 Step: 91 Loss: 2.1311722226667165\n",
      "Epoch: 0 Step: 101 Loss: 2.163415827745\n",
      "Epoch: 0 Step: 111 Loss: 2.098351225421997\n",
      "Epoch: 0 Step: 121 Loss: 2.131003291567371\n",
      "Epoch: 0 Step: 131 Loss: 2.053352794073231\n",
      "Epoch: 0 Step: 141 Loss: 2.152851099492297\n",
      "Epoch: 0 Step: 151 Loss: 2.0446457956303434\n",
      "Epoch: 0 Step: 161 Loss: 2.018716328497743\n",
      "Epoch: 0 Step: 171 Loss: 2.022317127301198\n",
      "Epoch: 0 Step: 181 Loss: 1.980413434030606\n",
      "Epoch: 0 Step: 191 Loss: 2.0088045202719034\n",
      "Epoch: 0 Step: 201 Loss: 1.8532034066471093\n",
      "Epoch: 0 Step: 211 Loss: 1.8533856941153364\n",
      "Epoch: 0 Step: 221 Loss: 1.7840784301383754\n",
      "Epoch: 0 Step: 231 Loss: 1.8490618620501573\n",
      "Epoch: 0 Step: 241 Loss: 1.496251889356526\n",
      "Epoch: 0 Step: 251 Loss: 1.6245385958104575\n",
      "Epoch: 0 Step: 261 Loss: 1.4665242012880277\n",
      "Epoch: 0 Step: 271 Loss: 1.2872198588368684\n",
      "Epoch: 0 Step: 281 Loss: 1.3301047525381922\n",
      "Epoch: 0 Step: 291 Loss: 1.4699230148882043\n",
      "Epoch: 0 Step: 301 Loss: 1.6282020621418458\n",
      "Epoch: 0 Step: 311 Loss: 1.1662378441609516\n",
      "Epoch: 0 Step: 321 Loss: 1.1773661544042326\n",
      "Epoch: 0 Step: 331 Loss: 0.9947129864549656\n",
      "Epoch: 0 Step: 341 Loss: 0.7074004326094943\n",
      "Epoch: 0 Step: 351 Loss: 0.901036552864571\n",
      "Epoch: 0 Step: 361 Loss: 0.9708696048507106\n",
      "Epoch: 0 Step: 371 Loss: 0.906672809355379\n",
      "Epoch: 0 Step: 381 Loss: 0.48035858612480553\n",
      "Epoch: 0 Step: 391 Loss: 0.7428570246125389\n",
      "Epoch: 0 Step: 401 Loss: 0.8530335984081363\n",
      "Epoch: 0 Step: 411 Loss: 0.5812329689290582\n",
      "Epoch: 0 Step: 421 Loss: 0.6209428469693312\n",
      "Epoch: 0 Step: 431 Loss: 0.5134582460287358\n",
      "Epoch: 0 Step: 441 Loss: 0.6728769229112079\n",
      "Epoch: 0 Step: 451 Loss: 0.3817344607344546\n",
      "Epoch: 0 Step: 461 Loss: 0.3373966307519959\n",
      "Epoch: 0 Step: 471 Loss: 0.49805711040219747\n",
      "Epoch: 0 Step: 481 Loss: 0.5285965687538313\n",
      "Epoch: 0 Step: 491 Loss: 0.2646415254457366\n",
      "Epoch: 0 Step: 501 Loss: 0.37381138466383856\n",
      "Epoch: 0 Step: 511 Loss: 0.47003711205795284\n",
      "Epoch: 0 Step: 521 Loss: 0.3623893151662677\n",
      "Epoch: 0 Step: 531 Loss: 0.12630296089867168\n",
      "Epoch: 0 Step: 541 Loss: 0.25093358625705187\n",
      "Epoch: 0 Step: 551 Loss: 0.3691389415118004\n",
      "Epoch: 0 Step: 561 Loss: 0.23161437900041743\n",
      "Epoch: 0 Step: 571 Loss: 0.29058999944994074\n",
      "Epoch: 0 Step: 581 Loss: 0.5076242909673613\n",
      "Epoch: 0 Step: 591 Loss: 0.33523599206131816\n",
      "Epoch: 0 Step: 601 Loss: 0.26657717165750033\n",
      "Epoch: 0 Step: 611 Loss: 0.1553309261589553\n",
      "Epoch: 0 Step: 621 Loss: 0.22984724490610364\n",
      "Epoch: 0 Step: 631 Loss: 0.2287875782375614\n",
      "Epoch: 0 Step: 641 Loss: 0.6261272216498341\n",
      "Epoch: 0 Step: 651 Loss: 0.1373644576805834\n",
      "Epoch: 0 Step: 661 Loss: 0.12026416396317863\n",
      "Epoch: 0 Step: 671 Loss: 0.33261705633842226\n",
      "Epoch: 0 Step: 681 Loss: 0.3532463067332563\n",
      "Epoch: 0 Step: 691 Loss: 0.19640177536573677\n",
      "Epoch: 0 Step: 701 Loss: 0.3988710682901474\n",
      "Epoch: 0 Step: 711 Loss: 0.2643402163491785\n",
      "Epoch: 0 Step: 721 Loss: 0.29793727924881397\n",
      "Epoch: 0 Step: 731 Loss: 0.32406535782064294\n",
      "Epoch: 0 Step: 741 Loss: 0.29216503430828256\n",
      "Epoch: 0 Step: 751 Loss: 0.120738679504844\n",
      "Epoch: 0 Step: 761 Loss: 0.17656240056675782\n",
      "Epoch: 0 Step: 771 Loss: 0.22372766406426584\n",
      "Epoch: 0 Step: 781 Loss: 0.1965185197192857\n",
      "Epoch: 0 Step: 791 Loss: 0.323989729243112\n",
      "Epoch: 0 Step: 801 Loss: 0.27418452650105246\n",
      "Epoch: 0 Step: 811 Loss: 0.08628631605008047\n",
      "Epoch: 0 Step: 821 Loss: 0.18101399843472352\n",
      "Epoch: 0 Step: 831 Loss: 0.4333539188603927\n",
      "Epoch: 0 Step: 841 Loss: 0.11324432860904199\n",
      "Epoch: 0 Step: 851 Loss: 0.17832005227365103\n",
      "Epoch: 0 Step: 861 Loss: 0.14908071620766716\n",
      "Epoch: 0 Step: 871 Loss: 0.2675567850939272\n",
      "Epoch: 0 Step: 881 Loss: 0.21561043731551177\n",
      "Epoch: 0 Step: 891 Loss: 0.26613205092573783\n",
      "Epoch: 0 Step: 901 Loss: 0.3147767092483171\n",
      "Epoch: 0 Step: 911 Loss: 0.1992665468930902\n",
      "Epoch: 0 Step: 921 Loss: 0.115771576402319\n",
      "Epoch: 0 Step: 931 Loss: 0.07954364159070121\n",
      "Epoch: 1 Step: 1 Loss: 0.116278409064343\n",
      "Epoch: 1 Step: 11 Loss: 0.16448814566717282\n",
      "Epoch: 1 Step: 21 Loss: 0.48580753347669425\n",
      "Epoch: 1 Step: 31 Loss: 0.27385445721121865\n",
      "Epoch: 1 Step: 41 Loss: 0.2182233483301924\n",
      "Epoch: 1 Step: 51 Loss: 0.2911133182180461\n",
      "Epoch: 1 Step: 61 Loss: 0.14307702320568577\n",
      "Epoch: 1 Step: 71 Loss: 0.13282796895297896\n",
      "Epoch: 1 Step: 81 Loss: 0.16832112600449572\n",
      "Epoch: 1 Step: 91 Loss: 0.13821696579922266\n",
      "Epoch: 1 Step: 101 Loss: 0.15511341736343354\n",
      "Epoch: 1 Step: 111 Loss: 0.19461067860519565\n",
      "Epoch: 1 Step: 121 Loss: 0.17659879243058865\n",
      "Epoch: 1 Step: 131 Loss: 0.09537300223263039\n",
      "Epoch: 1 Step: 141 Loss: 0.3161945563903308\n",
      "Epoch: 1 Step: 151 Loss: 0.18038208234747827\n",
      "Epoch: 1 Step: 161 Loss: 0.578323280922268\n",
      "Epoch: 1 Step: 171 Loss: 0.10097587118641632\n",
      "Epoch: 1 Step: 181 Loss: 0.24574599905234093\n",
      "Epoch: 1 Step: 191 Loss: 0.10734078273552164\n",
      "Epoch: 1 Step: 201 Loss: 0.20879075617774673\n",
      "Epoch: 1 Step: 211 Loss: 0.04788612202916227\n",
      "Epoch: 1 Step: 221 Loss: 0.1394618022584082\n",
      "Epoch: 1 Step: 231 Loss: 0.3956716373339639\n",
      "Epoch: 1 Step: 241 Loss: 0.3242314574855383\n",
      "Epoch: 1 Step: 251 Loss: 0.37384775601109327\n",
      "Epoch: 1 Step: 261 Loss: 0.2687552890290318\n",
      "Epoch: 1 Step: 271 Loss: 0.08461301544139803\n",
      "Epoch: 1 Step: 281 Loss: 0.1975462104660776\n",
      "Epoch: 1 Step: 291 Loss: 0.09571043678574051\n",
      "Epoch: 1 Step: 301 Loss: 0.2927956304538265\n",
      "Epoch: 1 Step: 311 Loss: 0.16289964939880625\n",
      "Epoch: 1 Step: 321 Loss: 0.11795707549882123\n",
      "Epoch: 1 Step: 331 Loss: 0.20623426495519379\n",
      "Epoch: 1 Step: 341 Loss: 0.08015602129847796\n",
      "Epoch: 1 Step: 351 Loss: 0.14691036016387995\n",
      "Epoch: 1 Step: 361 Loss: 0.2546900704004044\n",
      "Epoch: 1 Step: 371 Loss: 0.09144038337010348\n",
      "Epoch: 1 Step: 381 Loss: 0.04560424602625225\n",
      "Epoch: 1 Step: 391 Loss: 0.17105117938654127\n",
      "Epoch: 1 Step: 401 Loss: 0.10958082670721689\n",
      "Epoch: 1 Step: 411 Loss: 0.09843702299655901\n",
      "Epoch: 1 Step: 421 Loss: 0.1659885597571386\n",
      "Epoch: 1 Step: 431 Loss: 0.11122212279687452\n",
      "Epoch: 1 Step: 441 Loss: 0.19933972045534212\n",
      "Epoch: 1 Step: 451 Loss: 0.19706963429265967\n",
      "Epoch: 1 Step: 461 Loss: 0.038443737785690046\n",
      "Epoch: 1 Step: 471 Loss: 0.2783769133428847\n",
      "Epoch: 1 Step: 481 Loss: 0.09272269450907536\n",
      "Epoch: 1 Step: 491 Loss: 0.11100807548209868\n",
      "Epoch: 1 Step: 501 Loss: 0.0920084830328162\n",
      "Epoch: 1 Step: 511 Loss: 0.26370927821849494\n",
      "Epoch: 1 Step: 521 Loss: 0.1222367798260658\n",
      "Epoch: 1 Step: 531 Loss: 0.05536409133785418\n",
      "Epoch: 1 Step: 541 Loss: 0.09138661576606108\n",
      "Epoch: 1 Step: 551 Loss: 0.32461883597271596\n",
      "Epoch: 1 Step: 561 Loss: 0.10953891520363855\n",
      "Epoch: 1 Step: 571 Loss: 0.1598650357899815\n",
      "Epoch: 1 Step: 581 Loss: 0.19822812639100854\n",
      "Epoch: 1 Step: 591 Loss: 0.0760260667921944\n",
      "Epoch: 1 Step: 601 Loss: 0.08602080697926308\n",
      "Epoch: 1 Step: 611 Loss: 0.042599017924859074\n",
      "Epoch: 1 Step: 621 Loss: 0.11990918799739998\n",
      "Epoch: 1 Step: 631 Loss: 0.04378229102760597\n",
      "Epoch: 1 Step: 641 Loss: 0.21578882905168467\n",
      "Epoch: 1 Step: 651 Loss: 0.13650898635030217\n",
      "Epoch: 1 Step: 661 Loss: 0.07562341530899269\n",
      "Epoch: 1 Step: 671 Loss: 0.07024556167716399\n",
      "Epoch: 1 Step: 681 Loss: 0.19667935738322037\n",
      "Epoch: 1 Step: 691 Loss: 0.13156373763149212\n",
      "Epoch: 1 Step: 701 Loss: 0.43262023819790796\n",
      "Epoch: 1 Step: 711 Loss: 0.16020353322629513\n",
      "Epoch: 1 Step: 721 Loss: 0.24157908536085534\n",
      "Epoch: 1 Step: 731 Loss: 0.16255640786297726\n",
      "Epoch: 1 Step: 741 Loss: 0.08742303966247217\n",
      "Epoch: 1 Step: 751 Loss: 0.11950421780454552\n",
      "Epoch: 1 Step: 761 Loss: 0.05607917835328269\n",
      "Epoch: 1 Step: 771 Loss: 0.04460147987706134\n",
      "Epoch: 1 Step: 781 Loss: 0.17550348612536285\n",
      "Epoch: 1 Step: 791 Loss: 0.210619210194172\n",
      "Epoch: 1 Step: 801 Loss: 0.10980375861644993\n",
      "Epoch: 1 Step: 811 Loss: 0.015751691122975316\n",
      "Epoch: 1 Step: 821 Loss: 0.04250586994891509\n",
      "Epoch: 1 Step: 831 Loss: 0.1500496787737298\n",
      "Epoch: 1 Step: 841 Loss: 0.07587536361800268\n",
      "Epoch: 1 Step: 851 Loss: 0.13836111531922918\n",
      "Epoch: 1 Step: 861 Loss: 0.07465119454294485\n",
      "Epoch: 1 Step: 871 Loss: 0.15342495945658088\n",
      "Epoch: 1 Step: 881 Loss: 0.09289241872773765\n",
      "Epoch: 1 Step: 891 Loss: 0.10876153519751719\n",
      "Epoch: 1 Step: 901 Loss: 0.15108492686684447\n",
      "Epoch: 1 Step: 911 Loss: 0.06867375739178572\n",
      "Epoch: 1 Step: 921 Loss: 0.10731707007500489\n",
      "Epoch: 1 Step: 931 Loss: 0.016967192269184507\n",
      "Epoch: 2 Step: 1 Loss: 0.0872615543636435\n",
      "Epoch: 2 Step: 11 Loss: 0.06175975379075704\n",
      "Epoch: 2 Step: 21 Loss: 0.3269249792061847\n",
      "Epoch: 2 Step: 31 Loss: 0.17006762479163573\n",
      "Epoch: 2 Step: 41 Loss: 0.09880383299443002\n",
      "Epoch: 2 Step: 51 Loss: 0.10816583491198167\n",
      "Epoch: 2 Step: 61 Loss: 0.037180379604343394\n",
      "Epoch: 2 Step: 71 Loss: 0.10281044279975379\n",
      "Epoch: 2 Step: 81 Loss: 0.12343171861867452\n",
      "Epoch: 2 Step: 91 Loss: 0.07521681912283676\n",
      "Epoch: 2 Step: 101 Loss: 0.08348185287982257\n",
      "Epoch: 2 Step: 111 Loss: 0.12038405419429038\n",
      "Epoch: 2 Step: 121 Loss: 0.05848771896321697\n",
      "Epoch: 2 Step: 131 Loss: 0.10514686842624042\n",
      "Epoch: 2 Step: 141 Loss: 0.1381529839111862\n",
      "Epoch: 2 Step: 151 Loss: 0.1297908655465048\n",
      "Epoch: 2 Step: 161 Loss: 0.32213430969418544\n",
      "Epoch: 2 Step: 171 Loss: 0.053069640632696216\n",
      "Epoch: 2 Step: 181 Loss: 0.08879006530055471\n",
      "Epoch: 2 Step: 191 Loss: 0.0824644563477483\n",
      "Epoch: 2 Step: 201 Loss: 0.16953205284226538\n",
      "Epoch: 2 Step: 211 Loss: 0.06510339338210243\n",
      "Epoch: 2 Step: 221 Loss: 0.15527215893700994\n",
      "Epoch: 2 Step: 231 Loss: 0.12806645621716908\n",
      "Epoch: 2 Step: 241 Loss: 0.23933599153056745\n",
      "Epoch: 2 Step: 251 Loss: 0.23383031870259346\n",
      "Epoch: 2 Step: 261 Loss: 0.2346493957145449\n",
      "Epoch: 2 Step: 271 Loss: 0.08908245287937729\n",
      "Epoch: 2 Step: 281 Loss: 0.1061205121198481\n",
      "Epoch: 2 Step: 291 Loss: 0.09893085699620763\n",
      "Epoch: 2 Step: 301 Loss: 0.2057931967399031\n",
      "Epoch: 2 Step: 311 Loss: 0.08896161582053201\n",
      "Epoch: 2 Step: 321 Loss: 0.07591418457007473\n",
      "Epoch: 2 Step: 331 Loss: 0.17132660000913022\n",
      "Epoch: 2 Step: 341 Loss: 0.09054609782461548\n",
      "Epoch: 2 Step: 351 Loss: 0.16502833650032017\n",
      "Epoch: 2 Step: 361 Loss: 0.11591163176485465\n",
      "Epoch: 2 Step: 371 Loss: 0.10814511943922964\n",
      "Epoch: 2 Step: 381 Loss: 0.05383032121553193\n",
      "Epoch: 2 Step: 391 Loss: 0.05373770567113189\n",
      "Epoch: 2 Step: 401 Loss: 0.0773935159365852\n",
      "Epoch: 2 Step: 411 Loss: 0.19901063209423503\n",
      "Epoch: 2 Step: 421 Loss: 0.14801744101891154\n",
      "Epoch: 2 Step: 431 Loss: 0.057121490186942896\n",
      "Epoch: 2 Step: 441 Loss: 0.04481433294744101\n",
      "Epoch: 2 Step: 451 Loss: 0.13523610368128447\n",
      "Epoch: 2 Step: 461 Loss: 0.07964069517384356\n",
      "Epoch: 2 Step: 471 Loss: 0.1537225080892406\n",
      "Epoch: 2 Step: 481 Loss: 0.0394792503563329\n",
      "Epoch: 2 Step: 491 Loss: 0.06355315550554985\n",
      "Epoch: 2 Step: 501 Loss: 0.11300114646716475\n",
      "Epoch: 2 Step: 511 Loss: 0.14173771737057878\n",
      "Epoch: 2 Step: 521 Loss: 0.16754920322246977\n",
      "Epoch: 2 Step: 531 Loss: 0.014799114500899747\n",
      "Epoch: 2 Step: 541 Loss: 0.12882325921427543\n",
      "Epoch: 2 Step: 551 Loss: 0.1980884769432063\n",
      "Epoch: 2 Step: 561 Loss: 0.04709724653638649\n",
      "Epoch: 2 Step: 571 Loss: 0.05019469929820078\n",
      "Epoch: 2 Step: 581 Loss: 0.10411358890902707\n",
      "Epoch: 2 Step: 591 Loss: 0.0709898522068072\n",
      "Epoch: 2 Step: 601 Loss: 0.11188466600434566\n",
      "Epoch: 2 Step: 611 Loss: 0.018863205017827074\n",
      "Epoch: 2 Step: 621 Loss: 0.12767744132759656\n",
      "Epoch: 2 Step: 631 Loss: 0.067847303742672\n",
      "Epoch: 2 Step: 641 Loss: 0.12248738886792915\n",
      "Epoch: 2 Step: 651 Loss: 0.08104979128723966\n",
      "Epoch: 2 Step: 661 Loss: 0.026347632863409902\n",
      "Epoch: 2 Step: 671 Loss: 0.03414144549948067\n",
      "Epoch: 2 Step: 681 Loss: 0.2291451008144914\n",
      "Epoch: 2 Step: 691 Loss: 0.10355659836604089\n",
      "Epoch: 2 Step: 701 Loss: 0.34338481284791644\n",
      "Epoch: 2 Step: 711 Loss: 0.13825481357290198\n",
      "Epoch: 2 Step: 721 Loss: 0.24931306388621902\n",
      "Epoch: 2 Step: 731 Loss: 0.1464095138120665\n",
      "Epoch: 2 Step: 741 Loss: 0.09779311210504055\n",
      "Epoch: 2 Step: 751 Loss: 0.11210088031780618\n",
      "Epoch: 2 Step: 761 Loss: 0.07636192215752553\n",
      "Epoch: 2 Step: 771 Loss: 0.027343046708724512\n",
      "Epoch: 2 Step: 781 Loss: 0.025200024824368384\n",
      "Epoch: 2 Step: 791 Loss: 0.1545344494519511\n",
      "Epoch: 2 Step: 801 Loss: 0.12221687687398794\n",
      "Epoch: 2 Step: 811 Loss: 0.02315162048365009\n",
      "Epoch: 2 Step: 821 Loss: 0.06933450261299645\n",
      "Epoch: 2 Step: 831 Loss: 0.09088834922595085\n",
      "Epoch: 2 Step: 841 Loss: 0.07984670494470834\n",
      "Epoch: 2 Step: 851 Loss: 0.07831779943097067\n",
      "Epoch: 2 Step: 861 Loss: 0.03042592841351055\n",
      "Epoch: 2 Step: 871 Loss: 0.11163097342544138\n",
      "Epoch: 2 Step: 881 Loss: 0.09093810706355022\n",
      "Epoch: 2 Step: 891 Loss: 0.04603538973110513\n",
      "Epoch: 2 Step: 901 Loss: 0.1025145577094916\n",
      "Epoch: 2 Step: 911 Loss: 0.015128254868148188\n",
      "Epoch: 2 Step: 921 Loss: 0.04846876800347157\n",
      "Epoch: 2 Step: 931 Loss: 0.012909869517358358\n",
      "Epoch: 3 Step: 1 Loss: 0.03345904540912237\n",
      "Epoch: 3 Step: 11 Loss: 0.04147626646011133\n",
      "Epoch: 3 Step: 21 Loss: 0.12246229148569501\n",
      "Epoch: 3 Step: 31 Loss: 0.0850281034733683\n",
      "Epoch: 3 Step: 41 Loss: 0.07503106946216248\n",
      "Epoch: 3 Step: 51 Loss: 0.11183283134301376\n",
      "Epoch: 3 Step: 61 Loss: 0.016953872410157063\n",
      "Epoch: 3 Step: 71 Loss: 0.12337370304899514\n",
      "Epoch: 3 Step: 81 Loss: 0.08536282204600072\n",
      "Epoch: 3 Step: 91 Loss: 0.08863301707952081\n",
      "Epoch: 3 Step: 101 Loss: 0.06048101550175657\n",
      "Epoch: 3 Step: 111 Loss: 0.07266967024966416\n",
      "Epoch: 3 Step: 121 Loss: 0.0391454622559622\n",
      "Epoch: 3 Step: 131 Loss: 0.05632675014909224\n",
      "Epoch: 3 Step: 141 Loss: 0.06127275492973693\n",
      "Epoch: 3 Step: 151 Loss: 0.10936332069252715\n",
      "Epoch: 3 Step: 161 Loss: 0.3204835849739262\n",
      "Epoch: 3 Step: 171 Loss: 0.10000774899989621\n",
      "Epoch: 3 Step: 181 Loss: 0.03125837046332175\n",
      "Epoch: 3 Step: 191 Loss: 0.02113734767549614\n",
      "Epoch: 3 Step: 201 Loss: 0.2403083372815499\n",
      "Epoch: 3 Step: 211 Loss: 0.011842339589432437\n",
      "Epoch: 3 Step: 221 Loss: 0.018894024152248015\n",
      "Epoch: 3 Step: 231 Loss: 0.12964609686493117\n",
      "Epoch: 3 Step: 241 Loss: 0.06394177360416788\n",
      "Epoch: 3 Step: 251 Loss: 0.21084619128109103\n",
      "Epoch: 3 Step: 261 Loss: 0.09240506076680145\n",
      "Epoch: 3 Step: 271 Loss: 0.04981933200367867\n",
      "Epoch: 3 Step: 281 Loss: 0.13676038113150496\n",
      "Epoch: 3 Step: 291 Loss: 0.07674611340536089\n",
      "Epoch: 3 Step: 301 Loss: 0.13545662201129796\n",
      "Epoch: 3 Step: 311 Loss: 0.0424563279387505\n",
      "Epoch: 3 Step: 321 Loss: 0.02971400866583794\n",
      "Epoch: 3 Step: 331 Loss: 0.17142377338560133\n",
      "Epoch: 3 Step: 341 Loss: 0.029749352110566788\n",
      "Epoch: 3 Step: 351 Loss: 0.05826757311518454\n",
      "Epoch: 3 Step: 361 Loss: 0.162196316554026\n",
      "Epoch: 3 Step: 371 Loss: 0.03317360556528628\n",
      "Epoch: 3 Step: 381 Loss: 0.008119234688065843\n",
      "Epoch: 3 Step: 391 Loss: 0.030101887067905238\n",
      "Epoch: 3 Step: 401 Loss: 0.033305589697500804\n",
      "Epoch: 3 Step: 411 Loss: 0.06359487247369874\n",
      "Epoch: 3 Step: 421 Loss: 0.18779108288626944\n",
      "Epoch: 3 Step: 431 Loss: 0.05408978441907208\n",
      "Epoch: 3 Step: 441 Loss: 0.03820599288730509\n",
      "Epoch: 3 Step: 451 Loss: 0.1196469334352451\n",
      "Epoch: 3 Step: 461 Loss: 0.0483091764409172\n",
      "Epoch: 3 Step: 471 Loss: 0.11831791905950967\n",
      "Epoch: 3 Step: 481 Loss: 0.05700995951881509\n",
      "Epoch: 3 Step: 491 Loss: 0.05465317517860473\n",
      "Epoch: 3 Step: 501 Loss: 0.0081492036191239\n",
      "Epoch: 3 Step: 511 Loss: 0.1703076662737566\n",
      "Epoch: 3 Step: 521 Loss: 0.14794172000926856\n",
      "Epoch: 3 Step: 531 Loss: 0.007605967558370899\n",
      "Epoch: 3 Step: 541 Loss: 0.12962518415729432\n",
      "Epoch: 3 Step: 551 Loss: 0.2620415885939469\n",
      "Epoch: 3 Step: 561 Loss: 0.12972816490783126\n",
      "Epoch: 3 Step: 571 Loss: 0.019556812474311798\n",
      "Epoch: 3 Step: 581 Loss: 0.13418485644397127\n",
      "Epoch: 3 Step: 591 Loss: 0.019006516531803685\n",
      "Epoch: 3 Step: 601 Loss: 0.01755589873748397\n",
      "Epoch: 3 Step: 611 Loss: 0.03011290610805762\n",
      "Epoch: 3 Step: 621 Loss: 0.11766091014792801\n",
      "Epoch: 3 Step: 631 Loss: 0.08936249799495194\n",
      "Epoch: 3 Step: 641 Loss: 0.13161353936155124\n",
      "Epoch: 3 Step: 651 Loss: 0.1000845431928222\n",
      "Epoch: 3 Step: 661 Loss: 0.01845654634476787\n",
      "Epoch: 3 Step: 671 Loss: 0.04551518934836585\n",
      "Epoch: 3 Step: 681 Loss: 0.07246987547679945\n",
      "Epoch: 3 Step: 691 Loss: 0.02960986673826705\n",
      "Epoch: 3 Step: 701 Loss: 0.17990863816918623\n",
      "Epoch: 3 Step: 711 Loss: 0.032441380890333125\n",
      "Epoch: 3 Step: 721 Loss: 0.15380537305220793\n",
      "Epoch: 3 Step: 731 Loss: 0.12609568867509602\n",
      "Epoch: 3 Step: 741 Loss: 0.012297803163106198\n",
      "Epoch: 3 Step: 751 Loss: 0.01662623601599197\n",
      "Epoch: 3 Step: 761 Loss: 0.09397435906417247\n",
      "Epoch: 3 Step: 771 Loss: 0.010016087135216335\n",
      "Epoch: 3 Step: 781 Loss: 0.009864233520926951\n",
      "Epoch: 3 Step: 791 Loss: 0.07337839959006988\n",
      "Epoch: 3 Step: 801 Loss: 0.09832686883248332\n",
      "Epoch: 3 Step: 811 Loss: 0.01710594107187355\n",
      "Epoch: 3 Step: 821 Loss: 0.058113558691526734\n",
      "Epoch: 3 Step: 831 Loss: 0.04312730584550094\n",
      "Epoch: 3 Step: 841 Loss: 0.11201418207824762\n",
      "Epoch: 3 Step: 851 Loss: 0.20383614226672464\n",
      "Epoch: 3 Step: 861 Loss: 0.028656461583349394\n",
      "Epoch: 3 Step: 871 Loss: 0.12368406072618707\n",
      "Epoch: 3 Step: 881 Loss: 0.02835633283819792\n",
      "Epoch: 3 Step: 891 Loss: 0.12907236134577144\n",
      "Epoch: 3 Step: 901 Loss: 0.09009062645771616\n",
      "Epoch: 3 Step: 911 Loss: 0.12923669373958516\n",
      "Epoch: 3 Step: 921 Loss: 0.009978942925252454\n",
      "Epoch: 3 Step: 931 Loss: 0.024031742924466866\n",
      "Epoch: 4 Step: 1 Loss: 0.01657201149318307\n",
      "Epoch: 4 Step: 11 Loss: 0.05168388687309883\n",
      "Epoch: 4 Step: 21 Loss: 0.06202119387653509\n",
      "Epoch: 4 Step: 31 Loss: 0.1013773732169613\n",
      "Epoch: 4 Step: 41 Loss: 0.01873978125754429\n",
      "Epoch: 4 Step: 51 Loss: 0.11529195826282201\n",
      "Epoch: 4 Step: 61 Loss: 0.01209262304584745\n",
      "Epoch: 4 Step: 71 Loss: 0.07539056094037275\n",
      "Epoch: 4 Step: 81 Loss: 0.03448575059678982\n",
      "Epoch: 4 Step: 91 Loss: 0.11405233797803575\n",
      "Epoch: 4 Step: 101 Loss: 0.07544771898339003\n",
      "Epoch: 4 Step: 111 Loss: 0.1025118879441114\n",
      "Epoch: 4 Step: 121 Loss: 0.025792280575150303\n",
      "Epoch: 4 Step: 131 Loss: 0.0820326892513939\n",
      "Epoch: 4 Step: 141 Loss: 0.1360578265170637\n",
      "Epoch: 4 Step: 151 Loss: 0.0760908783913781\n",
      "Epoch: 4 Step: 161 Loss: 0.15465849338936138\n",
      "Epoch: 4 Step: 171 Loss: 0.0977861719212024\n",
      "Epoch: 4 Step: 181 Loss: 0.0313859492984061\n",
      "Epoch: 4 Step: 191 Loss: 0.029525818484300283\n",
      "Epoch: 4 Step: 201 Loss: 0.047386747932072724\n",
      "Epoch: 4 Step: 211 Loss: 0.04288895380560729\n",
      "Epoch: 4 Step: 221 Loss: 0.06621654360289815\n",
      "Epoch: 4 Step: 231 Loss: 0.12919979955636246\n",
      "Epoch: 4 Step: 241 Loss: 0.10008913392320609\n",
      "Epoch: 4 Step: 251 Loss: 0.12008500214373383\n",
      "Epoch: 4 Step: 261 Loss: 0.21791953338445494\n",
      "Epoch: 4 Step: 271 Loss: 0.04554425392583639\n",
      "Epoch: 4 Step: 281 Loss: 0.12685955216507694\n",
      "Epoch: 4 Step: 291 Loss: 0.07437021392639492\n",
      "Epoch: 4 Step: 301 Loss: 0.16259905943400899\n",
      "Epoch: 4 Step: 311 Loss: 0.039758057576646855\n",
      "Epoch: 4 Step: 321 Loss: 0.06056590784242273\n",
      "Epoch: 4 Step: 331 Loss: 0.16776042521151885\n",
      "Epoch: 4 Step: 341 Loss: 0.00809571661443306\n",
      "Epoch: 4 Step: 351 Loss: 0.08260717924052416\n",
      "Epoch: 4 Step: 361 Loss: 0.09663177827524137\n",
      "Epoch: 4 Step: 371 Loss: 0.050429816278097596\n",
      "Epoch: 4 Step: 381 Loss: 0.008181032662795655\n",
      "Epoch: 4 Step: 391 Loss: 0.04197713113320409\n",
      "Epoch: 4 Step: 401 Loss: 0.02021927806563545\n",
      "Epoch: 4 Step: 411 Loss: 0.0927875692658428\n",
      "Epoch: 4 Step: 421 Loss: 0.07026245053064892\n",
      "Epoch: 4 Step: 431 Loss: 0.04825414813983915\n",
      "Epoch: 4 Step: 441 Loss: 0.03350257146851128\n",
      "Epoch: 4 Step: 451 Loss: 0.08340989220657215\n",
      "Epoch: 4 Step: 461 Loss: 0.01797595377484129\n",
      "Epoch: 4 Step: 471 Loss: 0.07231619768829053\n",
      "Epoch: 4 Step: 481 Loss: 0.00698505544190908\n",
      "Epoch: 4 Step: 491 Loss: 0.04444529735016732\n",
      "Epoch: 4 Step: 501 Loss: 0.03533915473442344\n",
      "Epoch: 4 Step: 511 Loss: 0.12723197611397627\n",
      "Epoch: 4 Step: 521 Loss: 0.11470471816095236\n",
      "Epoch: 4 Step: 531 Loss: 0.003085112147775625\n",
      "Epoch: 4 Step: 541 Loss: 0.06726132291401456\n",
      "Epoch: 4 Step: 551 Loss: 0.2227670731771296\n",
      "Epoch: 4 Step: 561 Loss: 0.09946600826308899\n",
      "Epoch: 4 Step: 571 Loss: 0.03244153193161253\n",
      "Epoch: 4 Step: 581 Loss: 0.033517362378850446\n",
      "Epoch: 4 Step: 591 Loss: 0.018252602600251577\n",
      "Epoch: 4 Step: 601 Loss: 0.01532425620161091\n",
      "Epoch: 4 Step: 611 Loss: 0.021312408752216648\n",
      "Epoch: 4 Step: 621 Loss: 0.03646628946095449\n",
      "Epoch: 4 Step: 631 Loss: 0.06892430762492133\n",
      "Epoch: 4 Step: 641 Loss: 0.09264274227370288\n",
      "Epoch: 4 Step: 651 Loss: 0.009525184406484973\n",
      "Epoch: 4 Step: 661 Loss: 0.006228184410049075\n",
      "Epoch: 4 Step: 671 Loss: 0.008760415026332877\n",
      "Epoch: 4 Step: 681 Loss: 0.04251342344527649\n",
      "Epoch: 4 Step: 691 Loss: 0.02341190137574067\n",
      "Epoch: 4 Step: 701 Loss: 0.1453371506961255\n",
      "Epoch: 4 Step: 711 Loss: 0.03451974552057849\n",
      "Epoch: 4 Step: 721 Loss: 0.12370469677200664\n",
      "Epoch: 4 Step: 731 Loss: 0.04598734151906582\n",
      "Epoch: 4 Step: 741 Loss: 0.012256160395170461\n",
      "Epoch: 4 Step: 751 Loss: 0.019503438873298366\n",
      "Epoch: 4 Step: 761 Loss: 0.01877722808801054\n",
      "Epoch: 4 Step: 771 Loss: 0.00825133248279257\n",
      "Epoch: 4 Step: 781 Loss: 0.0231532299416945\n",
      "Epoch: 4 Step: 791 Loss: 0.08666924181460964\n",
      "Epoch: 4 Step: 801 Loss: 0.10682792869295772\n",
      "Epoch: 4 Step: 811 Loss: 0.01143562500192722\n",
      "Epoch: 4 Step: 821 Loss: 0.04476893298417687\n",
      "Epoch: 4 Step: 831 Loss: 0.024542519693062134\n",
      "Epoch: 4 Step: 841 Loss: 0.030462239563592355\n",
      "Epoch: 4 Step: 851 Loss: 0.16790368469020445\n",
      "Epoch: 4 Step: 861 Loss: 0.03835152892870779\n",
      "Epoch: 4 Step: 871 Loss: 0.06277557920075315\n",
      "Epoch: 4 Step: 881 Loss: 0.011560479327724754\n",
      "Epoch: 4 Step: 891 Loss: 0.00770066277555337\n",
      "Epoch: 4 Step: 901 Loss: 0.2395755053122002\n",
      "Epoch: 4 Step: 911 Loss: 0.0868171927854472\n",
      "Epoch: 4 Step: 921 Loss: 0.13383119020963485\n",
      "Epoch: 4 Step: 931 Loss: 0.011219803242202054\n",
      "Epoch: 5 Step: 1 Loss: 0.03397164118966943\n",
      "Epoch: 5 Step: 11 Loss: 0.025755991369302643\n",
      "Epoch: 5 Step: 21 Loss: 0.04279443433509202\n",
      "Epoch: 5 Step: 31 Loss: 0.02144017487627098\n",
      "Epoch: 5 Step: 41 Loss: 0.0962981482739452\n",
      "Epoch: 5 Step: 51 Loss: 0.06633650063189446\n",
      "Epoch: 5 Step: 61 Loss: 0.027362879081938133\n",
      "Epoch: 5 Step: 71 Loss: 0.07482844627506888\n",
      "Epoch: 5 Step: 81 Loss: 0.05316824527958019\n",
      "Epoch: 5 Step: 91 Loss: 0.14936031406384004\n",
      "Epoch: 5 Step: 101 Loss: 0.013247476671112639\n",
      "Epoch: 5 Step: 111 Loss: 0.0974127345556654\n",
      "Epoch: 5 Step: 121 Loss: 0.01788976185253504\n",
      "Epoch: 5 Step: 131 Loss: 0.026575651585294104\n",
      "Epoch: 5 Step: 141 Loss: 0.06589714133939781\n",
      "Epoch: 5 Step: 151 Loss: 0.11736686438508531\n",
      "Epoch: 5 Step: 161 Loss: 0.456285267286328\n",
      "Epoch: 5 Step: 171 Loss: 0.014560646241572064\n",
      "Epoch: 5 Step: 181 Loss: 0.015399100336138644\n",
      "Epoch: 5 Step: 191 Loss: 0.007638484908748614\n",
      "Epoch: 5 Step: 201 Loss: 0.12324360044429458\n",
      "Epoch: 5 Step: 211 Loss: 0.0044598268529848365\n",
      "Epoch: 5 Step: 221 Loss: 0.0521183780922504\n",
      "Epoch: 5 Step: 231 Loss: 0.04728890838816478\n",
      "Epoch: 5 Step: 241 Loss: 0.05876407884246354\n",
      "Epoch: 5 Step: 251 Loss: 0.077628132315329\n",
      "Epoch: 5 Step: 261 Loss: 0.18338417293119383\n",
      "Epoch: 5 Step: 271 Loss: 0.010618727570178699\n",
      "Epoch: 5 Step: 281 Loss: 0.12333346120309609\n",
      "Epoch: 5 Step: 291 Loss: 0.059612601908529905\n",
      "Epoch: 5 Step: 301 Loss: 0.07625341176968647\n",
      "Epoch: 5 Step: 311 Loss: 0.10148709135514532\n",
      "Epoch: 5 Step: 321 Loss: 0.03585243056977769\n",
      "Epoch: 5 Step: 331 Loss: 0.06984343294645477\n",
      "Epoch: 5 Step: 341 Loss: 0.10312937237506606\n",
      "Epoch: 5 Step: 351 Loss: 0.021474940706882613\n",
      "Epoch: 5 Step: 361 Loss: 0.13993422613468412\n",
      "Epoch: 5 Step: 371 Loss: 0.08919972621910902\n",
      "Epoch: 5 Step: 381 Loss: 0.003516836392881977\n",
      "Epoch: 5 Step: 391 Loss: 0.016866619381417276\n",
      "Epoch: 5 Step: 401 Loss: 0.011576371725964013\n",
      "Epoch: 5 Step: 411 Loss: 0.027605948330268866\n",
      "Epoch: 5 Step: 421 Loss: 0.060604939306051014\n",
      "Epoch: 5 Step: 431 Loss: 0.032794701018794586\n",
      "Epoch: 5 Step: 441 Loss: 0.012897476946695493\n",
      "Epoch: 5 Step: 451 Loss: 0.12784246051880002\n",
      "Epoch: 5 Step: 461 Loss: 0.054194497734581126\n",
      "Epoch: 5 Step: 471 Loss: 0.019173575513520433\n",
      "Epoch: 5 Step: 481 Loss: 0.038062060616567174\n",
      "Epoch: 5 Step: 491 Loss: 0.02372320032557874\n",
      "Epoch: 5 Step: 501 Loss: 0.027451340834614146\n",
      "Epoch: 5 Step: 511 Loss: 0.08410168139738076\n",
      "Epoch: 5 Step: 521 Loss: 0.07859959392485738\n",
      "Epoch: 5 Step: 531 Loss: 0.0025753022424665154\n",
      "Epoch: 5 Step: 541 Loss: 0.030074625258308917\n",
      "Epoch: 5 Step: 551 Loss: 0.19696646274096508\n",
      "Epoch: 5 Step: 561 Loss: 0.0228494314487959\n",
      "Epoch: 5 Step: 571 Loss: 0.009239486995387939\n",
      "Epoch: 5 Step: 581 Loss: 0.09077729850665017\n",
      "Epoch: 5 Step: 591 Loss: 0.010279298126190481\n",
      "Epoch: 5 Step: 601 Loss: 0.04671936893226556\n",
      "Epoch: 5 Step: 611 Loss: 0.01264097071696757\n",
      "Epoch: 5 Step: 621 Loss: 0.024761450538375238\n",
      "Epoch: 5 Step: 631 Loss: 0.10130188758018815\n",
      "Epoch: 5 Step: 641 Loss: 0.1592807752585541\n",
      "Epoch: 5 Step: 651 Loss: 0.053260492256290724\n",
      "Epoch: 5 Step: 661 Loss: 0.052120672399357984\n",
      "Epoch: 5 Step: 671 Loss: 0.041165101229587386\n",
      "Epoch: 5 Step: 681 Loss: 0.025432429230461438\n",
      "Epoch: 5 Step: 691 Loss: 0.02933211561116578\n",
      "Epoch: 5 Step: 701 Loss: 0.1690573292750136\n",
      "Epoch: 5 Step: 711 Loss: 0.06149880713287028\n",
      "Epoch: 5 Step: 721 Loss: 0.11468732144744374\n",
      "Epoch: 5 Step: 731 Loss: 0.08923805812651867\n",
      "Epoch: 5 Step: 741 Loss: 0.013594603018901643\n",
      "Epoch: 5 Step: 751 Loss: 0.04010260873439597\n",
      "Epoch: 5 Step: 761 Loss: 0.004776425392860887\n",
      "Epoch: 5 Step: 771 Loss: 0.0029318803211087815\n",
      "Epoch: 5 Step: 781 Loss: 0.03259374059006042\n",
      "Epoch: 5 Step: 791 Loss: 0.10017154935414543\n",
      "Epoch: 5 Step: 801 Loss: 0.06099486087388081\n",
      "Epoch: 5 Step: 811 Loss: 0.005915969245938388\n",
      "Epoch: 5 Step: 821 Loss: 0.03470031297661532\n",
      "Epoch: 5 Step: 831 Loss: 0.03815335427752689\n",
      "Epoch: 5 Step: 841 Loss: 0.03423354325537763\n",
      "Epoch: 5 Step: 851 Loss: 0.07832149134263283\n",
      "Epoch: 5 Step: 861 Loss: 0.022071921081858802\n",
      "Epoch: 5 Step: 871 Loss: 0.03211759594911039\n",
      "Epoch: 5 Step: 881 Loss: 0.03291074882662639\n",
      "Epoch: 5 Step: 891 Loss: 0.035291178876067406\n",
      "Epoch: 5 Step: 901 Loss: 0.04723218700282627\n",
      "Epoch: 5 Step: 911 Loss: 0.05278675407727904\n",
      "Epoch: 5 Step: 921 Loss: 0.020238725200082235\n",
      "Epoch: 5 Step: 931 Loss: 0.005802352770535288\n",
      "Epoch: 6 Step: 1 Loss: 0.027224503473463776\n",
      "Epoch: 6 Step: 11 Loss: 0.0202285224072406\n",
      "Epoch: 6 Step: 21 Loss: 0.05150243092036646\n",
      "Epoch: 6 Step: 31 Loss: 0.020553064283353274\n",
      "Epoch: 6 Step: 41 Loss: 0.061511878239522845\n",
      "Epoch: 6 Step: 51 Loss: 0.13307219572138207\n",
      "Epoch: 6 Step: 61 Loss: 0.01703781917997898\n",
      "Epoch: 6 Step: 71 Loss: 0.05233635044819407\n",
      "Epoch: 6 Step: 81 Loss: 0.01652677725777279\n",
      "Epoch: 6 Step: 91 Loss: 0.07434328282726547\n",
      "Epoch: 6 Step: 101 Loss: 0.025269859837535123\n",
      "Epoch: 6 Step: 111 Loss: 0.09032615133157171\n",
      "Epoch: 6 Step: 121 Loss: 0.002784456917786617\n",
      "Epoch: 6 Step: 131 Loss: 0.004116268806081517\n",
      "Epoch: 6 Step: 141 Loss: 0.08554356231300701\n",
      "Epoch: 6 Step: 151 Loss: 0.0389521806986777\n",
      "Epoch: 6 Step: 161 Loss: 0.18114372732372427\n",
      "Epoch: 6 Step: 171 Loss: 0.006646641368990373\n",
      "Epoch: 6 Step: 181 Loss: 0.017629029965555806\n",
      "Epoch: 6 Step: 191 Loss: 0.005356649144027066\n",
      "Epoch: 6 Step: 201 Loss: 0.03555673426710432\n",
      "Epoch: 6 Step: 211 Loss: 0.007386854021510012\n",
      "Epoch: 6 Step: 221 Loss: 0.006551246973316417\n",
      "Epoch: 6 Step: 231 Loss: 0.07082233305821684\n",
      "Epoch: 6 Step: 241 Loss: 0.08384310681904768\n",
      "Epoch: 6 Step: 251 Loss: 0.021634096081447122\n",
      "Epoch: 6 Step: 261 Loss: 0.10172280982575234\n",
      "Epoch: 6 Step: 271 Loss: 0.004905034951903602\n",
      "Epoch: 6 Step: 281 Loss: 0.09992641449094357\n",
      "Epoch: 6 Step: 291 Loss: 0.019779712655382378\n",
      "Epoch: 6 Step: 301 Loss: 0.04351930301334117\n",
      "Epoch: 6 Step: 311 Loss: 0.14531762579261137\n",
      "Epoch: 6 Step: 321 Loss: 0.038859394127999845\n",
      "Epoch: 6 Step: 331 Loss: 0.046070554414392194\n",
      "Epoch: 6 Step: 341 Loss: 0.004882028359089531\n",
      "Epoch: 6 Step: 351 Loss: 0.035430472135925144\n",
      "Epoch: 6 Step: 361 Loss: 0.08505510304381295\n",
      "Epoch: 6 Step: 371 Loss: 0.008325588539331236\n",
      "Epoch: 6 Step: 381 Loss: 0.004779290402470606\n",
      "Epoch: 6 Step: 391 Loss: 0.008701269560035172\n",
      "Epoch: 6 Step: 401 Loss: 0.011725937193593123\n",
      "Epoch: 6 Step: 411 Loss: 0.020811796762209095\n",
      "Epoch: 6 Step: 421 Loss: 0.04742322167491725\n",
      "Epoch: 6 Step: 431 Loss: 0.018233633208489065\n",
      "Epoch: 6 Step: 441 Loss: 0.03033868906055316\n",
      "Epoch: 6 Step: 451 Loss: 0.10953603895105371\n",
      "Epoch: 6 Step: 461 Loss: 0.0468443049365081\n",
      "Epoch: 6 Step: 471 Loss: 0.043720308746615005\n",
      "Epoch: 6 Step: 481 Loss: 0.0059174832237199135\n",
      "Epoch: 6 Step: 491 Loss: 0.039320926557389085\n",
      "Epoch: 6 Step: 501 Loss: 0.005663529203526851\n",
      "Epoch: 6 Step: 511 Loss: 0.05310446030805141\n",
      "Epoch: 6 Step: 521 Loss: 0.06247715737462045\n",
      "Epoch: 6 Step: 531 Loss: 0.005500318722584812\n",
      "Epoch: 6 Step: 541 Loss: 0.04588450882965566\n",
      "Epoch: 6 Step: 551 Loss: 0.10524953182480246\n",
      "Epoch: 6 Step: 561 Loss: 0.011400981693381305\n",
      "Epoch: 6 Step: 571 Loss: 0.007921308240296958\n",
      "Epoch: 6 Step: 581 Loss: 0.03924299266991496\n",
      "Epoch: 6 Step: 591 Loss: 0.005338125222302623\n",
      "Epoch: 6 Step: 601 Loss: 0.014455607065553945\n",
      "Epoch: 6 Step: 611 Loss: 0.003957854024646725\n",
      "Epoch: 6 Step: 621 Loss: 0.05268795200442883\n",
      "Epoch: 6 Step: 631 Loss: 0.05906949822778984\n",
      "Epoch: 6 Step: 641 Loss: 0.08301577894642527\n",
      "Epoch: 6 Step: 651 Loss: 0.01857419440270861\n",
      "Epoch: 6 Step: 661 Loss: 0.003331746474199863\n",
      "Epoch: 6 Step: 671 Loss: 0.07032963136639346\n",
      "Epoch: 6 Step: 681 Loss: 0.023332803322630317\n",
      "Epoch: 6 Step: 691 Loss: 0.0061809274465574795\n",
      "Epoch: 6 Step: 701 Loss: 0.17208655643866896\n",
      "Epoch: 6 Step: 711 Loss: 0.011211981239977603\n",
      "Epoch: 6 Step: 721 Loss: 0.14444043922470984\n",
      "Epoch: 6 Step: 731 Loss: 0.015024820073161305\n",
      "Epoch: 6 Step: 741 Loss: 0.025694885582845706\n",
      "Epoch: 6 Step: 751 Loss: 0.008381432298288983\n",
      "Epoch: 6 Step: 761 Loss: 0.007459577696919703\n",
      "Epoch: 6 Step: 771 Loss: 0.003554428217959347\n",
      "Epoch: 6 Step: 781 Loss: 0.05522139621285965\n",
      "Epoch: 6 Step: 791 Loss: 0.023994176980454113\n",
      "Epoch: 6 Step: 801 Loss: 0.07492095201300354\n",
      "Epoch: 6 Step: 811 Loss: 0.013888825150362955\n",
      "Epoch: 6 Step: 821 Loss: 0.02986714406807736\n",
      "Epoch: 6 Step: 831 Loss: 0.03831968099407404\n",
      "Epoch: 6 Step: 841 Loss: 0.06835619976872181\n",
      "Epoch: 6 Step: 851 Loss: 0.07902704274687213\n",
      "Epoch: 6 Step: 861 Loss: 0.006963398710673817\n",
      "Epoch: 6 Step: 871 Loss: 0.04529652072224572\n",
      "Epoch: 6 Step: 881 Loss: 0.0033680710595646417\n",
      "Epoch: 6 Step: 891 Loss: 0.03413423958488353\n",
      "Epoch: 6 Step: 901 Loss: 0.013665504047237277\n",
      "Epoch: 6 Step: 911 Loss: 0.045438543934542344\n",
      "Epoch: 6 Step: 921 Loss: 0.002303424189851161\n",
      "Epoch: 6 Step: 931 Loss: 0.0011804393720101615\n",
      "Epoch: 7 Step: 1 Loss: 0.01250368565076105\n",
      "Epoch: 7 Step: 11 Loss: 0.03157587167317735\n",
      "Epoch: 7 Step: 21 Loss: 0.031688273841637214\n",
      "Epoch: 7 Step: 31 Loss: 0.049324019168651145\n",
      "Epoch: 7 Step: 41 Loss: 0.003251057920942562\n",
      "Epoch: 7 Step: 51 Loss: 0.04481484712759723\n",
      "Epoch: 7 Step: 61 Loss: 0.01120204177433333\n",
      "Epoch: 7 Step: 71 Loss: 0.024232995584316668\n",
      "Epoch: 7 Step: 81 Loss: 0.00967578331896697\n",
      "Epoch: 7 Step: 91 Loss: 0.09318187843689027\n",
      "Epoch: 7 Step: 101 Loss: 0.0061961069408050405\n",
      "Epoch: 7 Step: 111 Loss: 0.040071378372348046\n",
      "Epoch: 7 Step: 121 Loss: 0.002450708462737203\n",
      "Epoch: 7 Step: 131 Loss: 0.10501243668181\n",
      "Epoch: 7 Step: 141 Loss: 0.035672753882605074\n",
      "Epoch: 7 Step: 151 Loss: 0.013289962343083363\n",
      "Epoch: 7 Step: 161 Loss: 0.3150390609275019\n",
      "Epoch: 7 Step: 171 Loss: 0.017248709609516254\n",
      "Epoch: 7 Step: 181 Loss: 0.02502770642468963\n",
      "Epoch: 7 Step: 191 Loss: 0.012840671890091079\n",
      "Epoch: 7 Step: 201 Loss: 0.010159825499341489\n",
      "Epoch: 7 Step: 211 Loss: 0.016879867399193234\n",
      "Epoch: 7 Step: 221 Loss: 0.007672827786710844\n",
      "Epoch: 7 Step: 231 Loss: 0.025996147201198395\n",
      "Epoch: 7 Step: 241 Loss: 0.003400020452260896\n",
      "Epoch: 7 Step: 251 Loss: 0.13438278153433597\n",
      "Epoch: 7 Step: 261 Loss: 0.17648171418828737\n",
      "Epoch: 7 Step: 271 Loss: 0.007732285502341027\n",
      "Epoch: 7 Step: 281 Loss: 0.11106638026081883\n",
      "Epoch: 7 Step: 291 Loss: 0.00860111032179351\n",
      "Epoch: 7 Step: 301 Loss: 0.002278510604788223\n",
      "Epoch: 7 Step: 311 Loss: 0.0035234529865786086\n",
      "Epoch: 7 Step: 321 Loss: 0.005530884504161741\n",
      "Epoch: 7 Step: 331 Loss: 0.042457694502775506\n",
      "Epoch: 7 Step: 341 Loss: 0.008840174883872206\n",
      "Epoch: 7 Step: 351 Loss: 0.051064260501499495\n",
      "Epoch: 7 Step: 361 Loss: 0.06834238356166605\n",
      "Epoch: 7 Step: 371 Loss: 0.015675410546616503\n",
      "Epoch: 7 Step: 381 Loss: 0.008554925446263796\n",
      "Epoch: 7 Step: 391 Loss: 0.0013147688878591944\n",
      "Epoch: 7 Step: 401 Loss: 0.0028454445997524768\n",
      "Epoch: 7 Step: 411 Loss: 0.012849829446505558\n",
      "Epoch: 7 Step: 421 Loss: 0.03180435918021943\n",
      "Epoch: 7 Step: 431 Loss: 0.008771021583602328\n",
      "Epoch: 7 Step: 441 Loss: 0.07083106500139427\n",
      "Epoch: 7 Step: 451 Loss: 0.02053965203618441\n",
      "Epoch: 7 Step: 461 Loss: 0.010328886386444858\n",
      "Epoch: 7 Step: 471 Loss: 0.007655736831410489\n",
      "Epoch: 7 Step: 481 Loss: 0.002827171581564384\n",
      "Epoch: 7 Step: 491 Loss: 0.02871424005114656\n",
      "Epoch: 7 Step: 501 Loss: 0.0032656225620896033\n",
      "Epoch: 7 Step: 511 Loss: 0.033602730531714746\n",
      "Epoch: 7 Step: 521 Loss: 0.009535074537814475\n",
      "Epoch: 7 Step: 531 Loss: 0.001098403727142956\n",
      "Epoch: 7 Step: 541 Loss: 0.004169607342872537\n",
      "Epoch: 7 Step: 551 Loss: 0.1885284364023433\n",
      "Epoch: 7 Step: 561 Loss: 0.08997953187251453\n",
      "Epoch: 7 Step: 571 Loss: 0.002144199853821328\n",
      "Epoch: 7 Step: 581 Loss: 0.04338061719837437\n",
      "Epoch: 7 Step: 591 Loss: 0.01994748566233813\n",
      "Epoch: 7 Step: 601 Loss: 0.013859791176014078\n",
      "Epoch: 7 Step: 611 Loss: 0.03581458302308259\n",
      "Epoch: 7 Step: 621 Loss: 0.04240468811174135\n",
      "Epoch: 7 Step: 631 Loss: 0.06959507692845449\n",
      "Epoch: 7 Step: 641 Loss: 0.06533952818778484\n",
      "Epoch: 7 Step: 651 Loss: 0.04557444116591422\n",
      "Epoch: 7 Step: 661 Loss: 0.0018631906901992077\n",
      "Epoch: 7 Step: 671 Loss: 0.0026035606173757837\n",
      "Epoch: 7 Step: 681 Loss: 0.009524089037451394\n",
      "Epoch: 7 Step: 691 Loss: 0.0073925361115965964\n",
      "Epoch: 7 Step: 701 Loss: 0.09540838071739915\n",
      "Epoch: 7 Step: 711 Loss: 0.02404015383710207\n",
      "Epoch: 7 Step: 721 Loss: 0.07595673260275228\n",
      "Epoch: 7 Step: 731 Loss: 0.012934117100172844\n",
      "Epoch: 7 Step: 741 Loss: 0.0033570575150181246\n",
      "Epoch: 7 Step: 751 Loss: 0.05278605875970818\n",
      "Epoch: 7 Step: 761 Loss: 0.012181771789917913\n",
      "Epoch: 7 Step: 771 Loss: 0.0015646247229472426\n",
      "Epoch: 7 Step: 781 Loss: 0.004543850780028486\n",
      "Epoch: 7 Step: 791 Loss: 0.047339295349540074\n",
      "Epoch: 7 Step: 801 Loss: 0.07776919448159157\n",
      "Epoch: 7 Step: 811 Loss: 0.027726480968302998\n",
      "Epoch: 7 Step: 821 Loss: 0.010007577850362104\n",
      "Epoch: 7 Step: 831 Loss: 0.028356674080014504\n",
      "Epoch: 7 Step: 841 Loss: 0.016799008292123937\n",
      "Epoch: 7 Step: 851 Loss: 0.1281945838775597\n",
      "Epoch: 7 Step: 861 Loss: 0.026536284966243856\n",
      "Epoch: 7 Step: 871 Loss: 0.015757422210705932\n",
      "Epoch: 7 Step: 881 Loss: 0.008383738730845212\n",
      "Epoch: 7 Step: 891 Loss: 0.022618684264904872\n",
      "Epoch: 7 Step: 901 Loss: 0.12114018735610957\n",
      "Epoch: 7 Step: 911 Loss: 0.04235833483468705\n",
      "Epoch: 7 Step: 921 Loss: 0.011383749756090772\n",
      "Epoch: 7 Step: 931 Loss: 0.004843362157661894\n",
      "Epoch: 8 Step: 1 Loss: 0.010312153560132703\n",
      "Epoch: 8 Step: 11 Loss: 0.029435774514338296\n",
      "Epoch: 8 Step: 21 Loss: 0.0897287299727135\n",
      "Epoch: 8 Step: 31 Loss: 0.006329557272612224\n",
      "Epoch: 8 Step: 41 Loss: 0.003098012475390694\n",
      "Epoch: 8 Step: 51 Loss: 0.008366641042195101\n",
      "Epoch: 8 Step: 61 Loss: 0.03705944969861044\n",
      "Epoch: 8 Step: 71 Loss: 0.01729527570123672\n",
      "Epoch: 8 Step: 81 Loss: 0.011353491569245408\n",
      "Epoch: 8 Step: 91 Loss: 0.09409712533540944\n",
      "Epoch: 8 Step: 101 Loss: 0.023487905335389435\n",
      "Epoch: 8 Step: 111 Loss: 0.02715457823651514\n",
      "Epoch: 8 Step: 121 Loss: 0.007003779725849061\n",
      "Epoch: 8 Step: 131 Loss: 0.002998570152317446\n",
      "Epoch: 8 Step: 141 Loss: 0.02353558432597034\n",
      "Epoch: 8 Step: 151 Loss: 0.09727480127456942\n",
      "Epoch: 8 Step: 161 Loss: 0.11198249769123349\n",
      "Epoch: 8 Step: 171 Loss: 0.012488031040693128\n",
      "Epoch: 8 Step: 181 Loss: 0.015559628216198102\n",
      "Epoch: 8 Step: 191 Loss: 0.03621603686279656\n",
      "Epoch: 8 Step: 201 Loss: 0.023592502869716855\n",
      "Epoch: 8 Step: 211 Loss: 0.0021030279019931993\n",
      "Epoch: 8 Step: 221 Loss: 0.014380439501742398\n",
      "Epoch: 8 Step: 231 Loss: 0.013044777480804886\n",
      "Epoch: 8 Step: 241 Loss: 0.028132164921010096\n",
      "Epoch: 8 Step: 251 Loss: 0.03376966514882016\n",
      "Epoch: 8 Step: 261 Loss: 0.14868119004954844\n",
      "Epoch: 8 Step: 271 Loss: 0.002460953608083618\n",
      "Epoch: 8 Step: 281 Loss: 0.10110793920623973\n",
      "Epoch: 8 Step: 291 Loss: 0.0034805709319454823\n",
      "Epoch: 8 Step: 301 Loss: 0.0038969329248653944\n",
      "Epoch: 8 Step: 311 Loss: 0.003856879931534495\n",
      "Epoch: 8 Step: 321 Loss: 0.006844723052081727\n",
      "Epoch: 8 Step: 331 Loss: 0.010432478236894454\n",
      "Epoch: 8 Step: 341 Loss: 0.015391058209798624\n",
      "Epoch: 8 Step: 351 Loss: 0.013650033366846252\n",
      "Epoch: 8 Step: 361 Loss: 0.03245807000509274\n",
      "Epoch: 8 Step: 371 Loss: 0.006106320531429331\n",
      "Epoch: 8 Step: 381 Loss: 0.0019603273220202833\n",
      "Epoch: 8 Step: 391 Loss: 0.02169355114908926\n",
      "Epoch: 8 Step: 401 Loss: 0.0048402671993951155\n",
      "Epoch: 8 Step: 411 Loss: 0.028783344533340867\n",
      "Epoch: 8 Step: 421 Loss: 0.007098223537526169\n",
      "Epoch: 8 Step: 431 Loss: 0.008839964340758476\n",
      "Epoch: 8 Step: 441 Loss: 0.05538251152069585\n",
      "Epoch: 8 Step: 451 Loss: 0.019177342343442857\n",
      "Epoch: 8 Step: 461 Loss: 0.0023915446827626344\n",
      "Epoch: 8 Step: 471 Loss: 0.041636947449670704\n",
      "Epoch: 8 Step: 481 Loss: 0.00513673454293891\n",
      "Epoch: 8 Step: 491 Loss: 0.009050713022961208\n",
      "Epoch: 8 Step: 501 Loss: 0.06345417850353204\n",
      "Epoch: 8 Step: 511 Loss: 0.015002894682909445\n",
      "Epoch: 8 Step: 521 Loss: 0.004624933654298468\n",
      "Epoch: 8 Step: 531 Loss: 0.0020725243276528975\n",
      "Epoch: 8 Step: 541 Loss: 0.03323911516426841\n",
      "Epoch: 8 Step: 551 Loss: 0.021550558058568436\n",
      "Epoch: 8 Step: 561 Loss: 0.061570140587526204\n",
      "Epoch: 8 Step: 571 Loss: 0.011298099049052688\n",
      "Epoch: 8 Step: 581 Loss: 0.0023652045052458023\n",
      "Epoch: 8 Step: 591 Loss: 0.001990400392126339\n",
      "Epoch: 8 Step: 601 Loss: 0.00695533320102708\n",
      "Epoch: 8 Step: 611 Loss: 0.002390062313398223\n",
      "Epoch: 8 Step: 621 Loss: 0.02046232509741833\n",
      "Epoch: 8 Step: 631 Loss: 0.06069620179480362\n",
      "Epoch: 8 Step: 641 Loss: 0.01646228953068396\n",
      "Epoch: 8 Step: 651 Loss: 0.006717424822314187\n",
      "Epoch: 8 Step: 661 Loss: 0.00728628044683472\n",
      "Epoch: 8 Step: 671 Loss: 0.010998061429991646\n",
      "Epoch: 8 Step: 681 Loss: 0.016321858849814956\n",
      "Epoch: 8 Step: 691 Loss: 0.010818853643752043\n",
      "Epoch: 8 Step: 701 Loss: 0.0712663395591401\n",
      "Epoch: 8 Step: 711 Loss: 0.019039342461185542\n",
      "Epoch: 8 Step: 721 Loss: 0.09633560644046688\n",
      "Epoch: 8 Step: 731 Loss: 0.0894759489964208\n",
      "Epoch: 8 Step: 741 Loss: 0.0552332549648259\n",
      "Epoch: 8 Step: 751 Loss: 0.016690254601823933\n",
      "Epoch: 8 Step: 761 Loss: 0.012480135297921378\n",
      "Epoch: 8 Step: 771 Loss: 0.0009898447531948447\n",
      "Epoch: 8 Step: 781 Loss: 0.004836157642023138\n",
      "Epoch: 8 Step: 791 Loss: 0.012902247054781216\n",
      "Epoch: 8 Step: 801 Loss: 0.06417455768108421\n",
      "Epoch: 8 Step: 811 Loss: 0.004243501929745212\n",
      "Epoch: 8 Step: 821 Loss: 0.012773427672539476\n",
      "Epoch: 8 Step: 831 Loss: 0.06920032235414646\n",
      "Epoch: 8 Step: 841 Loss: 0.021132374168599432\n",
      "Epoch: 8 Step: 851 Loss: 0.013607702505259674\n",
      "Epoch: 8 Step: 861 Loss: 0.0026713416975659345\n",
      "Epoch: 8 Step: 871 Loss: 0.022953894023407067\n",
      "Epoch: 8 Step: 881 Loss: 0.03582590273391755\n",
      "Epoch: 8 Step: 891 Loss: 0.0016815538735846553\n",
      "Epoch: 8 Step: 901 Loss: 0.03355131441512429\n",
      "Epoch: 8 Step: 911 Loss: 0.05633925952114363\n",
      "Epoch: 8 Step: 921 Loss: 0.04294352809630359\n",
      "Epoch: 8 Step: 931 Loss: 0.0011854615595348341\n",
      "Epoch: 9 Step: 1 Loss: 0.0027979914012254614\n",
      "Epoch: 9 Step: 11 Loss: 0.022059347095528793\n",
      "Epoch: 9 Step: 21 Loss: 0.017431656023532624\n",
      "Epoch: 9 Step: 31 Loss: 0.009326503048722477\n",
      "Epoch: 9 Step: 41 Loss: 0.0018943381304631708\n",
      "Epoch: 9 Step: 51 Loss: 0.15208009957024582\n",
      "Epoch: 9 Step: 61 Loss: 0.018584056423687503\n",
      "Epoch: 9 Step: 71 Loss: 0.0029541305777336714\n",
      "Epoch: 9 Step: 81 Loss: 0.06230356064779772\n",
      "Epoch: 9 Step: 91 Loss: 0.07072141012922246\n",
      "Epoch: 9 Step: 101 Loss: 0.00341056847076005\n",
      "Epoch: 9 Step: 111 Loss: 0.009601923763446117\n",
      "Epoch: 9 Step: 121 Loss: 0.0024265956593960904\n",
      "Epoch: 9 Step: 131 Loss: 0.035415216943482083\n",
      "Epoch: 9 Step: 141 Loss: 0.002405039391921821\n",
      "Epoch: 9 Step: 151 Loss: 0.0057876706326469565\n",
      "Epoch: 9 Step: 161 Loss: 0.19120929668307152\n",
      "Epoch: 9 Step: 171 Loss: 0.019844640033596525\n",
      "Epoch: 9 Step: 181 Loss: 0.02068164932359907\n",
      "Epoch: 9 Step: 191 Loss: 0.004024815382852375\n",
      "Epoch: 9 Step: 201 Loss: 0.002625005028689365\n",
      "Epoch: 9 Step: 211 Loss: 0.038321040678969076\n",
      "Epoch: 9 Step: 221 Loss: 0.008670624506608094\n",
      "Epoch: 9 Step: 231 Loss: 0.045165508055909895\n",
      "Epoch: 9 Step: 241 Loss: 0.014591215452528656\n",
      "Epoch: 9 Step: 251 Loss: 0.1019496495706399\n",
      "Epoch: 9 Step: 261 Loss: 0.07343613585146286\n",
      "Epoch: 9 Step: 271 Loss: 0.00411593050038806\n",
      "Epoch: 9 Step: 281 Loss: 0.06736280438599883\n",
      "Epoch: 9 Step: 291 Loss: 0.003123568916827865\n",
      "Epoch: 9 Step: 301 Loss: 0.007669715591903118\n",
      "Epoch: 9 Step: 311 Loss: 0.01046174770151458\n",
      "Epoch: 9 Step: 321 Loss: 0.002678376356524545\n",
      "Epoch: 9 Step: 331 Loss: 0.007674103962228818\n",
      "Epoch: 9 Step: 341 Loss: 0.019144393862075504\n",
      "Epoch: 9 Step: 351 Loss: 0.007827729913710656\n",
      "Epoch: 9 Step: 361 Loss: 0.026708574842236446\n",
      "Epoch: 9 Step: 371 Loss: 0.008811355314231965\n",
      "Epoch: 9 Step: 381 Loss: 0.0026940493594582345\n",
      "Epoch: 9 Step: 391 Loss: 0.0015398372220815743\n",
      "Epoch: 9 Step: 401 Loss: 0.009725881456792974\n",
      "Epoch: 9 Step: 411 Loss: 0.06257971259277634\n",
      "Epoch: 9 Step: 421 Loss: 0.00185472259707455\n",
      "Epoch: 9 Step: 431 Loss: 0.0015494166877868983\n",
      "Epoch: 9 Step: 441 Loss: 0.0667372484100211\n",
      "Epoch: 9 Step: 451 Loss: 0.0535938791547108\n",
      "Epoch: 9 Step: 461 Loss: 0.0095463241313908\n",
      "Epoch: 9 Step: 471 Loss: 0.02946171527179148\n",
      "Epoch: 9 Step: 481 Loss: 0.0022113604944896718\n",
      "Epoch: 9 Step: 491 Loss: 0.012934159831740897\n",
      "Epoch: 9 Step: 501 Loss: 0.004805433493718102\n",
      "Epoch: 9 Step: 511 Loss: 0.010383525971197152\n",
      "Epoch: 9 Step: 521 Loss: 0.0019211215365480714\n",
      "Epoch: 9 Step: 531 Loss: 0.0009937417392448934\n",
      "Epoch: 9 Step: 541 Loss: 0.019599754319131087\n",
      "Epoch: 9 Step: 551 Loss: 0.05424173955211669\n",
      "Epoch: 9 Step: 561 Loss: 0.019192575766612464\n",
      "Epoch: 9 Step: 571 Loss: 0.004304485712859579\n",
      "Epoch: 9 Step: 581 Loss: 0.021019230150332524\n",
      "Epoch: 9 Step: 591 Loss: 0.00783710863476713\n",
      "Epoch: 9 Step: 601 Loss: 0.0139296618385596\n",
      "Epoch: 9 Step: 611 Loss: 0.0026661248559125914\n",
      "Epoch: 9 Step: 621 Loss: 0.017123469336171402\n",
      "Epoch: 9 Step: 631 Loss: 0.07424087761979754\n",
      "Epoch: 9 Step: 641 Loss: 0.0821928905527716\n",
      "Epoch: 9 Step: 651 Loss: 0.015908671869639186\n",
      "Epoch: 9 Step: 661 Loss: 0.003216339236966694\n",
      "Epoch: 9 Step: 671 Loss: 0.0027561995522252967\n",
      "Epoch: 9 Step: 681 Loss: 0.00814200058022875\n",
      "Epoch: 9 Step: 691 Loss: 0.026690145469957523\n",
      "Epoch: 9 Step: 701 Loss: 0.013619389171191343\n",
      "Epoch: 9 Step: 711 Loss: 0.005962870102756572\n",
      "Epoch: 9 Step: 721 Loss: 0.17445260071500285\n",
      "Epoch: 9 Step: 731 Loss: 0.06759061442996545\n",
      "Epoch: 9 Step: 741 Loss: 0.01926419332045167\n",
      "Epoch: 9 Step: 751 Loss: 0.0011982829721401624\n",
      "Epoch: 9 Step: 761 Loss: 0.0030150366150575704\n",
      "Epoch: 9 Step: 771 Loss: 0.006313020557962225\n",
      "Epoch: 9 Step: 781 Loss: 0.03785307395863836\n",
      "Epoch: 9 Step: 791 Loss: 0.05970582663976115\n",
      "Epoch: 9 Step: 801 Loss: 0.009008466006944325\n",
      "Epoch: 9 Step: 811 Loss: 0.003995710693636311\n",
      "Epoch: 9 Step: 821 Loss: 0.004405017678405453\n",
      "Epoch: 9 Step: 831 Loss: 0.05287847601240568\n",
      "Epoch: 9 Step: 841 Loss: 0.08802197896481859\n",
      "Epoch: 9 Step: 851 Loss: 0.020363700388506625\n",
      "Epoch: 9 Step: 861 Loss: 0.0020269770775227904\n",
      "Epoch: 9 Step: 871 Loss: 0.0032978618781441277\n",
      "Epoch: 9 Step: 881 Loss: 0.0024918095235514854\n",
      "Epoch: 9 Step: 891 Loss: 0.0008956847952516104\n",
      "Epoch: 9 Step: 901 Loss: 0.005168972012155385\n",
      "Epoch: 9 Step: 911 Loss: 0.0006950470173377403\n",
      "Epoch: 9 Step: 921 Loss: 0.015503876653728006\n",
      "Epoch: 9 Step: 931 Loss: 0.0005367480142016946\n",
      "Epoch: 10 Step: 1 Loss: 0.014797606615494396\n",
      "Epoch: 10 Step: 11 Loss: 0.006480539319390337\n",
      "Epoch: 10 Step: 21 Loss: 0.005231447453352734\n",
      "Epoch: 10 Step: 31 Loss: 0.003330516357661872\n",
      "Epoch: 10 Step: 41 Loss: 0.007692697056413878\n",
      "Epoch: 10 Step: 51 Loss: 0.00458437452825199\n",
      "Epoch: 10 Step: 61 Loss: 0.00422675585502002\n",
      "Epoch: 10 Step: 71 Loss: 0.0014650353779533877\n",
      "Epoch: 10 Step: 81 Loss: 0.0036743879196910537\n",
      "Epoch: 10 Step: 91 Loss: 0.029206812647834573\n",
      "Epoch: 10 Step: 101 Loss: 0.0062623663986351675\n",
      "Epoch: 10 Step: 111 Loss: 0.05335226893217873\n",
      "Epoch: 10 Step: 121 Loss: 0.007269450051470466\n",
      "Epoch: 10 Step: 131 Loss: 0.0012836196924556603\n",
      "Epoch: 10 Step: 141 Loss: 0.00506383744212297\n",
      "Epoch: 10 Step: 151 Loss: 0.0024884031761529413\n",
      "Epoch: 10 Step: 161 Loss: 0.08733386828503992\n",
      "Epoch: 10 Step: 171 Loss: 0.0025216556479859317\n",
      "Epoch: 10 Step: 181 Loss: 0.004460667827989378\n",
      "Epoch: 10 Step: 191 Loss: 0.004525720721807312\n",
      "Epoch: 10 Step: 201 Loss: 0.009143401130150065\n",
      "Epoch: 10 Step: 211 Loss: 0.001419315644732461\n",
      "Epoch: 10 Step: 221 Loss: 0.006172377991246684\n",
      "Epoch: 10 Step: 231 Loss: 0.011982007943235057\n",
      "Epoch: 10 Step: 241 Loss: 0.003766644928383841\n",
      "Epoch: 10 Step: 251 Loss: 0.055515780876631185\n",
      "Epoch: 10 Step: 261 Loss: 0.17214057003834005\n",
      "Epoch: 10 Step: 271 Loss: 0.037431297610149634\n",
      "Epoch: 10 Step: 281 Loss: 0.007178825822838972\n",
      "Epoch: 10 Step: 291 Loss: 0.0019641058630079982\n",
      "Epoch: 10 Step: 301 Loss: 0.024273966959505906\n",
      "Epoch: 10 Step: 311 Loss: 0.0059971091734459065\n",
      "Epoch: 10 Step: 321 Loss: 0.0022533611229683856\n",
      "Epoch: 10 Step: 331 Loss: 0.003917832315773455\n",
      "Epoch: 10 Step: 341 Loss: 0.0010241239354193369\n",
      "Epoch: 10 Step: 351 Loss: 0.036718721401798333\n",
      "Epoch: 10 Step: 361 Loss: 0.053581940419111435\n",
      "Epoch: 10 Step: 371 Loss: 0.028793066052940235\n",
      "Epoch: 10 Step: 381 Loss: 0.0028792800389522946\n",
      "Epoch: 10 Step: 391 Loss: 0.005912232896866867\n",
      "Epoch: 10 Step: 401 Loss: 0.006203729900760289\n",
      "Epoch: 10 Step: 411 Loss: 0.021530411478285116\n",
      "Epoch: 10 Step: 421 Loss: 0.010861268520011381\n",
      "Epoch: 10 Step: 431 Loss: 0.013960798724458\n",
      "Epoch: 10 Step: 441 Loss: 0.00608159716160182\n",
      "Epoch: 10 Step: 451 Loss: 0.01982372811435691\n",
      "Epoch: 10 Step: 461 Loss: 0.0072120763556632935\n",
      "Epoch: 10 Step: 471 Loss: 0.01906700074561735\n",
      "Epoch: 10 Step: 481 Loss: 0.008615974334753734\n",
      "Epoch: 10 Step: 491 Loss: 0.004652931316462237\n",
      "Epoch: 10 Step: 501 Loss: 0.005775431831499556\n",
      "Epoch: 10 Step: 511 Loss: 0.0279390107555867\n",
      "Epoch: 10 Step: 521 Loss: 0.06568846893470295\n",
      "Epoch: 10 Step: 531 Loss: 0.000659631587204117\n",
      "Epoch: 10 Step: 541 Loss: 0.008712415711164436\n",
      "Epoch: 10 Step: 551 Loss: 0.25155610830647\n",
      "Epoch: 10 Step: 561 Loss: 0.09139089848333276\n",
      "Epoch: 10 Step: 571 Loss: 0.0008120059414176755\n",
      "Epoch: 10 Step: 581 Loss: 0.005179077102252211\n",
      "Epoch: 10 Step: 591 Loss: 0.005146594502315202\n",
      "Epoch: 10 Step: 601 Loss: 0.0013106378792513596\n",
      "Epoch: 10 Step: 611 Loss: 0.09599008785417923\n",
      "Epoch: 10 Step: 621 Loss: 0.0013113299965312243\n",
      "Epoch: 10 Step: 631 Loss: 0.03761983412901235\n",
      "Epoch: 10 Step: 641 Loss: 0.028516122416169867\n",
      "Epoch: 10 Step: 651 Loss: 0.006454036960511106\n",
      "Epoch: 10 Step: 661 Loss: 0.007022576468588436\n",
      "Epoch: 10 Step: 671 Loss: 0.0016935207145347404\n",
      "Epoch: 10 Step: 681 Loss: 0.007429482260968694\n",
      "Epoch: 10 Step: 691 Loss: 0.0185189481453512\n",
      "Epoch: 10 Step: 701 Loss: 0.16693920877887553\n",
      "Epoch: 10 Step: 711 Loss: 0.00834665141696227\n",
      "Epoch: 10 Step: 721 Loss: 0.12636367672069887\n",
      "Epoch: 10 Step: 731 Loss: 0.03823529984292469\n",
      "Epoch: 10 Step: 741 Loss: 0.006799990859625639\n",
      "Epoch: 10 Step: 751 Loss: 0.003159495332707991\n",
      "Epoch: 10 Step: 761 Loss: 0.0016822871068688803\n",
      "Epoch: 10 Step: 771 Loss: 0.0004294498590672892\n",
      "Epoch: 10 Step: 781 Loss: 0.0011086397017881463\n",
      "Epoch: 10 Step: 791 Loss: 0.04281370315159138\n",
      "Epoch: 10 Step: 801 Loss: 0.03389806181276815\n",
      "Epoch: 10 Step: 811 Loss: 0.0006909056484140143\n",
      "Epoch: 10 Step: 821 Loss: 0.003127669251592422\n",
      "Epoch: 10 Step: 831 Loss: 0.014991060925278611\n",
      "Epoch: 10 Step: 841 Loss: 0.046167469027501705\n",
      "Epoch: 10 Step: 851 Loss: 0.0034015129161408908\n",
      "Epoch: 10 Step: 861 Loss: 0.020859476093726008\n",
      "Epoch: 10 Step: 871 Loss: 0.006462021435829658\n",
      "Epoch: 10 Step: 881 Loss: 0.01002001956673279\n",
      "Epoch: 10 Step: 891 Loss: 0.0007304755627564636\n",
      "Epoch: 10 Step: 901 Loss: 0.015896416293068066\n",
      "Epoch: 10 Step: 911 Loss: 0.0010540459127594865\n",
      "Epoch: 10 Step: 921 Loss: 0.004075336338814496\n",
      "Epoch: 10 Step: 931 Loss: 0.00046629594710039673\n",
      "Epoch: 11 Step: 1 Loss: 0.016649360976339577\n",
      "Epoch: 11 Step: 11 Loss: 0.005104040241617155\n",
      "Epoch: 11 Step: 21 Loss: 0.051945142599697694\n",
      "Epoch: 11 Step: 31 Loss: 0.005501120582969905\n",
      "Epoch: 11 Step: 41 Loss: 0.021998231449446116\n",
      "Epoch: 11 Step: 51 Loss: 0.0021106650204807983\n",
      "Epoch: 11 Step: 61 Loss: 0.0017198291793400723\n",
      "Epoch: 11 Step: 71 Loss: 0.020962231725176157\n",
      "Epoch: 11 Step: 81 Loss: 0.01243041097527377\n",
      "Epoch: 11 Step: 91 Loss: 0.07216367431522182\n",
      "Epoch: 11 Step: 101 Loss: 0.0016275219618641255\n",
      "Epoch: 11 Step: 111 Loss: 0.001007098373380779\n",
      "Epoch: 11 Step: 121 Loss: 0.0017105691814595925\n",
      "Epoch: 11 Step: 131 Loss: 0.044026706645533334\n",
      "Epoch: 11 Step: 141 Loss: 0.006216840498430819\n",
      "Epoch: 11 Step: 151 Loss: 0.055299781470326916\n",
      "Epoch: 11 Step: 161 Loss: 0.1278409088451543\n",
      "Epoch: 11 Step: 171 Loss: 0.06863285715583894\n",
      "Epoch: 11 Step: 181 Loss: 0.015232599116675627\n",
      "Epoch: 11 Step: 191 Loss: 0.0012182283148099052\n",
      "Epoch: 11 Step: 201 Loss: 0.00586005380439562\n",
      "Epoch: 11 Step: 211 Loss: 0.0004186464039545628\n",
      "Epoch: 11 Step: 221 Loss: 0.004888593998747538\n",
      "Epoch: 11 Step: 231 Loss: 0.013741141488201878\n",
      "Epoch: 11 Step: 241 Loss: 0.06100479496284357\n",
      "Epoch: 11 Step: 251 Loss: 0.020430458814090904\n",
      "Epoch: 11 Step: 261 Loss: 0.13327613749398554\n",
      "Epoch: 11 Step: 271 Loss: 0.002160333777777776\n",
      "Epoch: 11 Step: 281 Loss: 0.027311339213190323\n",
      "Epoch: 11 Step: 291 Loss: 0.00535312489431962\n",
      "Epoch: 11 Step: 301 Loss: 0.013664797201416279\n",
      "Epoch: 11 Step: 311 Loss: 0.005096227845991007\n",
      "Epoch: 11 Step: 321 Loss: 0.00121983847353975\n",
      "Epoch: 11 Step: 331 Loss: 0.0032077493832760556\n",
      "Epoch: 11 Step: 341 Loss: 0.003182126417692753\n",
      "Epoch: 11 Step: 351 Loss: 0.005450944099930473\n",
      "Epoch: 11 Step: 361 Loss: 0.07389222194662542\n",
      "Epoch: 11 Step: 371 Loss: 0.0022823927171880982\n",
      "Epoch: 11 Step: 381 Loss: 0.001940853942220133\n",
      "Epoch: 11 Step: 391 Loss: 0.0015440041757568699\n",
      "Epoch: 11 Step: 401 Loss: 0.013831698694270233\n",
      "Epoch: 11 Step: 411 Loss: 0.0007312185225052822\n",
      "Epoch: 11 Step: 421 Loss: 0.001425425005381932\n",
      "Epoch: 11 Step: 431 Loss: 0.003493989559002419\n",
      "Epoch: 11 Step: 441 Loss: 0.0017377839423355023\n",
      "Epoch: 11 Step: 451 Loss: 0.002660643470225616\n",
      "Epoch: 11 Step: 461 Loss: 0.0017306471741451615\n",
      "Epoch: 11 Step: 471 Loss: 0.0069024487415804865\n",
      "Epoch: 11 Step: 481 Loss: 0.0011397754821864535\n",
      "Epoch: 11 Step: 491 Loss: 0.033962865000630234\n",
      "Epoch: 11 Step: 501 Loss: 0.05445682627054763\n",
      "Epoch: 11 Step: 511 Loss: 0.0050009014727959485\n",
      "Epoch: 11 Step: 521 Loss: 0.0018339665339928647\n",
      "Epoch: 11 Step: 531 Loss: 0.0002498060925708692\n",
      "Epoch: 11 Step: 541 Loss: 0.02672938419250654\n",
      "Epoch: 11 Step: 551 Loss: 0.13362661791725636\n",
      "Epoch: 11 Step: 561 Loss: 0.013172081617515638\n",
      "Epoch: 11 Step: 571 Loss: 0.0019214379957808384\n",
      "Epoch: 11 Step: 581 Loss: 0.006648727996904226\n",
      "Epoch: 11 Step: 591 Loss: 0.003426449136830525\n",
      "Epoch: 11 Step: 601 Loss: 0.0038259087488866045\n",
      "Epoch: 11 Step: 611 Loss: 0.07642509659645222\n",
      "Epoch: 11 Step: 621 Loss: 0.034909054408500804\n",
      "Epoch: 11 Step: 631 Loss: 0.008579029107178953\n",
      "Epoch: 11 Step: 641 Loss: 0.03378950392889281\n",
      "Epoch: 11 Step: 651 Loss: 0.005601744316518774\n",
      "Epoch: 11 Step: 661 Loss: 0.0014655146934554261\n",
      "Epoch: 11 Step: 671 Loss: 0.001964836958192858\n",
      "Epoch: 11 Step: 681 Loss: 0.017710727637768306\n",
      "Epoch: 11 Step: 691 Loss: 0.02853864169490999\n",
      "Epoch: 11 Step: 701 Loss: 0.013778519178901355\n",
      "Epoch: 11 Step: 711 Loss: 0.0010895066531709796\n",
      "Epoch: 11 Step: 721 Loss: 0.0952482807889822\n",
      "Epoch: 11 Step: 731 Loss: 0.006283966007375208\n",
      "Epoch: 11 Step: 741 Loss: 0.0014926649801735308\n",
      "Epoch: 11 Step: 751 Loss: 0.002584982289819575\n",
      "Epoch: 11 Step: 761 Loss: 0.004554806286365051\n",
      "Epoch: 11 Step: 771 Loss: 0.0006410480350626204\n",
      "Epoch: 11 Step: 781 Loss: 0.00543746837321714\n",
      "Epoch: 11 Step: 791 Loss: 0.0025064305882972217\n",
      "Epoch: 11 Step: 801 Loss: 0.06941264185084238\n",
      "Epoch: 11 Step: 811 Loss: 0.0014799415095170057\n",
      "Epoch: 11 Step: 821 Loss: 0.015608483376186456\n",
      "Epoch: 11 Step: 831 Loss: 0.010497871080245769\n",
      "Epoch: 11 Step: 841 Loss: 0.001383387052195977\n",
      "Epoch: 11 Step: 851 Loss: 0.010814040941504508\n",
      "Epoch: 11 Step: 861 Loss: 0.002529772841583462\n",
      "Epoch: 11 Step: 871 Loss: 0.037565816492094964\n",
      "Epoch: 11 Step: 881 Loss: 0.0010079063409233644\n",
      "Epoch: 11 Step: 891 Loss: 0.000649607781081497\n",
      "Epoch: 11 Step: 901 Loss: 0.06917352785900859\n",
      "Epoch: 11 Step: 911 Loss: 0.010352532072604058\n",
      "Epoch: 11 Step: 921 Loss: 0.000420554600105091\n",
      "Epoch: 11 Step: 931 Loss: 0.002031704728032365\n",
      "Epoch: 12 Step: 1 Loss: 0.003088080993855665\n",
      "Epoch: 12 Step: 11 Loss: 0.008031743945088175\n",
      "Epoch: 12 Step: 21 Loss: 0.004685348163501865\n",
      "Epoch: 12 Step: 31 Loss: 0.0023380464163005148\n",
      "Epoch: 12 Step: 41 Loss: 0.007122995204321018\n",
      "Epoch: 12 Step: 51 Loss: 0.0644708760496268\n",
      "Epoch: 12 Step: 61 Loss: 0.0012463592431338937\n",
      "Epoch: 12 Step: 71 Loss: 0.0074757111296773725\n",
      "Epoch: 12 Step: 81 Loss: 0.019354910267769684\n",
      "Epoch: 12 Step: 91 Loss: 0.07896818744902792\n",
      "Epoch: 12 Step: 101 Loss: 0.002963167150741494\n",
      "Epoch: 12 Step: 111 Loss: 0.0021034468882932702\n",
      "Epoch: 12 Step: 121 Loss: 0.0034711423583817704\n",
      "Epoch: 12 Step: 131 Loss: 0.009730311049468147\n",
      "Epoch: 12 Step: 141 Loss: 0.006992785017870292\n",
      "Epoch: 12 Step: 151 Loss: 0.015584172511723338\n",
      "Epoch: 12 Step: 161 Loss: 0.08584589378045068\n",
      "Epoch: 12 Step: 171 Loss: 0.010342363595850756\n",
      "Epoch: 12 Step: 181 Loss: 0.048191673016200406\n",
      "Epoch: 12 Step: 191 Loss: 0.08184221117053445\n",
      "Epoch: 12 Step: 201 Loss: 0.011850287834356297\n",
      "Epoch: 12 Step: 211 Loss: 0.0007715929562541227\n",
      "Epoch: 12 Step: 221 Loss: 0.0023934090233588357\n",
      "Epoch: 12 Step: 231 Loss: 0.014865281320424185\n",
      "Epoch: 12 Step: 241 Loss: 0.0008170819897734616\n",
      "Epoch: 12 Step: 251 Loss: 0.04100628445983914\n",
      "Epoch: 12 Step: 261 Loss: 0.12823979048673464\n",
      "Epoch: 12 Step: 271 Loss: 0.00213935455851073\n",
      "Epoch: 12 Step: 281 Loss: 0.01207193005829499\n",
      "Epoch: 12 Step: 291 Loss: 0.0024874660126283704\n",
      "Epoch: 12 Step: 301 Loss: 0.0018163372306380333\n",
      "Epoch: 12 Step: 311 Loss: 0.0012558444152832907\n",
      "Epoch: 12 Step: 321 Loss: 0.004854734847999348\n",
      "Epoch: 12 Step: 331 Loss: 0.0033286258121094257\n",
      "Epoch: 12 Step: 341 Loss: 0.002856320362129133\n",
      "Epoch: 12 Step: 351 Loss: 0.0016119952086494425\n",
      "Epoch: 12 Step: 361 Loss: 0.009500625606711088\n",
      "Epoch: 12 Step: 371 Loss: 0.05435835351720252\n",
      "Epoch: 12 Step: 381 Loss: 0.0003840950729593029\n",
      "Epoch: 12 Step: 391 Loss: 0.0007573160380205767\n",
      "Epoch: 12 Step: 401 Loss: 0.015738884134670818\n",
      "Epoch: 12 Step: 411 Loss: 0.016140949827120034\n",
      "Epoch: 12 Step: 421 Loss: 0.0075244531236522225\n",
      "Epoch: 12 Step: 431 Loss: 0.0021335003002499165\n",
      "Epoch: 12 Step: 441 Loss: 0.003066677676359768\n",
      "Epoch: 12 Step: 451 Loss: 0.018549987422071493\n",
      "Epoch: 12 Step: 461 Loss: 0.003365059150892845\n",
      "Epoch: 12 Step: 471 Loss: 0.0008387052956271633\n",
      "Epoch: 12 Step: 481 Loss: 0.0033178131245691837\n",
      "Epoch: 12 Step: 491 Loss: 0.002186312686925925\n",
      "Epoch: 12 Step: 501 Loss: 0.004773031874756197\n",
      "Epoch: 12 Step: 511 Loss: 0.010751300714407006\n",
      "Epoch: 12 Step: 521 Loss: 0.003440311709088333\n",
      "Epoch: 12 Step: 531 Loss: 0.0006156648436757561\n",
      "Epoch: 12 Step: 541 Loss: 0.0026875959512632375\n",
      "Epoch: 12 Step: 551 Loss: 0.013512199220033263\n",
      "Epoch: 12 Step: 561 Loss: 0.018631362589729323\n",
      "Epoch: 12 Step: 571 Loss: 0.0010296473391840982\n",
      "Epoch: 12 Step: 581 Loss: 0.0015192533327749625\n",
      "Epoch: 12 Step: 591 Loss: 0.003021963231241571\n",
      "Epoch: 12 Step: 601 Loss: 0.005717391480468008\n",
      "Epoch: 12 Step: 611 Loss: 0.0009796680607392\n",
      "Epoch: 12 Step: 621 Loss: 0.0008919769628943677\n",
      "Epoch: 12 Step: 631 Loss: 0.09604846453081069\n",
      "Epoch: 12 Step: 641 Loss: 0.07470141971152791\n",
      "Epoch: 12 Step: 651 Loss: 0.057995261084242834\n",
      "Epoch: 12 Step: 661 Loss: 0.005018311241042029\n",
      "Epoch: 12 Step: 671 Loss: 0.0013770218852874477\n",
      "Epoch: 12 Step: 681 Loss: 0.00217111065942917\n",
      "Epoch: 12 Step: 691 Loss: 0.0029628815765379937\n",
      "Epoch: 12 Step: 701 Loss: 0.006901810145588234\n",
      "Epoch: 12 Step: 711 Loss: 0.0013348227224054866\n",
      "Epoch: 12 Step: 721 Loss: 0.07863275343559838\n",
      "Epoch: 12 Step: 731 Loss: 0.012964444943193928\n",
      "Epoch: 12 Step: 741 Loss: 0.051687672938621865\n",
      "Epoch: 12 Step: 751 Loss: 0.0056929098214422175\n",
      "Epoch: 12 Step: 761 Loss: 0.003088882759800946\n",
      "Epoch: 12 Step: 771 Loss: 0.00028896700032604247\n",
      "Epoch: 12 Step: 781 Loss: 0.0028815055400525074\n",
      "Epoch: 12 Step: 791 Loss: 0.003571120709397962\n",
      "Epoch: 12 Step: 801 Loss: 0.012696395755197274\n",
      "Epoch: 12 Step: 811 Loss: 0.00021206682064177446\n",
      "Epoch: 12 Step: 821 Loss: 0.03690164686290495\n",
      "Epoch: 12 Step: 831 Loss: 0.025254848516432275\n",
      "Epoch: 12 Step: 841 Loss: 0.0010498177410702407\n",
      "Epoch: 12 Step: 851 Loss: 0.0008242597670190994\n",
      "Epoch: 12 Step: 861 Loss: 0.004182791229641942\n",
      "Epoch: 12 Step: 871 Loss: 0.0027120178250073417\n",
      "Epoch: 12 Step: 881 Loss: 0.007221763527584348\n",
      "Epoch: 12 Step: 891 Loss: 0.0006772503225222902\n",
      "Epoch: 12 Step: 901 Loss: 0.007129577417722329\n",
      "Epoch: 12 Step: 911 Loss: 0.07951763455299764\n",
      "Epoch: 12 Step: 921 Loss: 0.006128116720875269\n",
      "Epoch: 12 Step: 931 Loss: 0.0007360763600605294\n",
      "Epoch: 13 Step: 1 Loss: 0.0010624579013606777\n",
      "Epoch: 13 Step: 11 Loss: 0.002719335718765832\n",
      "Epoch: 13 Step: 21 Loss: 0.012197057041999223\n",
      "Epoch: 13 Step: 31 Loss: 0.0036675503105187803\n",
      "Epoch: 13 Step: 41 Loss: 0.22654907134373248\n",
      "Epoch: 13 Step: 51 Loss: 0.015499409093587962\n",
      "Epoch: 13 Step: 61 Loss: 0.0020328960673567298\n",
      "Epoch: 13 Step: 71 Loss: 0.00172826594398504\n",
      "Epoch: 13 Step: 81 Loss: 0.014150320382114431\n",
      "Epoch: 13 Step: 91 Loss: 0.1377770561012539\n",
      "Epoch: 13 Step: 101 Loss: 0.005961283126680165\n",
      "Epoch: 13 Step: 111 Loss: 0.07139330802063167\n",
      "Epoch: 13 Step: 121 Loss: 0.0015922177035955476\n",
      "Epoch: 13 Step: 131 Loss: 0.00042689896835446887\n",
      "Epoch: 13 Step: 141 Loss: 0.05543614893301251\n",
      "Epoch: 13 Step: 151 Loss: 0.02422556965808395\n",
      "Epoch: 13 Step: 161 Loss: 0.04735192610999014\n",
      "Epoch: 13 Step: 171 Loss: 0.008977868679005335\n",
      "Epoch: 13 Step: 181 Loss: 0.02575120556357765\n",
      "Epoch: 13 Step: 191 Loss: 0.0012359112094398903\n",
      "Epoch: 13 Step: 201 Loss: 0.007308302073223439\n",
      "Epoch: 13 Step: 211 Loss: 0.005424766429435885\n",
      "Epoch: 13 Step: 221 Loss: 0.0009848969639328926\n",
      "Epoch: 13 Step: 231 Loss: 0.008782890247468558\n",
      "Epoch: 13 Step: 241 Loss: 0.006650040076287128\n",
      "Epoch: 13 Step: 251 Loss: 0.016620874549799006\n",
      "Epoch: 13 Step: 261 Loss: 0.08133018391644432\n",
      "Epoch: 13 Step: 271 Loss: 0.024947745802154253\n",
      "Epoch: 13 Step: 281 Loss: 0.08006514701854178\n",
      "Epoch: 13 Step: 291 Loss: 0.0011118957079489476\n",
      "Epoch: 13 Step: 301 Loss: 0.011277159153209752\n",
      "Epoch: 13 Step: 311 Loss: 0.018618499769848397\n",
      "Epoch: 13 Step: 321 Loss: 0.0023150699011955517\n",
      "Epoch: 13 Step: 331 Loss: 0.023855673034180843\n",
      "Epoch: 13 Step: 341 Loss: 0.0020951494337307945\n",
      "Epoch: 13 Step: 351 Loss: 0.013910495383756874\n",
      "Epoch: 13 Step: 361 Loss: 0.031359251858110775\n",
      "Epoch: 13 Step: 371 Loss: 0.005810343568149335\n",
      "Epoch: 13 Step: 381 Loss: 0.0020668470040886536\n",
      "Epoch: 13 Step: 391 Loss: 0.0007680091991683826\n",
      "Epoch: 13 Step: 401 Loss: 0.0016883939964142094\n",
      "Epoch: 13 Step: 411 Loss: 0.0022614931709846386\n",
      "Epoch: 13 Step: 421 Loss: 0.02165301868473321\n",
      "Epoch: 13 Step: 431 Loss: 0.023954630076483012\n",
      "Epoch: 13 Step: 441 Loss: 0.0016799852873737957\n",
      "Epoch: 13 Step: 451 Loss: 0.0034253841974606716\n",
      "Epoch: 13 Step: 461 Loss: 0.0033453800110886814\n",
      "Epoch: 13 Step: 471 Loss: 0.002486471466082535\n",
      "Epoch: 13 Step: 481 Loss: 0.0010116760083312797\n",
      "Epoch: 13 Step: 491 Loss: 0.0033871634348934918\n",
      "Epoch: 13 Step: 501 Loss: 0.000568246300383337\n",
      "Epoch: 13 Step: 511 Loss: 0.0032257284415166663\n",
      "Epoch: 13 Step: 521 Loss: 0.007901941232271477\n",
      "Epoch: 13 Step: 531 Loss: 0.0003294756036780712\n",
      "Epoch: 13 Step: 541 Loss: 0.0014858711776944806\n",
      "Epoch: 13 Step: 551 Loss: 0.010991544758464098\n",
      "Epoch: 13 Step: 561 Loss: 0.002775010753131617\n",
      "Epoch: 13 Step: 571 Loss: 0.0023926690127254067\n",
      "Epoch: 13 Step: 581 Loss: 0.004912477441293821\n",
      "Epoch: 13 Step: 591 Loss: 0.0012055202649738706\n",
      "Epoch: 13 Step: 601 Loss: 0.04174558557348538\n",
      "Epoch: 13 Step: 611 Loss: 0.0005575975297365106\n",
      "Epoch: 13 Step: 621 Loss: 0.003381625304351572\n",
      "Epoch: 13 Step: 631 Loss: 0.00809339206710033\n",
      "Epoch: 13 Step: 641 Loss: 0.03643059787616178\n",
      "Epoch: 13 Step: 651 Loss: 0.004047497792059647\n",
      "Epoch: 13 Step: 661 Loss: 0.004175525642585627\n",
      "Epoch: 13 Step: 671 Loss: 0.00969017306487563\n",
      "Epoch: 13 Step: 681 Loss: 0.024099686089813922\n",
      "Epoch: 13 Step: 691 Loss: 0.0021880263912077893\n",
      "Epoch: 13 Step: 701 Loss: 0.006399105144613832\n",
      "Epoch: 13 Step: 711 Loss: 0.0015743834895002092\n",
      "Epoch: 13 Step: 721 Loss: 0.03287068294068132\n",
      "Epoch: 13 Step: 731 Loss: 0.02295496609158308\n",
      "Epoch: 13 Step: 741 Loss: 0.0024631430167827663\n",
      "Epoch: 13 Step: 751 Loss: 0.000549120553126829\n",
      "Epoch: 13 Step: 761 Loss: 0.004595032593487166\n",
      "Epoch: 13 Step: 771 Loss: 0.0006131919370347765\n",
      "Epoch: 13 Step: 781 Loss: 0.001920512616448565\n",
      "Epoch: 13 Step: 791 Loss: 0.004355516727111049\n",
      "Epoch: 13 Step: 801 Loss: 0.004762221877499342\n",
      "Epoch: 13 Step: 811 Loss: 0.0007414094862530185\n",
      "Epoch: 13 Step: 821 Loss: 0.010053937223876793\n",
      "Epoch: 13 Step: 831 Loss: 0.003743961427673001\n",
      "Epoch: 13 Step: 841 Loss: 0.0042998665090593444\n",
      "Epoch: 13 Step: 851 Loss: 0.0010487106079706886\n",
      "Epoch: 13 Step: 861 Loss: 0.0017717259271638475\n",
      "Epoch: 13 Step: 871 Loss: 0.002839539256860949\n",
      "Epoch: 13 Step: 881 Loss: 0.000900122990314579\n",
      "Epoch: 13 Step: 891 Loss: 0.0005754773426869912\n",
      "Epoch: 13 Step: 901 Loss: 0.004543451018549239\n",
      "Epoch: 13 Step: 911 Loss: 0.000520605705188354\n",
      "Epoch: 13 Step: 921 Loss: 0.008072228930475864\n",
      "Epoch: 13 Step: 931 Loss: 0.00037217736737658685\n",
      "Epoch: 14 Step: 1 Loss: 0.0016999650245958394\n",
      "Epoch: 14 Step: 11 Loss: 0.012438722316273782\n",
      "Epoch: 14 Step: 21 Loss: 0.003026914377925815\n",
      "Epoch: 14 Step: 31 Loss: 0.002426705152125547\n",
      "Epoch: 14 Step: 41 Loss: 0.001349899802845342\n",
      "Epoch: 14 Step: 51 Loss: 0.001539987168449734\n",
      "Epoch: 14 Step: 61 Loss: 0.0006214362288438786\n",
      "Epoch: 14 Step: 71 Loss: 0.0009775889679306034\n",
      "Epoch: 14 Step: 81 Loss: 0.002660328088505796\n",
      "Epoch: 14 Step: 91 Loss: 0.06836894232787077\n",
      "Epoch: 14 Step: 101 Loss: 0.000732438323280281\n",
      "Epoch: 14 Step: 111 Loss: 0.0013583994106495152\n",
      "Epoch: 14 Step: 121 Loss: 0.02620277954155405\n",
      "Epoch: 14 Step: 131 Loss: 0.0034038067232697033\n",
      "Epoch: 14 Step: 141 Loss: 0.0013154084984729262\n",
      "Epoch: 14 Step: 151 Loss: 0.005801562808405671\n",
      "Epoch: 14 Step: 161 Loss: 0.005245803437060395\n",
      "Epoch: 14 Step: 171 Loss: 0.0011866138418363706\n",
      "Epoch: 14 Step: 181 Loss: 0.07189264635812245\n",
      "Epoch: 14 Step: 191 Loss: 0.000441688741237762\n",
      "Epoch: 14 Step: 201 Loss: 0.008180705764374647\n",
      "Epoch: 14 Step: 211 Loss: 0.0002959113893097559\n",
      "Epoch: 14 Step: 221 Loss: 0.009734591390770951\n",
      "Epoch: 14 Step: 231 Loss: 0.02352430054101408\n",
      "Epoch: 14 Step: 241 Loss: 0.0012358647895646569\n",
      "Epoch: 14 Step: 251 Loss: 0.008201030327109315\n",
      "Epoch: 14 Step: 261 Loss: 0.10351022242140423\n",
      "Epoch: 14 Step: 271 Loss: 0.011454748691261804\n",
      "Epoch: 14 Step: 281 Loss: 0.03241219282492676\n",
      "Epoch: 14 Step: 291 Loss: 0.005641545020594458\n",
      "Epoch: 14 Step: 301 Loss: 0.0009791573505354178\n",
      "Epoch: 14 Step: 311 Loss: 0.0057839071331948835\n",
      "Epoch: 14 Step: 321 Loss: 0.006294580290683853\n",
      "Epoch: 14 Step: 331 Loss: 0.0017210750737214424\n",
      "Epoch: 14 Step: 341 Loss: 0.0006990131405928801\n",
      "Epoch: 14 Step: 351 Loss: 0.0709238723332361\n",
      "Epoch: 14 Step: 361 Loss: 0.0027474885096990956\n",
      "Epoch: 14 Step: 371 Loss: 0.0033311891229178764\n",
      "Epoch: 14 Step: 381 Loss: 0.003344116097573054\n",
      "Epoch: 14 Step: 391 Loss: 0.00038090945154292335\n",
      "Epoch: 14 Step: 401 Loss: 0.0017648715004779422\n",
      "Epoch: 14 Step: 411 Loss: 0.000271245702348443\n",
      "Epoch: 14 Step: 421 Loss: 0.0006430854194768726\n",
      "Epoch: 14 Step: 431 Loss: 0.0007130134858012131\n",
      "Epoch: 14 Step: 441 Loss: 0.005009885066876437\n",
      "Epoch: 14 Step: 451 Loss: 0.002102018824971475\n",
      "Epoch: 14 Step: 461 Loss: 0.003128979985324437\n",
      "Epoch: 14 Step: 471 Loss: 0.0018179254011488032\n",
      "Epoch: 14 Step: 481 Loss: 0.000254631008442984\n",
      "Epoch: 14 Step: 491 Loss: 0.003780621466770345\n",
      "Epoch: 14 Step: 501 Loss: 0.013820747521590477\n",
      "Epoch: 14 Step: 511 Loss: 0.00763176120742093\n",
      "Epoch: 14 Step: 521 Loss: 0.0005991919849355275\n",
      "Epoch: 14 Step: 531 Loss: 0.00035417242010648403\n",
      "Epoch: 14 Step: 541 Loss: 0.0023817740943889074\n",
      "Epoch: 14 Step: 551 Loss: 0.05209759505807825\n",
      "Epoch: 14 Step: 561 Loss: 0.021947833850221428\n",
      "Epoch: 14 Step: 571 Loss: 0.002355247342034892\n",
      "Epoch: 14 Step: 581 Loss: 0.00041669030544586\n",
      "Epoch: 14 Step: 591 Loss: 0.0028468664575994553\n",
      "Epoch: 14 Step: 601 Loss: 0.0007655279843999552\n",
      "Epoch: 14 Step: 611 Loss: 0.0014287347984796924\n",
      "Epoch: 14 Step: 621 Loss: 0.00714898218533819\n",
      "Epoch: 14 Step: 631 Loss: 0.005709353372760956\n",
      "Epoch: 14 Step: 641 Loss: 0.004303546637753684\n",
      "Epoch: 14 Step: 651 Loss: 0.09263737069916429\n",
      "Epoch: 14 Step: 661 Loss: 0.0008567614186788404\n",
      "Epoch: 14 Step: 671 Loss: 0.0007222600231339445\n",
      "Epoch: 14 Step: 681 Loss: 0.0006844477939368814\n",
      "Epoch: 14 Step: 691 Loss: 0.003078410355737399\n",
      "Epoch: 14 Step: 701 Loss: 0.007100765659255099\n",
      "Epoch: 14 Step: 711 Loss: 0.0016297951493528542\n",
      "Epoch: 14 Step: 721 Loss: 0.05858123081922509\n",
      "Epoch: 14 Step: 731 Loss: 0.09226988190215785\n",
      "Epoch: 14 Step: 741 Loss: 0.005945548730411821\n",
      "Epoch: 14 Step: 751 Loss: 0.04109614036293142\n",
      "Epoch: 14 Step: 761 Loss: 0.026402519722708524\n",
      "Epoch: 14 Step: 771 Loss: 0.00041247580795181703\n",
      "Epoch: 14 Step: 781 Loss: 0.00023067983901606498\n",
      "Epoch: 14 Step: 791 Loss: 0.011545296522372196\n",
      "Epoch: 14 Step: 801 Loss: 0.003470545933294391\n",
      "Epoch: 14 Step: 811 Loss: 0.00300631675562374\n",
      "Epoch: 14 Step: 821 Loss: 0.0012696491816162065\n",
      "Epoch: 14 Step: 831 Loss: 0.0794378333951105\n",
      "Epoch: 14 Step: 841 Loss: 0.006953623631603548\n",
      "Epoch: 14 Step: 851 Loss: 0.0015218760437783248\n",
      "Epoch: 14 Step: 861 Loss: 0.004759368771591018\n",
      "Epoch: 14 Step: 871 Loss: 0.006471188007123866\n",
      "Epoch: 14 Step: 881 Loss: 0.05457932566821768\n",
      "Epoch: 14 Step: 891 Loss: 0.002158211692126277\n",
      "Epoch: 14 Step: 901 Loss: 0.00717332131596879\n",
      "Epoch: 14 Step: 911 Loss: 0.000979937115313326\n",
      "Epoch: 14 Step: 921 Loss: 0.0005895827760798971\n",
      "Epoch: 14 Step: 931 Loss: 0.0007345400601626044\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score is 0.9859333333333333\n",
      "Score is 0.9699519230769231\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "model = ConvNet(datasets='mnist', opt='sgd')\n",
    "model.datas = [data, label]\n",
    "model.train(15)\n",
    "plt.plot(np.arange(len(model.history)), model.history)\n",
    "plt.show()\n",
    "np.savetxt('/home/oneran/Downloads/sgd_mnist_ConvNet_history.txt', model.history)\n",
    "model.save_model('/home/oneran/机器学习课设/cifar-10/Photon/sgd_mnist_ConvNet.pkl')\n",
    "score, pred = model.score(X_train, Y_train)\n",
    "score, pred = model.score(X_test, Y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 0 Step: 1 Loss: 2.3033163603370657\n",
      "Epoch: 0 Step: 11 Loss: 2.26627104794916\n",
      "Epoch: 0 Step: 21 Loss: 2.322913212612204\n",
      "Epoch: 0 Step: 31 Loss: 2.2949498052595843\n",
      "Epoch: 0 Step: 41 Loss: 2.1890450527230634\n",
      "Epoch: 0 Step: 51 Loss: 2.252209773329572\n",
      "Epoch: 0 Step: 61 Loss: 2.1419523588920484\n",
      "Epoch: 0 Step: 71 Loss: 2.1795005036833794\n",
      "Epoch: 0 Step: 81 Loss: 2.123324651209615\n",
      "Epoch: 0 Step: 91 Loss: 2.08160206908867\n",
      "Epoch: 0 Step: 101 Loss: 2.189156392142857\n",
      "Epoch: 0 Step: 111 Loss: 2.1093265456916863\n",
      "Epoch: 0 Step: 121 Loss: 2.1699222679528902\n",
      "Epoch: 0 Step: 131 Loss: 2.01245559359466\n",
      "Epoch: 0 Step: 141 Loss: 2.058408000820503\n",
      "Epoch: 0 Step: 151 Loss: 2.123694463165793\n",
      "Epoch: 0 Step: 161 Loss: 1.994322863576484\n",
      "Epoch: 0 Step: 171 Loss: 2.041516530642294\n",
      "Epoch: 0 Step: 181 Loss: 2.015633222945067\n",
      "Epoch: 0 Step: 191 Loss: 2.0320221870197024\n",
      "Epoch: 0 Step: 201 Loss: 2.0837961300856103\n",
      "Epoch: 0 Step: 211 Loss: 1.9652175445025337\n",
      "Epoch: 0 Step: 221 Loss: 2.2578398887682405\n",
      "Epoch: 0 Step: 231 Loss: 1.965864712717046\n",
      "Epoch: 0 Step: 241 Loss: 1.8156872893574385\n",
      "Epoch: 0 Step: 251 Loss: 2.056767412948712\n",
      "Epoch: 0 Step: 261 Loss: 1.9435831238165413\n",
      "Epoch: 0 Step: 271 Loss: 1.8892703560675281\n",
      "Epoch: 0 Step: 281 Loss: 1.9428977872616406\n",
      "Epoch: 0 Step: 291 Loss: 1.8207307617002209\n",
      "Epoch: 0 Step: 301 Loss: 1.7403538668668057\n",
      "Epoch: 0 Step: 311 Loss: 1.68093759858778\n",
      "Epoch: 0 Step: 321 Loss: 1.5358307086213483\n",
      "Epoch: 0 Step: 331 Loss: 1.6565741561747256\n",
      "Epoch: 0 Step: 341 Loss: 1.4387998678789373\n",
      "Epoch: 0 Step: 351 Loss: 1.5819216751287946\n",
      "Epoch: 0 Step: 361 Loss: 1.4768530731863114\n",
      "Epoch: 0 Step: 371 Loss: 1.510397351987891\n",
      "Epoch: 0 Step: 381 Loss: 1.3491054057155791\n",
      "Epoch: 0 Step: 391 Loss: 1.4479790550607805\n",
      "Epoch: 0 Step: 401 Loss: 1.5714593781974884\n",
      "Epoch: 0 Step: 411 Loss: 1.3876493124872673\n",
      "Epoch: 0 Step: 421 Loss: 1.2416249950627034\n",
      "Epoch: 0 Step: 431 Loss: 1.130597303733345\n",
      "Epoch: 0 Step: 441 Loss: 1.0907403422926012\n",
      "Epoch: 0 Step: 451 Loss: 0.891459766016347\n",
      "Epoch: 0 Step: 461 Loss: 1.0197680613303879\n",
      "Epoch: 0 Step: 471 Loss: 1.0169087302635755\n",
      "Epoch: 0 Step: 481 Loss: 1.129506124262869\n",
      "Epoch: 0 Step: 491 Loss: 1.021412092891024\n",
      "Epoch: 0 Step: 501 Loss: 0.999698955501198\n",
      "Epoch: 0 Step: 511 Loss: 1.0788996483587014\n",
      "Epoch: 0 Step: 521 Loss: 1.045905669647242\n",
      "Epoch: 0 Step: 531 Loss: 0.6069546968020767\n",
      "Epoch: 0 Step: 541 Loss: 0.8491791410494178\n",
      "Epoch: 0 Step: 551 Loss: 0.8627075533886785\n",
      "Epoch: 0 Step: 561 Loss: 0.8957390994782846\n",
      "Epoch: 0 Step: 571 Loss: 0.9320360217268295\n",
      "Epoch: 0 Step: 581 Loss: 0.7553798677294233\n",
      "Epoch: 0 Step: 591 Loss: 0.8698891456521973\n",
      "Epoch: 0 Step: 601 Loss: 0.7075529198680697\n",
      "Epoch: 0 Step: 611 Loss: 0.4348272545965325\n",
      "Epoch: 0 Step: 621 Loss: 0.5583096501061189\n",
      "Epoch: 0 Step: 631 Loss: 0.43896945121858094\n",
      "Epoch: 0 Step: 641 Loss: 0.7260367163682193\n",
      "Epoch: 0 Step: 651 Loss: 0.35929641743046564\n",
      "Epoch: 0 Step: 661 Loss: 0.5703772476616022\n",
      "Epoch: 0 Step: 671 Loss: 0.8068229196758169\n",
      "Epoch: 0 Step: 681 Loss: 0.7014078662174765\n",
      "Epoch: 0 Step: 691 Loss: 0.402702138218141\n",
      "Epoch: 0 Step: 701 Loss: 0.7569764555791245\n",
      "Epoch: 0 Step: 711 Loss: 0.9187919066652028\n",
      "Epoch: 0 Step: 721 Loss: 0.5618753840617733\n",
      "Epoch: 0 Step: 731 Loss: 0.655815739713983\n",
      "Epoch: 0 Step: 741 Loss: 0.302889882754358\n",
      "Epoch: 0 Step: 751 Loss: 0.34367459233031583\n",
      "Epoch: 0 Step: 761 Loss: 0.4036485546680897\n",
      "Epoch: 0 Step: 771 Loss: 0.3069444423645557\n",
      "Epoch: 0 Step: 781 Loss: 0.26593602993624677\n",
      "Epoch: 0 Step: 791 Loss: 0.6903467315609804\n",
      "Epoch: 0 Step: 801 Loss: 0.48041002284458845\n",
      "Epoch: 0 Step: 811 Loss: 0.31676045902438627\n",
      "Epoch: 0 Step: 821 Loss: 0.3112623394734314\n",
      "Epoch: 0 Step: 831 Loss: 0.5110524401851839\n",
      "Epoch: 0 Step: 841 Loss: 0.1700607213009169\n",
      "Epoch: 0 Step: 851 Loss: 0.34658647109771124\n",
      "Epoch: 0 Step: 861 Loss: 0.2765043467362692\n",
      "Epoch: 0 Step: 871 Loss: 0.3166745580260678\n",
      "Epoch: 0 Step: 881 Loss: 0.27283374251384906\n",
      "Epoch: 0 Step: 891 Loss: 0.1706543306035453\n",
      "Epoch: 0 Step: 901 Loss: 0.4413322592298435\n",
      "Epoch: 0 Step: 911 Loss: 0.2090081019907929\n",
      "Epoch: 0 Step: 921 Loss: 0.07766967464539531\n",
      "Epoch: 0 Step: 931 Loss: 0.1553461873472855\n",
      "Epoch: 1 Step: 1 Loss: 0.37771270359682196\n",
      "Epoch: 1 Step: 11 Loss: 0.13988707208154566\n",
      "Epoch: 1 Step: 21 Loss: 0.4894147864007163\n",
      "Epoch: 1 Step: 31 Loss: 0.2808327331565412\n",
      "Epoch: 1 Step: 41 Loss: 0.23121863862500583\n",
      "Epoch: 1 Step: 51 Loss: 0.22790835365426956\n",
      "Epoch: 1 Step: 61 Loss: 0.12207462186590348\n",
      "Epoch: 1 Step: 71 Loss: 0.23967141407773396\n",
      "Epoch: 1 Step: 81 Loss: 0.28680231939290973\n",
      "Epoch: 1 Step: 91 Loss: 0.2088952421334306\n",
      "Epoch: 1 Step: 101 Loss: 0.3026035838040887\n",
      "Epoch: 1 Step: 111 Loss: 0.19972596226059236\n",
      "Epoch: 1 Step: 121 Loss: 0.22350616640005527\n",
      "Epoch: 1 Step: 131 Loss: 0.1280622537010484\n",
      "Epoch: 1 Step: 141 Loss: 0.24737331304256882\n",
      "Epoch: 1 Step: 151 Loss: 0.25592414870647817\n",
      "Epoch: 1 Step: 161 Loss: 0.5311242816766686\n",
      "Epoch: 1 Step: 171 Loss: 0.20700696686374934\n",
      "Epoch: 1 Step: 181 Loss: 0.3597640541070308\n",
      "Epoch: 1 Step: 191 Loss: 0.26680495595705633\n",
      "Epoch: 1 Step: 201 Loss: 0.27697758793255856\n",
      "Epoch: 1 Step: 211 Loss: 0.1013947938653091\n",
      "Epoch: 1 Step: 221 Loss: 0.23567606177840555\n",
      "Epoch: 1 Step: 231 Loss: 0.3766055856098297\n",
      "Epoch: 1 Step: 241 Loss: 0.1941515175014128\n",
      "Epoch: 1 Step: 251 Loss: 0.4359758805876471\n",
      "Epoch: 1 Step: 261 Loss: 0.46815924394951136\n",
      "Epoch: 1 Step: 271 Loss: 0.20416418032582856\n",
      "Epoch: 1 Step: 281 Loss: 0.292509150121022\n",
      "Epoch: 1 Step: 291 Loss: 0.1726545714506864\n",
      "Epoch: 1 Step: 301 Loss: 0.2835247059142768\n",
      "Epoch: 1 Step: 311 Loss: 0.19944333821964438\n",
      "Epoch: 1 Step: 321 Loss: 0.2149201128664955\n",
      "Epoch: 1 Step: 331 Loss: 0.2175815532829728\n",
      "Epoch: 1 Step: 341 Loss: 0.1194991353852291\n",
      "Epoch: 1 Step: 351 Loss: 0.32618642621023586\n",
      "Epoch: 1 Step: 361 Loss: 0.32989023657739747\n",
      "Epoch: 1 Step: 371 Loss: 0.3075811292196329\n",
      "Epoch: 1 Step: 381 Loss: 0.07940044171024352\n",
      "Epoch: 1 Step: 391 Loss: 0.1487302385594923\n",
      "Epoch: 1 Step: 401 Loss: 0.20390014844733312\n",
      "Epoch: 1 Step: 411 Loss: 0.13743417377176387\n",
      "Epoch: 1 Step: 421 Loss: 0.21867860573079478\n",
      "Epoch: 1 Step: 431 Loss: 0.17875635992663752\n",
      "Epoch: 1 Step: 441 Loss: 0.19503315430924562\n",
      "Epoch: 1 Step: 451 Loss: 0.15450154261381494\n",
      "Epoch: 1 Step: 461 Loss: 0.19723587654752156\n",
      "Epoch: 1 Step: 471 Loss: 0.1924593329898733\n",
      "Epoch: 1 Step: 481 Loss: 0.17494529256800698\n",
      "Epoch: 1 Step: 491 Loss: 0.3059083421392513\n",
      "Epoch: 1 Step: 501 Loss: 0.2154572162386047\n",
      "Epoch: 1 Step: 511 Loss: 0.4809529390881284\n",
      "Epoch: 1 Step: 521 Loss: 0.15155218869657344\n",
      "Epoch: 1 Step: 531 Loss: 0.1163807173610473\n",
      "Epoch: 1 Step: 541 Loss: 0.04677937843083966\n",
      "Epoch: 1 Step: 551 Loss: 0.29296059208614916\n",
      "Epoch: 1 Step: 561 Loss: 0.16478174609070645\n",
      "Epoch: 1 Step: 571 Loss: 0.1346461287190731\n",
      "Epoch: 1 Step: 581 Loss: 0.15524164678421581\n",
      "Epoch: 1 Step: 591 Loss: 0.22332253247796197\n",
      "Epoch: 1 Step: 601 Loss: 0.2945471587472638\n",
      "Epoch: 1 Step: 611 Loss: 0.07298531002484351\n",
      "Epoch: 1 Step: 621 Loss: 0.1252524792396959\n",
      "Epoch: 1 Step: 631 Loss: 0.20511252496425483\n",
      "Epoch: 1 Step: 641 Loss: 0.19236093068850815\n",
      "Epoch: 1 Step: 651 Loss: 0.09032747276571529\n",
      "Epoch: 1 Step: 661 Loss: 0.059826958535146815\n",
      "Epoch: 1 Step: 671 Loss: 0.23293423838864108\n",
      "Epoch: 1 Step: 681 Loss: 0.24018507252232557\n",
      "Epoch: 1 Step: 691 Loss: 0.05283306974638052\n",
      "Epoch: 1 Step: 701 Loss: 0.5180534403993183\n",
      "Epoch: 1 Step: 711 Loss: 0.2203070898229202\n",
      "Epoch: 1 Step: 721 Loss: 0.28586365156044014\n",
      "Epoch: 1 Step: 731 Loss: 0.20933343648275166\n",
      "Epoch: 1 Step: 741 Loss: 0.07464462983662112\n",
      "Epoch: 1 Step: 751 Loss: 0.12083751125563624\n",
      "Epoch: 1 Step: 761 Loss: 0.09288462853908808\n",
      "Epoch: 1 Step: 771 Loss: 0.0751963691607371\n",
      "Epoch: 1 Step: 781 Loss: 0.2619476956775221\n",
      "Epoch: 1 Step: 791 Loss: 0.27378637573239606\n",
      "Epoch: 1 Step: 801 Loss: 0.11212710837005235\n",
      "Epoch: 1 Step: 811 Loss: 0.156203131299225\n",
      "Epoch: 1 Step: 821 Loss: 0.10395424704660035\n",
      "Epoch: 1 Step: 831 Loss: 0.09586820595936384\n",
      "Epoch: 1 Step: 841 Loss: 0.05589460991479375\n",
      "Epoch: 1 Step: 851 Loss: 0.2124376466432905\n",
      "Epoch: 1 Step: 861 Loss: 0.05412144954061861\n",
      "Epoch: 1 Step: 871 Loss: 0.2614885335832632\n",
      "Epoch: 1 Step: 881 Loss: 0.16460853592029964\n",
      "Epoch: 1 Step: 891 Loss: 0.07996058533994727\n",
      "Epoch: 1 Step: 901 Loss: 0.31245304508298233\n",
      "Epoch: 1 Step: 911 Loss: 0.10121168356456643\n",
      "Epoch: 1 Step: 921 Loss: 0.07708617196184968\n",
      "Epoch: 1 Step: 931 Loss: 0.0563873110131366\n",
      "Epoch: 2 Step: 1 Loss: 0.18736116350958726\n",
      "Epoch: 2 Step: 11 Loss: 0.05021891970457883\n",
      "Epoch: 2 Step: 21 Loss: 0.4585853102603635\n",
      "Epoch: 2 Step: 31 Loss: 0.1043677247645707\n",
      "Epoch: 2 Step: 41 Loss: 0.16190218900544662\n",
      "Epoch: 2 Step: 51 Loss: 0.07998211945982363\n",
      "Epoch: 2 Step: 61 Loss: 0.09702224073163737\n",
      "Epoch: 2 Step: 71 Loss: 0.10661284207986316\n",
      "Epoch: 2 Step: 81 Loss: 0.10037143810439147\n",
      "Epoch: 2 Step: 91 Loss: 0.11749281400255807\n",
      "Epoch: 2 Step: 101 Loss: 0.1640285781603005\n",
      "Epoch: 2 Step: 111 Loss: 0.203032871111185\n",
      "Epoch: 2 Step: 121 Loss: 0.07158429813024256\n",
      "Epoch: 2 Step: 131 Loss: 0.0551597709501485\n",
      "Epoch: 2 Step: 141 Loss: 0.12014318472436657\n",
      "Epoch: 2 Step: 151 Loss: 0.2939888960526795\n",
      "Epoch: 2 Step: 161 Loss: 0.2714726843571919\n",
      "Epoch: 2 Step: 171 Loss: 0.12073564759420984\n",
      "Epoch: 2 Step: 181 Loss: 0.14667672098070486\n",
      "Epoch: 2 Step: 191 Loss: 0.11824712851141161\n",
      "Epoch: 2 Step: 201 Loss: 0.1778295017584807\n",
      "Epoch: 2 Step: 211 Loss: 0.12225435154992197\n",
      "Epoch: 2 Step: 221 Loss: 0.09240822909282369\n",
      "Epoch: 2 Step: 231 Loss: 0.3374422597560139\n",
      "Epoch: 2 Step: 241 Loss: 0.1546293764357396\n",
      "Epoch: 2 Step: 251 Loss: 0.2934388473685275\n",
      "Epoch: 2 Step: 261 Loss: 0.16006737025259182\n",
      "Epoch: 2 Step: 271 Loss: 0.13978209954836274\n",
      "Epoch: 2 Step: 281 Loss: 0.1796862073516565\n",
      "Epoch: 2 Step: 291 Loss: 0.08691366389166257\n",
      "Epoch: 2 Step: 301 Loss: 0.20684481758385936\n",
      "Epoch: 2 Step: 311 Loss: 0.11575181160540476\n",
      "Epoch: 2 Step: 321 Loss: 0.09662237080218249\n",
      "Epoch: 2 Step: 331 Loss: 0.25271436823861304\n",
      "Epoch: 2 Step: 341 Loss: 0.20211848103907368\n",
      "Epoch: 2 Step: 351 Loss: 0.2401340973123467\n",
      "Epoch: 2 Step: 361 Loss: 0.1099916433202983\n",
      "Epoch: 2 Step: 371 Loss: 0.17707541788124023\n",
      "Epoch: 2 Step: 381 Loss: 0.11693138337189872\n",
      "Epoch: 2 Step: 391 Loss: 0.04653904232708085\n",
      "Epoch: 2 Step: 401 Loss: 0.0510121517327175\n",
      "Epoch: 2 Step: 411 Loss: 0.061281060316145886\n",
      "Epoch: 2 Step: 421 Loss: 0.17516694564338048\n",
      "Epoch: 2 Step: 431 Loss: 0.1417924009551771\n",
      "Epoch: 2 Step: 441 Loss: 0.07228046817386809\n",
      "Epoch: 2 Step: 451 Loss: 0.10241776362708149\n",
      "Epoch: 2 Step: 461 Loss: 0.16459127519914563\n",
      "Epoch: 2 Step: 471 Loss: 0.23500983460721067\n",
      "Epoch: 2 Step: 481 Loss: 0.07526938787279969\n",
      "Epoch: 2 Step: 491 Loss: 0.054108218536838754\n",
      "Epoch: 2 Step: 501 Loss: 0.18234441368233273\n",
      "Epoch: 2 Step: 511 Loss: 0.24512786385769983\n",
      "Epoch: 2 Step: 521 Loss: 0.1263910131176738\n",
      "Epoch: 2 Step: 531 Loss: 0.03413397357381351\n",
      "Epoch: 2 Step: 541 Loss: 0.03136472395067613\n",
      "Epoch: 2 Step: 551 Loss: 0.23660429575255046\n",
      "Epoch: 2 Step: 561 Loss: 0.16524324431738044\n",
      "Epoch: 2 Step: 571 Loss: 0.06998438986280428\n",
      "Epoch: 2 Step: 581 Loss: 0.21025696044854408\n",
      "Epoch: 2 Step: 591 Loss: 0.0912905357830687\n",
      "Epoch: 2 Step: 601 Loss: 0.09739722423145944\n",
      "Epoch: 2 Step: 611 Loss: 0.010434597025901745\n",
      "Epoch: 2 Step: 621 Loss: 0.24034974036967724\n",
      "Epoch: 2 Step: 631 Loss: 0.09584754840929616\n",
      "Epoch: 2 Step: 641 Loss: 0.14587268997818909\n",
      "Epoch: 2 Step: 651 Loss: 0.052608600846338616\n",
      "Epoch: 2 Step: 661 Loss: 0.09399818083338468\n",
      "Epoch: 2 Step: 671 Loss: 0.11077797082371987\n",
      "Epoch: 2 Step: 681 Loss: 0.14463199327353665\n",
      "Epoch: 2 Step: 691 Loss: 0.10071797128635439\n",
      "Epoch: 2 Step: 701 Loss: 0.3223173006304181\n",
      "Epoch: 2 Step: 711 Loss: 0.12458728378746715\n",
      "Epoch: 2 Step: 721 Loss: 0.12455264768469476\n",
      "Epoch: 2 Step: 731 Loss: 0.11223238360318794\n",
      "Epoch: 2 Step: 741 Loss: 0.02712779054815149\n",
      "Epoch: 2 Step: 751 Loss: 0.07965129780162603\n",
      "Epoch: 2 Step: 761 Loss: 0.14559207927099085\n",
      "Epoch: 2 Step: 771 Loss: 0.016692320224410914\n",
      "Epoch: 2 Step: 781 Loss: 0.11327325988831027\n",
      "Epoch: 2 Step: 791 Loss: 0.10182609273171658\n",
      "Epoch: 2 Step: 801 Loss: 0.16028154358377322\n",
      "Epoch: 2 Step: 811 Loss: 0.058646033988909115\n",
      "Epoch: 2 Step: 821 Loss: 0.07088693927440676\n",
      "Epoch: 2 Step: 831 Loss: 0.21066230847152564\n",
      "Epoch: 2 Step: 841 Loss: 0.02789142519637461\n",
      "Epoch: 2 Step: 851 Loss: 0.13762802851691366\n",
      "Epoch: 2 Step: 861 Loss: 0.07534321498604123\n",
      "Epoch: 2 Step: 871 Loss: 0.24303200443933978\n",
      "Epoch: 2 Step: 881 Loss: 0.0585357559759007\n",
      "Epoch: 2 Step: 891 Loss: 0.03154169750196508\n",
      "Epoch: 2 Step: 901 Loss: 0.22228727827940784\n",
      "Epoch: 2 Step: 911 Loss: 0.03532102482062423\n",
      "Epoch: 2 Step: 921 Loss: 0.05001362855406076\n",
      "Epoch: 2 Step: 931 Loss: 0.06761240844233049\n",
      "Epoch: 3 Step: 1 Loss: 0.08970978675954142\n",
      "Epoch: 3 Step: 11 Loss: 0.10062214694814159\n",
      "Epoch: 3 Step: 21 Loss: 0.25342801753590427\n",
      "Epoch: 3 Step: 31 Loss: 0.06610090453414165\n",
      "Epoch: 3 Step: 41 Loss: 0.09627616778561934\n",
      "Epoch: 3 Step: 51 Loss: 0.08111368656469874\n",
      "Epoch: 3 Step: 61 Loss: 0.018277197182636453\n",
      "Epoch: 3 Step: 71 Loss: 0.05317071727150714\n",
      "Epoch: 3 Step: 81 Loss: 0.09397106063143143\n",
      "Epoch: 3 Step: 91 Loss: 0.07521040324197972\n",
      "Epoch: 3 Step: 101 Loss: 0.15265688757300794\n",
      "Epoch: 3 Step: 111 Loss: 0.15209913540703923\n",
      "Epoch: 3 Step: 121 Loss: 0.061569814277952495\n",
      "Epoch: 3 Step: 131 Loss: 0.07221422202742081\n",
      "Epoch: 3 Step: 141 Loss: 0.08382040934484201\n",
      "Epoch: 3 Step: 151 Loss: 0.23785283925000028\n",
      "Epoch: 3 Step: 161 Loss: 0.27515681908201517\n",
      "Epoch: 3 Step: 171 Loss: 0.01793872110049176\n",
      "Epoch: 3 Step: 181 Loss: 0.1168175157557932\n",
      "Epoch: 3 Step: 191 Loss: 0.05128905364179203\n",
      "Epoch: 3 Step: 201 Loss: 0.06908385468254408\n",
      "Epoch: 3 Step: 211 Loss: 0.016839578678615227\n",
      "Epoch: 3 Step: 221 Loss: 0.06429723400584263\n",
      "Epoch: 3 Step: 231 Loss: 0.24269163711081887\n",
      "Epoch: 3 Step: 241 Loss: 0.11524887263583902\n",
      "Epoch: 3 Step: 251 Loss: 0.09231509462534865\n",
      "Epoch: 3 Step: 261 Loss: 0.10498752585297891\n",
      "Epoch: 3 Step: 271 Loss: 0.08647111029326758\n",
      "Epoch: 3 Step: 281 Loss: 0.15162295307912116\n",
      "Epoch: 3 Step: 291 Loss: 0.03968393715611127\n",
      "Epoch: 3 Step: 301 Loss: 0.09226878306530033\n",
      "Epoch: 3 Step: 311 Loss: 0.11426056003171534\n",
      "Epoch: 3 Step: 321 Loss: 0.04092376673959043\n",
      "Epoch: 3 Step: 331 Loss: 0.23793404941412288\n",
      "Epoch: 3 Step: 341 Loss: 0.06839907294433828\n",
      "Epoch: 3 Step: 351 Loss: 0.09959097936691737\n",
      "Epoch: 3 Step: 361 Loss: 0.09115545148786573\n",
      "Epoch: 3 Step: 371 Loss: 0.10174537511688295\n",
      "Epoch: 3 Step: 381 Loss: 0.023083562294588307\n",
      "Epoch: 3 Step: 391 Loss: 0.017169343734865797\n",
      "Epoch: 3 Step: 401 Loss: 0.11110538194896358\n",
      "Epoch: 3 Step: 411 Loss: 0.1669905646180943\n",
      "Epoch: 3 Step: 421 Loss: 0.1631784884478653\n",
      "Epoch: 3 Step: 431 Loss: 0.15330965920716585\n",
      "Epoch: 3 Step: 441 Loss: 0.11334192754944\n",
      "Epoch: 3 Step: 451 Loss: 0.16018634950869337\n",
      "Epoch: 3 Step: 461 Loss: 0.0726229339896671\n",
      "Epoch: 3 Step: 471 Loss: 0.313423268289873\n",
      "Epoch: 3 Step: 481 Loss: 0.10169045784821437\n",
      "Epoch: 3 Step: 491 Loss: 0.1371429689550531\n",
      "Epoch: 3 Step: 501 Loss: 0.12494006216223057\n",
      "Epoch: 3 Step: 511 Loss: 0.13144051694374256\n",
      "Epoch: 3 Step: 521 Loss: 0.3360686114842568\n",
      "Epoch: 3 Step: 531 Loss: 0.023793025957451752\n",
      "Epoch: 3 Step: 541 Loss: 0.03792691591410929\n",
      "Epoch: 3 Step: 551 Loss: 0.21051450726546\n",
      "Epoch: 3 Step: 561 Loss: 0.12445649316131935\n",
      "Epoch: 3 Step: 571 Loss: 0.049206730539140445\n",
      "Epoch: 3 Step: 581 Loss: 0.08002507944295247\n",
      "Epoch: 3 Step: 591 Loss: 0.08065681873099165\n",
      "Epoch: 3 Step: 601 Loss: 0.06330863479769502\n",
      "Epoch: 3 Step: 611 Loss: 0.015507181296435127\n",
      "Epoch: 3 Step: 621 Loss: 0.14425092305470646\n",
      "Epoch: 3 Step: 631 Loss: 0.07605216020774662\n",
      "Epoch: 3 Step: 641 Loss: 0.09306139018508217\n",
      "Epoch: 3 Step: 651 Loss: 0.05977226743846695\n",
      "Epoch: 3 Step: 661 Loss: 0.02856671217063056\n",
      "Epoch: 3 Step: 671 Loss: 0.06761052697983759\n",
      "Epoch: 3 Step: 681 Loss: 0.07668587654753617\n",
      "Epoch: 3 Step: 691 Loss: 0.030646294023835424\n",
      "Epoch: 3 Step: 701 Loss: 0.27348873385843187\n",
      "Epoch: 3 Step: 711 Loss: 0.09679676486926007\n",
      "Epoch: 3 Step: 721 Loss: 0.15884280294944322\n",
      "Epoch: 3 Step: 731 Loss: 0.2864202253323968\n",
      "Epoch: 3 Step: 741 Loss: 0.02227135268787782\n",
      "Epoch: 3 Step: 751 Loss: 0.07399244995970783\n",
      "Epoch: 3 Step: 761 Loss: 0.07381671582997476\n",
      "Epoch: 3 Step: 771 Loss: 0.0167979850743072\n",
      "Epoch: 3 Step: 781 Loss: 0.04187646548973794\n",
      "Epoch: 3 Step: 791 Loss: 0.19941487242282935\n",
      "Epoch: 3 Step: 801 Loss: 0.09227772695189616\n",
      "Epoch: 3 Step: 811 Loss: 0.029848494818987322\n",
      "Epoch: 3 Step: 821 Loss: 0.08957272472675096\n",
      "Epoch: 3 Step: 831 Loss: 0.14003263254425316\n",
      "Epoch: 3 Step: 841 Loss: 0.021330183073959084\n",
      "Epoch: 3 Step: 851 Loss: 0.0818472354177185\n",
      "Epoch: 3 Step: 861 Loss: 0.03697436231156426\n",
      "Epoch: 3 Step: 871 Loss: 0.17669151489466403\n",
      "Epoch: 3 Step: 881 Loss: 0.10030185730398204\n",
      "Epoch: 3 Step: 891 Loss: 0.0286901035605884\n",
      "Epoch: 3 Step: 901 Loss: 0.18051154959604002\n",
      "Epoch: 3 Step: 911 Loss: 0.05043965640895265\n",
      "Epoch: 3 Step: 921 Loss: 0.02059876783159854\n",
      "Epoch: 3 Step: 931 Loss: 0.07241465523642858\n",
      "Epoch: 4 Step: 1 Loss: 0.048096808613283575\n",
      "Epoch: 4 Step: 11 Loss: 0.06674227670570268\n",
      "Epoch: 4 Step: 21 Loss: 0.392612171486215\n",
      "Epoch: 4 Step: 31 Loss: 0.026380688122536373\n",
      "Epoch: 4 Step: 41 Loss: 0.1301092661261779\n",
      "Epoch: 4 Step: 51 Loss: 0.04638551130607979\n",
      "Epoch: 4 Step: 61 Loss: 0.0399899458365858\n",
      "Epoch: 4 Step: 71 Loss: 0.03419064217890111\n",
      "Epoch: 4 Step: 81 Loss: 0.08803956782434261\n",
      "Epoch: 4 Step: 91 Loss: 0.11886236920801432\n",
      "Epoch: 4 Step: 101 Loss: 0.10055500977475043\n",
      "Epoch: 4 Step: 111 Loss: 0.15727077266950626\n",
      "Epoch: 4 Step: 121 Loss: 0.09393839746707622\n",
      "Epoch: 4 Step: 131 Loss: 0.04625972159167471\n",
      "Epoch: 4 Step: 141 Loss: 0.06586424089829573\n",
      "Epoch: 4 Step: 151 Loss: 0.10423859788220483\n",
      "Epoch: 4 Step: 161 Loss: 0.2651604050855396\n",
      "Epoch: 4 Step: 171 Loss: 0.12822047345723322\n",
      "Epoch: 4 Step: 181 Loss: 0.0734706018954131\n",
      "Epoch: 4 Step: 191 Loss: 0.06839842052239971\n",
      "Epoch: 4 Step: 201 Loss: 0.05826266787215914\n",
      "Epoch: 4 Step: 211 Loss: 0.013638067569213317\n",
      "Epoch: 4 Step: 221 Loss: 0.05018426428270534\n",
      "Epoch: 4 Step: 231 Loss: 0.10227082856011899\n",
      "Epoch: 4 Step: 241 Loss: 0.19167171034540237\n",
      "Epoch: 4 Step: 251 Loss: 0.23070855974246784\n",
      "Epoch: 4 Step: 261 Loss: 0.18902523790973005\n",
      "Epoch: 4 Step: 271 Loss: 0.09981456977851286\n",
      "Epoch: 4 Step: 281 Loss: 0.04385050114352928\n",
      "Epoch: 4 Step: 291 Loss: 0.03453388169133665\n",
      "Epoch: 4 Step: 301 Loss: 0.15012651142025954\n",
      "Epoch: 4 Step: 311 Loss: 0.022959874469645855\n",
      "Epoch: 4 Step: 321 Loss: 0.05056090848524068\n",
      "Epoch: 4 Step: 331 Loss: 0.09032328946139383\n",
      "Epoch: 4 Step: 341 Loss: 0.05901490541217439\n",
      "Epoch: 4 Step: 351 Loss: 0.07847969285916155\n",
      "Epoch: 4 Step: 361 Loss: 0.16376761159619696\n",
      "Epoch: 4 Step: 371 Loss: 0.14112223860606007\n",
      "Epoch: 4 Step: 381 Loss: 0.06563819808937311\n",
      "Epoch: 4 Step: 391 Loss: 0.035625704892366994\n",
      "Epoch: 4 Step: 401 Loss: 0.08217393421118707\n",
      "Epoch: 4 Step: 411 Loss: 0.03868649956813626\n",
      "Epoch: 4 Step: 421 Loss: 0.16544950464308003\n",
      "Epoch: 4 Step: 431 Loss: 0.1341338074343632\n",
      "Epoch: 4 Step: 441 Loss: 0.13889503938411074\n",
      "Epoch: 4 Step: 451 Loss: 0.15255893416333552\n",
      "Epoch: 4 Step: 461 Loss: 0.050128315412440096\n",
      "Epoch: 4 Step: 471 Loss: 0.3013850182348475\n",
      "Epoch: 4 Step: 481 Loss: 0.0861828052554992\n",
      "Epoch: 4 Step: 491 Loss: 0.1814459784025574\n",
      "Epoch: 4 Step: 501 Loss: 0.0829683730899941\n",
      "Epoch: 4 Step: 511 Loss: 0.20684139533078516\n",
      "Epoch: 4 Step: 521 Loss: 0.16321119893495273\n",
      "Epoch: 4 Step: 531 Loss: 0.039984514741098307\n",
      "Epoch: 4 Step: 541 Loss: 0.019037700179968264\n",
      "Epoch: 4 Step: 551 Loss: 0.17631443576677094\n",
      "Epoch: 4 Step: 561 Loss: 0.14975776076248687\n",
      "Epoch: 4 Step: 571 Loss: 0.11668048675760732\n",
      "Epoch: 4 Step: 581 Loss: 0.017840257337458722\n",
      "Epoch: 4 Step: 591 Loss: 0.10784086139050698\n",
      "Epoch: 4 Step: 601 Loss: 0.04308752298775291\n",
      "Epoch: 4 Step: 611 Loss: 0.03281908506755596\n",
      "Epoch: 4 Step: 621 Loss: 0.14446900054711848\n",
      "Epoch: 4 Step: 631 Loss: 0.04030359238244981\n",
      "Epoch: 4 Step: 641 Loss: 0.10482910380603486\n",
      "Epoch: 4 Step: 651 Loss: 0.0400900811787719\n",
      "Epoch: 4 Step: 661 Loss: 0.015865514683398044\n",
      "Epoch: 4 Step: 671 Loss: 0.08093814795507105\n",
      "Epoch: 4 Step: 681 Loss: 0.04794102588010024\n",
      "Epoch: 4 Step: 691 Loss: 0.02202094304679083\n",
      "Epoch: 4 Step: 701 Loss: 0.12316628519362946\n",
      "Epoch: 4 Step: 711 Loss: 0.07205973507264599\n",
      "Epoch: 4 Step: 721 Loss: 0.08419649404070406\n",
      "Epoch: 4 Step: 731 Loss: 0.14884206653110474\n",
      "Epoch: 4 Step: 741 Loss: 0.026189836873151358\n",
      "Epoch: 4 Step: 751 Loss: 0.05683764730450629\n",
      "Epoch: 4 Step: 761 Loss: 0.18474348896668608\n",
      "Epoch: 4 Step: 771 Loss: 0.0435143306918165\n",
      "Epoch: 4 Step: 781 Loss: 0.10278395891542354\n",
      "Epoch: 4 Step: 791 Loss: 0.0693463020737909\n",
      "Epoch: 4 Step: 801 Loss: 0.06384912642047459\n",
      "Epoch: 4 Step: 811 Loss: 0.012547984555589288\n",
      "Epoch: 4 Step: 821 Loss: 0.043352879759753986\n",
      "Epoch: 4 Step: 831 Loss: 0.11455825595247926\n",
      "Epoch: 4 Step: 841 Loss: 0.03042523550331625\n",
      "Epoch: 4 Step: 851 Loss: 0.11879683769566432\n",
      "Epoch: 4 Step: 861 Loss: 0.018792931724428794\n",
      "Epoch: 4 Step: 871 Loss: 0.1896938112193177\n",
      "Epoch: 4 Step: 881 Loss: 0.09306168961063133\n",
      "Epoch: 4 Step: 891 Loss: 0.013513452132260404\n",
      "Epoch: 4 Step: 901 Loss: 0.11950612965936924\n",
      "Epoch: 4 Step: 911 Loss: 0.044817342352769005\n",
      "Epoch: 4 Step: 921 Loss: 0.025857454830010965\n",
      "Epoch: 4 Step: 931 Loss: 0.017652098283695353\n",
      "Epoch: 5 Step: 1 Loss: 0.12301270298416685\n",
      "Epoch: 5 Step: 11 Loss: 0.01782783139687147\n",
      "Epoch: 5 Step: 21 Loss: 0.21131528661319912\n",
      "Epoch: 5 Step: 31 Loss: 0.023090503616658667\n",
      "Epoch: 5 Step: 41 Loss: 0.019294170969997235\n",
      "Epoch: 5 Step: 51 Loss: 0.12523655783773802\n",
      "Epoch: 5 Step: 61 Loss: 0.01816818136522135\n",
      "Epoch: 5 Step: 71 Loss: 0.018959782874096467\n",
      "Epoch: 5 Step: 81 Loss: 0.03757053253319515\n",
      "Epoch: 5 Step: 91 Loss: 0.05779886956260835\n",
      "Epoch: 5 Step: 101 Loss: 0.12586852159280554\n",
      "Epoch: 5 Step: 111 Loss: 0.10844715468525336\n",
      "Epoch: 5 Step: 121 Loss: 0.08201884036182681\n",
      "Epoch: 5 Step: 131 Loss: 0.0939260963466815\n",
      "Epoch: 5 Step: 141 Loss: 0.06521637518666665\n",
      "Epoch: 5 Step: 151 Loss: 0.1124196213782542\n",
      "Epoch: 5 Step: 161 Loss: 0.34454153491335954\n",
      "Epoch: 5 Step: 171 Loss: 0.0065620913545981485\n",
      "Epoch: 5 Step: 181 Loss: 0.07237903936554707\n",
      "Epoch: 5 Step: 191 Loss: 0.013139433431403382\n",
      "Epoch: 5 Step: 201 Loss: 0.0730946938591675\n",
      "Epoch: 5 Step: 211 Loss: 0.05231265304095382\n",
      "Epoch: 5 Step: 221 Loss: 0.07759724147185709\n",
      "Epoch: 5 Step: 231 Loss: 0.09874307693489147\n",
      "Epoch: 5 Step: 241 Loss: 0.037804378024737816\n",
      "Epoch: 5 Step: 251 Loss: 0.26488620186945055\n",
      "Epoch: 5 Step: 261 Loss: 0.11838527479041602\n",
      "Epoch: 5 Step: 271 Loss: 0.037080615198626155\n",
      "Epoch: 5 Step: 281 Loss: 0.08480313636485792\n",
      "Epoch: 5 Step: 291 Loss: 0.012499500968790055\n",
      "Epoch: 5 Step: 301 Loss: 0.1105397058773985\n",
      "Epoch: 5 Step: 311 Loss: 0.05131233083325367\n",
      "Epoch: 5 Step: 321 Loss: 0.13659932287090823\n",
      "Epoch: 5 Step: 331 Loss: 0.05401666919125604\n",
      "Epoch: 5 Step: 341 Loss: 0.15138229144714138\n",
      "Epoch: 5 Step: 351 Loss: 0.09418521290334117\n",
      "Epoch: 5 Step: 361 Loss: 0.09409547855925177\n",
      "Epoch: 5 Step: 371 Loss: 0.04217284915621332\n",
      "Epoch: 5 Step: 381 Loss: 0.014418994311381095\n",
      "Epoch: 5 Step: 391 Loss: 0.018392555872918943\n",
      "Epoch: 5 Step: 401 Loss: 0.011733522142561754\n",
      "Epoch: 5 Step: 411 Loss: 0.05114940870427786\n",
      "Epoch: 5 Step: 421 Loss: 0.07153043492369582\n",
      "Epoch: 5 Step: 431 Loss: 0.10824333447481238\n",
      "Epoch: 5 Step: 441 Loss: 0.09230935009989905\n",
      "Epoch: 5 Step: 451 Loss: 0.06330611803263532\n",
      "Epoch: 5 Step: 461 Loss: 0.03303987709813189\n",
      "Epoch: 5 Step: 471 Loss: 0.27265562775425145\n",
      "Epoch: 5 Step: 481 Loss: 0.0617573066425266\n",
      "Epoch: 5 Step: 491 Loss: 0.14657346663858123\n",
      "Epoch: 5 Step: 501 Loss: 0.041504868626270466\n",
      "Epoch: 5 Step: 511 Loss: 0.09002012168886993\n",
      "Epoch: 5 Step: 521 Loss: 0.0697934998749738\n",
      "Epoch: 5 Step: 531 Loss: 0.006121479795489795\n",
      "Epoch: 5 Step: 541 Loss: 0.01893062142874316\n",
      "Epoch: 5 Step: 551 Loss: 0.10747813112864568\n",
      "Epoch: 5 Step: 561 Loss: 0.05288118992827507\n",
      "Epoch: 5 Step: 571 Loss: 0.02921347248394186\n",
      "Epoch: 5 Step: 581 Loss: 0.10611589290879507\n",
      "Epoch: 5 Step: 591 Loss: 0.028082514382258963\n",
      "Epoch: 5 Step: 601 Loss: 0.03589973716063064\n",
      "Epoch: 5 Step: 611 Loss: 0.014319350039661578\n",
      "Epoch: 5 Step: 621 Loss: 0.1450576554871413\n",
      "Epoch: 5 Step: 631 Loss: 0.08619554048265451\n",
      "Epoch: 5 Step: 641 Loss: 0.0647759879646249\n",
      "Epoch: 5 Step: 651 Loss: 0.017014550669559876\n",
      "Epoch: 5 Step: 661 Loss: 0.03571664662072073\n",
      "Epoch: 5 Step: 671 Loss: 0.06420746322932533\n",
      "Epoch: 5 Step: 681 Loss: 0.16454407791656722\n",
      "Epoch: 5 Step: 691 Loss: 0.02637052368998579\n",
      "Epoch: 5 Step: 701 Loss: 0.3295343503302912\n",
      "Epoch: 5 Step: 711 Loss: 0.054144862220888795\n",
      "Epoch: 5 Step: 721 Loss: 0.1405597347765027\n",
      "Epoch: 5 Step: 731 Loss: 0.12322295431935923\n",
      "Epoch: 5 Step: 741 Loss: 0.01504603428715589\n",
      "Epoch: 5 Step: 751 Loss: 0.036806871200383826\n",
      "Epoch: 5 Step: 761 Loss: 0.03706363086458306\n",
      "Epoch: 5 Step: 771 Loss: 0.010194989513715322\n",
      "Epoch: 5 Step: 781 Loss: 0.16077582266880677\n",
      "Epoch: 5 Step: 791 Loss: 0.06500678501789012\n",
      "Epoch: 5 Step: 801 Loss: 0.11180489666762641\n",
      "Epoch: 5 Step: 811 Loss: 0.042229429955804254\n",
      "Epoch: 5 Step: 821 Loss: 0.035594728015586066\n",
      "Epoch: 5 Step: 831 Loss: 0.11030120687263158\n",
      "Epoch: 5 Step: 841 Loss: 0.03270336277971971\n",
      "Epoch: 5 Step: 851 Loss: 0.039859528967377995\n",
      "Epoch: 5 Step: 861 Loss: 0.010426565897338463\n",
      "Epoch: 5 Step: 871 Loss: 0.15697515375181353\n",
      "Epoch: 5 Step: 881 Loss: 0.07756452455575348\n",
      "Epoch: 5 Step: 891 Loss: 0.03228869913627802\n",
      "Epoch: 5 Step: 901 Loss: 0.1293135863889686\n",
      "Epoch: 5 Step: 911 Loss: 0.042166317970634325\n",
      "Epoch: 5 Step: 921 Loss: 0.003983331733426077\n",
      "Epoch: 5 Step: 931 Loss: 0.03189066416404263\n",
      "Epoch: 6 Step: 1 Loss: 0.020466132323970404\n",
      "Epoch: 6 Step: 11 Loss: 0.10871949457481672\n",
      "Epoch: 6 Step: 21 Loss: 0.17808991673837077\n",
      "Epoch: 6 Step: 31 Loss: 0.01891426866829117\n",
      "Epoch: 6 Step: 41 Loss: 0.07293584022983211\n",
      "Epoch: 6 Step: 51 Loss: 0.05069952529033227\n",
      "Epoch: 6 Step: 61 Loss: 0.026827057740657897\n",
      "Epoch: 6 Step: 71 Loss: 0.012006038924808083\n",
      "Epoch: 6 Step: 81 Loss: 0.032645373196643526\n",
      "Epoch: 6 Step: 91 Loss: 0.050637024121921816\n",
      "Epoch: 6 Step: 101 Loss: 0.1312945918699501\n",
      "Epoch: 6 Step: 111 Loss: 0.05257475119974145\n",
      "Epoch: 6 Step: 121 Loss: 0.050717348701078496\n",
      "Epoch: 6 Step: 131 Loss: 0.016375104001359123\n",
      "Epoch: 6 Step: 141 Loss: 0.041574937744689275\n",
      "Epoch: 6 Step: 151 Loss: 0.13697572220869697\n",
      "Epoch: 6 Step: 161 Loss: 0.2171083464758929\n",
      "Epoch: 6 Step: 171 Loss: 0.012837678046343979\n",
      "Epoch: 6 Step: 181 Loss: 0.1231822949464784\n",
      "Epoch: 6 Step: 191 Loss: 0.03367642057302128\n",
      "Epoch: 6 Step: 201 Loss: 0.039176201564462984\n",
      "Epoch: 6 Step: 211 Loss: 0.026050066558794438\n",
      "Epoch: 6 Step: 221 Loss: 0.07790789593938147\n",
      "Epoch: 6 Step: 231 Loss: 0.09344196032179258\n",
      "Epoch: 6 Step: 241 Loss: 0.023400168633018845\n",
      "Epoch: 6 Step: 251 Loss: 0.09823453471625455\n",
      "Epoch: 6 Step: 261 Loss: 0.10660154274690459\n",
      "Epoch: 6 Step: 271 Loss: 0.03777613646231954\n",
      "Epoch: 6 Step: 281 Loss: 0.041158107949088606\n",
      "Epoch: 6 Step: 291 Loss: 0.018131792008062215\n",
      "Epoch: 6 Step: 301 Loss: 0.055997896462546846\n",
      "Epoch: 6 Step: 311 Loss: 0.0560616203031051\n",
      "Epoch: 6 Step: 321 Loss: 0.026581215462014363\n",
      "Epoch: 6 Step: 331 Loss: 0.04520610084034192\n",
      "Epoch: 6 Step: 341 Loss: 0.02377466108072127\n",
      "Epoch: 6 Step: 351 Loss: 0.01727339272352194\n",
      "Epoch: 6 Step: 361 Loss: 0.0598121940588859\n",
      "Epoch: 6 Step: 371 Loss: 0.1137406386107274\n",
      "Epoch: 6 Step: 381 Loss: 0.005802966776767123\n",
      "Epoch: 6 Step: 391 Loss: 0.010296506338470093\n",
      "Epoch: 6 Step: 401 Loss: 0.02999485630701203\n",
      "Epoch: 6 Step: 411 Loss: 0.1383741325732638\n",
      "Epoch: 6 Step: 421 Loss: 0.1349856085382986\n",
      "Epoch: 6 Step: 431 Loss: 0.1183796439343559\n",
      "Epoch: 6 Step: 441 Loss: 0.010982193153729163\n",
      "Epoch: 6 Step: 451 Loss: 0.04815865345036367\n",
      "Epoch: 6 Step: 461 Loss: 0.085464153417249\n",
      "Epoch: 6 Step: 471 Loss: 0.08434260340277658\n",
      "Epoch: 6 Step: 481 Loss: 0.02478903539435561\n",
      "Epoch: 6 Step: 491 Loss: 0.03637800691577999\n",
      "Epoch: 6 Step: 501 Loss: 0.011758610984870176\n",
      "Epoch: 6 Step: 511 Loss: 0.051507783916766456\n",
      "Epoch: 6 Step: 521 Loss: 0.021274169121636526\n",
      "Epoch: 6 Step: 531 Loss: 0.005058256315706622\n",
      "Epoch: 6 Step: 541 Loss: 0.02831913773562988\n",
      "Epoch: 6 Step: 551 Loss: 0.1190845089136349\n",
      "Epoch: 6 Step: 561 Loss: 0.05678405384982128\n",
      "Epoch: 6 Step: 571 Loss: 0.10309035041055062\n",
      "Epoch: 6 Step: 581 Loss: 0.06069357635919693\n",
      "Epoch: 6 Step: 591 Loss: 0.0766852411788501\n",
      "Epoch: 6 Step: 601 Loss: 0.04599133848684724\n",
      "Epoch: 6 Step: 611 Loss: 0.004281955063218448\n",
      "Epoch: 6 Step: 621 Loss: 0.09652077514025716\n",
      "Epoch: 6 Step: 631 Loss: 0.06771194303041854\n",
      "Epoch: 6 Step: 641 Loss: 0.07868431448549228\n",
      "Epoch: 6 Step: 651 Loss: 0.06291319592480436\n",
      "Epoch: 6 Step: 661 Loss: 0.023134878312756273\n",
      "Epoch: 6 Step: 671 Loss: 0.09785537159900588\n",
      "Epoch: 6 Step: 681 Loss: 0.09353049846182566\n",
      "Epoch: 6 Step: 691 Loss: 0.02962731362966777\n",
      "Epoch: 6 Step: 701 Loss: 0.230168989992874\n",
      "Epoch: 6 Step: 711 Loss: 0.02972442789002028\n",
      "Epoch: 6 Step: 721 Loss: 0.09272633834691452\n",
      "Epoch: 6 Step: 731 Loss: 0.1079672401586596\n",
      "Epoch: 6 Step: 741 Loss: 0.007060326606200437\n",
      "Epoch: 6 Step: 751 Loss: 0.037519483594314534\n",
      "Epoch: 6 Step: 761 Loss: 0.06729881866694984\n",
      "Epoch: 6 Step: 771 Loss: 0.0042351735438491845\n",
      "Epoch: 6 Step: 781 Loss: 0.11787354602178374\n",
      "Epoch: 6 Step: 791 Loss: 0.16542509557147259\n",
      "Epoch: 6 Step: 801 Loss: 0.05090736696174204\n",
      "Epoch: 6 Step: 811 Loss: 0.01592909365499505\n",
      "Epoch: 6 Step: 821 Loss: 0.02915915662651451\n",
      "Epoch: 6 Step: 831 Loss: 0.06586856781436776\n",
      "Epoch: 6 Step: 841 Loss: 0.008957549732609116\n",
      "Epoch: 6 Step: 851 Loss: 0.02706779709536262\n",
      "Epoch: 6 Step: 861 Loss: 0.014284274176128226\n",
      "Epoch: 6 Step: 871 Loss: 0.03605582190577495\n",
      "Epoch: 6 Step: 881 Loss: 0.13167496664819198\n",
      "Epoch: 6 Step: 891 Loss: 0.010474023858522193\n",
      "Epoch: 6 Step: 901 Loss: 0.08017327596961145\n",
      "Epoch: 6 Step: 911 Loss: 0.04719707705932268\n",
      "Epoch: 6 Step: 921 Loss: 0.0019636244076867513\n",
      "Epoch: 6 Step: 931 Loss: 0.003964238724612562\n",
      "Epoch: 7 Step: 1 Loss: 0.02592710143352235\n",
      "Epoch: 7 Step: 11 Loss: 0.10182296828029325\n",
      "Epoch: 7 Step: 21 Loss: 0.12801820606458322\n",
      "Epoch: 7 Step: 31 Loss: 0.052276615117627406\n",
      "Epoch: 7 Step: 41 Loss: 0.015510423732144653\n",
      "Epoch: 7 Step: 51 Loss: 0.10193146555437305\n",
      "Epoch: 7 Step: 61 Loss: 0.015637104838655092\n",
      "Epoch: 7 Step: 71 Loss: 0.023542211732235137\n",
      "Epoch: 7 Step: 81 Loss: 0.03673693711928915\n",
      "Epoch: 7 Step: 91 Loss: 0.052187638932686804\n",
      "Epoch: 7 Step: 101 Loss: 0.07340356801201565\n",
      "Epoch: 7 Step: 111 Loss: 0.057988582041379085\n",
      "Epoch: 7 Step: 121 Loss: 0.07857211908433051\n",
      "Epoch: 7 Step: 131 Loss: 0.014987446846510205\n",
      "Epoch: 7 Step: 141 Loss: 0.06748212535607007\n",
      "Epoch: 7 Step: 151 Loss: 0.04293887774889311\n",
      "Epoch: 7 Step: 161 Loss: 0.16887362429332792\n",
      "Epoch: 7 Step: 171 Loss: 0.007384707923593024\n",
      "Epoch: 7 Step: 181 Loss: 0.01905960647602156\n",
      "Epoch: 7 Step: 191 Loss: 0.02857233799625334\n",
      "Epoch: 7 Step: 201 Loss: 0.04680868274339937\n",
      "Epoch: 7 Step: 211 Loss: 0.008223603689907249\n",
      "Epoch: 7 Step: 221 Loss: 0.07679521619917418\n",
      "Epoch: 7 Step: 231 Loss: 0.15910593153208086\n",
      "Epoch: 7 Step: 241 Loss: 0.04910207811146388\n",
      "Epoch: 7 Step: 251 Loss: 0.15210227501068227\n",
      "Epoch: 7 Step: 261 Loss: 0.08697819742578125\n",
      "Epoch: 7 Step: 271 Loss: 0.03480015122352477\n",
      "Epoch: 7 Step: 281 Loss: 0.033549087280449835\n",
      "Epoch: 7 Step: 291 Loss: 0.012450287827517425\n",
      "Epoch: 7 Step: 301 Loss: 0.030314238597250735\n",
      "Epoch: 7 Step: 311 Loss: 0.05667579106938875\n",
      "Epoch: 7 Step: 321 Loss: 0.01780055829280754\n",
      "Epoch: 7 Step: 331 Loss: 0.024562501728607924\n",
      "Epoch: 7 Step: 341 Loss: 0.03995790603157665\n",
      "Epoch: 7 Step: 351 Loss: 0.041486626417189816\n",
      "Epoch: 7 Step: 361 Loss: 0.056769543308722886\n",
      "Epoch: 7 Step: 371 Loss: 0.08142841359148799\n",
      "Epoch: 7 Step: 381 Loss: 0.00653294356172174\n",
      "Epoch: 7 Step: 391 Loss: 0.0025793311489536357\n",
      "Epoch: 7 Step: 401 Loss: 0.019325061518924283\n",
      "Epoch: 7 Step: 411 Loss: 0.03344608088259276\n",
      "Epoch: 7 Step: 421 Loss: 0.07720744705498621\n",
      "Epoch: 7 Step: 431 Loss: 0.09542807209020973\n",
      "Epoch: 7 Step: 441 Loss: 0.15960105976637218\n",
      "Epoch: 7 Step: 451 Loss: 0.014647348137009021\n",
      "Epoch: 7 Step: 461 Loss: 0.024667065298034675\n",
      "Epoch: 7 Step: 471 Loss: 0.048161199272567186\n",
      "Epoch: 7 Step: 481 Loss: 0.032598955488714235\n",
      "Epoch: 7 Step: 491 Loss: 0.05279603613033408\n",
      "Epoch: 7 Step: 501 Loss: 0.016154964443109012\n",
      "Epoch: 7 Step: 511 Loss: 0.07893275716843948\n",
      "Epoch: 7 Step: 521 Loss: 0.04559639442279819\n",
      "Epoch: 7 Step: 531 Loss: 0.00913591233848842\n",
      "Epoch: 7 Step: 541 Loss: 0.06002564472523478\n",
      "Epoch: 7 Step: 551 Loss: 0.07130786676378119\n",
      "Epoch: 7 Step: 561 Loss: 0.08377971088436081\n",
      "Epoch: 7 Step: 571 Loss: 0.09884706981871591\n",
      "Epoch: 7 Step: 581 Loss: 0.1236102931932992\n",
      "Epoch: 7 Step: 591 Loss: 0.06380057936870956\n",
      "Epoch: 7 Step: 601 Loss: 0.07233415794501158\n",
      "Epoch: 7 Step: 611 Loss: 0.006644750965429705\n",
      "Epoch: 7 Step: 621 Loss: 0.08364071121383458\n",
      "Epoch: 7 Step: 631 Loss: 0.10484972762798074\n",
      "Epoch: 7 Step: 641 Loss: 0.1410875579131782\n",
      "Epoch: 7 Step: 651 Loss: 0.028087138796533982\n",
      "Epoch: 7 Step: 661 Loss: 0.05372673366073325\n",
      "Epoch: 7 Step: 671 Loss: 0.14638727874139795\n",
      "Epoch: 7 Step: 681 Loss: 0.06014488393799297\n",
      "Epoch: 7 Step: 691 Loss: 0.019755658673907515\n",
      "Epoch: 7 Step: 701 Loss: 0.18216604718154983\n",
      "Epoch: 7 Step: 711 Loss: 0.05579877239812011\n",
      "Epoch: 7 Step: 721 Loss: 0.07268054392681324\n",
      "Epoch: 7 Step: 731 Loss: 0.1278317496321256\n",
      "Epoch: 7 Step: 741 Loss: 0.0076777023852500305\n",
      "Epoch: 7 Step: 751 Loss: 0.033241380840618735\n",
      "Epoch: 7 Step: 761 Loss: 0.07163138884899885\n",
      "Epoch: 7 Step: 771 Loss: 0.004764821422484293\n",
      "Epoch: 7 Step: 781 Loss: 0.07400233998911512\n",
      "Epoch: 7 Step: 791 Loss: 0.08298464466236963\n",
      "Epoch: 7 Step: 801 Loss: 0.041461475887904505\n",
      "Epoch: 7 Step: 811 Loss: 0.051553733121347735\n",
      "Epoch: 7 Step: 821 Loss: 0.05177432302867663\n",
      "Epoch: 7 Step: 831 Loss: 0.07195513034556511\n",
      "Epoch: 7 Step: 841 Loss: 0.0077083247875961375\n",
      "Epoch: 7 Step: 851 Loss: 0.21475240822593783\n",
      "Epoch: 7 Step: 861 Loss: 0.012272722068314184\n",
      "Epoch: 7 Step: 871 Loss: 0.15578344672097794\n",
      "Epoch: 7 Step: 881 Loss: 0.1603354246847705\n",
      "Epoch: 7 Step: 891 Loss: 0.016123203557007967\n",
      "Epoch: 7 Step: 901 Loss: 0.20122081733742603\n",
      "Epoch: 7 Step: 911 Loss: 0.018890777887978837\n",
      "Epoch: 7 Step: 921 Loss: 0.01158091151805313\n",
      "Epoch: 7 Step: 931 Loss: 0.00275972432698463\n",
      "Epoch: 8 Step: 1 Loss: 0.05257511727000797\n",
      "Epoch: 8 Step: 11 Loss: 0.007198151538803345\n",
      "Epoch: 8 Step: 21 Loss: 0.19898804144935445\n",
      "Epoch: 8 Step: 31 Loss: 0.04698172188144078\n",
      "Epoch: 8 Step: 41 Loss: 0.007806707016709364\n",
      "Epoch: 8 Step: 51 Loss: 0.06490134732515264\n",
      "Epoch: 8 Step: 61 Loss: 0.03351851559419157\n",
      "Epoch: 8 Step: 71 Loss: 0.018389217758113946\n",
      "Epoch: 8 Step: 81 Loss: 0.029608206079646076\n",
      "Epoch: 8 Step: 91 Loss: 0.05309756003257929\n",
      "Epoch: 8 Step: 101 Loss: 0.1013024918110136\n",
      "Epoch: 8 Step: 111 Loss: 0.11037351922984591\n",
      "Epoch: 8 Step: 121 Loss: 0.057011510734124776\n",
      "Epoch: 8 Step: 131 Loss: 0.0168145486831793\n",
      "Epoch: 8 Step: 141 Loss: 0.051473674634078585\n",
      "Epoch: 8 Step: 151 Loss: 0.01967751882096417\n",
      "Epoch: 8 Step: 161 Loss: 0.0788595778603159\n",
      "Epoch: 8 Step: 171 Loss: 0.053608768204314934\n",
      "Epoch: 8 Step: 181 Loss: 0.014219446472006516\n",
      "Epoch: 8 Step: 191 Loss: 0.12299901334157969\n",
      "Epoch: 8 Step: 201 Loss: 0.05808269408931016\n",
      "Epoch: 8 Step: 211 Loss: 0.044634077674038465\n",
      "Epoch: 8 Step: 221 Loss: 0.14133862047802054\n",
      "Epoch: 8 Step: 231 Loss: 0.03835621351453434\n",
      "Epoch: 8 Step: 241 Loss: 0.07679519857106673\n",
      "Epoch: 8 Step: 251 Loss: 0.12633278172142798\n",
      "Epoch: 8 Step: 261 Loss: 0.10209133564079861\n",
      "Epoch: 8 Step: 271 Loss: 0.02969691110144115\n",
      "Epoch: 8 Step: 281 Loss: 0.04613889397011771\n",
      "Epoch: 8 Step: 291 Loss: 0.018291485923459902\n",
      "Epoch: 8 Step: 301 Loss: 0.06782529890829214\n",
      "Epoch: 8 Step: 311 Loss: 0.04853543625168005\n",
      "Epoch: 8 Step: 321 Loss: 0.01373642434727827\n",
      "Epoch: 8 Step: 331 Loss: 0.06260670987623534\n",
      "Epoch: 8 Step: 341 Loss: 0.05360786295448335\n",
      "Epoch: 8 Step: 351 Loss: 0.041800146548915576\n",
      "Epoch: 8 Step: 361 Loss: 0.0447931525703915\n",
      "Epoch: 8 Step: 371 Loss: 0.0829254748231308\n",
      "Epoch: 8 Step: 381 Loss: 0.018002578399778875\n",
      "Epoch: 8 Step: 391 Loss: 0.005620773112503713\n",
      "Epoch: 8 Step: 401 Loss: 0.010157678386541257\n",
      "Epoch: 8 Step: 411 Loss: 0.029461171393677234\n",
      "Epoch: 8 Step: 421 Loss: 0.0529412745533838\n",
      "Epoch: 8 Step: 431 Loss: 0.09346869785833413\n",
      "Epoch: 8 Step: 441 Loss: 0.042479485988451436\n",
      "Epoch: 8 Step: 451 Loss: 0.021925564210479455\n",
      "Epoch: 8 Step: 461 Loss: 0.006197009796071377\n",
      "Epoch: 8 Step: 471 Loss: 0.07979969049900897\n",
      "Epoch: 8 Step: 481 Loss: 0.062446448893678896\n",
      "Epoch: 8 Step: 491 Loss: 0.01536620322311469\n",
      "Epoch: 8 Step: 501 Loss: 0.018769911336688754\n",
      "Epoch: 8 Step: 511 Loss: 0.028958452677321368\n",
      "Epoch: 8 Step: 521 Loss: 0.03833986722298667\n",
      "Epoch: 8 Step: 531 Loss: 0.013674925141874251\n",
      "Epoch: 8 Step: 541 Loss: 0.006904664977644765\n",
      "Epoch: 8 Step: 551 Loss: 0.03153486311596102\n",
      "Epoch: 8 Step: 561 Loss: 0.005320944944762493\n",
      "Epoch: 8 Step: 571 Loss: 0.02820071767319684\n",
      "Epoch: 8 Step: 581 Loss: 0.02429396136446966\n",
      "Epoch: 8 Step: 591 Loss: 0.04574803555296663\n",
      "Epoch: 8 Step: 601 Loss: 0.0069254415852882615\n",
      "Epoch: 8 Step: 611 Loss: 0.006261700377594749\n",
      "Epoch: 8 Step: 621 Loss: 0.05310505042754785\n",
      "Epoch: 8 Step: 631 Loss: 0.03236816719108723\n",
      "Epoch: 8 Step: 641 Loss: 0.058899722552671\n",
      "Epoch: 8 Step: 651 Loss: 0.10839296437888318\n",
      "Epoch: 8 Step: 661 Loss: 0.009790292830931642\n",
      "Epoch: 8 Step: 671 Loss: 0.013382134338130153\n",
      "Epoch: 8 Step: 681 Loss: 0.13337344450027422\n",
      "Epoch: 8 Step: 691 Loss: 0.03480679524753269\n",
      "Epoch: 8 Step: 701 Loss: 0.24273664751949367\n",
      "Epoch: 8 Step: 711 Loss: 0.05020083477581537\n",
      "Epoch: 8 Step: 721 Loss: 0.03804469449857908\n",
      "Epoch: 8 Step: 731 Loss: 0.10152903199477684\n",
      "Epoch: 8 Step: 741 Loss: 0.007949315771294081\n",
      "Epoch: 8 Step: 751 Loss: 0.01814320890420744\n",
      "Epoch: 8 Step: 761 Loss: 0.02191756740497953\n",
      "Epoch: 8 Step: 771 Loss: 0.0066831685913729035\n",
      "Epoch: 8 Step: 781 Loss: 0.010175348726196834\n",
      "Epoch: 8 Step: 791 Loss: 0.0687811939347499\n",
      "Epoch: 8 Step: 801 Loss: 0.023432845237414877\n",
      "Epoch: 8 Step: 811 Loss: 0.01362367557838993\n",
      "Epoch: 8 Step: 821 Loss: 0.04138729587940589\n",
      "Epoch: 8 Step: 831 Loss: 0.05147876395987712\n",
      "Epoch: 8 Step: 841 Loss: 0.014657529120956955\n",
      "Epoch: 8 Step: 851 Loss: 0.08308325420225207\n",
      "Epoch: 8 Step: 861 Loss: 0.0035271493803586606\n",
      "Epoch: 8 Step: 871 Loss: 0.04365660404630075\n",
      "Epoch: 8 Step: 881 Loss: 0.029090910217528854\n",
      "Epoch: 8 Step: 891 Loss: 0.011922552856090254\n",
      "Epoch: 8 Step: 901 Loss: 0.14050957054087057\n",
      "Epoch: 8 Step: 911 Loss: 0.023781400137035905\n",
      "Epoch: 8 Step: 921 Loss: 0.0019843533152656507\n",
      "Epoch: 8 Step: 931 Loss: 0.02708868470993916\n",
      "Epoch: 9 Step: 1 Loss: 0.04258029194281897\n",
      "Epoch: 9 Step: 11 Loss: 0.015664667898341405\n",
      "Epoch: 9 Step: 21 Loss: 0.18380264883348957\n",
      "Epoch: 9 Step: 31 Loss: 0.024024215369782602\n",
      "Epoch: 9 Step: 41 Loss: 0.05307425857887936\n",
      "Epoch: 9 Step: 51 Loss: 0.06122330914501292\n",
      "Epoch: 9 Step: 61 Loss: 0.06810364468576482\n",
      "Epoch: 9 Step: 71 Loss: 0.004973622979965044\n",
      "Epoch: 9 Step: 81 Loss: 0.028906686424690308\n",
      "Epoch: 9 Step: 91 Loss: 0.04503708747865612\n",
      "Epoch: 9 Step: 101 Loss: 0.10635515277084187\n",
      "Epoch: 9 Step: 111 Loss: 0.13446316799469218\n",
      "Epoch: 9 Step: 121 Loss: 0.008671789162677697\n",
      "Epoch: 9 Step: 131 Loss: 0.006596929471547597\n",
      "Epoch: 9 Step: 141 Loss: 0.046186361039364715\n",
      "Epoch: 9 Step: 151 Loss: 0.23218518693330603\n",
      "Epoch: 9 Step: 161 Loss: 0.11508934370447406\n",
      "Epoch: 9 Step: 171 Loss: 0.01040020973362457\n",
      "Epoch: 9 Step: 181 Loss: 0.06542209708152333\n",
      "Epoch: 9 Step: 191 Loss: 0.011354248516059828\n",
      "Epoch: 9 Step: 201 Loss: 0.06464248247650911\n",
      "Epoch: 9 Step: 211 Loss: 0.027259533073283104\n",
      "Epoch: 9 Step: 221 Loss: 0.00708074068852636\n",
      "Epoch: 9 Step: 231 Loss: 0.11968036291914134\n",
      "Epoch: 9 Step: 241 Loss: 0.023176550432229433\n",
      "Epoch: 9 Step: 251 Loss: 0.12528139908000907\n",
      "Epoch: 9 Step: 261 Loss: 0.1446528351330162\n",
      "Epoch: 9 Step: 271 Loss: 0.12773070789312346\n",
      "Epoch: 9 Step: 281 Loss: 0.07834679301000827\n",
      "Epoch: 9 Step: 291 Loss: 0.07949576954850071\n",
      "Epoch: 9 Step: 301 Loss: 0.025141624021828075\n",
      "Epoch: 9 Step: 311 Loss: 0.11931504836615588\n",
      "Epoch: 9 Step: 321 Loss: 0.017994151264586495\n",
      "Epoch: 9 Step: 331 Loss: 0.11707273483454343\n",
      "Epoch: 9 Step: 341 Loss: 0.012085042525118831\n",
      "Epoch: 9 Step: 351 Loss: 0.07273843508724916\n",
      "Epoch: 9 Step: 361 Loss: 0.0674983256628683\n",
      "Epoch: 9 Step: 371 Loss: 0.017495929601661266\n",
      "Epoch: 9 Step: 381 Loss: 0.004971532355507051\n",
      "Epoch: 9 Step: 391 Loss: 0.005493453781197446\n",
      "Epoch: 9 Step: 401 Loss: 0.03581937221196424\n",
      "Epoch: 9 Step: 411 Loss: 0.1262540992352233\n",
      "Epoch: 9 Step: 421 Loss: 0.12751512527280892\n",
      "Epoch: 9 Step: 431 Loss: 0.12009750145899882\n",
      "Epoch: 9 Step: 441 Loss: 0.05575529839748566\n",
      "Epoch: 9 Step: 451 Loss: 0.03312560186433971\n",
      "Epoch: 9 Step: 461 Loss: 0.007966411066642571\n",
      "Epoch: 9 Step: 471 Loss: 0.045359121465903596\n",
      "Epoch: 9 Step: 481 Loss: 0.016727884704249765\n",
      "Epoch: 9 Step: 491 Loss: 0.05295638900942232\n",
      "Epoch: 9 Step: 501 Loss: 0.020401008584589486\n",
      "Epoch: 9 Step: 511 Loss: 0.17629544551543455\n",
      "Epoch: 9 Step: 521 Loss: 0.07420120442408575\n",
      "Epoch: 9 Step: 531 Loss: 0.002524388780134841\n",
      "Epoch: 9 Step: 541 Loss: 0.006475624812284554\n",
      "Epoch: 9 Step: 551 Loss: 0.05987299738984665\n",
      "Epoch: 9 Step: 561 Loss: 0.029001908598797387\n",
      "Epoch: 9 Step: 571 Loss: 0.027057093857414446\n",
      "Epoch: 9 Step: 581 Loss: 0.028761412312179227\n",
      "Epoch: 9 Step: 591 Loss: 0.09166467082714855\n",
      "Epoch: 9 Step: 601 Loss: 0.0704488824522145\n",
      "Epoch: 9 Step: 611 Loss: 0.02301526090409351\n",
      "Epoch: 9 Step: 621 Loss: 0.06513301614323241\n",
      "Epoch: 9 Step: 631 Loss: 0.010315151903364062\n",
      "Epoch: 9 Step: 641 Loss: 0.1132900767751317\n",
      "Epoch: 9 Step: 651 Loss: 0.006987570778118868\n",
      "Epoch: 9 Step: 661 Loss: 0.0985993312423117\n",
      "Epoch: 9 Step: 671 Loss: 0.0029083891834313586\n",
      "Epoch: 9 Step: 681 Loss: 0.03309605984190864\n",
      "Epoch: 9 Step: 691 Loss: 0.006999441724728833\n",
      "Epoch: 9 Step: 701 Loss: 0.164158870576916\n",
      "Epoch: 9 Step: 711 Loss: 0.04285313756016786\n",
      "Epoch: 9 Step: 721 Loss: 0.09091356543336888\n",
      "Epoch: 9 Step: 731 Loss: 0.06897565349127979\n",
      "Epoch: 9 Step: 741 Loss: 0.006455814155378391\n",
      "Epoch: 9 Step: 751 Loss: 0.07952928572566542\n",
      "Epoch: 9 Step: 761 Loss: 0.030283406526229864\n",
      "Epoch: 9 Step: 771 Loss: 0.029298396163877014\n",
      "Epoch: 9 Step: 781 Loss: 0.01258862225722666\n",
      "Epoch: 9 Step: 791 Loss: 0.08208470995454387\n",
      "Epoch: 9 Step: 801 Loss: 0.004103882752197121\n",
      "Epoch: 9 Step: 811 Loss: 0.007794304428191968\n",
      "Epoch: 9 Step: 821 Loss: 0.010114992614943443\n",
      "Epoch: 9 Step: 831 Loss: 0.014680053799588647\n",
      "Epoch: 9 Step: 841 Loss: 0.008850130174304381\n",
      "Epoch: 9 Step: 851 Loss: 0.04737803754356948\n",
      "Epoch: 9 Step: 861 Loss: 0.008450499312892781\n",
      "Epoch: 9 Step: 871 Loss: 0.07815603802495506\n",
      "Epoch: 9 Step: 881 Loss: 0.02962111725687638\n",
      "Epoch: 9 Step: 891 Loss: 0.04633141105316775\n",
      "Epoch: 9 Step: 901 Loss: 0.028732464166146787\n",
      "Epoch: 9 Step: 911 Loss: 0.02768937073470141\n",
      "Epoch: 9 Step: 921 Loss: 0.006714821673635952\n",
      "Epoch: 9 Step: 931 Loss: 0.0016869871788322843\n",
      "Epoch: 10 Step: 1 Loss: 0.020588429238960506\n",
      "Epoch: 10 Step: 11 Loss: 0.009994305007374651\n",
      "Epoch: 10 Step: 21 Loss: 0.17585680728169437\n",
      "Epoch: 10 Step: 31 Loss: 0.007129525058854804\n",
      "Epoch: 10 Step: 41 Loss: 0.046667737129949295\n",
      "Epoch: 10 Step: 51 Loss: 0.03134283448606055\n",
      "Epoch: 10 Step: 61 Loss: 0.01330224387416013\n",
      "Epoch: 10 Step: 71 Loss: 0.014469096953034406\n",
      "Epoch: 10 Step: 81 Loss: 0.025515423129829656\n",
      "Epoch: 10 Step: 91 Loss: 0.09802171755012973\n",
      "Epoch: 10 Step: 101 Loss: 0.035304341526962824\n",
      "Epoch: 10 Step: 111 Loss: 0.06548452106874243\n",
      "Epoch: 10 Step: 121 Loss: 0.04419779600077769\n",
      "Epoch: 10 Step: 131 Loss: 0.006821948865910114\n",
      "Epoch: 10 Step: 141 Loss: 0.03347015102329908\n",
      "Epoch: 10 Step: 151 Loss: 0.03189169176225757\n",
      "Epoch: 10 Step: 161 Loss: 0.24438790273404332\n",
      "Epoch: 10 Step: 171 Loss: 0.0058626076547126935\n",
      "Epoch: 10 Step: 181 Loss: 0.01847324345260665\n",
      "Epoch: 10 Step: 191 Loss: 0.012975661309874823\n",
      "Epoch: 10 Step: 201 Loss: 0.06188991951596594\n",
      "Epoch: 10 Step: 211 Loss: 0.012991243426361406\n",
      "Epoch: 10 Step: 221 Loss: 0.04142966758125413\n",
      "Epoch: 10 Step: 231 Loss: 0.04454435725776488\n",
      "Epoch: 10 Step: 241 Loss: 0.06978331004273583\n",
      "Epoch: 10 Step: 251 Loss: 0.06051985138560616\n",
      "Epoch: 10 Step: 261 Loss: 0.07176756383814978\n",
      "Epoch: 10 Step: 271 Loss: 0.05624251723968453\n",
      "Epoch: 10 Step: 281 Loss: 0.019379656656756804\n",
      "Epoch: 10 Step: 291 Loss: 0.04500111505836914\n",
      "Epoch: 10 Step: 301 Loss: 0.026813351122579075\n",
      "Epoch: 10 Step: 311 Loss: 0.04503545825247301\n",
      "Epoch: 10 Step: 321 Loss: 0.008011809595538657\n",
      "Epoch: 10 Step: 331 Loss: 0.03781621502234704\n",
      "Epoch: 10 Step: 341 Loss: 0.03506251207561417\n",
      "Epoch: 10 Step: 351 Loss: 0.052996442652222406\n",
      "Epoch: 10 Step: 361 Loss: 0.04146562824272267\n",
      "Epoch: 10 Step: 371 Loss: 0.05201783470023761\n",
      "Epoch: 10 Step: 381 Loss: 0.004705706651128757\n",
      "Epoch: 10 Step: 391 Loss: 0.00653850811310059\n",
      "Epoch: 10 Step: 401 Loss: 0.07626343659323889\n",
      "Epoch: 10 Step: 411 Loss: 0.013398590154520239\n",
      "Epoch: 10 Step: 421 Loss: 0.05362036792787334\n",
      "Epoch: 10 Step: 431 Loss: 0.08544111150609837\n",
      "Epoch: 10 Step: 441 Loss: 0.012327376053597744\n",
      "Epoch: 10 Step: 451 Loss: 0.04323383988794917\n",
      "Epoch: 10 Step: 461 Loss: 0.008526592202180366\n",
      "Epoch: 10 Step: 471 Loss: 0.13405248273770104\n",
      "Epoch: 10 Step: 481 Loss: 0.03134628423425742\n",
      "Epoch: 10 Step: 491 Loss: 0.02340125775068302\n",
      "Epoch: 10 Step: 501 Loss: 0.055432977784588916\n",
      "Epoch: 10 Step: 511 Loss: 0.0822074680377198\n",
      "Epoch: 10 Step: 521 Loss: 0.02442005339424224\n",
      "Epoch: 10 Step: 531 Loss: 0.002747517920729022\n",
      "Epoch: 10 Step: 541 Loss: 0.00763053396891962\n",
      "Epoch: 10 Step: 551 Loss: 0.047190733812138196\n",
      "Epoch: 10 Step: 561 Loss: 0.0246014187220495\n",
      "Epoch: 10 Step: 571 Loss: 0.012359172519319579\n",
      "Epoch: 10 Step: 581 Loss: 0.02544770528603797\n",
      "Epoch: 10 Step: 591 Loss: 0.059966877039360995\n",
      "Epoch: 10 Step: 601 Loss: 0.021095540682847004\n",
      "Epoch: 10 Step: 611 Loss: 0.002317440152088012\n",
      "Epoch: 10 Step: 621 Loss: 0.08302131873259785\n",
      "Epoch: 10 Step: 631 Loss: 0.03248936947784845\n",
      "Epoch: 10 Step: 641 Loss: 0.09403281820864749\n",
      "Epoch: 10 Step: 651 Loss: 0.011439341823548914\n",
      "Epoch: 10 Step: 661 Loss: 0.04910412546904863\n",
      "Epoch: 10 Step: 671 Loss: 0.06636742716769888\n",
      "Epoch: 10 Step: 681 Loss: 0.06973040901204398\n",
      "Epoch: 10 Step: 691 Loss: 0.005651266168221064\n",
      "Epoch: 10 Step: 701 Loss: 0.12211950155124282\n",
      "Epoch: 10 Step: 711 Loss: 0.008970760663820607\n",
      "Epoch: 10 Step: 721 Loss: 0.031134060812179714\n",
      "Epoch: 10 Step: 731 Loss: 0.014228904279173928\n",
      "Epoch: 10 Step: 741 Loss: 0.0017698412912070449\n",
      "Epoch: 10 Step: 751 Loss: 0.04790976518151224\n",
      "Epoch: 10 Step: 761 Loss: 0.025101427756663162\n",
      "Epoch: 10 Step: 771 Loss: 0.013463736030333205\n",
      "Epoch: 10 Step: 781 Loss: 0.014865559445298333\n",
      "Epoch: 10 Step: 791 Loss: 0.053605613755770526\n",
      "Epoch: 10 Step: 801 Loss: 0.027428213846285597\n",
      "Epoch: 10 Step: 811 Loss: 0.02992467631832147\n",
      "Epoch: 10 Step: 821 Loss: 0.00908828455604211\n",
      "Epoch: 10 Step: 831 Loss: 0.011920742948956183\n",
      "Epoch: 10 Step: 841 Loss: 0.03957639523907116\n",
      "Epoch: 10 Step: 851 Loss: 0.09652627087368863\n",
      "Epoch: 10 Step: 861 Loss: 0.004164362781755595\n",
      "Epoch: 10 Step: 871 Loss: 0.058990719664076575\n",
      "Epoch: 10 Step: 881 Loss: 0.04495264925823766\n",
      "Epoch: 10 Step: 891 Loss: 0.027298047408844596\n",
      "Epoch: 10 Step: 901 Loss: 0.10474719761845516\n",
      "Epoch: 10 Step: 911 Loss: 0.039764605127241115\n",
      "Epoch: 10 Step: 921 Loss: 0.0024934642828415552\n",
      "Epoch: 10 Step: 931 Loss: 0.009483619233072588\n",
      "Epoch: 11 Step: 1 Loss: 0.0048120893725661215\n",
      "Epoch: 11 Step: 11 Loss: 0.010073095578326802\n",
      "Epoch: 11 Step: 21 Loss: 0.03719350751086308\n",
      "Epoch: 11 Step: 31 Loss: 0.04749655641795887\n",
      "Epoch: 11 Step: 41 Loss: 0.038219412291973814\n",
      "Epoch: 11 Step: 51 Loss: 0.0810123979779204\n",
      "Epoch: 11 Step: 61 Loss: 0.00649227141870703\n",
      "Epoch: 11 Step: 71 Loss: 0.004895185188272328\n",
      "Epoch: 11 Step: 81 Loss: 0.07349127361205866\n",
      "Epoch: 11 Step: 91 Loss: 0.03686812860641388\n",
      "Epoch: 11 Step: 101 Loss: 0.014018243500402514\n",
      "Epoch: 11 Step: 111 Loss: 0.07806118118970212\n",
      "Epoch: 11 Step: 121 Loss: 0.010181708248846122\n",
      "Epoch: 11 Step: 131 Loss: 0.034137437983052396\n",
      "Epoch: 11 Step: 141 Loss: 0.01795296892749031\n",
      "Epoch: 11 Step: 151 Loss: 0.02726900028695188\n",
      "Epoch: 11 Step: 161 Loss: 0.11104960556729579\n",
      "Epoch: 11 Step: 171 Loss: 0.021838173006796746\n",
      "Epoch: 11 Step: 181 Loss: 0.018474652295319187\n",
      "Epoch: 11 Step: 191 Loss: 0.09028293686059502\n",
      "Epoch: 11 Step: 201 Loss: 0.01872321492184202\n",
      "Epoch: 11 Step: 211 Loss: 0.008540321641576356\n",
      "Epoch: 11 Step: 221 Loss: 0.011683236665955898\n",
      "Epoch: 11 Step: 231 Loss: 0.05548424776543639\n",
      "Epoch: 11 Step: 241 Loss: 0.03382421862018448\n",
      "Epoch: 11 Step: 251 Loss: 0.02554324464787729\n",
      "Epoch: 11 Step: 261 Loss: 0.06693221029693881\n",
      "Epoch: 11 Step: 271 Loss: 0.0056079562352261145\n",
      "Epoch: 11 Step: 281 Loss: 0.05078414067300469\n",
      "Epoch: 11 Step: 291 Loss: 0.009130572885015573\n",
      "Epoch: 11 Step: 301 Loss: 0.02048663426970814\n",
      "Epoch: 11 Step: 311 Loss: 0.006457471271236099\n",
      "Epoch: 11 Step: 321 Loss: 0.043599548752416686\n",
      "Epoch: 11 Step: 331 Loss: 0.018926876808519455\n",
      "Epoch: 11 Step: 341 Loss: 0.035352173872136794\n",
      "Epoch: 11 Step: 351 Loss: 0.03221986836973334\n",
      "Epoch: 11 Step: 361 Loss: 0.00979010498425344\n",
      "Epoch: 11 Step: 371 Loss: 0.021137041380498215\n",
      "Epoch: 11 Step: 381 Loss: 0.00507330861005836\n",
      "Epoch: 11 Step: 391 Loss: 0.010570143527861803\n",
      "Epoch: 11 Step: 401 Loss: 0.011768224982941588\n",
      "Epoch: 11 Step: 411 Loss: 0.002506543831831516\n",
      "Epoch: 11 Step: 421 Loss: 0.054071833239061395\n",
      "Epoch: 11 Step: 431 Loss: 0.13583971027718522\n",
      "Epoch: 11 Step: 441 Loss: 0.00398440681053726\n",
      "Epoch: 11 Step: 451 Loss: 0.00749199766344603\n",
      "Epoch: 11 Step: 461 Loss: 0.046980010524519146\n",
      "Epoch: 11 Step: 471 Loss: 0.006038325865308654\n",
      "Epoch: 11 Step: 481 Loss: 0.01906979425533048\n",
      "Epoch: 11 Step: 491 Loss: 0.02247711702241962\n",
      "Epoch: 11 Step: 501 Loss: 0.011710152697126072\n",
      "Epoch: 11 Step: 511 Loss: 0.012090582683442428\n",
      "Epoch: 11 Step: 521 Loss: 0.005169180490128492\n",
      "Epoch: 11 Step: 531 Loss: 0.0011389315784147485\n",
      "Epoch: 11 Step: 541 Loss: 0.0034810011478602896\n",
      "Epoch: 11 Step: 551 Loss: 0.011314683769735387\n",
      "Epoch: 11 Step: 561 Loss: 0.023764790333078493\n",
      "Epoch: 11 Step: 571 Loss: 0.014447411185579424\n",
      "Epoch: 11 Step: 581 Loss: 0.12325318954438282\n",
      "Epoch: 11 Step: 591 Loss: 0.010348453087820576\n",
      "Epoch: 11 Step: 601 Loss: 0.0025563968754363947\n",
      "Epoch: 11 Step: 611 Loss: 0.0029945928637405577\n",
      "Epoch: 11 Step: 621 Loss: 0.021992951580270263\n",
      "Epoch: 11 Step: 631 Loss: 0.06265320657348583\n",
      "Epoch: 11 Step: 641 Loss: 0.00747603777080726\n",
      "Epoch: 11 Step: 651 Loss: 0.011684832871357713\n",
      "Epoch: 11 Step: 661 Loss: 0.004685962648699087\n",
      "Epoch: 11 Step: 671 Loss: 0.0031262134792134854\n",
      "Epoch: 11 Step: 681 Loss: 0.13025994960772846\n",
      "Epoch: 11 Step: 691 Loss: 0.0028650582049397676\n",
      "Epoch: 11 Step: 701 Loss: 0.1442291915170972\n",
      "Epoch: 11 Step: 711 Loss: 0.020832711533534103\n",
      "Epoch: 11 Step: 721 Loss: 0.01652951576704125\n",
      "Epoch: 11 Step: 731 Loss: 0.0795070747061077\n",
      "Epoch: 11 Step: 741 Loss: 0.011332298393861295\n",
      "Epoch: 11 Step: 751 Loss: 0.003507230810407838\n",
      "Epoch: 11 Step: 761 Loss: 0.011618898952822736\n",
      "Epoch: 11 Step: 771 Loss: 0.001616177311020252\n",
      "Epoch: 11 Step: 781 Loss: 0.05565562269586591\n",
      "Epoch: 11 Step: 791 Loss: 0.02044763493592263\n",
      "Epoch: 11 Step: 801 Loss: 0.006891572606191536\n",
      "Epoch: 11 Step: 811 Loss: 0.017470483992990032\n",
      "Epoch: 11 Step: 821 Loss: 0.027408975806300695\n",
      "Epoch: 11 Step: 831 Loss: 0.08913904670412859\n",
      "Epoch: 11 Step: 841 Loss: 0.03067665281855964\n",
      "Epoch: 11 Step: 851 Loss: 0.03476918702048349\n",
      "Epoch: 11 Step: 861 Loss: 0.0042192031550004755\n",
      "Epoch: 11 Step: 871 Loss: 0.04336331459023267\n",
      "Epoch: 11 Step: 881 Loss: 0.06119958748664536\n",
      "Epoch: 11 Step: 891 Loss: 0.010577082569522011\n",
      "Epoch: 11 Step: 901 Loss: 0.055757589543363774\n",
      "Epoch: 11 Step: 911 Loss: 0.002347917647341838\n",
      "Epoch: 11 Step: 921 Loss: 0.0010407465241622084\n",
      "Epoch: 11 Step: 931 Loss: 0.01580979105986629\n",
      "Epoch: 12 Step: 1 Loss: 0.008640914815546734\n",
      "Epoch: 12 Step: 11 Loss: 0.037393767253007096\n",
      "Epoch: 12 Step: 21 Loss: 0.07284278613447054\n",
      "Epoch: 12 Step: 31 Loss: 0.015344984979101552\n",
      "Epoch: 12 Step: 41 Loss: 0.021269596807602417\n",
      "Epoch: 12 Step: 51 Loss: 0.0052673834946167074\n",
      "Epoch: 12 Step: 61 Loss: 0.028090745024979213\n",
      "Epoch: 12 Step: 71 Loss: 0.005976971467700362\n",
      "Epoch: 12 Step: 81 Loss: 0.013806544388317134\n",
      "Epoch: 12 Step: 91 Loss: 0.05811748270557464\n",
      "Epoch: 12 Step: 101 Loss: 0.07562848281408627\n",
      "Epoch: 12 Step: 111 Loss: 0.0617256087848502\n",
      "Epoch: 12 Step: 121 Loss: 0.010252057741562688\n",
      "Epoch: 12 Step: 131 Loss: 0.010983950963879703\n",
      "Epoch: 12 Step: 141 Loss: 0.01704917551382058\n",
      "Epoch: 12 Step: 151 Loss: 0.07841310154025305\n",
      "Epoch: 12 Step: 161 Loss: 0.035744881517765635\n",
      "Epoch: 12 Step: 171 Loss: 0.004032159045994328\n",
      "Epoch: 12 Step: 181 Loss: 0.009704477559732718\n",
      "Epoch: 12 Step: 191 Loss: 0.0050395529594672315\n",
      "Epoch: 12 Step: 201 Loss: 0.021460043011131927\n",
      "Epoch: 12 Step: 211 Loss: 0.01072571966086994\n",
      "Epoch: 12 Step: 221 Loss: 0.00514697932562588\n",
      "Epoch: 12 Step: 231 Loss: 0.018335857673835845\n",
      "Epoch: 12 Step: 241 Loss: 0.02335881923295563\n",
      "Epoch: 12 Step: 251 Loss: 0.09570010002918941\n",
      "Epoch: 12 Step: 261 Loss: 0.027855812195467143\n",
      "Epoch: 12 Step: 271 Loss: 0.017558858833475688\n",
      "Epoch: 12 Step: 281 Loss: 0.01514103545690243\n",
      "Epoch: 12 Step: 291 Loss: 0.0023067948139796823\n",
      "Epoch: 12 Step: 301 Loss: 0.015030610817613206\n",
      "Epoch: 12 Step: 311 Loss: 0.018684992915747194\n",
      "Epoch: 12 Step: 321 Loss: 0.003345098828570891\n",
      "Epoch: 12 Step: 331 Loss: 0.005802355129133985\n",
      "Epoch: 12 Step: 341 Loss: 0.010408631876049401\n",
      "Epoch: 12 Step: 351 Loss: 0.032002132881674375\n",
      "Epoch: 12 Step: 361 Loss: 0.011737138142423727\n",
      "Epoch: 12 Step: 371 Loss: 0.020251647961761716\n",
      "Epoch: 12 Step: 381 Loss: 0.006413643074399745\n",
      "Epoch: 12 Step: 391 Loss: 0.0035165098808468275\n",
      "Epoch: 12 Step: 401 Loss: 0.02114252200960502\n",
      "Epoch: 12 Step: 411 Loss: 0.024952146431652365\n",
      "Epoch: 12 Step: 421 Loss: 0.01050130841775616\n",
      "Epoch: 12 Step: 431 Loss: 0.10091939649975463\n",
      "Epoch: 12 Step: 441 Loss: 0.11230514042900695\n",
      "Epoch: 12 Step: 451 Loss: 0.0057909362371772214\n",
      "Epoch: 12 Step: 461 Loss: 0.06625776700712113\n",
      "Epoch: 12 Step: 471 Loss: 0.03103172274637695\n",
      "Epoch: 12 Step: 481 Loss: 0.013842887404230002\n",
      "Epoch: 12 Step: 491 Loss: 0.02293777012322716\n",
      "Epoch: 12 Step: 501 Loss: 0.0035361207893808092\n",
      "Epoch: 12 Step: 511 Loss: 0.009158014531571206\n",
      "Epoch: 12 Step: 521 Loss: 0.0029780829101876704\n",
      "Epoch: 12 Step: 531 Loss: 0.001798067901314591\n",
      "Epoch: 12 Step: 541 Loss: 0.010598267379546293\n",
      "Epoch: 12 Step: 551 Loss: 0.03227162609888322\n",
      "Epoch: 12 Step: 561 Loss: 0.011255070378825015\n",
      "Epoch: 12 Step: 571 Loss: 0.011013332020698128\n",
      "Epoch: 12 Step: 581 Loss: 0.056353392303361886\n",
      "Epoch: 12 Step: 591 Loss: 0.12011891078687639\n",
      "Epoch: 12 Step: 601 Loss: 0.003769324519271691\n",
      "Epoch: 12 Step: 611 Loss: 0.005705742808134596\n",
      "Epoch: 12 Step: 621 Loss: 0.01080742281192487\n",
      "Epoch: 12 Step: 631 Loss: 0.023137189844126785\n",
      "Epoch: 12 Step: 641 Loss: 0.08962786990751435\n",
      "Epoch: 12 Step: 651 Loss: 0.006562936219833679\n",
      "Epoch: 12 Step: 661 Loss: 0.024834545170079696\n",
      "Epoch: 12 Step: 671 Loss: 0.005740340255116832\n",
      "Epoch: 12 Step: 681 Loss: 0.0407655823239195\n",
      "Epoch: 12 Step: 691 Loss: 0.013535729096087488\n",
      "Epoch: 12 Step: 701 Loss: 0.09776682091701018\n",
      "Epoch: 12 Step: 711 Loss: 0.006921303037794414\n",
      "Epoch: 12 Step: 721 Loss: 0.023358586080110887\n",
      "Epoch: 12 Step: 731 Loss: 0.07022367741673309\n",
      "Epoch: 12 Step: 741 Loss: 0.011411943357335337\n",
      "Epoch: 12 Step: 751 Loss: 0.10593897774760241\n",
      "Epoch: 12 Step: 761 Loss: 0.010364912074078404\n",
      "Epoch: 12 Step: 771 Loss: 0.0010862751993253078\n",
      "Epoch: 12 Step: 781 Loss: 0.03358928839099574\n",
      "Epoch: 12 Step: 791 Loss: 0.059298611434625295\n",
      "Epoch: 12 Step: 801 Loss: 0.017059842480082608\n",
      "Epoch: 12 Step: 811 Loss: 0.02268070181144195\n",
      "Epoch: 12 Step: 821 Loss: 0.017539639869923376\n",
      "Epoch: 12 Step: 831 Loss: 0.054895698563159984\n",
      "Epoch: 12 Step: 841 Loss: 0.038044927347724765\n",
      "Epoch: 12 Step: 851 Loss: 0.10292473527253838\n",
      "Epoch: 12 Step: 861 Loss: 0.006720729990873317\n",
      "Epoch: 12 Step: 871 Loss: 0.14491823804307694\n",
      "Epoch: 12 Step: 881 Loss: 0.007906937395635676\n",
      "Epoch: 12 Step: 891 Loss: 0.014628332492292378\n",
      "Epoch: 12 Step: 901 Loss: 0.007989954783766474\n",
      "Epoch: 12 Step: 911 Loss: 0.0025535978762516545\n",
      "Epoch: 12 Step: 921 Loss: 0.0009281382841968339\n",
      "Epoch: 12 Step: 931 Loss: 0.0015541942223972793\n",
      "Epoch: 13 Step: 1 Loss: 0.005939671577389837\n",
      "Epoch: 13 Step: 11 Loss: 0.002799687314884983\n",
      "Epoch: 13 Step: 21 Loss: 0.01585862477689411\n",
      "Epoch: 13 Step: 31 Loss: 0.016348454769865454\n",
      "Epoch: 13 Step: 41 Loss: 0.012914194204405316\n",
      "Epoch: 13 Step: 51 Loss: 0.006366898082328938\n",
      "Epoch: 13 Step: 61 Loss: 0.0022633237487053727\n",
      "Epoch: 13 Step: 71 Loss: 0.05902772248899501\n",
      "Epoch: 13 Step: 81 Loss: 0.045675073238692056\n",
      "Epoch: 13 Step: 91 Loss: 0.08962465549468174\n",
      "Epoch: 13 Step: 101 Loss: 0.03802095415714142\n",
      "Epoch: 13 Step: 111 Loss: 0.1465346103189638\n",
      "Epoch: 13 Step: 121 Loss: 0.008815692186888142\n",
      "Epoch: 13 Step: 131 Loss: 0.0023429835225099215\n",
      "Epoch: 13 Step: 141 Loss: 0.07805344243243054\n",
      "Epoch: 13 Step: 151 Loss: 0.03731880547134333\n",
      "Epoch: 13 Step: 161 Loss: 0.07014413775152226\n",
      "Epoch: 13 Step: 171 Loss: 0.0019093934658160614\n",
      "Epoch: 13 Step: 181 Loss: 0.018725720425449104\n",
      "Epoch: 13 Step: 191 Loss: 0.01947978018547216\n",
      "Epoch: 13 Step: 201 Loss: 0.011805637059185189\n",
      "Epoch: 13 Step: 211 Loss: 0.007997578067626606\n",
      "Epoch: 13 Step: 221 Loss: 0.006531965467127574\n",
      "Epoch: 13 Step: 231 Loss: 0.03213788292737366\n",
      "Epoch: 13 Step: 241 Loss: 0.030223094278336624\n",
      "Epoch: 13 Step: 251 Loss: 0.10417010630586603\n",
      "Epoch: 13 Step: 261 Loss: 0.034696271990703874\n",
      "Epoch: 13 Step: 271 Loss: 0.025507366625747548\n",
      "Epoch: 13 Step: 281 Loss: 0.05406070924915392\n",
      "Epoch: 13 Step: 291 Loss: 0.0023058046010304744\n",
      "Epoch: 13 Step: 301 Loss: 0.04748028529098036\n",
      "Epoch: 13 Step: 311 Loss: 0.010881899348716749\n",
      "Epoch: 13 Step: 321 Loss: 0.0028191225173154924\n",
      "Epoch: 13 Step: 331 Loss: 0.009351470315485175\n",
      "Epoch: 13 Step: 341 Loss: 0.0021932461545940973\n",
      "Epoch: 13 Step: 351 Loss: 0.021767074550533998\n",
      "Epoch: 13 Step: 361 Loss: 0.08999771609310361\n",
      "Epoch: 13 Step: 371 Loss: 0.02849111877550986\n",
      "Epoch: 13 Step: 381 Loss: 0.007828490342141513\n",
      "Epoch: 13 Step: 391 Loss: 0.002760583478902164\n",
      "Epoch: 13 Step: 401 Loss: 0.01991017945423696\n",
      "Epoch: 13 Step: 411 Loss: 0.006504705019537753\n",
      "Epoch: 13 Step: 421 Loss: 0.012474235837085046\n",
      "Epoch: 13 Step: 431 Loss: 0.09021999167323179\n",
      "Epoch: 13 Step: 441 Loss: 0.01419762196305005\n",
      "Epoch: 13 Step: 451 Loss: 0.005167267819539074\n",
      "Epoch: 13 Step: 461 Loss: 0.013674434140235194\n",
      "Epoch: 13 Step: 471 Loss: 0.006959418996294766\n",
      "Epoch: 13 Step: 481 Loss: 0.0038692672751975323\n",
      "Epoch: 13 Step: 491 Loss: 0.026167237804127483\n",
      "Epoch: 13 Step: 501 Loss: 0.00319262983826865\n",
      "Epoch: 13 Step: 511 Loss: 0.055486036921785546\n",
      "Epoch: 13 Step: 521 Loss: 0.056598222725318725\n",
      "Epoch: 13 Step: 531 Loss: 0.01859831663648461\n",
      "Epoch: 13 Step: 541 Loss: 0.04801070586780959\n",
      "Epoch: 13 Step: 551 Loss: 0.029811406559649107\n",
      "Epoch: 13 Step: 561 Loss: 0.0023978693497165963\n",
      "Epoch: 13 Step: 571 Loss: 0.01934437891526756\n",
      "Epoch: 13 Step: 581 Loss: 0.013114773419837487\n",
      "Epoch: 13 Step: 591 Loss: 0.04658694850578951\n",
      "Epoch: 13 Step: 601 Loss: 0.0011692405188746023\n",
      "Epoch: 13 Step: 611 Loss: 0.002463346476417009\n",
      "Epoch: 13 Step: 621 Loss: 0.04141883538603339\n",
      "Epoch: 13 Step: 631 Loss: 0.00304910448893157\n",
      "Epoch: 13 Step: 641 Loss: 0.004430401781256909\n",
      "Epoch: 13 Step: 651 Loss: 0.011769040251515055\n",
      "Epoch: 13 Step: 661 Loss: 0.0014554315506903198\n",
      "Epoch: 13 Step: 671 Loss: 0.010249244867603003\n",
      "Epoch: 13 Step: 681 Loss: 0.02242212179458053\n",
      "Epoch: 13 Step: 691 Loss: 0.029523181986646316\n",
      "Epoch: 13 Step: 701 Loss: 0.028518466372822862\n",
      "Epoch: 13 Step: 711 Loss: 0.02964739374654346\n",
      "Epoch: 13 Step: 721 Loss: 0.0433614164728979\n",
      "Epoch: 13 Step: 731 Loss: 0.09614907862530425\n",
      "Epoch: 13 Step: 741 Loss: 0.00645518249142102\n",
      "Epoch: 13 Step: 751 Loss: 0.05151906314667305\n",
      "Epoch: 13 Step: 761 Loss: 0.013942040438006125\n",
      "Epoch: 13 Step: 771 Loss: 0.001285748011457805\n",
      "Epoch: 13 Step: 781 Loss: 0.018607993389243068\n",
      "Epoch: 13 Step: 791 Loss: 0.009916495562673974\n",
      "Epoch: 13 Step: 801 Loss: 0.01797156197861191\n",
      "Epoch: 13 Step: 811 Loss: 0.014039466489331328\n",
      "Epoch: 13 Step: 821 Loss: 0.04479066698505608\n",
      "Epoch: 13 Step: 831 Loss: 0.017893508922427165\n",
      "Epoch: 13 Step: 841 Loss: 0.004379355106526315\n",
      "Epoch: 13 Step: 851 Loss: 0.013055196842084574\n",
      "Epoch: 13 Step: 861 Loss: 0.007635875872413629\n",
      "Epoch: 13 Step: 871 Loss: 0.03828559798329811\n",
      "Epoch: 13 Step: 881 Loss: 0.04761005921801753\n",
      "Epoch: 13 Step: 891 Loss: 0.007606481521358139\n",
      "Epoch: 13 Step: 901 Loss: 0.11448059912735026\n",
      "Epoch: 13 Step: 911 Loss: 0.005443352842838984\n",
      "Epoch: 13 Step: 921 Loss: 0.0037073753190032025\n",
      "Epoch: 13 Step: 931 Loss: 0.002121746914852821\n",
      "Epoch: 14 Step: 1 Loss: 0.015299105447290651\n",
      "Epoch: 14 Step: 11 Loss: 0.025582103885281055\n",
      "Epoch: 14 Step: 21 Loss: 0.033766069855694004\n",
      "Epoch: 14 Step: 31 Loss: 0.007408830394565773\n",
      "Epoch: 14 Step: 41 Loss: 0.0037426364200107975\n",
      "Epoch: 14 Step: 51 Loss: 0.0722730476750359\n",
      "Epoch: 14 Step: 61 Loss: 0.002238282698953042\n",
      "Epoch: 14 Step: 71 Loss: 0.0066099155097306276\n",
      "Epoch: 14 Step: 81 Loss: 0.02714398220969723\n",
      "Epoch: 14 Step: 91 Loss: 0.013652682532938495\n",
      "Epoch: 14 Step: 101 Loss: 0.04711746657207158\n",
      "Epoch: 14 Step: 111 Loss: 0.05400384984817046\n",
      "Epoch: 14 Step: 121 Loss: 0.0017465126070076538\n",
      "Epoch: 14 Step: 131 Loss: 0.007548970035017779\n",
      "Epoch: 14 Step: 141 Loss: 0.09130748148758387\n",
      "Epoch: 14 Step: 151 Loss: 0.13667218074311185\n",
      "Epoch: 14 Step: 161 Loss: 0.10268048948383882\n",
      "Epoch: 14 Step: 171 Loss: 0.01984797646625591\n",
      "Epoch: 14 Step: 181 Loss: 0.033838725355266996\n",
      "Epoch: 14 Step: 191 Loss: 0.0046187574558913735\n",
      "Epoch: 14 Step: 201 Loss: 0.035031996286795604\n",
      "Epoch: 14 Step: 211 Loss: 0.011561327886950079\n",
      "Epoch: 14 Step: 221 Loss: 0.006435915763102715\n",
      "Epoch: 14 Step: 231 Loss: 0.0362139572728188\n",
      "Epoch: 14 Step: 241 Loss: 0.009089975240968488\n",
      "Epoch: 14 Step: 251 Loss: 0.03787923533139458\n",
      "Epoch: 14 Step: 261 Loss: 0.06828361218387585\n",
      "Epoch: 14 Step: 271 Loss: 0.029382675497759577\n",
      "Epoch: 14 Step: 281 Loss: 0.08985660096623792\n",
      "Epoch: 14 Step: 291 Loss: 0.03019470489632285\n",
      "Epoch: 14 Step: 301 Loss: 0.010189291306609076\n",
      "Epoch: 14 Step: 311 Loss: 0.0029904291135327936\n",
      "Epoch: 14 Step: 321 Loss: 0.00710756793228574\n",
      "Epoch: 14 Step: 331 Loss: 0.017829482554914903\n",
      "Epoch: 14 Step: 341 Loss: 0.009647310856232407\n",
      "Epoch: 14 Step: 351 Loss: 0.008791933977185657\n",
      "Epoch: 14 Step: 361 Loss: 0.024557297768923604\n",
      "Epoch: 14 Step: 371 Loss: 0.012557899369904027\n",
      "Epoch: 14 Step: 381 Loss: 0.003126803429038893\n",
      "Epoch: 14 Step: 391 Loss: 0.007420724323920629\n",
      "Epoch: 14 Step: 401 Loss: 0.028235888845520717\n",
      "Epoch: 14 Step: 411 Loss: 0.005585943139667578\n",
      "Epoch: 14 Step: 421 Loss: 0.011776539777337766\n",
      "Epoch: 14 Step: 431 Loss: 0.06435769839481101\n",
      "Epoch: 14 Step: 441 Loss: 0.0243709695958261\n",
      "Epoch: 14 Step: 451 Loss: 0.041501073317351755\n",
      "Epoch: 14 Step: 461 Loss: 0.013490030967402694\n",
      "Epoch: 14 Step: 471 Loss: 0.011913474360558297\n",
      "Epoch: 14 Step: 481 Loss: 0.004175681298175389\n",
      "Epoch: 14 Step: 491 Loss: 0.004213444417944925\n",
      "Epoch: 14 Step: 501 Loss: 0.09386009314960392\n",
      "Epoch: 14 Step: 511 Loss: 0.00825202394912045\n",
      "Epoch: 14 Step: 521 Loss: 0.011705927915907195\n",
      "Epoch: 14 Step: 531 Loss: 0.03374276898349813\n",
      "Epoch: 14 Step: 541 Loss: 0.0022218111489201017\n",
      "Epoch: 14 Step: 551 Loss: 0.014835974424237858\n",
      "Epoch: 14 Step: 561 Loss: 0.003738216158692947\n",
      "Epoch: 14 Step: 571 Loss: 0.005588741989852278\n",
      "Epoch: 14 Step: 581 Loss: 0.07313044014378263\n",
      "Epoch: 14 Step: 591 Loss: 0.01645913573778082\n",
      "Epoch: 14 Step: 601 Loss: 0.022254175686999257\n",
      "Epoch: 14 Step: 611 Loss: 0.0034100476377705424\n",
      "Epoch: 14 Step: 621 Loss: 0.023028455019873165\n",
      "Epoch: 14 Step: 631 Loss: 0.015580817790443926\n",
      "Epoch: 14 Step: 641 Loss: 0.0062524213399147485\n",
      "Epoch: 14 Step: 651 Loss: 0.0019172993100529047\n",
      "Epoch: 14 Step: 661 Loss: 0.00841597764110597\n",
      "Epoch: 14 Step: 671 Loss: 0.0026718563609873626\n",
      "Epoch: 14 Step: 681 Loss: 0.04053482929139562\n",
      "Epoch: 14 Step: 691 Loss: 0.006354261208543325\n",
      "Epoch: 14 Step: 701 Loss: 0.111491495388147\n",
      "Epoch: 14 Step: 711 Loss: 0.05376169330499732\n",
      "Epoch: 14 Step: 721 Loss: 0.040445036773907574\n",
      "Epoch: 14 Step: 731 Loss: 0.10796536552398503\n",
      "Epoch: 14 Step: 741 Loss: 0.017736792951427154\n",
      "Epoch: 14 Step: 751 Loss: 0.024325584188420214\n",
      "Epoch: 14 Step: 761 Loss: 0.004806066997727041\n",
      "Epoch: 14 Step: 771 Loss: 0.0016427177867269337\n",
      "Epoch: 14 Step: 781 Loss: 0.024692820594149796\n",
      "Epoch: 14 Step: 791 Loss: 0.023635930703736388\n",
      "Epoch: 14 Step: 801 Loss: 0.002372881805203921\n",
      "Epoch: 14 Step: 811 Loss: 0.004690843524664905\n",
      "Epoch: 14 Step: 821 Loss: 0.014776039124998865\n",
      "Epoch: 14 Step: 831 Loss: 0.009075666485521737\n",
      "Epoch: 14 Step: 841 Loss: 0.0035579898611691274\n",
      "Epoch: 14 Step: 851 Loss: 0.01864861642533802\n",
      "Epoch: 14 Step: 861 Loss: 0.00496064588946766\n",
      "Epoch: 14 Step: 871 Loss: 0.0379684626896644\n",
      "Epoch: 14 Step: 881 Loss: 0.0031941255338479905\n",
      "Epoch: 14 Step: 891 Loss: 0.005981267124120177\n",
      "Epoch: 14 Step: 901 Loss: 0.011951364462689948\n",
      "Epoch: 14 Step: 911 Loss: 0.0024985517557363423\n",
      "Epoch: 14 Step: 921 Loss: 0.001641615777258374\n",
      "Epoch: 14 Step: 931 Loss: 0.0021309834018887336\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score is 0.9760333333333333\n",
      "Score is 0.961738782051282\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "model = DenseNet(datasets='mnist', opt='sgd')\n",
    "model.datas = [data, label]\n",
    "model.train(15)\n",
    "plt.plot(np.arange(len(model.history)), model.history)\n",
    "plt.show()\n",
    "np.savetxt('/home/oneran/Downloads/sgd_mnist_DenseNet_history.txt', model.history)\n",
    "model.save_model('/home/oneran/机器学习课设/cifar-10/Photon/sgd_mnist_DenseNet.pkl')\n",
    "score, pred = model.score(X_train, Y_train)\n",
    "score, pred = model.score(X_test, Y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 0 Step: 1 Loss: 2.3031780564871465\n",
      "Epoch: 0 Step: 11 Loss: 2.2264225782079694\n",
      "Epoch: 0 Step: 21 Loss: 2.3025087324242506\n",
      "Epoch: 0 Step: 31 Loss: 2.122275184828082\n",
      "Epoch: 0 Step: 41 Loss: 2.000779618374798\n",
      "Epoch: 0 Step: 51 Loss: 2.0720483191195624\n",
      "Epoch: 0 Step: 61 Loss: 2.0549649783310695\n",
      "Epoch: 0 Step: 71 Loss: 2.0237443425726087\n",
      "Epoch: 0 Step: 81 Loss: 2.049522499766515\n",
      "Epoch: 0 Step: 91 Loss: 2.1088937464254984\n",
      "Epoch: 0 Step: 101 Loss: 2.0102458710364814\n",
      "Epoch: 0 Step: 111 Loss: 2.0894018307277626\n",
      "Epoch: 0 Step: 121 Loss: 2.017222489637224\n",
      "Epoch: 0 Step: 131 Loss: 2.0292460225920244\n",
      "Epoch: 0 Step: 141 Loss: 2.0243227306997973\n",
      "Epoch: 0 Step: 151 Loss: 2.363813202719985\n",
      "Epoch: 0 Step: 161 Loss: 2.004977612020025\n",
      "Epoch: 0 Step: 171 Loss: 2.0962749138628833\n",
      "Epoch: 0 Step: 181 Loss: 2.0287733400168535\n",
      "Epoch: 0 Step: 191 Loss: 1.996801862011595\n",
      "Epoch: 0 Step: 201 Loss: 2.184842858563539\n",
      "Epoch: 0 Step: 211 Loss: 2.0071192119934285\n",
      "Epoch: 0 Step: 221 Loss: 2.016500424169612\n",
      "Epoch: 0 Step: 231 Loss: 2.008067810760867\n",
      "Epoch: 0 Step: 241 Loss: 2.155860150124678\n",
      "Epoch: 0 Step: 251 Loss: 2.2594144743521998\n",
      "Epoch: 0 Step: 261 Loss: 2.1635783919879974\n",
      "Epoch: 0 Step: 271 Loss: 2.051161259530465\n",
      "Epoch: 0 Step: 281 Loss: 1.9908375136083913\n",
      "Epoch: 0 Step: 291 Loss: 1.9865798963753896\n",
      "Epoch: 0 Step: 301 Loss: 1.9845840154746412\n",
      "Epoch: 0 Step: 311 Loss: 1.9267766880461559\n",
      "Epoch: 0 Step: 321 Loss: 1.9785013604606354\n",
      "Epoch: 0 Step: 331 Loss: 2.109147223956802\n",
      "Epoch: 0 Step: 341 Loss: 2.062373526575892\n",
      "Epoch: 0 Step: 351 Loss: 2.0055640320246546\n",
      "Epoch: 0 Step: 361 Loss: 2.0310805767765476\n",
      "Epoch: 0 Step: 371 Loss: 2.0939830597136324\n",
      "Epoch: 0 Step: 381 Loss: 1.9715891273065171\n",
      "Epoch: 0 Step: 391 Loss: 1.947973560118305\n",
      "Epoch: 0 Step: 401 Loss: 2.087599346829452\n",
      "Epoch: 0 Step: 411 Loss: 2.022058329583143\n",
      "Epoch: 0 Step: 421 Loss: 2.1531563281871895\n",
      "Epoch: 0 Step: 431 Loss: 1.9869852791084615\n",
      "Epoch: 0 Step: 441 Loss: 2.018541992970647\n",
      "Epoch: 0 Step: 451 Loss: 1.9305139594276561\n",
      "Epoch: 0 Step: 461 Loss: 1.8910952521102924\n",
      "Epoch: 0 Step: 471 Loss: 1.9349775525247288\n",
      "Epoch: 0 Step: 481 Loss: 2.097401290625391\n",
      "Epoch: 0 Step: 491 Loss: 1.9993764258142948\n",
      "Epoch: 0 Step: 501 Loss: 2.0447350086923652\n",
      "Epoch: 0 Step: 511 Loss: 2.0942278430462475\n",
      "Epoch: 0 Step: 521 Loss: 1.9708480572486868\n",
      "Epoch: 0 Step: 531 Loss: 1.9429270302229353\n",
      "Epoch: 0 Step: 541 Loss: 1.9954501283370092\n",
      "Epoch: 0 Step: 551 Loss: 1.8656522066642935\n",
      "Epoch: 0 Step: 561 Loss: 1.9188823904174674\n",
      "Epoch: 0 Step: 571 Loss: 1.90926830788752\n",
      "Epoch: 0 Step: 581 Loss: 1.9071716745544258\n",
      "Epoch: 0 Step: 591 Loss: 1.8340858637119788\n",
      "Epoch: 0 Step: 601 Loss: 1.7191163557077274\n",
      "Epoch: 0 Step: 611 Loss: 1.7884561096393643\n",
      "Epoch: 0 Step: 621 Loss: 1.7362201886414432\n",
      "Epoch: 0 Step: 631 Loss: 1.876434771726628\n",
      "Epoch: 0 Step: 641 Loss: 1.8811801144717157\n",
      "Epoch: 0 Step: 651 Loss: 1.7789389042686126\n",
      "Epoch: 0 Step: 661 Loss: 1.8097149322594208\n",
      "Epoch: 0 Step: 671 Loss: 1.7844849071707929\n",
      "Epoch: 0 Step: 681 Loss: 1.8272841899127996\n",
      "Epoch: 0 Step: 691 Loss: 1.886887439757098\n",
      "Epoch: 0 Step: 701 Loss: 1.82537432181392\n",
      "Epoch: 0 Step: 711 Loss: 1.755434103211932\n",
      "Epoch: 0 Step: 721 Loss: 1.8455006021487383\n",
      "Epoch: 0 Step: 731 Loss: 1.803020698847115\n",
      "Epoch: 0 Step: 741 Loss: 1.7154684956662227\n",
      "Epoch: 0 Step: 751 Loss: 1.6917961549976388\n",
      "Epoch: 0 Step: 761 Loss: 1.755876070113285\n",
      "Epoch: 0 Step: 771 Loss: 1.621908922267393\n",
      "Epoch: 0 Step: 781 Loss: 1.5195439446982415\n",
      "Epoch: 0 Step: 791 Loss: 1.7024045753110078\n",
      "Epoch: 0 Step: 801 Loss: 1.62337154697884\n",
      "Epoch: 0 Step: 811 Loss: 1.7228300812022819\n",
      "Epoch: 0 Step: 821 Loss: 1.5844293652754222\n",
      "Epoch: 0 Step: 831 Loss: 1.8039878446455089\n",
      "Epoch: 0 Step: 841 Loss: 1.588538339087495\n",
      "Epoch: 0 Step: 851 Loss: 1.5424704765489998\n",
      "Epoch: 0 Step: 861 Loss: 1.5887854457901918\n",
      "Epoch: 0 Step: 871 Loss: 1.7143234866167707\n",
      "Epoch: 0 Step: 881 Loss: 1.656110000390906\n",
      "Epoch: 0 Step: 891 Loss: 1.452822006761161\n",
      "Epoch: 0 Step: 901 Loss: 1.6284807734187785\n",
      "Epoch: 0 Step: 911 Loss: 1.344252809143028\n",
      "Epoch: 0 Step: 921 Loss: 1.4329355682263165\n",
      "Epoch: 0 Step: 931 Loss: 1.2699838676529862\n",
      "Epoch: 1 Step: 1 Loss: 1.5292386264805948\n",
      "Epoch: 1 Step: 11 Loss: 1.2640206169486365\n",
      "Epoch: 1 Step: 21 Loss: 1.5533765011185765\n",
      "Epoch: 1 Step: 31 Loss: 1.4858382507903365\n",
      "Epoch: 1 Step: 41 Loss: 1.3551571309703203\n",
      "Epoch: 1 Step: 51 Loss: 1.5569585331158806\n",
      "Epoch: 1 Step: 61 Loss: 1.3190183873074357\n",
      "Epoch: 1 Step: 71 Loss: 1.2511263986376409\n",
      "Epoch: 1 Step: 81 Loss: 1.455061621223139\n",
      "Epoch: 1 Step: 91 Loss: 1.410194042439585\n",
      "Epoch: 1 Step: 101 Loss: 1.3447799891502132\n",
      "Epoch: 1 Step: 111 Loss: 1.1679702663610707\n",
      "Epoch: 1 Step: 121 Loss: 1.2848458216215488\n",
      "Epoch: 1 Step: 131 Loss: 1.3210194447707329\n",
      "Epoch: 1 Step: 141 Loss: 1.2487937586207316\n",
      "Epoch: 1 Step: 151 Loss: 1.2891680532657315\n",
      "Epoch: 1 Step: 161 Loss: 1.229772740870224\n",
      "Epoch: 1 Step: 171 Loss: 1.2222826038276529\n",
      "Epoch: 1 Step: 181 Loss: 1.2058077933428504\n",
      "Epoch: 1 Step: 191 Loss: 1.3216610970278952\n",
      "Epoch: 1 Step: 201 Loss: 1.1743287042564599\n",
      "Epoch: 1 Step: 211 Loss: 1.1112990700549918\n",
      "Epoch: 1 Step: 221 Loss: 1.1058681157014556\n",
      "Epoch: 1 Step: 231 Loss: 1.3138687280432504\n",
      "Epoch: 1 Step: 241 Loss: 1.0697391142674422\n",
      "Epoch: 1 Step: 251 Loss: 1.4840846053891672\n",
      "Epoch: 1 Step: 261 Loss: 1.0151092154713492\n",
      "Epoch: 1 Step: 271 Loss: 1.152482658677056\n",
      "Epoch: 1 Step: 281 Loss: 1.3438240108590676\n",
      "Epoch: 1 Step: 291 Loss: 1.2062686722531883\n",
      "Epoch: 1 Step: 301 Loss: 1.2247647891205187\n",
      "Epoch: 1 Step: 311 Loss: 0.9444652236483253\n",
      "Epoch: 1 Step: 321 Loss: 0.9477518484416693\n",
      "Epoch: 1 Step: 331 Loss: 1.1525323335129563\n",
      "Epoch: 1 Step: 341 Loss: 0.8827009926486169\n",
      "Epoch: 1 Step: 351 Loss: 1.0285992356312053\n",
      "Epoch: 1 Step: 361 Loss: 1.1176601396475143\n",
      "Epoch: 1 Step: 371 Loss: 1.207360356576455\n",
      "Epoch: 1 Step: 381 Loss: 0.9347649251078187\n",
      "Epoch: 1 Step: 391 Loss: 1.1035883300882314\n",
      "Epoch: 1 Step: 401 Loss: 1.1583474428675034\n",
      "Epoch: 1 Step: 411 Loss: 1.06358180522429\n",
      "Epoch: 1 Step: 421 Loss: 1.0267342163486595\n",
      "Epoch: 1 Step: 431 Loss: 0.9849240573792082\n",
      "Epoch: 1 Step: 441 Loss: 1.0520180042367586\n",
      "Epoch: 1 Step: 451 Loss: 0.8779356705762617\n",
      "Epoch: 1 Step: 461 Loss: 0.9789480818622714\n",
      "Epoch: 1 Step: 471 Loss: 0.9258217107214992\n",
      "Epoch: 1 Step: 481 Loss: 1.0400914976724798\n",
      "Epoch: 1 Step: 491 Loss: 1.2866933039217998\n",
      "Epoch: 1 Step: 501 Loss: 0.887684674914962\n",
      "Epoch: 1 Step: 511 Loss: 0.9849813142788635\n",
      "Epoch: 1 Step: 521 Loss: 1.1281158956028159\n",
      "Epoch: 1 Step: 531 Loss: 0.8482266408035815\n",
      "Epoch: 1 Step: 541 Loss: 0.9448734537489261\n",
      "Epoch: 1 Step: 551 Loss: 0.9328255566570371\n",
      "Epoch: 1 Step: 561 Loss: 0.836888309384876\n",
      "Epoch: 1 Step: 571 Loss: 0.8186416633546885\n",
      "Epoch: 1 Step: 581 Loss: 0.9090689688267534\n",
      "Epoch: 1 Step: 591 Loss: 0.775775738640928\n",
      "Epoch: 1 Step: 601 Loss: 0.6573730513450184\n",
      "Epoch: 1 Step: 611 Loss: 0.6860643393082793\n",
      "Epoch: 1 Step: 621 Loss: 0.7964770904474009\n",
      "Epoch: 1 Step: 631 Loss: 0.9264156696181267\n",
      "Epoch: 1 Step: 641 Loss: 0.7556468160731735\n",
      "Epoch: 1 Step: 651 Loss: 0.7404419699105766\n",
      "Epoch: 1 Step: 661 Loss: 0.6731077063974267\n",
      "Epoch: 1 Step: 671 Loss: 0.6098393064791099\n",
      "Epoch: 1 Step: 681 Loss: 0.7151335730972513\n",
      "Epoch: 1 Step: 691 Loss: 0.6645591728776981\n",
      "Epoch: 1 Step: 701 Loss: 1.0134144378836716\n",
      "Epoch: 1 Step: 711 Loss: 0.8219455101543819\n",
      "Epoch: 1 Step: 721 Loss: 0.7960637296855428\n",
      "Epoch: 1 Step: 731 Loss: 0.9249767185204298\n",
      "Epoch: 1 Step: 741 Loss: 0.7007400770578889\n",
      "Epoch: 1 Step: 751 Loss: 0.6078054868395464\n",
      "Epoch: 1 Step: 761 Loss: 0.5881971977629281\n",
      "Epoch: 1 Step: 771 Loss: 0.534345938373275\n",
      "Epoch: 1 Step: 781 Loss: 0.6463363217920735\n",
      "Epoch: 1 Step: 791 Loss: 0.722138243702983\n",
      "Epoch: 1 Step: 801 Loss: 0.493197057166649\n",
      "Epoch: 1 Step: 811 Loss: 0.44716825135444727\n",
      "Epoch: 1 Step: 821 Loss: 0.5221404267545708\n",
      "Epoch: 1 Step: 831 Loss: 0.6595737431693572\n",
      "Epoch: 1 Step: 841 Loss: 0.5218308411472081\n",
      "Epoch: 1 Step: 851 Loss: 0.5264826711330487\n",
      "Epoch: 1 Step: 861 Loss: 0.5989321154965722\n",
      "Epoch: 1 Step: 871 Loss: 0.5467253588026334\n",
      "Epoch: 1 Step: 881 Loss: 0.4625917086528455\n",
      "Epoch: 1 Step: 891 Loss: 0.3668489383413168\n",
      "Epoch: 1 Step: 901 Loss: 0.5942026547730461\n",
      "Epoch: 1 Step: 911 Loss: 0.44293356810050544\n",
      "Epoch: 1 Step: 921 Loss: 0.436989940937014\n",
      "Epoch: 1 Step: 931 Loss: 0.36276028796686427\n",
      "Epoch: 2 Step: 1 Loss: 0.5126743744643327\n",
      "Epoch: 2 Step: 11 Loss: 0.41949081848233616\n",
      "Epoch: 2 Step: 21 Loss: 0.6621272091382782\n",
      "Epoch: 2 Step: 31 Loss: 0.5290282972476974\n",
      "Epoch: 2 Step: 41 Loss: 0.37475091862523724\n",
      "Epoch: 2 Step: 51 Loss: 0.49030289782109104\n",
      "Epoch: 2 Step: 61 Loss: 0.35325517166622866\n",
      "Epoch: 2 Step: 71 Loss: 0.2619849870576909\n",
      "Epoch: 2 Step: 81 Loss: 0.4722274212655464\n",
      "Epoch: 2 Step: 91 Loss: 0.38177219180113275\n",
      "Epoch: 2 Step: 101 Loss: 0.27986419780943317\n",
      "Epoch: 2 Step: 111 Loss: 0.34782754239534985\n",
      "Epoch: 2 Step: 121 Loss: 0.347168773247357\n",
      "Epoch: 2 Step: 131 Loss: 0.326111901083039\n",
      "Epoch: 2 Step: 141 Loss: 0.2957208252255154\n",
      "Epoch: 2 Step: 151 Loss: 0.5505179780203417\n",
      "Epoch: 2 Step: 161 Loss: 0.5252375416685325\n",
      "Epoch: 2 Step: 171 Loss: 0.31648541459079715\n",
      "Epoch: 2 Step: 181 Loss: 0.5050652393943941\n",
      "Epoch: 2 Step: 191 Loss: 0.3719980170602975\n",
      "Epoch: 2 Step: 201 Loss: 0.3097706827777472\n",
      "Epoch: 2 Step: 211 Loss: 0.23838829115016377\n",
      "Epoch: 2 Step: 221 Loss: 0.3343336679247502\n",
      "Epoch: 2 Step: 231 Loss: 0.4463286265420271\n",
      "Epoch: 2 Step: 241 Loss: 0.31554528335676907\n",
      "Epoch: 2 Step: 251 Loss: 0.5576587379057298\n",
      "Epoch: 2 Step: 261 Loss: 0.2931528127793289\n",
      "Epoch: 2 Step: 271 Loss: 0.3451543134605169\n",
      "Epoch: 2 Step: 281 Loss: 0.24460369318159744\n",
      "Epoch: 2 Step: 291 Loss: 0.2665812602656481\n",
      "Epoch: 2 Step: 301 Loss: 0.36387249021519974\n",
      "Epoch: 2 Step: 311 Loss: 0.2830309037044352\n",
      "Epoch: 2 Step: 321 Loss: 0.34258940273672667\n",
      "Epoch: 2 Step: 331 Loss: 0.2498543344573949\n",
      "Epoch: 2 Step: 341 Loss: 0.18409273548150462\n",
      "Epoch: 2 Step: 351 Loss: 0.2872229504514161\n",
      "Epoch: 2 Step: 361 Loss: 0.34235797515088634\n",
      "Epoch: 2 Step: 371 Loss: 0.44249457629085964\n",
      "Epoch: 2 Step: 381 Loss: 0.1193116527239447\n",
      "Epoch: 2 Step: 391 Loss: 0.19180468478906276\n",
      "Epoch: 2 Step: 401 Loss: 0.1905624915377961\n",
      "Epoch: 2 Step: 411 Loss: 0.33423382391951983\n",
      "Epoch: 2 Step: 421 Loss: 0.1952558501227377\n",
      "Epoch: 2 Step: 431 Loss: 0.1474338446446531\n",
      "Epoch: 2 Step: 441 Loss: 0.15325671228704213\n",
      "Epoch: 2 Step: 451 Loss: 0.1564454378575455\n",
      "Epoch: 2 Step: 461 Loss: 0.22587427532521062\n",
      "Epoch: 2 Step: 471 Loss: 0.34072457185444804\n",
      "Epoch: 2 Step: 481 Loss: 0.2793457352376144\n",
      "Epoch: 2 Step: 491 Loss: 0.17528639692460982\n",
      "Epoch: 2 Step: 501 Loss: 0.38258209218802786\n",
      "Epoch: 2 Step: 511 Loss: 0.27853200296821884\n",
      "Epoch: 2 Step: 521 Loss: 0.21855222820846532\n",
      "Epoch: 2 Step: 531 Loss: 0.09296938034197012\n",
      "Epoch: 2 Step: 541 Loss: 0.19903918988244107\n",
      "Epoch: 2 Step: 551 Loss: 0.48464791945090735\n",
      "Epoch: 2 Step: 561 Loss: 0.17833850744980106\n",
      "Epoch: 2 Step: 571 Loss: 0.32388723974600425\n",
      "Epoch: 2 Step: 581 Loss: 0.2825690804267258\n",
      "Epoch: 2 Step: 591 Loss: 0.26211469534712306\n",
      "Epoch: 2 Step: 601 Loss: 0.27325111487493237\n",
      "Epoch: 2 Step: 611 Loss: 0.08701351276524684\n",
      "Epoch: 2 Step: 621 Loss: 0.27107356117227505\n",
      "Epoch: 2 Step: 631 Loss: 0.12810440234159878\n",
      "Epoch: 2 Step: 641 Loss: 0.30815602407399684\n",
      "Epoch: 2 Step: 651 Loss: 0.3276305850187711\n",
      "Epoch: 2 Step: 661 Loss: 0.12661194142024174\n",
      "Epoch: 2 Step: 671 Loss: 0.32698575591683177\n",
      "Epoch: 2 Step: 681 Loss: 0.2105713573428628\n",
      "Epoch: 2 Step: 691 Loss: 0.20915864152630975\n",
      "Epoch: 2 Step: 701 Loss: 0.4518263678769827\n",
      "Epoch: 2 Step: 711 Loss: 0.2547825413748055\n",
      "Epoch: 2 Step: 721 Loss: 0.24776654163049142\n",
      "Epoch: 2 Step: 731 Loss: 0.4284286208372517\n",
      "Epoch: 2 Step: 741 Loss: 0.11046785235867249\n",
      "Epoch: 2 Step: 751 Loss: 0.12896895684333085\n",
      "Epoch: 2 Step: 761 Loss: 0.17709272921650554\n",
      "Epoch: 2 Step: 771 Loss: 0.13942040565231556\n",
      "Epoch: 2 Step: 781 Loss: 0.23397962057049937\n",
      "Epoch: 2 Step: 791 Loss: 0.36120966499595175\n",
      "Epoch: 2 Step: 801 Loss: 0.23656933953049097\n",
      "Epoch: 2 Step: 811 Loss: 0.09474166955423226\n",
      "Epoch: 2 Step: 821 Loss: 0.15749681360289358\n",
      "Epoch: 2 Step: 831 Loss: 0.18692279307313858\n",
      "Epoch: 2 Step: 841 Loss: 0.16090932483212\n",
      "Epoch: 2 Step: 851 Loss: 0.20628668322570276\n",
      "Epoch: 2 Step: 861 Loss: 0.16890564216927081\n",
      "Epoch: 2 Step: 871 Loss: 0.285968622533316\n",
      "Epoch: 2 Step: 881 Loss: 0.1898368862424883\n",
      "Epoch: 2 Step: 891 Loss: 0.1613818806054187\n",
      "Epoch: 2 Step: 901 Loss: 0.31210552587535917\n",
      "Epoch: 2 Step: 911 Loss: 0.10964712565926077\n",
      "Epoch: 2 Step: 921 Loss: 0.07200828150908242\n",
      "Epoch: 2 Step: 931 Loss: 0.05562878186956887\n",
      "Epoch: 3 Step: 1 Loss: 0.07181102507979656\n",
      "Epoch: 3 Step: 11 Loss: 0.22885994317419678\n",
      "Epoch: 3 Step: 21 Loss: 0.35337843488821163\n",
      "Epoch: 3 Step: 31 Loss: 0.33255260875698367\n",
      "Epoch: 3 Step: 41 Loss: 0.14837144127385535\n",
      "Epoch: 3 Step: 51 Loss: 0.13678599060588248\n",
      "Epoch: 3 Step: 61 Loss: 0.19432383420383761\n",
      "Epoch: 3 Step: 71 Loss: 0.16038787317742018\n",
      "Epoch: 3 Step: 81 Loss: 0.15049624203775588\n",
      "Epoch: 3 Step: 91 Loss: 0.0824246187250381\n",
      "Epoch: 3 Step: 101 Loss: 0.2791164922072191\n",
      "Epoch: 3 Step: 111 Loss: 0.0750814214843781\n",
      "Epoch: 3 Step: 121 Loss: 0.16034440884655912\n",
      "Epoch: 3 Step: 131 Loss: 0.1530719376435523\n",
      "Epoch: 3 Step: 141 Loss: 0.11738517561947141\n",
      "Epoch: 3 Step: 151 Loss: 0.20503620610383524\n",
      "Epoch: 3 Step: 161 Loss: 0.43722046956103694\n",
      "Epoch: 3 Step: 171 Loss: 0.07556570827092027\n",
      "Epoch: 3 Step: 181 Loss: 0.4728409743092637\n",
      "Epoch: 3 Step: 191 Loss: 0.1873826034730144\n",
      "Epoch: 3 Step: 201 Loss: 0.27727623070202745\n",
      "Epoch: 3 Step: 211 Loss: 0.19064140281319664\n",
      "Epoch: 3 Step: 221 Loss: 0.19804950060636806\n",
      "Epoch: 3 Step: 231 Loss: 0.29519100388240443\n",
      "Epoch: 3 Step: 241 Loss: 0.13930463577121416\n",
      "Epoch: 3 Step: 251 Loss: 0.26134941119720495\n",
      "Epoch: 3 Step: 261 Loss: 0.1731881971317645\n",
      "Epoch: 3 Step: 271 Loss: 0.16256886705548598\n",
      "Epoch: 3 Step: 281 Loss: 0.13561350946284656\n",
      "Epoch: 3 Step: 291 Loss: 0.17150977586682709\n",
      "Epoch: 3 Step: 301 Loss: 0.2879295252609178\n",
      "Epoch: 3 Step: 311 Loss: 0.22549051341215307\n",
      "Epoch: 3 Step: 321 Loss: 0.32638705413297986\n",
      "Epoch: 3 Step: 331 Loss: 0.13177153009171333\n",
      "Epoch: 3 Step: 341 Loss: 0.06555556870455521\n",
      "Epoch: 3 Step: 351 Loss: 0.12588491455643677\n",
      "Epoch: 3 Step: 361 Loss: 0.19800490441833202\n",
      "Epoch: 3 Step: 371 Loss: 0.2557400359722874\n",
      "Epoch: 3 Step: 381 Loss: 0.08956785360308936\n",
      "Epoch: 3 Step: 391 Loss: 0.08111374028341835\n",
      "Epoch: 3 Step: 401 Loss: 0.2643104305069037\n",
      "Epoch: 3 Step: 411 Loss: 0.18951606008182117\n",
      "Epoch: 3 Step: 421 Loss: 0.20744264702845955\n",
      "Epoch: 3 Step: 431 Loss: 0.16239964198027185\n",
      "Epoch: 3 Step: 441 Loss: 0.14216399473300273\n",
      "Epoch: 3 Step: 451 Loss: 0.12368109456789773\n",
      "Epoch: 3 Step: 461 Loss: 0.13164657540198155\n",
      "Epoch: 3 Step: 471 Loss: 0.18542843712988427\n",
      "Epoch: 3 Step: 481 Loss: 0.29684072670677086\n",
      "Epoch: 3 Step: 491 Loss: 0.24415622266759554\n",
      "Epoch: 3 Step: 501 Loss: 0.17260610775767216\n",
      "Epoch: 3 Step: 511 Loss: 0.18857454105595137\n",
      "Epoch: 3 Step: 521 Loss: 0.1650345870988541\n",
      "Epoch: 3 Step: 531 Loss: 0.047736086826032156\n",
      "Epoch: 3 Step: 541 Loss: 0.14096096866352031\n",
      "Epoch: 3 Step: 551 Loss: 0.3903808600907065\n",
      "Epoch: 3 Step: 561 Loss: 0.10656179172640509\n",
      "Epoch: 3 Step: 571 Loss: 0.19627302544540554\n",
      "Epoch: 3 Step: 581 Loss: 0.18713625314334378\n",
      "Epoch: 3 Step: 591 Loss: 0.1860151427683086\n",
      "Epoch: 3 Step: 601 Loss: 0.21084137277244314\n",
      "Epoch: 3 Step: 611 Loss: 0.08143695787509843\n",
      "Epoch: 3 Step: 621 Loss: 0.23523019005931248\n",
      "Epoch: 3 Step: 631 Loss: 0.10118830036142847\n",
      "Epoch: 3 Step: 641 Loss: 0.28024537899493884\n",
      "Epoch: 3 Step: 651 Loss: 0.10840363733084987\n",
      "Epoch: 3 Step: 661 Loss: 0.09215624526056104\n",
      "Epoch: 3 Step: 671 Loss: 0.2871923878519336\n",
      "Epoch: 3 Step: 681 Loss: 0.1850849613996646\n",
      "Epoch: 3 Step: 691 Loss: 0.21593890744506142\n",
      "Epoch: 3 Step: 701 Loss: 0.47498351162993335\n",
      "Epoch: 3 Step: 711 Loss: 0.12412816972697044\n",
      "Epoch: 3 Step: 721 Loss: 0.17994818685360842\n",
      "Epoch: 3 Step: 731 Loss: 0.2682842469144305\n",
      "Epoch: 3 Step: 741 Loss: 0.16184074631506484\n",
      "Epoch: 3 Step: 751 Loss: 0.1753637246286179\n",
      "Epoch: 3 Step: 761 Loss: 0.21960727467070745\n",
      "Epoch: 3 Step: 771 Loss: 0.10562786470027562\n",
      "Epoch: 3 Step: 781 Loss: 0.20929486513852655\n",
      "Epoch: 3 Step: 791 Loss: 0.22175959818852856\n",
      "Epoch: 3 Step: 801 Loss: 0.13164471112724097\n",
      "Epoch: 3 Step: 811 Loss: 0.08500419160397372\n",
      "Epoch: 3 Step: 821 Loss: 0.09297832481439755\n",
      "Epoch: 3 Step: 831 Loss: 0.24421221207095067\n",
      "Epoch: 3 Step: 841 Loss: 0.09672058301663686\n",
      "Epoch: 3 Step: 851 Loss: 0.21747699289361194\n",
      "Epoch: 3 Step: 861 Loss: 0.12302833790846715\n",
      "Epoch: 3 Step: 871 Loss: 0.25147539854477946\n",
      "Epoch: 3 Step: 881 Loss: 0.18988917971484037\n",
      "Epoch: 3 Step: 891 Loss: 0.08481761165264688\n",
      "Epoch: 3 Step: 901 Loss: 0.31671814103862483\n",
      "Epoch: 3 Step: 911 Loss: 0.05442307941745504\n",
      "Epoch: 3 Step: 921 Loss: 0.06480172626039034\n",
      "Epoch: 3 Step: 931 Loss: 0.014817841093428746\n",
      "Epoch: 4 Step: 1 Loss: 0.1736661210146397\n",
      "Epoch: 4 Step: 11 Loss: 0.17383929348831936\n",
      "Epoch: 4 Step: 21 Loss: 0.2040168335079362\n",
      "Epoch: 4 Step: 31 Loss: 0.21373672306218872\n",
      "Epoch: 4 Step: 41 Loss: 0.05160387734650966\n",
      "Epoch: 4 Step: 51 Loss: 0.13972411293141146\n",
      "Epoch: 4 Step: 61 Loss: 0.0584435667899762\n",
      "Epoch: 4 Step: 71 Loss: 0.07769634635341664\n",
      "Epoch: 4 Step: 81 Loss: 0.1763945480460387\n",
      "Epoch: 4 Step: 91 Loss: 0.2017501505160741\n",
      "Epoch: 4 Step: 101 Loss: 0.17366518115757487\n",
      "Epoch: 4 Step: 111 Loss: 0.13453170657563973\n",
      "Epoch: 4 Step: 121 Loss: 0.13721357156026648\n",
      "Epoch: 4 Step: 131 Loss: 0.20025026041144828\n",
      "Epoch: 4 Step: 141 Loss: 0.11359883302541317\n",
      "Epoch: 4 Step: 151 Loss: 0.2650862249221492\n",
      "Epoch: 4 Step: 161 Loss: 0.23029450288014203\n",
      "Epoch: 4 Step: 171 Loss: 0.05641655548406678\n",
      "Epoch: 4 Step: 181 Loss: 0.29175281258569236\n",
      "Epoch: 4 Step: 191 Loss: 0.1389323195423616\n",
      "Epoch: 4 Step: 201 Loss: 0.10958239536471345\n",
      "Epoch: 4 Step: 211 Loss: 0.12655796041697895\n",
      "Epoch: 4 Step: 221 Loss: 0.08269995149844273\n",
      "Epoch: 4 Step: 231 Loss: 0.269536568897225\n",
      "Epoch: 4 Step: 241 Loss: 0.16062818899469147\n",
      "Epoch: 4 Step: 251 Loss: 0.21733698804997809\n",
      "Epoch: 4 Step: 261 Loss: 0.22179736128724836\n",
      "Epoch: 4 Step: 271 Loss: 0.10497510344256428\n",
      "Epoch: 4 Step: 281 Loss: 0.11794419505063866\n",
      "Epoch: 4 Step: 291 Loss: 0.10273147085051532\n",
      "Epoch: 4 Step: 301 Loss: 0.10983997440538243\n",
      "Epoch: 4 Step: 311 Loss: 0.16848585035460617\n",
      "Epoch: 4 Step: 321 Loss: 0.22399194819947943\n",
      "Epoch: 4 Step: 331 Loss: 0.22375394356189343\n",
      "Epoch: 4 Step: 341 Loss: 0.02644278654841121\n",
      "Epoch: 4 Step: 351 Loss: 0.1298767881116523\n",
      "Epoch: 4 Step: 361 Loss: 0.22959511072212682\n",
      "Epoch: 4 Step: 371 Loss: 0.2901618580543162\n",
      "Epoch: 4 Step: 381 Loss: 0.059430267867580336\n",
      "Epoch: 4 Step: 391 Loss: 0.09265579381591862\n",
      "Epoch: 4 Step: 401 Loss: 0.13060503219441214\n",
      "Epoch: 4 Step: 411 Loss: 0.13459688272467876\n",
      "Epoch: 4 Step: 421 Loss: 0.2966339888668563\n",
      "Epoch: 4 Step: 431 Loss: 0.12797728452543128\n",
      "Epoch: 4 Step: 441 Loss: 0.17430964051308026\n",
      "Epoch: 4 Step: 451 Loss: 0.17864368362837052\n",
      "Epoch: 4 Step: 461 Loss: 0.20099028158247323\n",
      "Epoch: 4 Step: 471 Loss: 0.29288197701139307\n",
      "Epoch: 4 Step: 481 Loss: 0.10987618746991934\n",
      "Epoch: 4 Step: 491 Loss: 0.12398026278701833\n",
      "Epoch: 4 Step: 501 Loss: 0.22493840030961454\n",
      "Epoch: 4 Step: 511 Loss: 0.15007710854774634\n",
      "Epoch: 4 Step: 521 Loss: 0.15910645915502775\n",
      "Epoch: 4 Step: 531 Loss: 0.06450037650129369\n",
      "Epoch: 4 Step: 541 Loss: 0.19244761656926623\n",
      "Epoch: 4 Step: 551 Loss: 0.31198937702010177\n",
      "Epoch: 4 Step: 561 Loss: 0.21586345938891102\n",
      "Epoch: 4 Step: 571 Loss: 0.18389752752934035\n",
      "Epoch: 4 Step: 581 Loss: 0.16519937334626644\n",
      "Epoch: 4 Step: 591 Loss: 0.1275830841782146\n",
      "Epoch: 4 Step: 601 Loss: 0.1621345356598816\n",
      "Epoch: 4 Step: 611 Loss: 0.07371268772029668\n",
      "Epoch: 4 Step: 621 Loss: 0.12097011938361184\n",
      "Epoch: 4 Step: 631 Loss: 0.11309682456370058\n",
      "Epoch: 4 Step: 641 Loss: 0.3322339465037577\n",
      "Epoch: 4 Step: 651 Loss: 0.14177620762589876\n",
      "Epoch: 4 Step: 661 Loss: 0.11506724540965163\n",
      "Epoch: 4 Step: 671 Loss: 0.20601955424730553\n",
      "Epoch: 4 Step: 681 Loss: 0.21674872960910266\n",
      "Epoch: 4 Step: 691 Loss: 0.11023707711290004\n",
      "Epoch: 4 Step: 701 Loss: 0.44210584170583134\n",
      "Epoch: 4 Step: 711 Loss: 0.06290777279335505\n",
      "Epoch: 4 Step: 721 Loss: 0.15116449590672043\n",
      "Epoch: 4 Step: 731 Loss: 0.1679501029930226\n",
      "Epoch: 4 Step: 741 Loss: 0.15945128214690127\n",
      "Epoch: 4 Step: 751 Loss: 0.08509708752343734\n",
      "Epoch: 4 Step: 761 Loss: 0.118932684396086\n",
      "Epoch: 4 Step: 771 Loss: 0.13249247235492792\n",
      "Epoch: 4 Step: 781 Loss: 0.08237707467642785\n",
      "Epoch: 4 Step: 791 Loss: 0.2710556836747825\n",
      "Epoch: 4 Step: 801 Loss: 0.1769774867455348\n",
      "Epoch: 4 Step: 811 Loss: 0.11162852369965888\n",
      "Epoch: 4 Step: 821 Loss: 0.055280518129283834\n",
      "Epoch: 4 Step: 831 Loss: 0.1724189349181312\n",
      "Epoch: 4 Step: 841 Loss: 0.02453043269197947\n",
      "Epoch: 4 Step: 851 Loss: 0.11810261466588454\n",
      "Epoch: 4 Step: 861 Loss: 0.11043265481389153\n",
      "Epoch: 4 Step: 871 Loss: 0.22129898547679314\n",
      "Epoch: 4 Step: 881 Loss: 0.17184577136526732\n",
      "Epoch: 4 Step: 891 Loss: 0.041233385801647704\n",
      "Epoch: 4 Step: 901 Loss: 0.3533078487791741\n",
      "Epoch: 4 Step: 911 Loss: 0.05920393153733457\n",
      "Epoch: 4 Step: 921 Loss: 0.029485281634509884\n",
      "Epoch: 4 Step: 931 Loss: 0.022955597343384128\n",
      "Epoch: 5 Step: 1 Loss: 0.09502155699202558\n",
      "Epoch: 5 Step: 11 Loss: 0.10819276517366717\n",
      "Epoch: 5 Step: 21 Loss: 0.21962138458476407\n",
      "Epoch: 5 Step: 31 Loss: 0.15233302426602358\n",
      "Epoch: 5 Step: 41 Loss: 0.07871209835758905\n",
      "Epoch: 5 Step: 51 Loss: 0.2325539851017819\n",
      "Epoch: 5 Step: 61 Loss: 0.05455183738638802\n",
      "Epoch: 5 Step: 71 Loss: 0.02179117388765595\n",
      "Epoch: 5 Step: 81 Loss: 0.14228343587284584\n",
      "Epoch: 5 Step: 91 Loss: 0.09644350181287359\n",
      "Epoch: 5 Step: 101 Loss: 0.14699042965728562\n",
      "Epoch: 5 Step: 111 Loss: 0.08255012629255043\n",
      "Epoch: 5 Step: 121 Loss: 0.0914482759831618\n",
      "Epoch: 5 Step: 131 Loss: 0.0653219270334578\n",
      "Epoch: 5 Step: 141 Loss: 0.09255916207925535\n",
      "Epoch: 5 Step: 151 Loss: 0.13168242293262303\n",
      "Epoch: 5 Step: 161 Loss: 0.2589125438130848\n",
      "Epoch: 5 Step: 171 Loss: 0.09053472518844488\n",
      "Epoch: 5 Step: 181 Loss: 0.24812934870515513\n",
      "Epoch: 5 Step: 191 Loss: 0.046453213322660884\n",
      "Epoch: 5 Step: 201 Loss: 0.2322571992443445\n",
      "Epoch: 5 Step: 211 Loss: 0.11354474184172508\n",
      "Epoch: 5 Step: 221 Loss: 0.16567414249999432\n",
      "Epoch: 5 Step: 231 Loss: 0.15929103302853376\n",
      "Epoch: 5 Step: 241 Loss: 0.23599453450320912\n",
      "Epoch: 5 Step: 251 Loss: 0.19233185154125249\n",
      "Epoch: 5 Step: 261 Loss: 0.23165514002164897\n",
      "Epoch: 5 Step: 271 Loss: 0.18463759642003155\n",
      "Epoch: 5 Step: 281 Loss: 0.12432855909387522\n",
      "Epoch: 5 Step: 291 Loss: 0.048751639622933704\n",
      "Epoch: 5 Step: 301 Loss: 0.11546142280324527\n",
      "Epoch: 5 Step: 311 Loss: 0.07583949413864782\n",
      "Epoch: 5 Step: 321 Loss: 0.18159938822059385\n",
      "Epoch: 5 Step: 331 Loss: 0.2042576631742598\n",
      "Epoch: 5 Step: 341 Loss: 0.14904423033364048\n",
      "Epoch: 5 Step: 351 Loss: 0.08735333273958587\n",
      "Epoch: 5 Step: 361 Loss: 0.13149629380314015\n",
      "Epoch: 5 Step: 371 Loss: 0.11235356441518653\n",
      "Epoch: 5 Step: 381 Loss: 0.02920794135278142\n",
      "Epoch: 5 Step: 391 Loss: 0.028991404334456242\n",
      "Epoch: 5 Step: 401 Loss: 0.10300980800177127\n",
      "Epoch: 5 Step: 411 Loss: 0.09949586622499909\n",
      "Epoch: 5 Step: 421 Loss: 0.1692844574576988\n",
      "Epoch: 5 Step: 431 Loss: 0.14071092715846642\n",
      "Epoch: 5 Step: 441 Loss: 0.10773724327085707\n",
      "Epoch: 5 Step: 451 Loss: 0.1890225604150792\n",
      "Epoch: 5 Step: 461 Loss: 0.10412858999982996\n",
      "Epoch: 5 Step: 471 Loss: 0.17620865318327034\n",
      "Epoch: 5 Step: 481 Loss: 0.12654605308458636\n",
      "Epoch: 5 Step: 491 Loss: 0.20586145638721065\n",
      "Epoch: 5 Step: 501 Loss: 0.16736379916855348\n",
      "Epoch: 5 Step: 511 Loss: 0.16702751206001268\n",
      "Epoch: 5 Step: 521 Loss: 0.1842522534609433\n",
      "Epoch: 5 Step: 531 Loss: 0.02834458807491874\n",
      "Epoch: 5 Step: 541 Loss: 0.0424380916551331\n",
      "Epoch: 5 Step: 551 Loss: 0.26075906981308683\n",
      "Epoch: 5 Step: 561 Loss: 0.2205104711101124\n",
      "Epoch: 5 Step: 571 Loss: 0.12410338796357137\n",
      "Epoch: 5 Step: 581 Loss: 0.07866713500276173\n",
      "Epoch: 5 Step: 591 Loss: 0.18867823259163832\n",
      "Epoch: 5 Step: 601 Loss: 0.10588227986652562\n",
      "Epoch: 5 Step: 611 Loss: 0.02089844622175829\n",
      "Epoch: 5 Step: 621 Loss: 0.10329582453714078\n",
      "Epoch: 5 Step: 631 Loss: 0.1032255914494545\n",
      "Epoch: 5 Step: 641 Loss: 0.23583006897169184\n",
      "Epoch: 5 Step: 651 Loss: 0.14731659809992353\n",
      "Epoch: 5 Step: 661 Loss: 0.024556402108215847\n",
      "Epoch: 5 Step: 671 Loss: 0.23078544996735623\n",
      "Epoch: 5 Step: 681 Loss: 0.18383653631930513\n",
      "Epoch: 5 Step: 691 Loss: 0.0918859075234381\n",
      "Epoch: 5 Step: 701 Loss: 0.28271084194837165\n",
      "Epoch: 5 Step: 711 Loss: 0.0776993977717237\n",
      "Epoch: 5 Step: 721 Loss: 0.23491278569523755\n",
      "Epoch: 5 Step: 731 Loss: 0.20813362773590377\n",
      "Epoch: 5 Step: 741 Loss: 0.1285906005377149\n",
      "Epoch: 5 Step: 751 Loss: 0.05962419178172379\n",
      "Epoch: 5 Step: 761 Loss: 0.04135613572407967\n",
      "Epoch: 5 Step: 771 Loss: 0.08281186165053042\n",
      "Epoch: 5 Step: 781 Loss: 0.0511393523254734\n",
      "Epoch: 5 Step: 791 Loss: 0.22841527362896363\n",
      "Epoch: 5 Step: 801 Loss: 0.15766118260508283\n",
      "Epoch: 5 Step: 811 Loss: 0.04466003657296794\n",
      "Epoch: 5 Step: 821 Loss: 0.08201708545907394\n",
      "Epoch: 5 Step: 831 Loss: 0.16099620694085667\n",
      "Epoch: 5 Step: 841 Loss: 0.10121893798604671\n",
      "Epoch: 5 Step: 851 Loss: 0.1478448891893482\n",
      "Epoch: 5 Step: 861 Loss: 0.17305493020648763\n",
      "Epoch: 5 Step: 871 Loss: 0.23242124167226744\n",
      "Epoch: 5 Step: 881 Loss: 0.1585437501811064\n",
      "Epoch: 5 Step: 891 Loss: 0.1373956159420671\n",
      "Epoch: 5 Step: 901 Loss: 0.28271365028297707\n",
      "Epoch: 5 Step: 911 Loss: 0.0727210296069958\n",
      "Epoch: 5 Step: 921 Loss: 0.028668040117321603\n",
      "Epoch: 5 Step: 931 Loss: 0.009662642858470547\n",
      "Epoch: 6 Step: 1 Loss: 0.09477150013224944\n",
      "Epoch: 6 Step: 11 Loss: 0.06211482397683681\n",
      "Epoch: 6 Step: 21 Loss: 0.15095715207096524\n",
      "Epoch: 6 Step: 31 Loss: 0.09148586427664335\n",
      "Epoch: 6 Step: 41 Loss: 0.0735440268017212\n",
      "Epoch: 6 Step: 51 Loss: 0.1324564063983387\n",
      "Epoch: 6 Step: 61 Loss: 0.04487888367311409\n",
      "Epoch: 6 Step: 71 Loss: 0.053725709697135735\n",
      "Epoch: 6 Step: 81 Loss: 0.2883910402661414\n",
      "Epoch: 6 Step: 91 Loss: 0.11756129013956869\n",
      "Epoch: 6 Step: 101 Loss: 0.25369345276904154\n",
      "Epoch: 6 Step: 111 Loss: 0.08889104477142372\n",
      "Epoch: 6 Step: 121 Loss: 0.07140513991434759\n",
      "Epoch: 6 Step: 131 Loss: 0.033901045771723114\n",
      "Epoch: 6 Step: 141 Loss: 0.11376300373689346\n",
      "Epoch: 6 Step: 151 Loss: 0.19272874565195075\n",
      "Epoch: 6 Step: 161 Loss: 0.21495822768420392\n",
      "Epoch: 6 Step: 171 Loss: 0.052332465056831035\n",
      "Epoch: 6 Step: 181 Loss: 0.2874103070194417\n",
      "Epoch: 6 Step: 191 Loss: 0.10983489108322467\n",
      "Epoch: 6 Step: 201 Loss: 0.17108216258428882\n",
      "Epoch: 6 Step: 211 Loss: 0.15684322844244475\n",
      "Epoch: 6 Step: 221 Loss: 0.11008068774063756\n",
      "Epoch: 6 Step: 231 Loss: 0.21286021386004333\n",
      "Epoch: 6 Step: 241 Loss: 0.1273525351680519\n",
      "Epoch: 6 Step: 251 Loss: 0.17721478624808307\n",
      "Epoch: 6 Step: 261 Loss: 0.07942893491837631\n",
      "Epoch: 6 Step: 271 Loss: 0.10297714167043083\n",
      "Epoch: 6 Step: 281 Loss: 0.07609834279708468\n",
      "Epoch: 6 Step: 291 Loss: 0.08726724942838066\n",
      "Epoch: 6 Step: 301 Loss: 0.06733629605918386\n",
      "Epoch: 6 Step: 311 Loss: 0.10433768579080174\n",
      "Epoch: 6 Step: 321 Loss: 0.11662535178900459\n",
      "Epoch: 6 Step: 331 Loss: 0.18124860297073553\n",
      "Epoch: 6 Step: 341 Loss: 0.04394944463991078\n",
      "Epoch: 6 Step: 351 Loss: 0.10780318474724458\n",
      "Epoch: 6 Step: 361 Loss: 0.17850032208515132\n",
      "Epoch: 6 Step: 371 Loss: 0.1483566513621428\n",
      "Epoch: 6 Step: 381 Loss: 0.02801708060251735\n",
      "Epoch: 6 Step: 391 Loss: 0.02504802655510079\n",
      "Epoch: 6 Step: 401 Loss: 0.19578158938194012\n",
      "Epoch: 6 Step: 411 Loss: 0.0456363538246317\n",
      "Epoch: 6 Step: 421 Loss: 0.21903641328303403\n",
      "Epoch: 6 Step: 431 Loss: 0.09595281768776104\n",
      "Epoch: 6 Step: 441 Loss: 0.08602024783147587\n",
      "Epoch: 6 Step: 451 Loss: 0.0523928739183563\n",
      "Epoch: 6 Step: 461 Loss: 0.09018208073036552\n",
      "Epoch: 6 Step: 471 Loss: 0.12647597097248564\n",
      "Epoch: 6 Step: 481 Loss: 0.08749010892384408\n",
      "Epoch: 6 Step: 491 Loss: 0.06884851764225058\n",
      "Epoch: 6 Step: 501 Loss: 0.19209237886802016\n",
      "Epoch: 6 Step: 511 Loss: 0.16780190665872294\n",
      "Epoch: 6 Step: 521 Loss: 0.17167354602259624\n",
      "Epoch: 6 Step: 531 Loss: 0.027021356355528995\n",
      "Epoch: 6 Step: 541 Loss: 0.10112967766848723\n",
      "Epoch: 6 Step: 551 Loss: 0.22809251470530909\n",
      "Epoch: 6 Step: 561 Loss: 0.11005966185302554\n",
      "Epoch: 6 Step: 571 Loss: 0.044182979572137994\n",
      "Epoch: 6 Step: 581 Loss: 0.05869677260056694\n",
      "Epoch: 6 Step: 591 Loss: 0.1308565062154441\n",
      "Epoch: 6 Step: 601 Loss: 0.09049153254184843\n",
      "Epoch: 6 Step: 611 Loss: 0.028793600979756667\n",
      "Epoch: 6 Step: 621 Loss: 0.05668317613814841\n",
      "Epoch: 6 Step: 631 Loss: 0.13297127054903907\n",
      "Epoch: 6 Step: 641 Loss: 0.27259957650319755\n",
      "Epoch: 6 Step: 651 Loss: 0.0937503747353742\n",
      "Epoch: 6 Step: 661 Loss: 0.10712692701744286\n",
      "Epoch: 6 Step: 671 Loss: 0.18351795698377843\n",
      "Epoch: 6 Step: 681 Loss: 0.16019431486279923\n",
      "Epoch: 6 Step: 691 Loss: 0.071874797523231\n",
      "Epoch: 6 Step: 701 Loss: 0.2390646218230702\n",
      "Epoch: 6 Step: 711 Loss: 0.1047825573272381\n",
      "Epoch: 6 Step: 721 Loss: 0.07447686008645027\n",
      "Epoch: 6 Step: 731 Loss: 0.14341221694821238\n",
      "Epoch: 6 Step: 741 Loss: 0.07571281567553342\n",
      "Epoch: 6 Step: 751 Loss: 0.050476357802470825\n",
      "Epoch: 6 Step: 761 Loss: 0.08914999711923283\n",
      "Epoch: 6 Step: 771 Loss: 0.08011093384907252\n",
      "Epoch: 6 Step: 781 Loss: 0.1262269464864462\n",
      "Epoch: 6 Step: 791 Loss: 0.2506405636901874\n",
      "Epoch: 6 Step: 801 Loss: 0.06760023166043196\n",
      "Epoch: 6 Step: 811 Loss: 0.09644263168059267\n",
      "Epoch: 6 Step: 821 Loss: 0.017398299999080415\n",
      "Epoch: 6 Step: 831 Loss: 0.21815698628405275\n",
      "Epoch: 6 Step: 841 Loss: 0.06420479954996966\n",
      "Epoch: 6 Step: 851 Loss: 0.0715640639218314\n",
      "Epoch: 6 Step: 861 Loss: 0.139354178472126\n",
      "Epoch: 6 Step: 871 Loss: 0.2510460957740622\n",
      "Epoch: 6 Step: 881 Loss: 0.12251606215332009\n",
      "Epoch: 6 Step: 891 Loss: 0.09746920768455708\n",
      "Epoch: 6 Step: 901 Loss: 0.198124443047423\n",
      "Epoch: 6 Step: 911 Loss: 0.04198537997248129\n",
      "Epoch: 6 Step: 921 Loss: 0.016519968869863427\n",
      "Epoch: 6 Step: 931 Loss: 0.020624882121052023\n",
      "Epoch: 7 Step: 1 Loss: 0.0456929068433686\n",
      "Epoch: 7 Step: 11 Loss: 0.05786759129190359\n",
      "Epoch: 7 Step: 21 Loss: 0.07329390008869818\n",
      "Epoch: 7 Step: 31 Loss: 0.06805426839495701\n",
      "Epoch: 7 Step: 41 Loss: 0.07633473125813087\n",
      "Epoch: 7 Step: 51 Loss: 0.0539727133471357\n",
      "Epoch: 7 Step: 61 Loss: 0.026277242810190247\n",
      "Epoch: 7 Step: 71 Loss: 0.013076535675671574\n",
      "Epoch: 7 Step: 81 Loss: 0.1256951408916111\n",
      "Epoch: 7 Step: 91 Loss: 0.0736060651785825\n",
      "Epoch: 7 Step: 101 Loss: 0.1287358324098139\n",
      "Epoch: 7 Step: 111 Loss: 0.07939829160855166\n",
      "Epoch: 7 Step: 121 Loss: 0.0668113366271611\n",
      "Epoch: 7 Step: 131 Loss: 0.013685064420082594\n",
      "Epoch: 7 Step: 141 Loss: 0.10728260975285198\n",
      "Epoch: 7 Step: 151 Loss: 0.13961505849751063\n",
      "Epoch: 7 Step: 161 Loss: 0.26101306463681084\n",
      "Epoch: 7 Step: 171 Loss: 0.046033412949369024\n",
      "Epoch: 7 Step: 181 Loss: 0.10016074027549132\n",
      "Epoch: 7 Step: 191 Loss: 0.055645806051903765\n",
      "Epoch: 7 Step: 201 Loss: 0.0642217514254378\n",
      "Epoch: 7 Step: 211 Loss: 0.05797083630162714\n",
      "Epoch: 7 Step: 221 Loss: 0.06984961673618152\n",
      "Epoch: 7 Step: 231 Loss: 0.18461150515101668\n",
      "Epoch: 7 Step: 241 Loss: 0.09515144846340762\n",
      "Epoch: 7 Step: 251 Loss: 0.054534755964649184\n",
      "Epoch: 7 Step: 261 Loss: 0.041866333926268755\n",
      "Epoch: 7 Step: 271 Loss: 0.04607954064945428\n",
      "Epoch: 7 Step: 281 Loss: 0.12007383584300088\n",
      "Epoch: 7 Step: 291 Loss: 0.07345331499400988\n",
      "Epoch: 7 Step: 301 Loss: 0.05932648387710318\n",
      "Epoch: 7 Step: 311 Loss: 0.14604087518773265\n",
      "Epoch: 7 Step: 321 Loss: 0.10317742574728421\n",
      "Epoch: 7 Step: 331 Loss: 0.24107332290989927\n",
      "Epoch: 7 Step: 341 Loss: 0.07384390874312398\n",
      "Epoch: 7 Step: 351 Loss: 0.06217428718554677\n",
      "Epoch: 7 Step: 361 Loss: 0.15121632852415906\n",
      "Epoch: 7 Step: 371 Loss: 0.22448840728837144\n",
      "Epoch: 7 Step: 381 Loss: 0.008691366542900642\n",
      "Epoch: 7 Step: 391 Loss: 0.015579838696512898\n",
      "Epoch: 7 Step: 401 Loss: 0.09695689149347672\n",
      "Epoch: 7 Step: 411 Loss: 0.07283850374910039\n",
      "Epoch: 7 Step: 421 Loss: 0.23335794610228386\n",
      "Epoch: 7 Step: 431 Loss: 0.14890983658241952\n",
      "Epoch: 7 Step: 441 Loss: 0.04619238582892615\n",
      "Epoch: 7 Step: 451 Loss: 0.07039240134062659\n",
      "Epoch: 7 Step: 461 Loss: 0.0941898956458718\n",
      "Epoch: 7 Step: 471 Loss: 0.153027877791434\n",
      "Epoch: 7 Step: 481 Loss: 0.08467629967007131\n",
      "Epoch: 7 Step: 491 Loss: 0.1120058287749897\n",
      "Epoch: 7 Step: 501 Loss: 0.15388348359984855\n",
      "Epoch: 7 Step: 511 Loss: 0.09070279746006192\n",
      "Epoch: 7 Step: 521 Loss: 0.05216651726491468\n",
      "Epoch: 7 Step: 531 Loss: 0.031676150171562834\n",
      "Epoch: 7 Step: 541 Loss: 0.04255716731876359\n",
      "Epoch: 7 Step: 551 Loss: 0.1450404115273863\n",
      "Epoch: 7 Step: 561 Loss: 0.09050570716755427\n",
      "Epoch: 7 Step: 571 Loss: 0.06858353489576113\n",
      "Epoch: 7 Step: 581 Loss: 0.10447895000151053\n",
      "Epoch: 7 Step: 591 Loss: 0.1175121540408496\n",
      "Epoch: 7 Step: 601 Loss: 0.0630428063089731\n",
      "Epoch: 7 Step: 611 Loss: 0.025084754174005863\n",
      "Epoch: 7 Step: 621 Loss: 0.10119762440281506\n",
      "Epoch: 7 Step: 631 Loss: 0.14695038229061738\n",
      "Epoch: 7 Step: 641 Loss: 0.2462386474436128\n",
      "Epoch: 7 Step: 651 Loss: 0.08146449154771684\n",
      "Epoch: 7 Step: 661 Loss: 0.11122126593021267\n",
      "Epoch: 7 Step: 671 Loss: 0.13498943287408094\n",
      "Epoch: 7 Step: 681 Loss: 0.13445433535267043\n",
      "Epoch: 7 Step: 691 Loss: 0.05985277236810233\n",
      "Epoch: 7 Step: 701 Loss: 0.2586564421024767\n",
      "Epoch: 7 Step: 711 Loss: 0.09657627758407608\n",
      "Epoch: 7 Step: 721 Loss: 0.13228546699337565\n",
      "Epoch: 7 Step: 731 Loss: 0.24596678046382175\n",
      "Epoch: 7 Step: 741 Loss: 0.08625191477887416\n",
      "Epoch: 7 Step: 751 Loss: 0.030441321214453625\n",
      "Epoch: 7 Step: 761 Loss: 0.14601082538348148\n",
      "Epoch: 7 Step: 771 Loss: 0.039871928794033354\n",
      "Epoch: 7 Step: 781 Loss: 0.23124968147373465\n",
      "Epoch: 7 Step: 791 Loss: 0.1333081154325769\n",
      "Epoch: 7 Step: 801 Loss: 0.05718542027467355\n",
      "Epoch: 7 Step: 811 Loss: 0.03630633344243331\n",
      "Epoch: 7 Step: 821 Loss: 0.06236911006158932\n",
      "Epoch: 7 Step: 831 Loss: 0.15577380047415385\n",
      "Epoch: 7 Step: 841 Loss: 0.03482035483306201\n",
      "Epoch: 7 Step: 851 Loss: 0.09307961116216351\n",
      "Epoch: 7 Step: 861 Loss: 0.07633203517425581\n",
      "Epoch: 7 Step: 871 Loss: 0.22980243014874666\n",
      "Epoch: 7 Step: 881 Loss: 0.07834785893025789\n",
      "Epoch: 7 Step: 891 Loss: 0.03415365994527886\n",
      "Epoch: 7 Step: 901 Loss: 0.25541819002700583\n",
      "Epoch: 7 Step: 911 Loss: 0.01197429448364234\n",
      "Epoch: 7 Step: 921 Loss: 0.02998192571513294\n",
      "Epoch: 7 Step: 931 Loss: 0.011420907647223963\n",
      "Epoch: 8 Step: 1 Loss: 0.023443838229065164\n",
      "Epoch: 8 Step: 11 Loss: 0.16462230993288146\n",
      "Epoch: 8 Step: 21 Loss: 0.10950366896560598\n",
      "Epoch: 8 Step: 31 Loss: 0.0915233719131936\n",
      "Epoch: 8 Step: 41 Loss: 0.04490996400243019\n",
      "Epoch: 8 Step: 51 Loss: 0.137242038441221\n",
      "Epoch: 8 Step: 61 Loss: 0.02840531204033347\n",
      "Epoch: 8 Step: 71 Loss: 0.011652227901343943\n",
      "Epoch: 8 Step: 81 Loss: 0.13362262646970358\n",
      "Epoch: 8 Step: 91 Loss: 0.15278229983950287\n",
      "Epoch: 8 Step: 101 Loss: 0.07755134294028282\n",
      "Epoch: 8 Step: 111 Loss: 0.03105984567444403\n",
      "Epoch: 8 Step: 121 Loss: 0.1142325786517307\n",
      "Epoch: 8 Step: 131 Loss: 0.06588511425673717\n",
      "Epoch: 8 Step: 141 Loss: 0.1695154814853788\n",
      "Epoch: 8 Step: 151 Loss: 0.11605194716387895\n",
      "Epoch: 8 Step: 161 Loss: 0.3671513435384528\n",
      "Epoch: 8 Step: 171 Loss: 0.08991744651506954\n",
      "Epoch: 8 Step: 181 Loss: 0.270350967425953\n",
      "Epoch: 8 Step: 191 Loss: 0.07812970158055796\n",
      "Epoch: 8 Step: 201 Loss: 0.08083851945859148\n",
      "Epoch: 8 Step: 211 Loss: 0.12568676444152532\n",
      "Epoch: 8 Step: 221 Loss: 0.13105877056831275\n",
      "Epoch: 8 Step: 231 Loss: 0.18714268055004485\n",
      "Epoch: 8 Step: 241 Loss: 0.04332729958906727\n",
      "Epoch: 8 Step: 251 Loss: 0.17385601734564388\n",
      "Epoch: 8 Step: 261 Loss: 0.14689200527548568\n",
      "Epoch: 8 Step: 271 Loss: 0.09124129581255391\n",
      "Epoch: 8 Step: 281 Loss: 0.12936486402898018\n",
      "Epoch: 8 Step: 291 Loss: 0.06072801034888592\n",
      "Epoch: 8 Step: 301 Loss: 0.03829631480898663\n",
      "Epoch: 8 Step: 311 Loss: 0.07242830172802284\n",
      "Epoch: 8 Step: 321 Loss: 0.04527686920701751\n",
      "Epoch: 8 Step: 331 Loss: 0.05195355068397431\n",
      "Epoch: 8 Step: 341 Loss: 0.06878939846325438\n",
      "Epoch: 8 Step: 351 Loss: 0.06839534510047891\n",
      "Epoch: 8 Step: 361 Loss: 0.10753467590801623\n",
      "Epoch: 8 Step: 371 Loss: 0.17212932615601106\n",
      "Epoch: 8 Step: 381 Loss: 0.00867088459758075\n",
      "Epoch: 8 Step: 391 Loss: 0.0692077967936547\n",
      "Epoch: 8 Step: 401 Loss: 0.21228457587023208\n",
      "Epoch: 8 Step: 411 Loss: 0.08884068863297614\n",
      "Epoch: 8 Step: 421 Loss: 0.2237497104786002\n",
      "Epoch: 8 Step: 431 Loss: 0.10950234062428851\n",
      "Epoch: 8 Step: 441 Loss: 0.08811616803896988\n",
      "Epoch: 8 Step: 451 Loss: 0.09223895385066719\n",
      "Epoch: 8 Step: 461 Loss: 0.05394656467919691\n",
      "Epoch: 8 Step: 471 Loss: 0.13141499184408986\n",
      "Epoch: 8 Step: 481 Loss: 0.028528745928487233\n",
      "Epoch: 8 Step: 491 Loss: 0.02595522204466984\n",
      "Epoch: 8 Step: 501 Loss: 0.17700234169913087\n",
      "Epoch: 8 Step: 511 Loss: 0.1544067312617101\n",
      "Epoch: 8 Step: 521 Loss: 0.08743975527705082\n",
      "Epoch: 8 Step: 531 Loss: 0.00897526591873395\n",
      "Epoch: 8 Step: 541 Loss: 0.05827649824185168\n",
      "Epoch: 8 Step: 551 Loss: 0.15252530492038505\n",
      "Epoch: 8 Step: 561 Loss: 0.14777993743047496\n",
      "Epoch: 8 Step: 571 Loss: 0.0778975562385357\n",
      "Epoch: 8 Step: 581 Loss: 0.06305174419225301\n",
      "Epoch: 8 Step: 591 Loss: 0.1810730649539177\n",
      "Epoch: 8 Step: 601 Loss: 0.17418279663000039\n",
      "Epoch: 8 Step: 611 Loss: 0.026011520743179868\n",
      "Epoch: 8 Step: 621 Loss: 0.11402335028826617\n",
      "Epoch: 8 Step: 631 Loss: 0.11884842976194554\n",
      "Epoch: 8 Step: 641 Loss: 0.24518558089301934\n",
      "Epoch: 8 Step: 651 Loss: 0.04849413633507818\n",
      "Epoch: 8 Step: 661 Loss: 0.09175739126201397\n",
      "Epoch: 8 Step: 671 Loss: 0.16622639282408286\n",
      "Epoch: 8 Step: 681 Loss: 0.16910207302195207\n",
      "Epoch: 8 Step: 691 Loss: 0.14218119502583765\n",
      "Epoch: 8 Step: 701 Loss: 0.34663750922367526\n",
      "Epoch: 8 Step: 711 Loss: 0.15025166021380346\n",
      "Epoch: 8 Step: 721 Loss: 0.08029282372684385\n",
      "Epoch: 8 Step: 731 Loss: 0.15503985874546136\n",
      "Epoch: 8 Step: 741 Loss: 0.05614106271369486\n",
      "Epoch: 8 Step: 751 Loss: 0.10058104607248763\n",
      "Epoch: 8 Step: 761 Loss: 0.02891024755824566\n",
      "Epoch: 8 Step: 771 Loss: 0.03911365561544186\n",
      "Epoch: 8 Step: 781 Loss: 0.11110548377597393\n",
      "Epoch: 8 Step: 791 Loss: 0.1041639522002138\n",
      "Epoch: 8 Step: 801 Loss: 0.05200300374728209\n",
      "Epoch: 8 Step: 811 Loss: 0.01992203174691956\n",
      "Epoch: 8 Step: 821 Loss: 0.015681638582674372\n",
      "Epoch: 8 Step: 831 Loss: 0.16440833048438852\n",
      "Epoch: 8 Step: 841 Loss: 0.022633980651689315\n",
      "Epoch: 8 Step: 851 Loss: 0.13322359309853743\n",
      "Epoch: 8 Step: 861 Loss: 0.09950687180395963\n",
      "Epoch: 8 Step: 871 Loss: 0.2438625988632898\n",
      "Epoch: 8 Step: 881 Loss: 0.08320630245126745\n",
      "Epoch: 8 Step: 891 Loss: 0.03026406881336502\n",
      "Epoch: 8 Step: 901 Loss: 0.34738342412702805\n",
      "Epoch: 8 Step: 911 Loss: 0.03229844725555212\n",
      "Epoch: 8 Step: 921 Loss: 0.008264010000895914\n",
      "Epoch: 8 Step: 931 Loss: 0.012682539495007064\n",
      "Epoch: 9 Step: 1 Loss: 0.04284442878729504\n",
      "Epoch: 9 Step: 11 Loss: 0.040854182962022804\n",
      "Epoch: 9 Step: 21 Loss: 0.20392415373580589\n",
      "Epoch: 9 Step: 31 Loss: 0.13000181770884986\n",
      "Epoch: 9 Step: 41 Loss: 0.048146561213343986\n",
      "Epoch: 9 Step: 51 Loss: 0.059177972924778416\n",
      "Epoch: 9 Step: 61 Loss: 0.015104159671442715\n",
      "Epoch: 9 Step: 71 Loss: 0.055548458631861704\n",
      "Epoch: 9 Step: 81 Loss: 0.10264401146535342\n",
      "Epoch: 9 Step: 91 Loss: 0.12104993389194671\n",
      "Epoch: 9 Step: 101 Loss: 0.1907020705460997\n",
      "Epoch: 9 Step: 111 Loss: 0.06724710728578281\n",
      "Epoch: 9 Step: 121 Loss: 0.1047845934175197\n",
      "Epoch: 9 Step: 131 Loss: 0.04628067222495883\n",
      "Epoch: 9 Step: 141 Loss: 0.11004292251469355\n",
      "Epoch: 9 Step: 151 Loss: 0.1504897467363009\n",
      "Epoch: 9 Step: 161 Loss: 0.19715589491249919\n",
      "Epoch: 9 Step: 171 Loss: 0.04795012516222172\n",
      "Epoch: 9 Step: 181 Loss: 0.21341886098459487\n",
      "Epoch: 9 Step: 191 Loss: 0.08331600733515868\n",
      "Epoch: 9 Step: 201 Loss: 0.15737795960358963\n",
      "Epoch: 9 Step: 211 Loss: 0.0776778315654686\n",
      "Epoch: 9 Step: 221 Loss: 0.07819234503238787\n",
      "Epoch: 9 Step: 231 Loss: 0.1411762220323469\n",
      "Epoch: 9 Step: 241 Loss: 0.1365977345097205\n",
      "Epoch: 9 Step: 251 Loss: 0.10856265827910484\n",
      "Epoch: 9 Step: 261 Loss: 0.20844698545064286\n",
      "Epoch: 9 Step: 271 Loss: 0.08784540433991406\n",
      "Epoch: 9 Step: 281 Loss: 0.0698578067470876\n",
      "Epoch: 9 Step: 291 Loss: 0.12720218003934294\n",
      "Epoch: 9 Step: 301 Loss: 0.04612564765196686\n",
      "Epoch: 9 Step: 311 Loss: 0.07456799494152737\n",
      "Epoch: 9 Step: 321 Loss: 0.057066370293435226\n",
      "Epoch: 9 Step: 331 Loss: 0.2669943436109018\n",
      "Epoch: 9 Step: 341 Loss: 0.012016830354238407\n",
      "Epoch: 9 Step: 351 Loss: 0.12450166676717153\n",
      "Epoch: 9 Step: 361 Loss: 0.17622369930780518\n",
      "Epoch: 9 Step: 371 Loss: 0.2173265376652385\n",
      "Epoch: 9 Step: 381 Loss: 0.016697485321748612\n",
      "Epoch: 9 Step: 391 Loss: 0.0365827481310895\n",
      "Epoch: 9 Step: 401 Loss: 0.08073843659746208\n",
      "Epoch: 9 Step: 411 Loss: 0.07378100479786419\n",
      "Epoch: 9 Step: 421 Loss: 0.24935563980269698\n",
      "Epoch: 9 Step: 431 Loss: 0.18770543391365965\n",
      "Epoch: 9 Step: 441 Loss: 0.09322719766950152\n",
      "Epoch: 9 Step: 451 Loss: 0.0697699101408986\n",
      "Epoch: 9 Step: 461 Loss: 0.09052507648606035\n",
      "Epoch: 9 Step: 471 Loss: 0.1128430577146988\n",
      "Epoch: 9 Step: 481 Loss: 0.03989579066819292\n",
      "Epoch: 9 Step: 491 Loss: 0.053415853288193385\n",
      "Epoch: 9 Step: 501 Loss: 0.07475742462391734\n",
      "Epoch: 9 Step: 511 Loss: 0.0971785824612973\n",
      "Epoch: 9 Step: 521 Loss: 0.16797410601348806\n",
      "Epoch: 9 Step: 531 Loss: 0.005029097283478327\n",
      "Epoch: 9 Step: 541 Loss: 0.04342699192731049\n",
      "Epoch: 9 Step: 551 Loss: 0.24972233758998405\n",
      "Epoch: 9 Step: 561 Loss: 0.08369724020592087\n",
      "Epoch: 9 Step: 571 Loss: 0.03978269528600748\n",
      "Epoch: 9 Step: 581 Loss: 0.1291362871727956\n",
      "Epoch: 9 Step: 591 Loss: 0.11653997351412554\n",
      "Epoch: 9 Step: 601 Loss: 0.07652279075707294\n",
      "Epoch: 9 Step: 611 Loss: 0.021271324203885725\n",
      "Epoch: 9 Step: 621 Loss: 0.08536794638430258\n",
      "Epoch: 9 Step: 631 Loss: 0.0978850135677896\n",
      "Epoch: 9 Step: 641 Loss: 0.19227343720106319\n",
      "Epoch: 9 Step: 651 Loss: 0.061470986975139474\n",
      "Epoch: 9 Step: 661 Loss: 0.05176336652987276\n",
      "Epoch: 9 Step: 671 Loss: 0.15563262116320925\n",
      "Epoch: 9 Step: 681 Loss: 0.16342154995781727\n",
      "Epoch: 9 Step: 691 Loss: 0.12786507386777304\n",
      "Epoch: 9 Step: 701 Loss: 0.2095809010150117\n",
      "Epoch: 9 Step: 711 Loss: 0.06853189141820656\n",
      "Epoch: 9 Step: 721 Loss: 0.1258069210628688\n",
      "Epoch: 9 Step: 731 Loss: 0.13879240365981343\n",
      "Epoch: 9 Step: 741 Loss: 0.10825733751071079\n",
      "Epoch: 9 Step: 751 Loss: 0.018686302019017893\n",
      "Epoch: 9 Step: 761 Loss: 0.04276638970474016\n",
      "Epoch: 9 Step: 771 Loss: 0.01454261604717205\n",
      "Epoch: 9 Step: 781 Loss: 0.12696332924074044\n",
      "Epoch: 9 Step: 791 Loss: 0.0957575679072275\n",
      "Epoch: 9 Step: 801 Loss: 0.13952496217837443\n",
      "Epoch: 9 Step: 811 Loss: 0.054917250930208356\n",
      "Epoch: 9 Step: 821 Loss: 0.020352031209419936\n",
      "Epoch: 9 Step: 831 Loss: 0.17718619958122536\n",
      "Epoch: 9 Step: 841 Loss: 0.007886341671940836\n",
      "Epoch: 9 Step: 851 Loss: 0.12244295575991299\n",
      "Epoch: 9 Step: 861 Loss: 0.02092592706030658\n",
      "Epoch: 9 Step: 871 Loss: 0.19534696630345616\n",
      "Epoch: 9 Step: 881 Loss: 0.12066007727618837\n",
      "Epoch: 9 Step: 891 Loss: 0.038381518959481296\n",
      "Epoch: 9 Step: 901 Loss: 0.2571859378193654\n",
      "Epoch: 9 Step: 911 Loss: 0.04870581535334599\n",
      "Epoch: 9 Step: 921 Loss: 0.00996461943207452\n",
      "Epoch: 9 Step: 931 Loss: 0.003950355261685366\n",
      "Epoch: 10 Step: 1 Loss: 0.03756967928895157\n",
      "Epoch: 10 Step: 11 Loss: 0.16083491400670977\n",
      "Epoch: 10 Step: 21 Loss: 0.09699184894944138\n",
      "Epoch: 10 Step: 31 Loss: 0.017893951699775833\n",
      "Epoch: 10 Step: 41 Loss: 0.01489415864319579\n",
      "Epoch: 10 Step: 51 Loss: 0.06354207277276822\n",
      "Epoch: 10 Step: 61 Loss: 0.017640415246865694\n",
      "Epoch: 10 Step: 71 Loss: 0.06217543729315369\n",
      "Epoch: 10 Step: 81 Loss: 0.11372930319546214\n",
      "Epoch: 10 Step: 91 Loss: 0.0559395073214008\n",
      "Epoch: 10 Step: 101 Loss: 0.06534819997822872\n",
      "Epoch: 10 Step: 111 Loss: 0.14657916811309496\n",
      "Epoch: 10 Step: 121 Loss: 0.09787505135145685\n",
      "Epoch: 10 Step: 131 Loss: 0.04290945683398895\n",
      "Epoch: 10 Step: 141 Loss: 0.07134970420264887\n",
      "Epoch: 10 Step: 151 Loss: 0.06732430686130492\n",
      "Epoch: 10 Step: 161 Loss: 0.3060508840469165\n",
      "Epoch: 10 Step: 171 Loss: 0.02082659271567946\n",
      "Epoch: 10 Step: 181 Loss: 0.2298373128781807\n",
      "Epoch: 10 Step: 191 Loss: 0.07990142387088778\n",
      "Epoch: 10 Step: 201 Loss: 0.12824708923347167\n",
      "Epoch: 10 Step: 211 Loss: 0.04408696789554406\n",
      "Epoch: 10 Step: 221 Loss: 0.12284885598707619\n",
      "Epoch: 10 Step: 231 Loss: 0.12750531375511104\n",
      "Epoch: 10 Step: 241 Loss: 0.03574534208284781\n",
      "Epoch: 10 Step: 251 Loss: 0.15391493247653082\n",
      "Epoch: 10 Step: 261 Loss: 0.13593586699229085\n",
      "Epoch: 10 Step: 271 Loss: 0.04271606697449186\n",
      "Epoch: 10 Step: 281 Loss: 0.060308466980248346\n",
      "Epoch: 10 Step: 291 Loss: 0.01821239547041732\n",
      "Epoch: 10 Step: 301 Loss: 0.031241633493731887\n",
      "Epoch: 10 Step: 311 Loss: 0.03335241605562475\n",
      "Epoch: 10 Step: 321 Loss: 0.039738347880045044\n",
      "Epoch: 10 Step: 331 Loss: 0.11360912400072679\n",
      "Epoch: 10 Step: 341 Loss: 0.0709867909729615\n",
      "Epoch: 10 Step: 351 Loss: 0.0707536368245909\n",
      "Epoch: 10 Step: 361 Loss: 0.15720680039049403\n",
      "Epoch: 10 Step: 371 Loss: 0.09358385199190955\n",
      "Epoch: 10 Step: 381 Loss: 0.02131125642760033\n",
      "Epoch: 10 Step: 391 Loss: 0.03150922189813657\n",
      "Epoch: 10 Step: 401 Loss: 0.12857032177265967\n",
      "Epoch: 10 Step: 411 Loss: 0.042506928023077525\n",
      "Epoch: 10 Step: 421 Loss: 0.18890584171566926\n",
      "Epoch: 10 Step: 431 Loss: 0.16893697760142146\n",
      "Epoch: 10 Step: 441 Loss: 0.02307961507987219\n",
      "Epoch: 10 Step: 451 Loss: 0.11535122509556651\n",
      "Epoch: 10 Step: 461 Loss: 0.031144194106728924\n",
      "Epoch: 10 Step: 471 Loss: 0.12373632130343486\n",
      "Epoch: 10 Step: 481 Loss: 0.09802445969212152\n",
      "Epoch: 10 Step: 491 Loss: 0.024400002329076614\n",
      "Epoch: 10 Step: 501 Loss: 0.08846611868355167\n",
      "Epoch: 10 Step: 511 Loss: 0.031537285119817675\n",
      "Epoch: 10 Step: 521 Loss: 0.009840233167681156\n",
      "Epoch: 10 Step: 531 Loss: 0.017919895135170064\n",
      "Epoch: 10 Step: 541 Loss: 0.049099512841342605\n",
      "Epoch: 10 Step: 551 Loss: 0.10518074082977306\n",
      "Epoch: 10 Step: 561 Loss: 0.18818538314623137\n",
      "Epoch: 10 Step: 571 Loss: 0.033898448380140445\n",
      "Epoch: 10 Step: 581 Loss: 0.022259702237856255\n",
      "Epoch: 10 Step: 591 Loss: 0.057326421903535235\n",
      "Epoch: 10 Step: 601 Loss: 0.09536075927992627\n",
      "Epoch: 10 Step: 611 Loss: 0.02124068809485879\n",
      "Epoch: 10 Step: 621 Loss: 0.11304716545050941\n",
      "Epoch: 10 Step: 631 Loss: 0.07248579219472609\n",
      "Epoch: 10 Step: 641 Loss: 0.20967277040908977\n",
      "Epoch: 10 Step: 651 Loss: 0.07913175681703868\n",
      "Epoch: 10 Step: 661 Loss: 0.04222560611898534\n",
      "Epoch: 10 Step: 671 Loss: 0.1235705873890475\n",
      "Epoch: 10 Step: 681 Loss: 0.13515806405877395\n",
      "Epoch: 10 Step: 691 Loss: 0.0329911331668375\n",
      "Epoch: 10 Step: 701 Loss: 0.3332143682817986\n",
      "Epoch: 10 Step: 711 Loss: 0.024769960800371155\n",
      "Epoch: 10 Step: 721 Loss: 0.10251360517703158\n",
      "Epoch: 10 Step: 731 Loss: 0.08025003688663955\n",
      "Epoch: 10 Step: 741 Loss: 0.0254654522347117\n",
      "Epoch: 10 Step: 751 Loss: 0.019394876148541917\n",
      "Epoch: 10 Step: 761 Loss: 0.10790408220682075\n",
      "Epoch: 10 Step: 771 Loss: 0.07700326101676386\n",
      "Epoch: 10 Step: 781 Loss: 0.08657947339685025\n",
      "Epoch: 10 Step: 791 Loss: 0.13528393331124408\n",
      "Epoch: 10 Step: 801 Loss: 0.17008874889701678\n",
      "Epoch: 10 Step: 811 Loss: 0.011494263368572358\n",
      "Epoch: 10 Step: 821 Loss: 0.022297871372933358\n",
      "Epoch: 10 Step: 831 Loss: 0.1829384865007601\n",
      "Epoch: 10 Step: 841 Loss: 0.05721363063524475\n",
      "Epoch: 10 Step: 851 Loss: 0.12964064855863466\n",
      "Epoch: 10 Step: 861 Loss: 0.0906900778211942\n",
      "Epoch: 10 Step: 871 Loss: 0.20495845763118592\n",
      "Epoch: 10 Step: 881 Loss: 0.09433263011100289\n",
      "Epoch: 10 Step: 891 Loss: 0.0276717457782849\n",
      "Epoch: 10 Step: 901 Loss: 0.2326238047968709\n",
      "Epoch: 10 Step: 911 Loss: 0.05361769712010799\n",
      "Epoch: 10 Step: 921 Loss: 0.02588925303115306\n",
      "Epoch: 10 Step: 931 Loss: 0.007243939006238002\n",
      "Epoch: 11 Step: 1 Loss: 0.041287462452351625\n",
      "Epoch: 11 Step: 11 Loss: 0.0933550848398616\n",
      "Epoch: 11 Step: 21 Loss: 0.050005939591147554\n",
      "Epoch: 11 Step: 31 Loss: 0.1065256539031398\n",
      "Epoch: 11 Step: 41 Loss: 0.011551693743778499\n",
      "Epoch: 11 Step: 51 Loss: 0.053095828891039074\n",
      "Epoch: 11 Step: 61 Loss: 0.009463897558494886\n",
      "Epoch: 11 Step: 71 Loss: 0.01369506920205092\n",
      "Epoch: 11 Step: 81 Loss: 0.14781450935797058\n",
      "Epoch: 11 Step: 91 Loss: 0.09753897667197554\n",
      "Epoch: 11 Step: 101 Loss: 0.09695980695229134\n",
      "Epoch: 11 Step: 111 Loss: 0.046853172142641335\n",
      "Epoch: 11 Step: 121 Loss: 0.027366936565725565\n",
      "Epoch: 11 Step: 131 Loss: 0.025082094395082473\n",
      "Epoch: 11 Step: 141 Loss: 0.08773483538804616\n",
      "Epoch: 11 Step: 151 Loss: 0.09575551369666993\n",
      "Epoch: 11 Step: 161 Loss: 0.3070757428175308\n",
      "Epoch: 11 Step: 171 Loss: 0.013403614572892894\n",
      "Epoch: 11 Step: 181 Loss: 0.31658289619645485\n",
      "Epoch: 11 Step: 191 Loss: 0.028892449857271775\n",
      "Epoch: 11 Step: 201 Loss: 0.07073073386746537\n",
      "Epoch: 11 Step: 211 Loss: 0.037165563873255286\n",
      "Epoch: 11 Step: 221 Loss: 0.0834332607089455\n",
      "Epoch: 11 Step: 231 Loss: 0.16865154778691255\n",
      "Epoch: 11 Step: 241 Loss: 0.11272485061390394\n",
      "Epoch: 11 Step: 251 Loss: 0.16042359715916432\n",
      "Epoch: 11 Step: 261 Loss: 0.11396387455126954\n",
      "Epoch: 11 Step: 271 Loss: 0.018083422146815728\n",
      "Epoch: 11 Step: 281 Loss: 0.055710440102585974\n",
      "Epoch: 11 Step: 291 Loss: 0.02723274479304187\n",
      "Epoch: 11 Step: 301 Loss: 0.11641363829338885\n",
      "Epoch: 11 Step: 311 Loss: 0.16404842426256094\n",
      "Epoch: 11 Step: 321 Loss: 0.05594172257672324\n",
      "Epoch: 11 Step: 331 Loss: 0.08041236631534684\n",
      "Epoch: 11 Step: 341 Loss: 0.03131097817611029\n",
      "Epoch: 11 Step: 351 Loss: 0.1187816500971787\n",
      "Epoch: 11 Step: 361 Loss: 0.024524220256102718\n",
      "Epoch: 11 Step: 371 Loss: 0.13899366517584355\n",
      "Epoch: 11 Step: 381 Loss: 0.017566034832092802\n",
      "Epoch: 11 Step: 391 Loss: 0.014315428543447556\n",
      "Epoch: 11 Step: 401 Loss: 0.0559600067139637\n",
      "Epoch: 11 Step: 411 Loss: 0.09690740855963681\n",
      "Epoch: 11 Step: 421 Loss: 0.143557081495779\n",
      "Epoch: 11 Step: 431 Loss: 0.10581482453363221\n",
      "Epoch: 11 Step: 441 Loss: 0.06841660746805878\n",
      "Epoch: 11 Step: 451 Loss: 0.09613077772096632\n",
      "Epoch: 11 Step: 461 Loss: 0.049726035929756135\n",
      "Epoch: 11 Step: 471 Loss: 0.09681928731072692\n",
      "Epoch: 11 Step: 481 Loss: 0.036211499732480175\n",
      "Epoch: 11 Step: 491 Loss: 0.022526345024418193\n",
      "Epoch: 11 Step: 501 Loss: 0.033458284467027595\n",
      "Epoch: 11 Step: 511 Loss: 0.08821237440316994\n",
      "Epoch: 11 Step: 521 Loss: 0.03208989234165137\n",
      "Epoch: 11 Step: 531 Loss: 0.01604623730671551\n",
      "Epoch: 11 Step: 541 Loss: 0.020714725126081177\n",
      "Epoch: 11 Step: 551 Loss: 0.12446370908904704\n",
      "Epoch: 11 Step: 561 Loss: 0.09883727326665463\n",
      "Epoch: 11 Step: 571 Loss: 0.028242622435337095\n",
      "Epoch: 11 Step: 581 Loss: 0.0752624445236653\n",
      "Epoch: 11 Step: 591 Loss: 0.0905952373249693\n",
      "Epoch: 11 Step: 601 Loss: 0.07620513317072289\n",
      "Epoch: 11 Step: 611 Loss: 0.0066254302858789905\n",
      "Epoch: 11 Step: 621 Loss: 0.1231204304342508\n",
      "Epoch: 11 Step: 631 Loss: 0.08526874313132601\n",
      "Epoch: 11 Step: 641 Loss: 0.22417047302705057\n",
      "Epoch: 11 Step: 651 Loss: 0.024463570134721307\n",
      "Epoch: 11 Step: 661 Loss: 0.05737431637170862\n",
      "Epoch: 11 Step: 671 Loss: 0.11218530673240541\n",
      "Epoch: 11 Step: 681 Loss: 0.16797578320894466\n",
      "Epoch: 11 Step: 691 Loss: 0.06932707089740728\n",
      "Epoch: 11 Step: 701 Loss: 0.257923183921737\n",
      "Epoch: 11 Step: 711 Loss: 0.052737347064003355\n",
      "Epoch: 11 Step: 721 Loss: 0.014648951138242028\n",
      "Epoch: 11 Step: 731 Loss: 0.022814739389563726\n",
      "Epoch: 11 Step: 741 Loss: 0.08152694217305652\n",
      "Epoch: 11 Step: 751 Loss: 0.029687240587604607\n",
      "Epoch: 11 Step: 761 Loss: 0.05784664813890725\n",
      "Epoch: 11 Step: 771 Loss: 0.07453825169150767\n",
      "Epoch: 11 Step: 781 Loss: 0.07473795469356671\n",
      "Epoch: 11 Step: 791 Loss: 0.15641778545915572\n",
      "Epoch: 11 Step: 801 Loss: 0.04841374339774158\n",
      "Epoch: 11 Step: 811 Loss: 0.04452024153887793\n",
      "Epoch: 11 Step: 821 Loss: 0.041419683795424725\n",
      "Epoch: 11 Step: 831 Loss: 0.062024080245969046\n",
      "Epoch: 11 Step: 841 Loss: 0.01284268358115003\n",
      "Epoch: 11 Step: 851 Loss: 0.06635271609180748\n",
      "Epoch: 11 Step: 861 Loss: 0.08108094792582696\n",
      "Epoch: 11 Step: 871 Loss: 0.34585968424255664\n",
      "Epoch: 11 Step: 881 Loss: 0.11334879828802102\n",
      "Epoch: 11 Step: 891 Loss: 0.05278415855417873\n",
      "Epoch: 11 Step: 901 Loss: 0.3091240986207453\n",
      "Epoch: 11 Step: 911 Loss: 0.006890018262287544\n",
      "Epoch: 11 Step: 921 Loss: 0.056063485835488126\n",
      "Epoch: 11 Step: 931 Loss: 0.010925680282539832\n",
      "Epoch: 12 Step: 1 Loss: 0.09811111487874331\n",
      "Epoch: 12 Step: 11 Loss: 0.11869731269270921\n",
      "Epoch: 12 Step: 21 Loss: 0.089812699069667\n",
      "Epoch: 12 Step: 31 Loss: 0.15104449833620892\n",
      "Epoch: 12 Step: 41 Loss: 0.029456091258832313\n",
      "Epoch: 12 Step: 51 Loss: 0.05141163115079923\n",
      "Epoch: 12 Step: 61 Loss: 0.05850261374077356\n",
      "Epoch: 12 Step: 71 Loss: 0.013192012996451688\n",
      "Epoch: 12 Step: 81 Loss: 0.10798502013800111\n",
      "Epoch: 12 Step: 91 Loss: 0.1500835419436291\n",
      "Epoch: 12 Step: 101 Loss: 0.06114329478953845\n",
      "Epoch: 12 Step: 111 Loss: 0.020026775403899213\n",
      "Epoch: 12 Step: 121 Loss: 0.12587000533239812\n",
      "Epoch: 12 Step: 131 Loss: 0.08611436352498761\n",
      "Epoch: 12 Step: 141 Loss: 0.08710697269690072\n",
      "Epoch: 12 Step: 151 Loss: 0.060195928952378366\n",
      "Epoch: 12 Step: 161 Loss: 0.3034141001972318\n",
      "Epoch: 12 Step: 171 Loss: 0.04764571901543011\n",
      "Epoch: 12 Step: 181 Loss: 0.20141849239097145\n",
      "Epoch: 12 Step: 191 Loss: 0.03575553160697925\n",
      "Epoch: 12 Step: 201 Loss: 0.07375558894876927\n",
      "Epoch: 12 Step: 211 Loss: 0.09900868526155623\n",
      "Epoch: 12 Step: 221 Loss: 0.05630339812419061\n",
      "Epoch: 12 Step: 231 Loss: 0.1668963268672764\n",
      "Epoch: 12 Step: 241 Loss: 0.049338235371475775\n",
      "Epoch: 12 Step: 251 Loss: 0.05771013976175111\n",
      "Epoch: 12 Step: 261 Loss: 0.07311671450790211\n",
      "Epoch: 12 Step: 271 Loss: 0.013701109077180794\n",
      "Epoch: 12 Step: 281 Loss: 0.0903470946930493\n",
      "Epoch: 12 Step: 291 Loss: 0.11109505716414222\n",
      "Epoch: 12 Step: 301 Loss: 0.1089550946948188\n",
      "Epoch: 12 Step: 311 Loss: 0.05008602638118624\n",
      "Epoch: 12 Step: 321 Loss: 0.11983231090423782\n",
      "Epoch: 12 Step: 331 Loss: 0.12664980710649038\n",
      "Epoch: 12 Step: 341 Loss: 0.04712529059800222\n",
      "Epoch: 12 Step: 351 Loss: 0.10441613099636345\n",
      "Epoch: 12 Step: 361 Loss: 0.14333856403313847\n",
      "Epoch: 12 Step: 371 Loss: 0.16448169013881236\n",
      "Epoch: 12 Step: 381 Loss: 0.009207477483606487\n",
      "Epoch: 12 Step: 391 Loss: 0.012969005889594563\n",
      "Epoch: 12 Step: 401 Loss: 0.14264970267712376\n",
      "Epoch: 12 Step: 411 Loss: 0.035944913799137015\n",
      "Epoch: 12 Step: 421 Loss: 0.12854573646531142\n",
      "Epoch: 12 Step: 431 Loss: 0.21021177134860383\n",
      "Epoch: 12 Step: 441 Loss: 0.04326928881089552\n",
      "Epoch: 12 Step: 451 Loss: 0.01826522327521319\n",
      "Epoch: 12 Step: 461 Loss: 0.09957739517683038\n",
      "Epoch: 12 Step: 471 Loss: 0.11976726226643801\n",
      "Epoch: 12 Step: 481 Loss: 0.03787297294129943\n",
      "Epoch: 12 Step: 491 Loss: 0.05008451168857135\n",
      "Epoch: 12 Step: 501 Loss: 0.06536258187369243\n",
      "Epoch: 12 Step: 511 Loss: 0.04958176913983425\n",
      "Epoch: 12 Step: 521 Loss: 0.040116859993571966\n",
      "Epoch: 12 Step: 531 Loss: 0.015008779372932254\n",
      "Epoch: 12 Step: 541 Loss: 0.004566682771142947\n",
      "Epoch: 12 Step: 551 Loss: 0.155239962480897\n",
      "Epoch: 12 Step: 561 Loss: 0.07971876895028818\n",
      "Epoch: 12 Step: 571 Loss: 0.04033890089275507\n",
      "Epoch: 12 Step: 581 Loss: 0.03732261551223222\n",
      "Epoch: 12 Step: 591 Loss: 0.027634094548784273\n",
      "Epoch: 12 Step: 601 Loss: 0.03981735693438929\n",
      "Epoch: 12 Step: 611 Loss: 0.012423176525514385\n",
      "Epoch: 12 Step: 621 Loss: 0.08961722000613634\n",
      "Epoch: 12 Step: 631 Loss: 0.09826428016361814\n",
      "Epoch: 12 Step: 641 Loss: 0.21193997625657834\n",
      "Epoch: 12 Step: 651 Loss: 0.02369273393027375\n",
      "Epoch: 12 Step: 661 Loss: 0.06976199665296466\n",
      "Epoch: 12 Step: 671 Loss: 0.0931711935868806\n",
      "Epoch: 12 Step: 681 Loss: 0.12221597022109396\n",
      "Epoch: 12 Step: 691 Loss: 0.014371809611792892\n",
      "Epoch: 12 Step: 701 Loss: 0.11667810415358927\n",
      "Epoch: 12 Step: 711 Loss: 0.025328616631918897\n",
      "Epoch: 12 Step: 721 Loss: 0.0951884806356048\n",
      "Epoch: 12 Step: 731 Loss: 0.04806052068889273\n",
      "Epoch: 12 Step: 741 Loss: 0.039320400821546864\n",
      "Epoch: 12 Step: 751 Loss: 0.02306423477021245\n",
      "Epoch: 12 Step: 761 Loss: 0.008379172436988793\n",
      "Epoch: 12 Step: 771 Loss: 0.013299797421227824\n",
      "Epoch: 12 Step: 781 Loss: 0.149754934168403\n",
      "Epoch: 12 Step: 791 Loss: 0.09127603873925824\n",
      "Epoch: 12 Step: 801 Loss: 0.0809317043117847\n",
      "Epoch: 12 Step: 811 Loss: 0.016998921508925405\n",
      "Epoch: 12 Step: 821 Loss: 0.023035050906197202\n",
      "Epoch: 12 Step: 831 Loss: 0.13797991568191698\n",
      "Epoch: 12 Step: 841 Loss: 0.013765782706959023\n",
      "Epoch: 12 Step: 851 Loss: 0.051443045500164986\n",
      "Epoch: 12 Step: 861 Loss: 0.08459949481261775\n",
      "Epoch: 12 Step: 871 Loss: 0.20958910863395686\n",
      "Epoch: 12 Step: 881 Loss: 0.12795876181455465\n",
      "Epoch: 12 Step: 891 Loss: 0.10722707644170724\n",
      "Epoch: 12 Step: 901 Loss: 0.35965795668593636\n",
      "Epoch: 12 Step: 911 Loss: 0.03347528627914854\n",
      "Epoch: 12 Step: 921 Loss: 0.012118880602389581\n",
      "Epoch: 12 Step: 931 Loss: 0.004096062326437367\n",
      "Epoch: 13 Step: 1 Loss: 0.017861085056848865\n",
      "Epoch: 13 Step: 11 Loss: 0.06504533404942947\n",
      "Epoch: 13 Step: 21 Loss: 0.05409158349103447\n",
      "Epoch: 13 Step: 31 Loss: 0.11318220684870109\n",
      "Epoch: 13 Step: 41 Loss: 0.022967511753593652\n",
      "Epoch: 13 Step: 51 Loss: 0.028759744913789718\n",
      "Epoch: 13 Step: 61 Loss: 0.006558153204139418\n",
      "Epoch: 13 Step: 71 Loss: 0.011269531339900562\n",
      "Epoch: 13 Step: 81 Loss: 0.07031750815141774\n",
      "Epoch: 13 Step: 91 Loss: 0.07237418223723063\n",
      "Epoch: 13 Step: 101 Loss: 0.04616979856611128\n",
      "Epoch: 13 Step: 111 Loss: 0.0773311090640292\n",
      "Epoch: 13 Step: 121 Loss: 0.02886795137085334\n",
      "Epoch: 13 Step: 131 Loss: 0.06469192406924362\n",
      "Epoch: 13 Step: 141 Loss: 0.07205125075708009\n",
      "Epoch: 13 Step: 151 Loss: 0.09859568493049682\n",
      "Epoch: 13 Step: 161 Loss: 0.23150255975645923\n",
      "Epoch: 13 Step: 171 Loss: 0.023663772435692842\n",
      "Epoch: 13 Step: 181 Loss: 0.199379164167418\n",
      "Epoch: 13 Step: 191 Loss: 0.018766342446076223\n",
      "Epoch: 13 Step: 201 Loss: 0.1257368787810143\n",
      "Epoch: 13 Step: 211 Loss: 0.04374834856598635\n",
      "Epoch: 13 Step: 221 Loss: 0.03218161135415713\n",
      "Epoch: 13 Step: 231 Loss: 0.20614066860274097\n",
      "Epoch: 13 Step: 241 Loss: 0.04433461508665372\n",
      "Epoch: 13 Step: 251 Loss: 0.04465573114309186\n",
      "Epoch: 13 Step: 261 Loss: 0.03405928892575668\n",
      "Epoch: 13 Step: 271 Loss: 0.07594312359612974\n",
      "Epoch: 13 Step: 281 Loss: 0.06397262101947523\n",
      "Epoch: 13 Step: 291 Loss: 0.04891564753778201\n",
      "Epoch: 13 Step: 301 Loss: 0.016873943575971936\n",
      "Epoch: 13 Step: 311 Loss: 0.04625610310993138\n",
      "Epoch: 13 Step: 321 Loss: 0.04037949457896675\n",
      "Epoch: 13 Step: 331 Loss: 0.05556610704292314\n",
      "Epoch: 13 Step: 341 Loss: 0.07262595586896956\n",
      "Epoch: 13 Step: 351 Loss: 0.048858596936995284\n",
      "Epoch: 13 Step: 361 Loss: 0.04028868640145734\n",
      "Epoch: 13 Step: 371 Loss: 0.17401058674953507\n",
      "Epoch: 13 Step: 381 Loss: 0.024581834142789142\n",
      "Epoch: 13 Step: 391 Loss: 0.043928790105647375\n",
      "Epoch: 13 Step: 401 Loss: 0.07974362844432786\n",
      "Epoch: 13 Step: 411 Loss: 0.11433970790094236\n",
      "Epoch: 13 Step: 421 Loss: 0.18044835449793628\n",
      "Epoch: 13 Step: 431 Loss: 0.11191450348466538\n",
      "Epoch: 13 Step: 441 Loss: 0.007557156096677333\n",
      "Epoch: 13 Step: 451 Loss: 0.030924261506241106\n",
      "Epoch: 13 Step: 461 Loss: 0.053199323535644064\n",
      "Epoch: 13 Step: 471 Loss: 0.06759723974716343\n",
      "Epoch: 13 Step: 481 Loss: 0.07862177772998948\n",
      "Epoch: 13 Step: 491 Loss: 0.021266543240845717\n",
      "Epoch: 13 Step: 501 Loss: 0.016214247741019754\n",
      "Epoch: 13 Step: 511 Loss: 0.08825823527966806\n",
      "Epoch: 13 Step: 521 Loss: 0.029276423213294565\n",
      "Epoch: 13 Step: 531 Loss: 0.007097971418007899\n",
      "Epoch: 13 Step: 541 Loss: 0.044021370201533634\n",
      "Epoch: 13 Step: 551 Loss: 0.08153867883205047\n",
      "Epoch: 13 Step: 561 Loss: 0.0185308047695069\n",
      "Epoch: 13 Step: 571 Loss: 0.0591571195649287\n",
      "Epoch: 13 Step: 581 Loss: 0.08449693588719663\n",
      "Epoch: 13 Step: 591 Loss: 0.1171710870737799\n",
      "Epoch: 13 Step: 601 Loss: 0.045188901764041486\n",
      "Epoch: 13 Step: 611 Loss: 0.010998448109550571\n",
      "Epoch: 13 Step: 621 Loss: 0.05900119205977376\n",
      "Epoch: 13 Step: 631 Loss: 0.07917899767639588\n",
      "Epoch: 13 Step: 641 Loss: 0.23535234238056205\n",
      "Epoch: 13 Step: 651 Loss: 0.1616293193863439\n",
      "Epoch: 13 Step: 661 Loss: 0.038385266356432995\n",
      "Epoch: 13 Step: 671 Loss: 0.10659781492337939\n",
      "Epoch: 13 Step: 681 Loss: 0.11056236968587291\n",
      "Epoch: 13 Step: 691 Loss: 0.013524918657734173\n",
      "Epoch: 13 Step: 701 Loss: 0.17902063224191564\n",
      "Epoch: 13 Step: 711 Loss: 0.03725340644235223\n",
      "Epoch: 13 Step: 721 Loss: 0.030857580365553354\n",
      "Epoch: 13 Step: 731 Loss: 0.05739885562402358\n",
      "Epoch: 13 Step: 741 Loss: 0.07773025768326913\n",
      "Epoch: 13 Step: 751 Loss: 0.02089440656115675\n",
      "Epoch: 13 Step: 761 Loss: 0.03349746824385081\n",
      "Epoch: 13 Step: 771 Loss: 0.005492200156570776\n",
      "Epoch: 13 Step: 781 Loss: 0.028381435329596187\n",
      "Epoch: 13 Step: 791 Loss: 0.05453469953529707\n",
      "Epoch: 13 Step: 801 Loss: 0.16229892759256806\n",
      "Epoch: 13 Step: 811 Loss: 0.03125022321138442\n",
      "Epoch: 13 Step: 821 Loss: 0.0179421959813096\n",
      "Epoch: 13 Step: 831 Loss: 0.0573926110315104\n",
      "Epoch: 13 Step: 841 Loss: 0.010632369918378246\n",
      "Epoch: 13 Step: 851 Loss: 0.039764860473966636\n",
      "Epoch: 13 Step: 861 Loss: 0.08389422623929564\n",
      "Epoch: 13 Step: 871 Loss: 0.18150126822278784\n",
      "Epoch: 13 Step: 881 Loss: 0.07779640889298838\n",
      "Epoch: 13 Step: 891 Loss: 0.020804292067008782\n",
      "Epoch: 13 Step: 901 Loss: 0.12272352295031483\n",
      "Epoch: 13 Step: 911 Loss: 0.0520791171103907\n",
      "Epoch: 13 Step: 921 Loss: 0.005069732208289457\n",
      "Epoch: 13 Step: 931 Loss: 0.004579299058396037\n",
      "Epoch: 14 Step: 1 Loss: 0.017256869461427654\n",
      "Epoch: 14 Step: 11 Loss: 0.03065549278554773\n",
      "Epoch: 14 Step: 21 Loss: 0.09430201865900609\n",
      "Epoch: 14 Step: 31 Loss: 0.01748358914562686\n",
      "Epoch: 14 Step: 41 Loss: 0.028358717896623892\n",
      "Epoch: 14 Step: 51 Loss: 0.02792175493746982\n",
      "Epoch: 14 Step: 61 Loss: 0.010303153785663094\n",
      "Epoch: 14 Step: 71 Loss: 0.003947397359630799\n",
      "Epoch: 14 Step: 81 Loss: 0.031113063042322753\n",
      "Epoch: 14 Step: 91 Loss: 0.0651911310796311\n",
      "Epoch: 14 Step: 101 Loss: 0.11552326701563827\n",
      "Epoch: 14 Step: 111 Loss: 0.10567867605515753\n",
      "Epoch: 14 Step: 121 Loss: 0.02492522181040166\n",
      "Epoch: 14 Step: 131 Loss: 0.04893074379781917\n",
      "Epoch: 14 Step: 141 Loss: 0.04995772080494753\n",
      "Epoch: 14 Step: 151 Loss: 0.23233275261425196\n",
      "Epoch: 14 Step: 161 Loss: 0.29314344392217906\n",
      "Epoch: 14 Step: 171 Loss: 0.05656064919117048\n",
      "Epoch: 14 Step: 181 Loss: 0.26235463416728666\n",
      "Epoch: 14 Step: 191 Loss: 0.015409351173377245\n",
      "Epoch: 14 Step: 201 Loss: 0.03838547140603471\n",
      "Epoch: 14 Step: 211 Loss: 0.018614972497716237\n",
      "Epoch: 14 Step: 221 Loss: 0.05560449788064877\n",
      "Epoch: 14 Step: 231 Loss: 0.026141990597524645\n",
      "Epoch: 14 Step: 241 Loss: 0.0691359328686297\n",
      "Epoch: 14 Step: 251 Loss: 0.08997742192470798\n",
      "Epoch: 14 Step: 261 Loss: 0.05107835669379992\n",
      "Epoch: 14 Step: 271 Loss: 0.013487954562902546\n",
      "Epoch: 14 Step: 281 Loss: 0.0402710814188674\n",
      "Epoch: 14 Step: 291 Loss: 0.06468408025817807\n",
      "Epoch: 14 Step: 301 Loss: 0.03613175111452391\n",
      "Epoch: 14 Step: 311 Loss: 0.0885821993468583\n",
      "Epoch: 14 Step: 321 Loss: 0.015399979156842079\n",
      "Epoch: 14 Step: 331 Loss: 0.10355543756434239\n",
      "Epoch: 14 Step: 341 Loss: 0.05283108539871819\n",
      "Epoch: 14 Step: 351 Loss: 0.05928995816284045\n",
      "Epoch: 14 Step: 361 Loss: 0.13173366529716768\n",
      "Epoch: 14 Step: 371 Loss: 0.07896138935214514\n",
      "Epoch: 14 Step: 381 Loss: 0.00794643940229739\n",
      "Epoch: 14 Step: 391 Loss: 0.007185212477601753\n",
      "Epoch: 14 Step: 401 Loss: 0.09467508862112853\n",
      "Epoch: 14 Step: 411 Loss: 0.032276730554869446\n",
      "Epoch: 14 Step: 421 Loss: 0.1819520542627995\n",
      "Epoch: 14 Step: 431 Loss: 0.12867289716950447\n",
      "Epoch: 14 Step: 441 Loss: 0.017121857344072625\n",
      "Epoch: 14 Step: 451 Loss: 0.0817017933849676\n",
      "Epoch: 14 Step: 461 Loss: 0.08658235946024873\n",
      "Epoch: 14 Step: 471 Loss: 0.033311985711375385\n",
      "Epoch: 14 Step: 481 Loss: 0.06260543038452228\n",
      "Epoch: 14 Step: 491 Loss: 0.07836029927327558\n",
      "Epoch: 14 Step: 501 Loss: 0.21976497693028643\n",
      "Epoch: 14 Step: 511 Loss: 0.09184768960381715\n",
      "Epoch: 14 Step: 521 Loss: 0.030710536362167293\n",
      "Epoch: 14 Step: 531 Loss: 0.008978388093336991\n",
      "Epoch: 14 Step: 541 Loss: 0.06482568546332414\n",
      "Epoch: 14 Step: 551 Loss: 0.13957699177537788\n",
      "Epoch: 14 Step: 561 Loss: 0.09708397677438968\n",
      "Epoch: 14 Step: 571 Loss: 0.055210889002207456\n",
      "Epoch: 14 Step: 581 Loss: 0.023896871600446068\n",
      "Epoch: 14 Step: 591 Loss: 0.02180016067015173\n",
      "Epoch: 14 Step: 601 Loss: 0.06362670382574905\n",
      "Epoch: 14 Step: 611 Loss: 0.005242379464486375\n",
      "Epoch: 14 Step: 621 Loss: 0.08717890826960517\n",
      "Epoch: 14 Step: 631 Loss: 0.1140123401172572\n",
      "Epoch: 14 Step: 641 Loss: 0.16259454835001683\n",
      "Epoch: 14 Step: 651 Loss: 0.09099372582107598\n",
      "Epoch: 14 Step: 661 Loss: 0.027105060216369336\n",
      "Epoch: 14 Step: 671 Loss: 0.13217716887273523\n",
      "Epoch: 14 Step: 681 Loss: 0.07342078179603799\n",
      "Epoch: 14 Step: 691 Loss: 0.024576209976434227\n",
      "Epoch: 14 Step: 701 Loss: 0.2825404911485769\n",
      "Epoch: 14 Step: 711 Loss: 0.031012021492033533\n",
      "Epoch: 14 Step: 721 Loss: 0.20858862078479234\n",
      "Epoch: 14 Step: 731 Loss: 0.10449772764245943\n",
      "Epoch: 14 Step: 741 Loss: 0.16432488180135835\n",
      "Epoch: 14 Step: 751 Loss: 0.035686764835411944\n",
      "Epoch: 14 Step: 761 Loss: 0.04434315567636377\n",
      "Epoch: 14 Step: 771 Loss: 0.027562272280814308\n",
      "Epoch: 14 Step: 781 Loss: 0.02658685497498732\n",
      "Epoch: 14 Step: 791 Loss: 0.044732524722218364\n",
      "Epoch: 14 Step: 801 Loss: 0.15479209856276338\n",
      "Epoch: 14 Step: 811 Loss: 0.04998181884443841\n",
      "Epoch: 14 Step: 821 Loss: 0.0070742343111322116\n",
      "Epoch: 14 Step: 831 Loss: 0.09065027475726603\n",
      "Epoch: 14 Step: 841 Loss: 0.01532982505335503\n",
      "Epoch: 14 Step: 851 Loss: 0.008086343962351767\n",
      "Epoch: 14 Step: 861 Loss: 0.07677299425973383\n",
      "Epoch: 14 Step: 871 Loss: 0.3095490175243892\n",
      "Epoch: 14 Step: 881 Loss: 0.08919696819428957\n",
      "Epoch: 14 Step: 891 Loss: 0.01314206955094841\n",
      "Epoch: 14 Step: 901 Loss: 0.19095180634541192\n",
      "Epoch: 14 Step: 911 Loss: 0.11284948100645602\n",
      "Epoch: 14 Step: 921 Loss: 0.12880212196171853\n",
      "Epoch: 14 Step: 931 Loss: 0.0022997819925528106\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score is 0.9691833333333333\n",
      "Score is 0.9565304487179487\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = load_cifar()\n",
    "print(X_train.shape, Y_train.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(50000, 32, 32, 3) (50000, 1)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def to_category(labels, classes=10):\n",
    "    categories = np.zeros((len(labels), classes)) \n",
    "    for i in range(len(categories)):\n",
    "        categories[i, labels[i]] = 1\n",
    "    return categories\n",
    "if X_train.shape[0] == 50000:\n",
    "    data = X_train / 255.\n",
    "    label = to_category(Y_train, 10)\n",
    "else:\n",
    "    data = np.expand_dims(X_train / 255., axis=-1)\n",
    "    label = to_category(Y_train, 10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "model = ResNet(datasets='cifar_10', opt='sgd')\n",
    "model.datas = [data, label]\n",
    "model.train(30)\n",
    "plt.plot(np.arange(len(model.history)), model.history)\n",
    "plt.show()\n",
    "np.savetxt('/home/oneran/Downloads/sgd_cifar_ResNet_history.txt', model.history)\n",
    "model.save_model('/home/oneran/机器学习课设/cifar-10/Photon/sgd_cifar_ResNet.pkl')\n",
    "score, pred = model.score(X_train, Y_train)\n",
    "score, pred = model.score(X_test, Y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 0 Step: 1 Loss: 2.3022017862208433\n",
      "Epoch: 0 Step: 11 Loss: 2.294055489660327\n",
      "Epoch: 0 Step: 21 Loss: 2.3250514869242576\n",
      "Epoch: 0 Step: 31 Loss: 2.2988682906458453\n",
      "Epoch: 0 Step: 41 Loss: 2.283671302834675\n",
      "Epoch: 0 Step: 51 Loss: 2.2743738217248577\n",
      "Epoch: 0 Step: 61 Loss: 2.256334426968931\n",
      "Epoch: 0 Step: 71 Loss: 2.3161723575573285\n",
      "Epoch: 0 Step: 81 Loss: 2.2474506009661193\n",
      "Epoch: 0 Step: 91 Loss: 2.295746533858763\n",
      "Epoch: 0 Step: 101 Loss: 2.1338193795936897\n",
      "Epoch: 0 Step: 111 Loss: 2.109405535329227\n",
      "Epoch: 0 Step: 121 Loss: 2.146160487493793\n",
      "Epoch: 0 Step: 131 Loss: 2.2076817661448325\n",
      "Epoch: 0 Step: 141 Loss: 2.2668878081278696\n",
      "Epoch: 0 Step: 151 Loss: 2.136367733060723\n",
      "Epoch: 0 Step: 161 Loss: 2.107168269618567\n",
      "Epoch: 0 Step: 171 Loss: 2.1292822930656072\n",
      "Epoch: 0 Step: 181 Loss: 2.066944474869809\n",
      "Epoch: 0 Step: 191 Loss: 2.1804508824348625\n",
      "Epoch: 0 Step: 201 Loss: 2.056368846744255\n",
      "Epoch: 0 Step: 211 Loss: 2.1413688103896966\n",
      "Epoch: 0 Step: 221 Loss: 2.1868135035181115\n",
      "Epoch: 0 Step: 231 Loss: 2.1069441993204583\n",
      "Epoch: 0 Step: 241 Loss: 2.205327280887998\n",
      "Epoch: 0 Step: 251 Loss: 2.0559877977838505\n",
      "Epoch: 0 Step: 261 Loss: 2.0484927097684467\n",
      "Epoch: 0 Step: 271 Loss: 2.0859064073766715\n",
      "Epoch: 0 Step: 281 Loss: 2.1509151701774885\n",
      "Epoch: 0 Step: 291 Loss: 2.0793220709672102\n",
      "Epoch: 0 Step: 301 Loss: 2.1123746442122493\n",
      "Epoch: 0 Step: 311 Loss: 2.136113977709039\n",
      "Epoch: 0 Step: 321 Loss: 2.1201816550997306\n",
      "Epoch: 0 Step: 331 Loss: 1.9520326676857318\n",
      "Epoch: 0 Step: 341 Loss: 2.068319285578181\n",
      "Epoch: 0 Step: 351 Loss: 2.0639365584978373\n",
      "Epoch: 0 Step: 361 Loss: 2.102760923889517\n",
      "Epoch: 0 Step: 371 Loss: 1.9401689336571997\n",
      "Epoch: 0 Step: 381 Loss: 2.0775458233008104\n",
      "Epoch: 0 Step: 391 Loss: 2.1060635232163367\n",
      "Epoch: 0 Step: 401 Loss: 2.113896097769061\n",
      "Epoch: 0 Step: 411 Loss: 2.184236810114365\n",
      "Epoch: 0 Step: 421 Loss: 2.0586418954295564\n",
      "Epoch: 0 Step: 431 Loss: 1.977349881752982\n",
      "Epoch: 0 Step: 441 Loss: 2.0954690295373286\n",
      "Epoch: 0 Step: 451 Loss: 1.9543536866178308\n",
      "Epoch: 0 Step: 461 Loss: 2.0325760327523623\n",
      "Epoch: 0 Step: 471 Loss: 1.8650193969399085\n",
      "Epoch: 0 Step: 481 Loss: 1.9193466447339218\n",
      "Epoch: 0 Step: 491 Loss: 2.0423771526890073\n",
      "Epoch: 0 Step: 501 Loss: 1.8977601061939389\n",
      "Epoch: 0 Step: 511 Loss: 1.9784537458317373\n",
      "Epoch: 0 Step: 521 Loss: 2.0039455641421022\n",
      "Epoch: 0 Step: 531 Loss: 1.9599522173057704\n",
      "Epoch: 0 Step: 541 Loss: 1.9373803627597583\n",
      "Epoch: 0 Step: 551 Loss: 1.8318474037480403\n",
      "Epoch: 0 Step: 561 Loss: 1.907340075470487\n",
      "Epoch: 0 Step: 571 Loss: 1.8238097843910581\n",
      "Epoch: 0 Step: 581 Loss: 2.089930714574816\n",
      "Epoch: 0 Step: 591 Loss: 1.91546000635495\n",
      "Epoch: 0 Step: 601 Loss: 2.077309112032273\n",
      "Epoch: 0 Step: 611 Loss: 1.7499134901784483\n",
      "Epoch: 0 Step: 621 Loss: 1.873832114764269\n",
      "Epoch: 0 Step: 631 Loss: 2.0005736536410037\n",
      "Epoch: 0 Step: 641 Loss: 1.9635924183771\n",
      "Epoch: 0 Step: 651 Loss: 1.7363502661068073\n",
      "Epoch: 0 Step: 661 Loss: 1.9658986179050641\n",
      "Epoch: 0 Step: 671 Loss: 1.9092334043686976\n",
      "Epoch: 0 Step: 681 Loss: 2.03674120406568\n",
      "Epoch: 0 Step: 691 Loss: 1.7290979308915102\n",
      "Epoch: 0 Step: 701 Loss: 1.7807319548874523\n",
      "Epoch: 0 Step: 711 Loss: 1.7077146502400613\n",
      "Epoch: 0 Step: 721 Loss: 1.7190664138177603\n",
      "Epoch: 0 Step: 731 Loss: 1.7170689891576179\n",
      "Epoch: 0 Step: 741 Loss: 1.8785749855972522\n",
      "Epoch: 0 Step: 751 Loss: 2.2286347140663993\n",
      "Epoch: 0 Step: 761 Loss: 1.7633764174702689\n",
      "Epoch: 0 Step: 771 Loss: 1.830938581297489\n",
      "Epoch: 0 Step: 781 Loss: 1.721192959826906\n",
      "Epoch: 1 Step: 1 Loss: 1.874410014392308\n",
      "Epoch: 1 Step: 11 Loss: 1.9873468917660002\n",
      "Epoch: 1 Step: 21 Loss: 1.8977434427901774\n",
      "Epoch: 1 Step: 31 Loss: 1.8795366940070743\n",
      "Epoch: 1 Step: 41 Loss: 1.7950553751674876\n",
      "Epoch: 1 Step: 51 Loss: 1.7126393568941234\n",
      "Epoch: 1 Step: 61 Loss: 1.9380622643961334\n",
      "Epoch: 1 Step: 71 Loss: 2.015852057468316\n",
      "Epoch: 1 Step: 81 Loss: 1.8772083840973286\n",
      "Epoch: 1 Step: 91 Loss: 1.8856091838958275\n",
      "Epoch: 1 Step: 101 Loss: 1.7600468468168888\n",
      "Epoch: 1 Step: 111 Loss: 1.8003633817856497\n",
      "Epoch: 1 Step: 121 Loss: 1.6493078270697707\n",
      "Epoch: 1 Step: 131 Loss: 2.04942447946427\n",
      "Epoch: 1 Step: 141 Loss: 2.0584256714479316\n",
      "Epoch: 1 Step: 151 Loss: 1.851920288855765\n",
      "Epoch: 1 Step: 161 Loss: 1.8390296829557693\n",
      "Epoch: 1 Step: 171 Loss: 1.937125818811253\n",
      "Epoch: 1 Step: 181 Loss: 1.691539387631522\n",
      "Epoch: 1 Step: 191 Loss: 1.722460469774594\n",
      "Epoch: 1 Step: 201 Loss: 1.5178335165233614\n",
      "Epoch: 1 Step: 211 Loss: 1.773478061713762\n",
      "Epoch: 1 Step: 221 Loss: 1.9118951613593658\n",
      "Epoch: 1 Step: 231 Loss: 1.6668594306620963\n",
      "Epoch: 1 Step: 241 Loss: 1.87358058959173\n",
      "Epoch: 1 Step: 251 Loss: 1.6024603571628986\n",
      "Epoch: 1 Step: 261 Loss: 1.7091231321858533\n",
      "Epoch: 1 Step: 271 Loss: 1.778317366283333\n",
      "Epoch: 1 Step: 281 Loss: 1.740215998009487\n",
      "Epoch: 1 Step: 291 Loss: 1.6423518319076438\n",
      "Epoch: 1 Step: 301 Loss: 1.7031956338650844\n",
      "Epoch: 1 Step: 311 Loss: 1.6155218457408527\n",
      "Epoch: 1 Step: 321 Loss: 1.8197685417373175\n",
      "Epoch: 1 Step: 331 Loss: 1.628900217706519\n",
      "Epoch: 1 Step: 341 Loss: 1.8247360207308028\n",
      "Epoch: 1 Step: 351 Loss: 1.7338108096576088\n",
      "Epoch: 1 Step: 361 Loss: 1.7641426895717582\n",
      "Epoch: 1 Step: 371 Loss: 1.5218315007689789\n",
      "Epoch: 1 Step: 381 Loss: 1.765221719605242\n",
      "Epoch: 1 Step: 391 Loss: 1.7199973873705867\n",
      "Epoch: 1 Step: 401 Loss: 1.7983945028472652\n",
      "Epoch: 1 Step: 411 Loss: 1.7957208071763349\n",
      "Epoch: 1 Step: 421 Loss: 1.7578885264664597\n",
      "Epoch: 1 Step: 431 Loss: 1.494724769875602\n",
      "Epoch: 1 Step: 441 Loss: 1.7215204812788691\n",
      "Epoch: 1 Step: 451 Loss: 1.3974703545995744\n",
      "Epoch: 1 Step: 461 Loss: 1.5662667962607761\n",
      "Epoch: 1 Step: 471 Loss: 1.637112047106546\n",
      "Epoch: 1 Step: 481 Loss: 1.698703838118791\n",
      "Epoch: 1 Step: 491 Loss: 1.7773594526299432\n",
      "Epoch: 1 Step: 501 Loss: 1.683379915550963\n",
      "Epoch: 1 Step: 511 Loss: 1.8883779491998989\n",
      "Epoch: 1 Step: 521 Loss: 1.6586594765330858\n",
      "Epoch: 1 Step: 531 Loss: 1.726682272670122\n",
      "Epoch: 1 Step: 541 Loss: 1.661753683277146\n",
      "Epoch: 1 Step: 551 Loss: 1.633434569997703\n",
      "Epoch: 1 Step: 561 Loss: 1.5637173601784604\n",
      "Epoch: 1 Step: 571 Loss: 1.4932011151433575\n",
      "Epoch: 1 Step: 581 Loss: 1.780017682019798\n",
      "Epoch: 1 Step: 591 Loss: 1.7045005778249336\n",
      "Epoch: 1 Step: 601 Loss: 1.7342317200316886\n",
      "Epoch: 1 Step: 611 Loss: 1.5896904319698142\n",
      "Epoch: 1 Step: 621 Loss: 1.64442956657108\n",
      "Epoch: 1 Step: 631 Loss: 1.5883748534184416\n",
      "Epoch: 1 Step: 641 Loss: 1.6816895360666146\n",
      "Epoch: 1 Step: 651 Loss: 1.6292286917814598\n",
      "Epoch: 1 Step: 661 Loss: 1.5552599846887922\n",
      "Epoch: 1 Step: 671 Loss: 1.7542110046394939\n",
      "Epoch: 1 Step: 681 Loss: 1.821761130071578\n",
      "Epoch: 1 Step: 691 Loss: 1.723660194908914\n",
      "Epoch: 1 Step: 701 Loss: 1.5549394246619173\n",
      "Epoch: 1 Step: 711 Loss: 1.6892289366157338\n",
      "Epoch: 1 Step: 721 Loss: 1.5777054956956615\n",
      "Epoch: 1 Step: 731 Loss: 1.4385226147754335\n",
      "Epoch: 1 Step: 741 Loss: 1.72666840777275\n",
      "Epoch: 1 Step: 751 Loss: 2.0257639930242632\n",
      "Epoch: 1 Step: 761 Loss: 1.5039727293941794\n",
      "Epoch: 1 Step: 771 Loss: 1.7442196184401157\n",
      "Epoch: 1 Step: 781 Loss: 1.4837382649114481\n",
      "Epoch: 2 Step: 1 Loss: 1.671669258510663\n",
      "Epoch: 2 Step: 11 Loss: 1.7693606357941396\n",
      "Epoch: 2 Step: 21 Loss: 1.7972059612798952\n",
      "Epoch: 2 Step: 31 Loss: 1.8202983098892187\n",
      "Epoch: 2 Step: 41 Loss: 1.4727465072874018\n",
      "Epoch: 2 Step: 51 Loss: 1.4948572145142038\n",
      "Epoch: 2 Step: 61 Loss: 1.5335796346004438\n",
      "Epoch: 2 Step: 71 Loss: 1.824598856020688\n",
      "Epoch: 2 Step: 81 Loss: 1.5239380695074884\n",
      "Epoch: 2 Step: 91 Loss: 1.6753520187812718\n",
      "Epoch: 2 Step: 101 Loss: 1.5567955728986504\n",
      "Epoch: 2 Step: 111 Loss: 1.5620113496503323\n",
      "Epoch: 2 Step: 121 Loss: 1.670196865890033\n",
      "Epoch: 2 Step: 131 Loss: 1.7720690166677167\n",
      "Epoch: 2 Step: 141 Loss: 2.1009036712143163\n",
      "Epoch: 2 Step: 151 Loss: 1.5846066374333083\n",
      "Epoch: 2 Step: 161 Loss: 1.7263847852808865\n",
      "Epoch: 2 Step: 171 Loss: 1.725275132764526\n",
      "Epoch: 2 Step: 181 Loss: 1.5262767359409621\n",
      "Epoch: 2 Step: 191 Loss: 1.4302174052011831\n",
      "Epoch: 2 Step: 201 Loss: 1.2708644365980408\n",
      "Epoch: 2 Step: 211 Loss: 1.4530937265343395\n",
      "Epoch: 2 Step: 221 Loss: 1.6951918284021532\n",
      "Epoch: 2 Step: 231 Loss: 1.4311699264753757\n",
      "Epoch: 2 Step: 241 Loss: 1.7656322086968927\n",
      "Epoch: 2 Step: 251 Loss: 1.4062414150335198\n",
      "Epoch: 2 Step: 261 Loss: 1.5559104523482428\n",
      "Epoch: 2 Step: 271 Loss: 1.6588674071356346\n",
      "Epoch: 2 Step: 281 Loss: 1.6913430350981935\n",
      "Epoch: 2 Step: 291 Loss: 1.4991780260811638\n",
      "Epoch: 2 Step: 301 Loss: 1.6108763235654364\n",
      "Epoch: 2 Step: 311 Loss: 1.5462973387965464\n",
      "Epoch: 2 Step: 321 Loss: 1.5487782091100941\n",
      "Epoch: 2 Step: 331 Loss: 1.5663079749182807\n",
      "Epoch: 2 Step: 341 Loss: 1.6046638348117706\n",
      "Epoch: 2 Step: 351 Loss: 1.5602588840747296\n",
      "Epoch: 2 Step: 361 Loss: 1.4971314113698178\n",
      "Epoch: 2 Step: 371 Loss: 1.257740990636841\n",
      "Epoch: 2 Step: 381 Loss: 1.7014214391869351\n",
      "Epoch: 2 Step: 391 Loss: 1.4102465753624922\n",
      "Epoch: 2 Step: 401 Loss: 1.62546538705696\n",
      "Epoch: 2 Step: 411 Loss: 1.6848536127370235\n",
      "Epoch: 2 Step: 421 Loss: 1.653759424945437\n",
      "Epoch: 2 Step: 431 Loss: 1.472130140803651\n",
      "Epoch: 2 Step: 441 Loss: 1.6171455309369474\n",
      "Epoch: 2 Step: 451 Loss: 1.2297002593413682\n",
      "Epoch: 2 Step: 461 Loss: 1.5811831312865392\n",
      "Epoch: 2 Step: 471 Loss: 1.455767934991579\n",
      "Epoch: 2 Step: 481 Loss: 1.6414096994255851\n",
      "Epoch: 2 Step: 491 Loss: 1.8302368410335634\n",
      "Epoch: 2 Step: 501 Loss: 1.686109986978946\n",
      "Epoch: 2 Step: 511 Loss: 1.599013395771259\n",
      "Epoch: 2 Step: 521 Loss: 1.5904724474178902\n",
      "Epoch: 2 Step: 531 Loss: 1.6312603238555416\n",
      "Epoch: 2 Step: 541 Loss: 1.6121935343664273\n",
      "Epoch: 2 Step: 551 Loss: 1.4722947924144656\n",
      "Epoch: 2 Step: 561 Loss: 1.461707602820017\n",
      "Epoch: 2 Step: 571 Loss: 1.5076470212510422\n",
      "Epoch: 2 Step: 581 Loss: 1.506043487843876\n",
      "Epoch: 2 Step: 591 Loss: 1.5047778340007278\n",
      "Epoch: 2 Step: 601 Loss: 1.5824778516592253\n",
      "Epoch: 2 Step: 611 Loss: 1.4161766823266535\n",
      "Epoch: 2 Step: 621 Loss: 1.5818307070817474\n",
      "Epoch: 2 Step: 631 Loss: 1.5836668519190664\n",
      "Epoch: 2 Step: 641 Loss: 1.8953901782158957\n",
      "Epoch: 2 Step: 651 Loss: 1.6096572342648363\n",
      "Epoch: 2 Step: 661 Loss: 1.4875156732489185\n",
      "Epoch: 2 Step: 671 Loss: 1.7216986015201288\n",
      "Epoch: 2 Step: 681 Loss: 1.7622577926367686\n",
      "Epoch: 2 Step: 691 Loss: 1.6101228589095662\n",
      "Epoch: 2 Step: 701 Loss: 1.44374255521329\n",
      "Epoch: 2 Step: 711 Loss: 1.601811676395373\n",
      "Epoch: 2 Step: 721 Loss: 1.354387512376174\n",
      "Epoch: 2 Step: 731 Loss: 1.3861642522362594\n",
      "Epoch: 2 Step: 741 Loss: 1.5511609930500536\n",
      "Epoch: 2 Step: 751 Loss: 1.7465199394706667\n",
      "Epoch: 2 Step: 761 Loss: 1.43289829597702\n",
      "Epoch: 2 Step: 771 Loss: 1.7058496897585995\n",
      "Epoch: 2 Step: 781 Loss: 1.4890442555942398\n",
      "Epoch: 3 Step: 1 Loss: 1.519827604893294\n",
      "Epoch: 3 Step: 11 Loss: 1.5638250441034853\n",
      "Epoch: 3 Step: 21 Loss: 1.6526823830255726\n",
      "Epoch: 3 Step: 31 Loss: 1.638908060889266\n",
      "Epoch: 3 Step: 41 Loss: 1.3649912717131059\n",
      "Epoch: 3 Step: 51 Loss: 1.3665553905804635\n",
      "Epoch: 3 Step: 61 Loss: 1.5007497720896774\n",
      "Epoch: 3 Step: 71 Loss: 1.8733100983090583\n",
      "Epoch: 3 Step: 81 Loss: 1.6110955659120005\n",
      "Epoch: 3 Step: 91 Loss: 1.6366266788788122\n",
      "Epoch: 3 Step: 101 Loss: 1.4284528299457186\n",
      "Epoch: 3 Step: 111 Loss: 1.4814285781279846\n",
      "Epoch: 3 Step: 121 Loss: 1.3142327877831412\n",
      "Epoch: 3 Step: 131 Loss: 1.6761947070987981\n",
      "Epoch: 3 Step: 141 Loss: 1.8386294514011114\n",
      "Epoch: 3 Step: 151 Loss: 1.3348395596123293\n",
      "Epoch: 3 Step: 161 Loss: 1.5292777660396117\n",
      "Epoch: 3 Step: 171 Loss: 1.6430767534684136\n",
      "Epoch: 3 Step: 181 Loss: 1.2830299008857324\n",
      "Epoch: 3 Step: 191 Loss: 1.3756368560599794\n",
      "Epoch: 3 Step: 201 Loss: 1.2111627886166085\n",
      "Epoch: 3 Step: 211 Loss: 1.17420777998163\n",
      "Epoch: 3 Step: 221 Loss: 1.4691681609648113\n",
      "Epoch: 3 Step: 231 Loss: 1.340693293565578\n",
      "Epoch: 3 Step: 241 Loss: 1.5255026491721608\n",
      "Epoch: 3 Step: 251 Loss: 1.5190319902155696\n",
      "Epoch: 3 Step: 261 Loss: 1.5361347176055486\n",
      "Epoch: 3 Step: 271 Loss: 1.6068096919218426\n",
      "Epoch: 3 Step: 281 Loss: 1.4729967047813863\n",
      "Epoch: 3 Step: 291 Loss: 1.4836444778234998\n",
      "Epoch: 3 Step: 301 Loss: 1.3450253434778867\n",
      "Epoch: 3 Step: 311 Loss: 1.4015246488791075\n",
      "Epoch: 3 Step: 321 Loss: 1.4709825280485742\n",
      "Epoch: 3 Step: 331 Loss: 1.300903387663928\n",
      "Epoch: 3 Step: 341 Loss: 1.436484842846033\n",
      "Epoch: 3 Step: 351 Loss: 1.4984350905723778\n",
      "Epoch: 3 Step: 361 Loss: 1.3969250995467788\n",
      "Epoch: 3 Step: 371 Loss: 1.2027818886170762\n",
      "Epoch: 3 Step: 381 Loss: 1.505352541119123\n",
      "Epoch: 3 Step: 391 Loss: 1.2318338269778562\n",
      "Epoch: 3 Step: 401 Loss: 1.5555969275918642\n",
      "Epoch: 3 Step: 411 Loss: 1.7061194736288714\n",
      "Epoch: 3 Step: 421 Loss: 1.5567115727036072\n",
      "Epoch: 3 Step: 431 Loss: 1.4173031441026076\n",
      "Epoch: 3 Step: 441 Loss: 1.6283232464455573\n",
      "Epoch: 3 Step: 451 Loss: 1.1584369124960077\n",
      "Epoch: 3 Step: 461 Loss: 1.5003405093305657\n",
      "Epoch: 3 Step: 471 Loss: 1.3557499367771633\n",
      "Epoch: 3 Step: 481 Loss: 1.5889503088827257\n",
      "Epoch: 3 Step: 491 Loss: 1.692571753087878\n",
      "Epoch: 3 Step: 501 Loss: 1.567914473019343\n",
      "Epoch: 3 Step: 511 Loss: 1.4491803075035656\n",
      "Epoch: 3 Step: 521 Loss: 1.4372690155457382\n",
      "Epoch: 3 Step: 531 Loss: 1.5615397679960887\n",
      "Epoch: 3 Step: 541 Loss: 1.4257056782827648\n",
      "Epoch: 3 Step: 551 Loss: 1.3066301401527922\n",
      "Epoch: 3 Step: 561 Loss: 1.3413755621791634\n",
      "Epoch: 3 Step: 571 Loss: 1.4187104321901747\n",
      "Epoch: 3 Step: 581 Loss: 1.4947588958699407\n",
      "Epoch: 3 Step: 591 Loss: 1.5288852635513281\n",
      "Epoch: 3 Step: 601 Loss: 1.6916637519851068\n",
      "Epoch: 3 Step: 611 Loss: 1.2913899002582185\n",
      "Epoch: 3 Step: 621 Loss: 1.6234107599858694\n",
      "Epoch: 3 Step: 631 Loss: 1.4559870990094543\n",
      "Epoch: 3 Step: 641 Loss: 1.6609066954502991\n",
      "Epoch: 3 Step: 651 Loss: 1.2564559236666042\n",
      "Epoch: 3 Step: 661 Loss: 1.2433067140547633\n",
      "Epoch: 3 Step: 671 Loss: 1.5559682056513888\n",
      "Epoch: 3 Step: 681 Loss: 1.7274016196273978\n",
      "Epoch: 3 Step: 691 Loss: 1.4913814584043896\n",
      "Epoch: 3 Step: 701 Loss: 1.3094138226652081\n",
      "Epoch: 3 Step: 711 Loss: 1.3477880920491334\n",
      "Epoch: 3 Step: 721 Loss: 1.3312697155334936\n",
      "Epoch: 3 Step: 731 Loss: 1.1242700667043368\n",
      "Epoch: 3 Step: 741 Loss: 1.3978420989074167\n",
      "Epoch: 3 Step: 751 Loss: 1.5413676518234818\n",
      "Epoch: 3 Step: 761 Loss: 1.202740916586057\n",
      "Epoch: 3 Step: 771 Loss: 1.6858053222990255\n",
      "Epoch: 3 Step: 781 Loss: 1.403659002401314\n",
      "Epoch: 4 Step: 1 Loss: 1.482644086833274\n",
      "Epoch: 4 Step: 11 Loss: 1.568423074463281\n",
      "Epoch: 4 Step: 21 Loss: 1.552384123540668\n",
      "Epoch: 4 Step: 31 Loss: 1.4894213893120722\n",
      "Epoch: 4 Step: 41 Loss: 1.3005626115783717\n",
      "Epoch: 4 Step: 51 Loss: 1.2975562925918052\n",
      "Epoch: 4 Step: 61 Loss: 1.4260004445172445\n",
      "Epoch: 4 Step: 71 Loss: 1.6989159802476972\n",
      "Epoch: 4 Step: 81 Loss: 1.585859012998205\n",
      "Epoch: 4 Step: 91 Loss: 1.4422760579521685\n",
      "Epoch: 4 Step: 101 Loss: 1.2811295213464433\n",
      "Epoch: 4 Step: 111 Loss: 1.4063020486608635\n",
      "Epoch: 4 Step: 121 Loss: 1.2713530769879764\n",
      "Epoch: 4 Step: 131 Loss: 1.4192827777962496\n",
      "Epoch: 4 Step: 141 Loss: 1.6799387535937105\n",
      "Epoch: 4 Step: 151 Loss: 1.2864197082013313\n",
      "Epoch: 4 Step: 161 Loss: 1.3709362446884867\n",
      "Epoch: 4 Step: 171 Loss: 1.5460102392605708\n",
      "Epoch: 4 Step: 181 Loss: 1.3961907575583878\n",
      "Epoch: 4 Step: 191 Loss: 1.2800720686658296\n",
      "Epoch: 4 Step: 201 Loss: 1.1764181656441643\n",
      "Epoch: 4 Step: 211 Loss: 1.106340899315029\n",
      "Epoch: 4 Step: 221 Loss: 1.3925741548770265\n",
      "Epoch: 4 Step: 231 Loss: 1.3435819109249776\n",
      "Epoch: 4 Step: 241 Loss: 1.4739320814872299\n",
      "Epoch: 4 Step: 251 Loss: 1.2738808481127533\n",
      "Epoch: 4 Step: 261 Loss: 1.3137987007914278\n",
      "Epoch: 4 Step: 271 Loss: 1.4299451332270967\n",
      "Epoch: 4 Step: 281 Loss: 1.337593380144861\n",
      "Epoch: 4 Step: 291 Loss: 1.4742488870643147\n",
      "Epoch: 4 Step: 301 Loss: 1.3531294708511226\n",
      "Epoch: 4 Step: 311 Loss: 1.2708908988984302\n",
      "Epoch: 4 Step: 321 Loss: 1.4351923544949363\n",
      "Epoch: 4 Step: 331 Loss: 1.3220184616822692\n",
      "Epoch: 4 Step: 341 Loss: 1.367459829948968\n",
      "Epoch: 4 Step: 351 Loss: 1.417087871768276\n",
      "Epoch: 4 Step: 361 Loss: 1.3789446002871533\n",
      "Epoch: 4 Step: 371 Loss: 1.1159638061492951\n",
      "Epoch: 4 Step: 381 Loss: 1.5361280562139656\n",
      "Epoch: 4 Step: 391 Loss: 1.1809852514109274\n",
      "Epoch: 4 Step: 401 Loss: 1.552304259499623\n",
      "Epoch: 4 Step: 411 Loss: 1.493109377134115\n",
      "Epoch: 4 Step: 421 Loss: 1.4443879571753648\n",
      "Epoch: 4 Step: 431 Loss: 1.3544441102152391\n",
      "Epoch: 4 Step: 441 Loss: 1.4403945727768017\n",
      "Epoch: 4 Step: 451 Loss: 1.0509165848234445\n",
      "Epoch: 4 Step: 461 Loss: 1.4133979651909139\n",
      "Epoch: 4 Step: 471 Loss: 1.436068365117464\n",
      "Epoch: 4 Step: 481 Loss: 1.5001207336537137\n",
      "Epoch: 4 Step: 491 Loss: 1.592886680336212\n",
      "Epoch: 4 Step: 501 Loss: 1.3443398179704626\n",
      "Epoch: 4 Step: 511 Loss: 1.302548078110077\n",
      "Epoch: 4 Step: 521 Loss: 1.479093211429254\n",
      "Epoch: 4 Step: 531 Loss: 1.5016503409990336\n",
      "Epoch: 4 Step: 541 Loss: 1.375824529725226\n",
      "Epoch: 4 Step: 551 Loss: 1.319924455991091\n",
      "Epoch: 4 Step: 561 Loss: 1.3735408880280655\n",
      "Epoch: 4 Step: 571 Loss: 1.464898207946339\n",
      "Epoch: 4 Step: 581 Loss: 1.3468597690745387\n",
      "Epoch: 4 Step: 591 Loss: 1.3966026767855457\n",
      "Epoch: 4 Step: 601 Loss: 1.3728925836821975\n",
      "Epoch: 4 Step: 611 Loss: 1.1992362182746483\n",
      "Epoch: 4 Step: 621 Loss: 1.4925211347955418\n",
      "Epoch: 4 Step: 631 Loss: 1.2188902954065413\n",
      "Epoch: 4 Step: 641 Loss: 1.576007527925192\n",
      "Epoch: 4 Step: 651 Loss: 1.3038630790733183\n",
      "Epoch: 4 Step: 661 Loss: 1.18718432373083\n",
      "Epoch: 4 Step: 671 Loss: 1.523356880171151\n",
      "Epoch: 4 Step: 681 Loss: 1.556794428047179\n",
      "Epoch: 4 Step: 691 Loss: 1.462812489944532\n",
      "Epoch: 4 Step: 701 Loss: 1.2978758351893835\n",
      "Epoch: 4 Step: 711 Loss: 1.26327842092762\n",
      "Epoch: 4 Step: 721 Loss: 1.291880181410954\n",
      "Epoch: 4 Step: 731 Loss: 1.2494798330044836\n",
      "Epoch: 4 Step: 741 Loss: 1.3330323771341255\n",
      "Epoch: 4 Step: 751 Loss: 1.6532206869019346\n",
      "Epoch: 4 Step: 761 Loss: 1.2232207658022434\n",
      "Epoch: 4 Step: 771 Loss: 1.6024271905559333\n",
      "Epoch: 4 Step: 781 Loss: 1.2036199053946253\n",
      "Epoch: 5 Step: 1 Loss: 1.2518566090034777\n",
      "Epoch: 5 Step: 11 Loss: 1.3398152245547217\n",
      "Epoch: 5 Step: 21 Loss: 1.4027814191162495\n",
      "Epoch: 5 Step: 31 Loss: 1.5114516178179942\n",
      "Epoch: 5 Step: 41 Loss: 1.0803726034503027\n",
      "Epoch: 5 Step: 51 Loss: 1.2307470521348893\n",
      "Epoch: 5 Step: 61 Loss: 1.2019500677826525\n",
      "Epoch: 5 Step: 71 Loss: 1.6182265942686418\n",
      "Epoch: 5 Step: 81 Loss: 1.457743226965394\n",
      "Epoch: 5 Step: 91 Loss: 1.3393553817144785\n",
      "Epoch: 5 Step: 101 Loss: 1.1815934111558932\n",
      "Epoch: 5 Step: 111 Loss: 1.3812685980844202\n",
      "Epoch: 5 Step: 121 Loss: 1.264992170575812\n",
      "Epoch: 5 Step: 131 Loss: 1.3576234426561398\n",
      "Epoch: 5 Step: 141 Loss: 1.7866755455385468\n",
      "Epoch: 5 Step: 151 Loss: 1.2686086534625556\n",
      "Epoch: 5 Step: 161 Loss: 1.4977034285022786\n",
      "Epoch: 5 Step: 171 Loss: 1.4894046772121903\n",
      "Epoch: 5 Step: 181 Loss: 1.409386644259928\n",
      "Epoch: 5 Step: 191 Loss: 1.0678370326475997\n",
      "Epoch: 5 Step: 201 Loss: 1.1231281573653333\n",
      "Epoch: 5 Step: 211 Loss: 0.9881253426616541\n",
      "Epoch: 5 Step: 221 Loss: 1.3809761948518338\n",
      "Epoch: 5 Step: 231 Loss: 1.1859474254167188\n",
      "Epoch: 5 Step: 241 Loss: 1.3079475460277723\n",
      "Epoch: 5 Step: 251 Loss: 1.103309717149282\n",
      "Epoch: 5 Step: 261 Loss: 1.3063142318803007\n",
      "Epoch: 5 Step: 271 Loss: 1.279277811722515\n",
      "Epoch: 5 Step: 281 Loss: 1.1641626281888189\n",
      "Epoch: 5 Step: 291 Loss: 1.4378849405270868\n",
      "Epoch: 5 Step: 301 Loss: 1.3675544945342202\n",
      "Epoch: 5 Step: 311 Loss: 1.271623278546915\n",
      "Epoch: 5 Step: 321 Loss: 1.4338396614250999\n",
      "Epoch: 5 Step: 331 Loss: 1.3675479969739328\n",
      "Epoch: 5 Step: 341 Loss: 1.2734720209841175\n",
      "Epoch: 5 Step: 351 Loss: 1.345537750332471\n",
      "Epoch: 5 Step: 361 Loss: 1.289207992476866\n",
      "Epoch: 5 Step: 371 Loss: 0.97853943594348\n",
      "Epoch: 5 Step: 381 Loss: 1.3536377614919433\n",
      "Epoch: 5 Step: 391 Loss: 1.0188055179061888\n",
      "Epoch: 5 Step: 401 Loss: 1.2745919372203796\n",
      "Epoch: 5 Step: 411 Loss: 1.4022771670695617\n",
      "Epoch: 5 Step: 421 Loss: 1.4752511094450838\n",
      "Epoch: 5 Step: 431 Loss: 1.261056612731509\n",
      "Epoch: 5 Step: 441 Loss: 1.1989611729775485\n",
      "Epoch: 5 Step: 451 Loss: 1.032003409048078\n",
      "Epoch: 5 Step: 461 Loss: 1.3451566786239155\n",
      "Epoch: 5 Step: 471 Loss: 1.292432361638208\n",
      "Epoch: 5 Step: 481 Loss: 1.4245837722000099\n",
      "Epoch: 5 Step: 491 Loss: 1.6849757690437714\n",
      "Epoch: 5 Step: 501 Loss: 1.362381417212811\n",
      "Epoch: 5 Step: 511 Loss: 1.347664406209104\n",
      "Epoch: 5 Step: 521 Loss: 1.493761255284621\n",
      "Epoch: 5 Step: 531 Loss: 1.3121792185886374\n",
      "Epoch: 5 Step: 541 Loss: 1.3894053884218147\n",
      "Epoch: 5 Step: 551 Loss: 1.1543009189674749\n",
      "Epoch: 5 Step: 561 Loss: 1.242062293078246\n",
      "Epoch: 5 Step: 571 Loss: 1.3212662481883264\n",
      "Epoch: 5 Step: 581 Loss: 1.2688696568566957\n",
      "Epoch: 5 Step: 591 Loss: 1.332825880538734\n",
      "Epoch: 5 Step: 601 Loss: 1.2760954707395658\n",
      "Epoch: 5 Step: 611 Loss: 1.1324444071760569\n",
      "Epoch: 5 Step: 621 Loss: 1.3057511592984627\n",
      "Epoch: 5 Step: 631 Loss: 1.0811812229584699\n",
      "Epoch: 5 Step: 641 Loss: 1.4734539497276011\n",
      "Epoch: 5 Step: 651 Loss: 1.110296393997467\n",
      "Epoch: 5 Step: 661 Loss: 1.086832001690388\n",
      "Epoch: 5 Step: 671 Loss: 1.4934414413062111\n",
      "Epoch: 5 Step: 681 Loss: 1.724472967878382\n",
      "Epoch: 5 Step: 691 Loss: 1.320830746273203\n",
      "Epoch: 5 Step: 701 Loss: 1.3001961958227974\n",
      "Epoch: 5 Step: 711 Loss: 1.228246598937627\n",
      "Epoch: 5 Step: 721 Loss: 1.1668920792165476\n",
      "Epoch: 5 Step: 731 Loss: 0.9973849322419001\n",
      "Epoch: 5 Step: 741 Loss: 1.222565487199065\n",
      "Epoch: 5 Step: 751 Loss: 1.5167523408155321\n",
      "Epoch: 5 Step: 761 Loss: 1.0651840615397408\n",
      "Epoch: 5 Step: 771 Loss: 1.4829971798008599\n",
      "Epoch: 5 Step: 781 Loss: 1.2736272889635663\n",
      "Epoch: 6 Step: 1 Loss: 1.254952689875472\n",
      "Epoch: 6 Step: 11 Loss: 1.2614023687448839\n",
      "Epoch: 6 Step: 21 Loss: 1.4014719402103117\n",
      "Epoch: 6 Step: 31 Loss: 1.4365286678246003\n",
      "Epoch: 6 Step: 41 Loss: 1.0378071050055357\n",
      "Epoch: 6 Step: 51 Loss: 1.0689111655647148\n",
      "Epoch: 6 Step: 61 Loss: 1.1524793396565371\n",
      "Epoch: 6 Step: 71 Loss: 1.730443964043279\n",
      "Epoch: 6 Step: 81 Loss: 1.3109184825278188\n",
      "Epoch: 6 Step: 91 Loss: 1.357182692942803\n",
      "Epoch: 6 Step: 101 Loss: 1.3225474810941524\n",
      "Epoch: 6 Step: 111 Loss: 1.4221299622835124\n",
      "Epoch: 6 Step: 121 Loss: 1.1723773970478497\n",
      "Epoch: 6 Step: 131 Loss: 1.1812349895114282\n",
      "Epoch: 6 Step: 141 Loss: 1.5763247176011337\n",
      "Epoch: 6 Step: 151 Loss: 1.1940438506084288\n",
      "Epoch: 6 Step: 161 Loss: 1.3057731555915484\n",
      "Epoch: 6 Step: 171 Loss: 1.3927599836170503\n",
      "Epoch: 6 Step: 181 Loss: 1.136326896731683\n",
      "Epoch: 6 Step: 191 Loss: 1.1117331012912262\n",
      "Epoch: 6 Step: 201 Loss: 1.007093241178476\n",
      "Epoch: 6 Step: 211 Loss: 0.8494225401644407\n",
      "Epoch: 6 Step: 221 Loss: 1.3731174238043424\n",
      "Epoch: 6 Step: 231 Loss: 1.19749800642286\n",
      "Epoch: 6 Step: 241 Loss: 1.342111381257854\n",
      "Epoch: 6 Step: 251 Loss: 1.2518625460144597\n",
      "Epoch: 6 Step: 261 Loss: 1.4307101300185954\n",
      "Epoch: 6 Step: 271 Loss: 1.3357228539494728\n",
      "Epoch: 6 Step: 281 Loss: 1.2587254958534275\n",
      "Epoch: 6 Step: 291 Loss: 1.2737087641541678\n",
      "Epoch: 6 Step: 301 Loss: 1.2262643168778002\n",
      "Epoch: 6 Step: 311 Loss: 1.1704296323599017\n",
      "Epoch: 6 Step: 321 Loss: 1.2216253984337515\n",
      "Epoch: 6 Step: 331 Loss: 1.1565519047711914\n",
      "Epoch: 6 Step: 341 Loss: 1.1424904925062527\n",
      "Epoch: 6 Step: 351 Loss: 1.3035322668830538\n",
      "Epoch: 6 Step: 361 Loss: 1.3146298171786912\n",
      "Epoch: 6 Step: 371 Loss: 0.8882607469486771\n",
      "Epoch: 6 Step: 381 Loss: 1.231397004836126\n",
      "Epoch: 6 Step: 391 Loss: 0.9167004917062448\n",
      "Epoch: 6 Step: 401 Loss: 1.160909934634791\n",
      "Epoch: 6 Step: 411 Loss: 1.3264788408603883\n",
      "Epoch: 6 Step: 421 Loss: 1.286829651749344\n",
      "Epoch: 6 Step: 431 Loss: 1.2613216093010315\n",
      "Epoch: 6 Step: 441 Loss: 1.1125017037167377\n",
      "Epoch: 6 Step: 451 Loss: 1.0559513797107438\n",
      "Epoch: 6 Step: 461 Loss: 1.3853424334187037\n",
      "Epoch: 6 Step: 471 Loss: 1.242484418225777\n",
      "Epoch: 6 Step: 481 Loss: 1.4467189194411993\n",
      "Epoch: 6 Step: 491 Loss: 1.4019992895119673\n",
      "Epoch: 6 Step: 501 Loss: 1.3732032494181683\n",
      "Epoch: 6 Step: 511 Loss: 1.1801821600258484\n",
      "Epoch: 6 Step: 521 Loss: 1.3312141952040093\n",
      "Epoch: 6 Step: 531 Loss: 1.1869217308810174\n",
      "Epoch: 6 Step: 541 Loss: 1.2172401164502866\n",
      "Epoch: 6 Step: 551 Loss: 0.9928308158467491\n",
      "Epoch: 6 Step: 561 Loss: 1.105754180632549\n",
      "Epoch: 6 Step: 571 Loss: 1.0340388105313734\n",
      "Epoch: 6 Step: 581 Loss: 1.2544888758269115\n",
      "Epoch: 6 Step: 591 Loss: 1.3696168818838717\n",
      "Epoch: 6 Step: 601 Loss: 1.2418766040526013\n",
      "Epoch: 6 Step: 611 Loss: 1.2630496177827486\n",
      "Epoch: 6 Step: 621 Loss: 1.3743969920993075\n",
      "Epoch: 6 Step: 631 Loss: 1.2459380536443005\n",
      "Epoch: 6 Step: 641 Loss: 1.5141027432109289\n",
      "Epoch: 6 Step: 651 Loss: 1.0911043867865238\n",
      "Epoch: 6 Step: 661 Loss: 1.0379443527852303\n",
      "Epoch: 6 Step: 671 Loss: 1.4407014239846263\n",
      "Epoch: 6 Step: 681 Loss: 1.5261868792256132\n",
      "Epoch: 6 Step: 691 Loss: 1.3046113691936538\n",
      "Epoch: 6 Step: 701 Loss: 1.1379924378287032\n",
      "Epoch: 6 Step: 711 Loss: 1.2325830828501614\n",
      "Epoch: 6 Step: 721 Loss: 1.0277550288554702\n",
      "Epoch: 6 Step: 731 Loss: 0.9022206151827017\n",
      "Epoch: 6 Step: 741 Loss: 1.1205622798694606\n",
      "Epoch: 6 Step: 751 Loss: 1.4217007993289004\n",
      "Epoch: 6 Step: 761 Loss: 1.040918203886079\n",
      "Epoch: 6 Step: 771 Loss: 1.3871189305430094\n",
      "Epoch: 6 Step: 781 Loss: 1.1487852509604701\n",
      "Epoch: 7 Step: 1 Loss: 1.247719086844044\n",
      "Epoch: 7 Step: 11 Loss: 1.3356224099662595\n",
      "Epoch: 7 Step: 21 Loss: 1.3876125516863071\n",
      "Epoch: 7 Step: 31 Loss: 1.3870682702993258\n",
      "Epoch: 7 Step: 41 Loss: 1.0382586497058224\n",
      "Epoch: 7 Step: 51 Loss: 1.1379460944190756\n",
      "Epoch: 7 Step: 61 Loss: 1.2401507420662234\n",
      "Epoch: 7 Step: 71 Loss: 1.5838382623237601\n",
      "Epoch: 7 Step: 81 Loss: 1.2278039535535585\n",
      "Epoch: 7 Step: 91 Loss: 1.295230998184341\n",
      "Epoch: 7 Step: 101 Loss: 1.143128872453067\n",
      "Epoch: 7 Step: 111 Loss: 1.163910587546376\n",
      "Epoch: 7 Step: 121 Loss: 1.1744701508237765\n",
      "Epoch: 7 Step: 131 Loss: 1.1367600970006397\n",
      "Epoch: 7 Step: 141 Loss: 1.504335442437239\n",
      "Epoch: 7 Step: 151 Loss: 1.1463366980381893\n",
      "Epoch: 7 Step: 161 Loss: 1.176393922414396\n",
      "Epoch: 7 Step: 171 Loss: 1.2817605150415128\n",
      "Epoch: 7 Step: 181 Loss: 1.1481662162795139\n",
      "Epoch: 7 Step: 191 Loss: 1.0496400339461895\n",
      "Epoch: 7 Step: 201 Loss: 1.0291642945834871\n",
      "Epoch: 7 Step: 211 Loss: 0.922913242373451\n",
      "Epoch: 7 Step: 221 Loss: 1.3276628371179258\n",
      "Epoch: 7 Step: 231 Loss: 1.0976020345792559\n",
      "Epoch: 7 Step: 241 Loss: 1.2334810484716883\n",
      "Epoch: 7 Step: 251 Loss: 1.1707598957941756\n",
      "Epoch: 7 Step: 261 Loss: 1.324720013842629\n",
      "Epoch: 7 Step: 271 Loss: 1.1098738376969144\n",
      "Epoch: 7 Step: 281 Loss: 1.2750144519403719\n",
      "Epoch: 7 Step: 291 Loss: 1.1717191776435536\n",
      "Epoch: 7 Step: 301 Loss: 1.17148730479416\n",
      "Epoch: 7 Step: 311 Loss: 1.087678254792191\n",
      "Epoch: 7 Step: 321 Loss: 1.2070950971384407\n",
      "Epoch: 7 Step: 331 Loss: 1.1336771239227619\n",
      "Epoch: 7 Step: 341 Loss: 1.1798355614864793\n",
      "Epoch: 7 Step: 351 Loss: 1.2524863609527894\n",
      "Epoch: 7 Step: 361 Loss: 1.2177100662323528\n",
      "Epoch: 7 Step: 371 Loss: 0.8687830565544465\n",
      "Epoch: 7 Step: 381 Loss: 1.2277636541535855\n",
      "Epoch: 7 Step: 391 Loss: 1.073255433400844\n",
      "Epoch: 7 Step: 401 Loss: 1.1922387449746963\n",
      "Epoch: 7 Step: 411 Loss: 1.3403355512218535\n",
      "Epoch: 7 Step: 421 Loss: 1.3116378660330668\n",
      "Epoch: 7 Step: 431 Loss: 1.1071793580209996\n",
      "Epoch: 7 Step: 441 Loss: 1.1798371971510677\n",
      "Epoch: 7 Step: 451 Loss: 0.9550303548907872\n",
      "Epoch: 7 Step: 461 Loss: 1.1671175920467318\n",
      "Epoch: 7 Step: 471 Loss: 1.2749368581297653\n",
      "Epoch: 7 Step: 481 Loss: 1.351471242693501\n",
      "Epoch: 7 Step: 491 Loss: 1.2623830931203075\n",
      "Epoch: 7 Step: 501 Loss: 1.2489797882157856\n",
      "Epoch: 7 Step: 511 Loss: 1.0611501784296546\n",
      "Epoch: 7 Step: 521 Loss: 1.212754780856435\n",
      "Epoch: 7 Step: 531 Loss: 1.1338808612511007\n",
      "Epoch: 7 Step: 541 Loss: 1.1884686323809521\n",
      "Epoch: 7 Step: 551 Loss: 1.066027583100305\n",
      "Epoch: 7 Step: 561 Loss: 1.1639129743806738\n",
      "Epoch: 7 Step: 571 Loss: 1.1641414283205316\n",
      "Epoch: 7 Step: 581 Loss: 1.235858166867755\n",
      "Epoch: 7 Step: 591 Loss: 1.4563354929980004\n",
      "Epoch: 7 Step: 601 Loss: 1.1575388047994195\n",
      "Epoch: 7 Step: 611 Loss: 1.1432229067697264\n",
      "Epoch: 7 Step: 621 Loss: 1.3257734394544571\n",
      "Epoch: 7 Step: 631 Loss: 1.149327707696357\n",
      "Epoch: 7 Step: 641 Loss: 1.3362670275189457\n",
      "Epoch: 7 Step: 651 Loss: 0.9841651981231295\n",
      "Epoch: 7 Step: 661 Loss: 0.9765210324543986\n",
      "Epoch: 7 Step: 671 Loss: 1.3708267685677615\n",
      "Epoch: 7 Step: 681 Loss: 1.3516254368075764\n",
      "Epoch: 7 Step: 691 Loss: 1.2417272954371565\n",
      "Epoch: 7 Step: 701 Loss: 1.1729300727364587\n",
      "Epoch: 7 Step: 711 Loss: 1.1274726820192726\n",
      "Epoch: 7 Step: 721 Loss: 1.0688374108820522\n",
      "Epoch: 7 Step: 731 Loss: 0.8821322683979553\n",
      "Epoch: 7 Step: 741 Loss: 1.0873853322668345\n",
      "Epoch: 7 Step: 751 Loss: 1.577510039422604\n",
      "Epoch: 7 Step: 761 Loss: 1.0267600349717805\n",
      "Epoch: 7 Step: 771 Loss: 1.3201440373477333\n",
      "Epoch: 7 Step: 781 Loss: 1.098515423075602\n",
      "Epoch: 8 Step: 1 Loss: 1.2166744314737215\n",
      "Epoch: 8 Step: 11 Loss: 1.3423830433887396\n",
      "Epoch: 8 Step: 21 Loss: 1.1921342281925824\n",
      "Epoch: 8 Step: 31 Loss: 1.3469124439635207\n",
      "Epoch: 8 Step: 41 Loss: 0.9349910373074228\n",
      "Epoch: 8 Step: 51 Loss: 0.9631863460655378\n",
      "Epoch: 8 Step: 61 Loss: 0.9842439036712061\n",
      "Epoch: 8 Step: 71 Loss: 1.506552077021421\n",
      "Epoch: 8 Step: 81 Loss: 1.1111718698321822\n",
      "Epoch: 8 Step: 91 Loss: 1.1362453531096293\n",
      "Epoch: 8 Step: 101 Loss: 1.0145073598761725\n",
      "Epoch: 8 Step: 111 Loss: 1.1667582114034514\n",
      "Epoch: 8 Step: 121 Loss: 1.1508909924314494\n",
      "Epoch: 8 Step: 131 Loss: 0.9376185442382379\n",
      "Epoch: 8 Step: 141 Loss: 1.4529301456747192\n",
      "Epoch: 8 Step: 151 Loss: 1.1445098211536187\n",
      "Epoch: 8 Step: 161 Loss: 1.2558927662347452\n",
      "Epoch: 8 Step: 171 Loss: 1.2892524374722645\n",
      "Epoch: 8 Step: 181 Loss: 1.1338335757208107\n",
      "Epoch: 8 Step: 191 Loss: 1.0387693629228156\n",
      "Epoch: 8 Step: 201 Loss: 0.9580082817530193\n",
      "Epoch: 8 Step: 211 Loss: 0.7853639911341448\n",
      "Epoch: 8 Step: 221 Loss: 1.1783177259897086\n",
      "Epoch: 8 Step: 231 Loss: 1.0691863522470388\n",
      "Epoch: 8 Step: 241 Loss: 1.1046440678264897\n",
      "Epoch: 8 Step: 251 Loss: 1.0407044599262973\n",
      "Epoch: 8 Step: 261 Loss: 1.1808060644391682\n",
      "Epoch: 8 Step: 271 Loss: 0.9906271157682868\n",
      "Epoch: 8 Step: 281 Loss: 1.1146164400525667\n",
      "Epoch: 8 Step: 291 Loss: 1.055908878054999\n",
      "Epoch: 8 Step: 301 Loss: 1.1419733556127896\n",
      "Epoch: 8 Step: 311 Loss: 1.0690285374093333\n",
      "Epoch: 8 Step: 321 Loss: 1.1198168827201909\n",
      "Epoch: 8 Step: 331 Loss: 0.9977788830502542\n",
      "Epoch: 8 Step: 341 Loss: 1.1095174909823577\n",
      "Epoch: 8 Step: 351 Loss: 1.2719988036113534\n",
      "Epoch: 8 Step: 361 Loss: 1.258973768773758\n",
      "Epoch: 8 Step: 371 Loss: 0.8190169849631066\n",
      "Epoch: 8 Step: 381 Loss: 1.2480620640785491\n",
      "Epoch: 8 Step: 391 Loss: 0.8870717112030686\n",
      "Epoch: 8 Step: 401 Loss: 1.1047713220071094\n",
      "Epoch: 8 Step: 411 Loss: 1.3123235865763063\n",
      "Epoch: 8 Step: 421 Loss: 1.069438764523173\n",
      "Epoch: 8 Step: 431 Loss: 0.9916710179347741\n",
      "Epoch: 8 Step: 441 Loss: 0.9477808283433831\n",
      "Epoch: 8 Step: 451 Loss: 0.8721951065458732\n",
      "Epoch: 8 Step: 461 Loss: 1.0240324410680715\n",
      "Epoch: 8 Step: 471 Loss: 1.293884044650517\n",
      "Epoch: 8 Step: 481 Loss: 1.2752854267983882\n",
      "Epoch: 8 Step: 491 Loss: 1.157489887402696\n",
      "Epoch: 8 Step: 501 Loss: 1.2324223155578549\n",
      "Epoch: 8 Step: 511 Loss: 0.9863567330434979\n",
      "Epoch: 8 Step: 521 Loss: 1.210667728125066\n",
      "Epoch: 8 Step: 531 Loss: 1.160292492427455\n",
      "Epoch: 8 Step: 541 Loss: 1.0982097978222716\n",
      "Epoch: 8 Step: 551 Loss: 0.9278697766282247\n",
      "Epoch: 8 Step: 561 Loss: 0.9674061792129593\n",
      "Epoch: 8 Step: 571 Loss: 0.9111837022405704\n",
      "Epoch: 8 Step: 581 Loss: 1.1757991635976353\n",
      "Epoch: 8 Step: 591 Loss: 1.2474193866901033\n",
      "Epoch: 8 Step: 601 Loss: 1.1281665199434776\n",
      "Epoch: 8 Step: 611 Loss: 0.9453579572685482\n",
      "Epoch: 8 Step: 621 Loss: 1.1741576685682313\n",
      "Epoch: 8 Step: 631 Loss: 0.8814306072681789\n",
      "Epoch: 8 Step: 641 Loss: 1.0769913480724722\n",
      "Epoch: 8 Step: 651 Loss: 0.9567939863019614\n",
      "Epoch: 8 Step: 661 Loss: 0.8525266984151672\n",
      "Epoch: 8 Step: 671 Loss: 1.33505066515771\n",
      "Epoch: 8 Step: 681 Loss: 1.295161272370021\n",
      "Epoch: 8 Step: 691 Loss: 1.2038071041755392\n",
      "Epoch: 8 Step: 701 Loss: 1.1372105074220666\n",
      "Epoch: 8 Step: 711 Loss: 1.20941452351382\n",
      "Epoch: 8 Step: 721 Loss: 1.0086697630094943\n",
      "Epoch: 8 Step: 731 Loss: 0.8904207058987248\n",
      "Epoch: 8 Step: 741 Loss: 0.9636734499127615\n",
      "Epoch: 8 Step: 751 Loss: 1.3719468453294146\n",
      "Epoch: 8 Step: 761 Loss: 0.7477451273727402\n",
      "Epoch: 8 Step: 771 Loss: 1.3263548351426129\n",
      "Epoch: 8 Step: 781 Loss: 1.0824313578114813\n",
      "Epoch: 9 Step: 1 Loss: 1.0647580436746598\n",
      "Epoch: 9 Step: 11 Loss: 1.1752013904778695\n",
      "Epoch: 9 Step: 21 Loss: 1.1920175331647147\n",
      "Epoch: 9 Step: 31 Loss: 1.1440442323685904\n",
      "Epoch: 9 Step: 41 Loss: 0.8433982915758078\n",
      "Epoch: 9 Step: 51 Loss: 0.8444518938160603\n",
      "Epoch: 9 Step: 61 Loss: 0.9603159360271134\n",
      "Epoch: 9 Step: 71 Loss: 1.4174451988749845\n",
      "Epoch: 9 Step: 81 Loss: 1.126380632809071\n",
      "Epoch: 9 Step: 91 Loss: 1.1345506935622085\n",
      "Epoch: 9 Step: 101 Loss: 1.0444751601057656\n",
      "Epoch: 9 Step: 111 Loss: 1.1584813186429028\n",
      "Epoch: 9 Step: 121 Loss: 1.1515560599516945\n",
      "Epoch: 9 Step: 131 Loss: 0.9934889023165792\n",
      "Epoch: 9 Step: 141 Loss: 1.376588180210271\n",
      "Epoch: 9 Step: 151 Loss: 1.0213367845614494\n",
      "Epoch: 9 Step: 161 Loss: 1.0740809586337796\n",
      "Epoch: 9 Step: 171 Loss: 1.2906775065754563\n",
      "Epoch: 9 Step: 181 Loss: 0.9981924770594593\n",
      "Epoch: 9 Step: 191 Loss: 0.8785280377286179\n",
      "Epoch: 9 Step: 201 Loss: 0.8829935870460113\n",
      "Epoch: 9 Step: 211 Loss: 0.756458490028588\n",
      "Epoch: 9 Step: 221 Loss: 1.13226207910988\n",
      "Epoch: 9 Step: 231 Loss: 1.0111657561039988\n",
      "Epoch: 9 Step: 241 Loss: 0.9920103122791091\n",
      "Epoch: 9 Step: 251 Loss: 1.0385373565884206\n",
      "Epoch: 9 Step: 261 Loss: 1.298051176809528\n",
      "Epoch: 9 Step: 271 Loss: 1.1083448710053379\n",
      "Epoch: 9 Step: 281 Loss: 1.1196118754235531\n",
      "Epoch: 9 Step: 291 Loss: 1.148252884255901\n",
      "Epoch: 9 Step: 301 Loss: 1.1071710126329215\n",
      "Epoch: 9 Step: 311 Loss: 1.0996207254802175\n",
      "Epoch: 9 Step: 321 Loss: 1.0162864409295156\n",
      "Epoch: 9 Step: 331 Loss: 0.976032172588637\n",
      "Epoch: 9 Step: 341 Loss: 0.9860636338599573\n",
      "Epoch: 9 Step: 351 Loss: 1.1400721707668549\n",
      "Epoch: 9 Step: 361 Loss: 1.1159299148241382\n",
      "Epoch: 9 Step: 371 Loss: 0.7892895887989138\n",
      "Epoch: 9 Step: 381 Loss: 0.9645201749451683\n",
      "Epoch: 9 Step: 391 Loss: 0.7256000456457787\n",
      "Epoch: 9 Step: 401 Loss: 0.9831201964247945\n",
      "Epoch: 9 Step: 411 Loss: 1.278481937746467\n",
      "Epoch: 9 Step: 421 Loss: 1.0126694697626921\n",
      "Epoch: 9 Step: 431 Loss: 0.9058964794798057\n",
      "Epoch: 9 Step: 441 Loss: 0.8003137370827302\n",
      "Epoch: 9 Step: 451 Loss: 0.9135278865401146\n",
      "Epoch: 9 Step: 461 Loss: 1.1767510337280735\n",
      "Epoch: 9 Step: 471 Loss: 1.3275778503058626\n",
      "Epoch: 9 Step: 481 Loss: 1.3291783937591988\n",
      "Epoch: 9 Step: 491 Loss: 1.385190493977701\n",
      "Epoch: 9 Step: 501 Loss: 1.1313503779368181\n",
      "Epoch: 9 Step: 511 Loss: 0.9688844995489464\n",
      "Epoch: 9 Step: 521 Loss: 1.1537995378662793\n",
      "Epoch: 9 Step: 531 Loss: 1.0897756489823216\n",
      "Epoch: 9 Step: 541 Loss: 1.0184924168696563\n",
      "Epoch: 9 Step: 551 Loss: 0.8562155438837931\n",
      "Epoch: 9 Step: 561 Loss: 0.8970601136042683\n",
      "Epoch: 9 Step: 571 Loss: 0.8500426699890722\n",
      "Epoch: 9 Step: 581 Loss: 1.070704225280086\n",
      "Epoch: 9 Step: 591 Loss: 1.0846863385375256\n",
      "Epoch: 9 Step: 601 Loss: 0.8367358972556682\n",
      "Epoch: 9 Step: 611 Loss: 1.0732289423934378\n",
      "Epoch: 9 Step: 621 Loss: 1.0641603527529473\n",
      "Epoch: 9 Step: 631 Loss: 0.9153521531708291\n",
      "Epoch: 9 Step: 641 Loss: 1.2804794654168914\n",
      "Epoch: 9 Step: 651 Loss: 1.0174737508815215\n",
      "Epoch: 9 Step: 661 Loss: 0.9735200570689367\n",
      "Epoch: 9 Step: 671 Loss: 1.2277965447462829\n",
      "Epoch: 9 Step: 681 Loss: 1.3061313559666177\n",
      "Epoch: 9 Step: 691 Loss: 0.9755214120903969\n",
      "Epoch: 9 Step: 701 Loss: 0.8814291732480901\n",
      "Epoch: 9 Step: 711 Loss: 0.9867299911775809\n",
      "Epoch: 9 Step: 721 Loss: 0.8352659206836801\n",
      "Epoch: 9 Step: 731 Loss: 0.7550581625885698\n",
      "Epoch: 9 Step: 741 Loss: 0.8603943091791835\n",
      "Epoch: 9 Step: 751 Loss: 1.1565214184763781\n",
      "Epoch: 9 Step: 761 Loss: 0.8892571486649167\n",
      "Epoch: 9 Step: 771 Loss: 1.2675345481411484\n",
      "Epoch: 9 Step: 781 Loss: 1.0048732635858197\n",
      "Epoch: 10 Step: 1 Loss: 0.9940515507856078\n",
      "Epoch: 10 Step: 11 Loss: 1.0988813280901022\n",
      "Epoch: 10 Step: 21 Loss: 1.1361970614879298\n",
      "Epoch: 10 Step: 31 Loss: 1.2628333754774246\n",
      "Epoch: 10 Step: 41 Loss: 1.0071421418811202\n",
      "Epoch: 10 Step: 51 Loss: 0.9942768941223822\n",
      "Epoch: 10 Step: 61 Loss: 1.0305590630482637\n",
      "Epoch: 10 Step: 71 Loss: 1.407420782694531\n",
      "Epoch: 10 Step: 81 Loss: 0.9901834743201587\n",
      "Epoch: 10 Step: 91 Loss: 0.9951200454572626\n",
      "Epoch: 10 Step: 101 Loss: 0.9037841633031043\n",
      "Epoch: 10 Step: 111 Loss: 1.1783060052779226\n",
      "Epoch: 10 Step: 121 Loss: 0.8878071340871397\n",
      "Epoch: 10 Step: 131 Loss: 0.9087674550051215\n",
      "Epoch: 10 Step: 141 Loss: 1.303287420622446\n",
      "Epoch: 10 Step: 151 Loss: 1.0555238075040678\n",
      "Epoch: 10 Step: 161 Loss: 1.0174558204396824\n",
      "Epoch: 10 Step: 171 Loss: 1.1306252085911834\n",
      "Epoch: 10 Step: 181 Loss: 0.856843016814208\n",
      "Epoch: 10 Step: 191 Loss: 0.9291100470582101\n",
      "Epoch: 10 Step: 201 Loss: 0.823854980020289\n",
      "Epoch: 10 Step: 211 Loss: 0.746614018617779\n",
      "Epoch: 10 Step: 221 Loss: 1.0169665978138966\n",
      "Epoch: 10 Step: 231 Loss: 0.9444402741871292\n",
      "Epoch: 10 Step: 241 Loss: 1.0357621413901408\n",
      "Epoch: 10 Step: 251 Loss: 1.0334393460740943\n",
      "Epoch: 10 Step: 261 Loss: 1.1502462910062305\n",
      "Epoch: 10 Step: 271 Loss: 1.0485671782327388\n",
      "Epoch: 10 Step: 281 Loss: 0.8866231324017121\n",
      "Epoch: 10 Step: 291 Loss: 1.0657740470729036\n",
      "Epoch: 10 Step: 301 Loss: 1.099882183794692\n",
      "Epoch: 10 Step: 311 Loss: 0.9641200987542546\n",
      "Epoch: 10 Step: 321 Loss: 0.9984104923050692\n",
      "Epoch: 10 Step: 331 Loss: 0.9228805807398754\n",
      "Epoch: 10 Step: 341 Loss: 0.9000580331949531\n",
      "Epoch: 10 Step: 351 Loss: 1.1011113111101194\n",
      "Epoch: 10 Step: 361 Loss: 0.911239580354773\n",
      "Epoch: 10 Step: 371 Loss: 0.8548798746471897\n",
      "Epoch: 10 Step: 381 Loss: 1.0112379488370196\n",
      "Epoch: 10 Step: 391 Loss: 0.7006036556552346\n",
      "Epoch: 10 Step: 401 Loss: 0.9985371717857097\n",
      "Epoch: 10 Step: 411 Loss: 1.082717337950994\n",
      "Epoch: 10 Step: 421 Loss: 1.2201917939057374\n",
      "Epoch: 10 Step: 431 Loss: 0.9941757848390024\n",
      "Epoch: 10 Step: 441 Loss: 0.9705793334832067\n",
      "Epoch: 10 Step: 451 Loss: 0.8515572657644241\n",
      "Epoch: 10 Step: 461 Loss: 0.9995132378860896\n",
      "Epoch: 10 Step: 471 Loss: 1.0973929824298811\n",
      "Epoch: 10 Step: 481 Loss: 1.2891953395477347\n",
      "Epoch: 10 Step: 491 Loss: 1.1571255952678872\n",
      "Epoch: 10 Step: 501 Loss: 1.1194060102378998\n",
      "Epoch: 10 Step: 511 Loss: 0.9427570435687387\n",
      "Epoch: 10 Step: 521 Loss: 0.9550500157982214\n",
      "Epoch: 10 Step: 531 Loss: 0.9643540608705437\n",
      "Epoch: 10 Step: 541 Loss: 0.9680803417217866\n",
      "Epoch: 10 Step: 551 Loss: 0.808924265394748\n",
      "Epoch: 10 Step: 561 Loss: 0.9033766773750214\n",
      "Epoch: 10 Step: 571 Loss: 0.8535167394102311\n",
      "Epoch: 10 Step: 581 Loss: 1.042137800241822\n",
      "Epoch: 10 Step: 591 Loss: 1.317785640715011\n",
      "Epoch: 10 Step: 601 Loss: 0.9785042475701062\n",
      "Epoch: 10 Step: 611 Loss: 1.0101448381679732\n",
      "Epoch: 10 Step: 621 Loss: 1.1379140334787383\n",
      "Epoch: 10 Step: 631 Loss: 0.9922016437457646\n",
      "Epoch: 10 Step: 641 Loss: 1.127956706817005\n",
      "Epoch: 10 Step: 651 Loss: 0.8622181954236474\n",
      "Epoch: 10 Step: 661 Loss: 0.817016305603605\n",
      "Epoch: 10 Step: 671 Loss: 1.1998450168712962\n",
      "Epoch: 10 Step: 681 Loss: 1.2768154655265214\n",
      "Epoch: 10 Step: 691 Loss: 0.9244008331438678\n",
      "Epoch: 10 Step: 701 Loss: 0.9020516545087363\n",
      "Epoch: 10 Step: 711 Loss: 0.8781580026145036\n",
      "Epoch: 10 Step: 721 Loss: 0.8022572476393453\n",
      "Epoch: 10 Step: 731 Loss: 0.7305454322547189\n",
      "Epoch: 10 Step: 741 Loss: 0.931045610957411\n",
      "Epoch: 10 Step: 751 Loss: 1.2247327092057443\n",
      "Epoch: 10 Step: 761 Loss: 0.7851808966377604\n",
      "Epoch: 10 Step: 771 Loss: 1.334373659505123\n",
      "Epoch: 10 Step: 781 Loss: 0.9433028144549375\n",
      "Epoch: 11 Step: 1 Loss: 1.159085401399349\n",
      "Epoch: 11 Step: 11 Loss: 1.1994357234137834\n",
      "Epoch: 11 Step: 21 Loss: 1.0579530554709198\n",
      "Epoch: 11 Step: 31 Loss: 1.0532662102680257\n",
      "Epoch: 11 Step: 41 Loss: 0.8879613705904823\n",
      "Epoch: 11 Step: 51 Loss: 0.7267064563989052\n",
      "Epoch: 11 Step: 61 Loss: 1.0155384333458604\n",
      "Epoch: 11 Step: 71 Loss: 1.302104227569002\n",
      "Epoch: 11 Step: 81 Loss: 0.7762618982647889\n",
      "Epoch: 11 Step: 91 Loss: 1.021879490323782\n",
      "Epoch: 11 Step: 101 Loss: 0.8296811818457521\n",
      "Epoch: 11 Step: 111 Loss: 1.104520338422766\n",
      "Epoch: 11 Step: 121 Loss: 0.8274037171597637\n",
      "Epoch: 11 Step: 131 Loss: 0.7866005514209586\n",
      "Epoch: 11 Step: 141 Loss: 1.206791664333136\n",
      "Epoch: 11 Step: 151 Loss: 0.9300154159657166\n",
      "Epoch: 11 Step: 161 Loss: 1.0439591387507285\n",
      "Epoch: 11 Step: 171 Loss: 1.1873244005596515\n",
      "Epoch: 11 Step: 181 Loss: 1.1583403153100817\n",
      "Epoch: 11 Step: 191 Loss: 0.9415132048204629\n",
      "Epoch: 11 Step: 201 Loss: 0.9110020885659391\n",
      "Epoch: 11 Step: 211 Loss: 0.7183359691133075\n",
      "Epoch: 11 Step: 221 Loss: 1.078992753081653\n",
      "Epoch: 11 Step: 231 Loss: 0.9352335638608695\n",
      "Epoch: 11 Step: 241 Loss: 0.8685405992888886\n",
      "Epoch: 11 Step: 251 Loss: 0.9199805892590718\n",
      "Epoch: 11 Step: 261 Loss: 0.961604675307102\n",
      "Epoch: 11 Step: 271 Loss: 0.8841894493137722\n",
      "Epoch: 11 Step: 281 Loss: 0.8198225878837693\n",
      "Epoch: 11 Step: 291 Loss: 0.9214918414168739\n",
      "Epoch: 11 Step: 301 Loss: 1.131837965481377\n",
      "Epoch: 11 Step: 311 Loss: 0.8529406091611086\n",
      "Epoch: 11 Step: 321 Loss: 0.8991632633375068\n",
      "Epoch: 11 Step: 331 Loss: 0.8980174815682012\n",
      "Epoch: 11 Step: 341 Loss: 1.0073632280043603\n",
      "Epoch: 11 Step: 351 Loss: 1.223074780382554\n",
      "Epoch: 11 Step: 361 Loss: 0.9942066275147933\n",
      "Epoch: 11 Step: 371 Loss: 0.7937145437245117\n",
      "Epoch: 11 Step: 381 Loss: 1.0669345169779327\n",
      "Epoch: 11 Step: 391 Loss: 0.807894244791989\n",
      "Epoch: 11 Step: 401 Loss: 0.9101636451019893\n",
      "Epoch: 11 Step: 411 Loss: 1.2042366787679368\n",
      "Epoch: 11 Step: 421 Loss: 1.2032163175774317\n",
      "Epoch: 11 Step: 431 Loss: 0.8041192126304472\n",
      "Epoch: 11 Step: 441 Loss: 0.7966968038271406\n",
      "Epoch: 11 Step: 451 Loss: 0.8084609064086934\n",
      "Epoch: 11 Step: 461 Loss: 0.9003509944606068\n",
      "Epoch: 11 Step: 471 Loss: 1.176781041668812\n",
      "Epoch: 11 Step: 481 Loss: 1.211596446064842\n",
      "Epoch: 11 Step: 491 Loss: 1.00908946256919\n",
      "Epoch: 11 Step: 501 Loss: 0.9757636252109898\n",
      "Epoch: 11 Step: 511 Loss: 0.8191135529440717\n",
      "Epoch: 11 Step: 521 Loss: 0.9408011725972348\n",
      "Epoch: 11 Step: 531 Loss: 1.033622688897151\n",
      "Epoch: 11 Step: 541 Loss: 0.9743577835871697\n",
      "Epoch: 11 Step: 551 Loss: 0.8577740868053672\n",
      "Epoch: 11 Step: 561 Loss: 0.802034862663701\n",
      "Epoch: 11 Step: 571 Loss: 0.929120882300005\n",
      "Epoch: 11 Step: 581 Loss: 1.0223804717928664\n",
      "Epoch: 11 Step: 591 Loss: 1.15623227864299\n",
      "Epoch: 11 Step: 601 Loss: 1.0627597478033293\n",
      "Epoch: 11 Step: 611 Loss: 1.0046448753946382\n",
      "Epoch: 11 Step: 621 Loss: 0.9907720232585302\n",
      "Epoch: 11 Step: 631 Loss: 0.8971590940107116\n",
      "Epoch: 11 Step: 641 Loss: 0.8650176876367405\n",
      "Epoch: 11 Step: 651 Loss: 0.669493218591529\n",
      "Epoch: 11 Step: 661 Loss: 0.7166224357355909\n",
      "Epoch: 11 Step: 671 Loss: 1.109204846145865\n",
      "Epoch: 11 Step: 681 Loss: 1.0793799970710936\n",
      "Epoch: 11 Step: 691 Loss: 0.9187983419344139\n",
      "Epoch: 11 Step: 701 Loss: 0.9205912385335262\n",
      "Epoch: 11 Step: 711 Loss: 0.9465634518956882\n",
      "Epoch: 11 Step: 721 Loss: 0.7653064588640053\n",
      "Epoch: 11 Step: 731 Loss: 0.8086287794219147\n",
      "Epoch: 11 Step: 741 Loss: 1.0029379773102072\n",
      "Epoch: 11 Step: 751 Loss: 1.4168276802283648\n",
      "Epoch: 11 Step: 761 Loss: 0.7997035486820188\n",
      "Epoch: 11 Step: 771 Loss: 1.2345175458039164\n",
      "Epoch: 11 Step: 781 Loss: 0.7950254276025497\n",
      "Epoch: 12 Step: 1 Loss: 0.8737100614239874\n",
      "Epoch: 12 Step: 11 Loss: 1.0879934165511753\n",
      "Epoch: 12 Step: 21 Loss: 0.8991209879450203\n",
      "Epoch: 12 Step: 31 Loss: 0.9966884585775619\n",
      "Epoch: 12 Step: 41 Loss: 0.6853989864635195\n",
      "Epoch: 12 Step: 51 Loss: 0.5953975037278353\n",
      "Epoch: 12 Step: 61 Loss: 0.8546627393475923\n",
      "Epoch: 12 Step: 71 Loss: 1.193653300045325\n",
      "Epoch: 12 Step: 81 Loss: 0.8110245550984319\n",
      "Epoch: 12 Step: 91 Loss: 0.8898652522869014\n",
      "Epoch: 12 Step: 101 Loss: 0.7701676259622996\n",
      "Epoch: 12 Step: 111 Loss: 1.0808025440787845\n",
      "Epoch: 12 Step: 121 Loss: 0.9654602299686219\n",
      "Epoch: 12 Step: 131 Loss: 0.6671512113609354\n",
      "Epoch: 12 Step: 141 Loss: 1.462402790711907\n",
      "Epoch: 12 Step: 151 Loss: 0.942603740523138\n",
      "Epoch: 12 Step: 161 Loss: 0.9123240365511778\n",
      "Epoch: 12 Step: 171 Loss: 1.0339378434873758\n",
      "Epoch: 12 Step: 181 Loss: 0.9155206688648169\n",
      "Epoch: 12 Step: 191 Loss: 0.8395178549956869\n",
      "Epoch: 12 Step: 201 Loss: 0.8184622260836847\n",
      "Epoch: 12 Step: 211 Loss: 0.5994847511037195\n",
      "Epoch: 12 Step: 221 Loss: 0.9328135454695408\n",
      "Epoch: 12 Step: 231 Loss: 0.7426319391425551\n",
      "Epoch: 12 Step: 241 Loss: 0.7333638661624544\n",
      "Epoch: 12 Step: 251 Loss: 0.8425716766757088\n",
      "Epoch: 12 Step: 261 Loss: 0.9795928018789692\n",
      "Epoch: 12 Step: 271 Loss: 0.8627377971571264\n",
      "Epoch: 12 Step: 281 Loss: 0.7112281537926897\n",
      "Epoch: 12 Step: 291 Loss: 0.9284403330172288\n",
      "Epoch: 12 Step: 301 Loss: 1.0051605340220655\n",
      "Epoch: 12 Step: 311 Loss: 0.7739418243706375\n",
      "Epoch: 12 Step: 321 Loss: 0.9264082263361211\n",
      "Epoch: 12 Step: 331 Loss: 0.9058496607553483\n",
      "Epoch: 12 Step: 341 Loss: 0.8158235247729856\n",
      "Epoch: 12 Step: 351 Loss: 0.9940423577448779\n",
      "Epoch: 12 Step: 361 Loss: 0.9220734674635522\n",
      "Epoch: 12 Step: 371 Loss: 0.7003977242613137\n",
      "Epoch: 12 Step: 381 Loss: 0.9271784856786243\n",
      "Epoch: 12 Step: 391 Loss: 0.7267462296633034\n",
      "Epoch: 12 Step: 401 Loss: 0.7764348181586678\n",
      "Epoch: 12 Step: 411 Loss: 0.9441768996180966\n",
      "Epoch: 12 Step: 421 Loss: 1.006251641291168\n",
      "Epoch: 12 Step: 431 Loss: 0.7533385910439113\n",
      "Epoch: 12 Step: 441 Loss: 0.6729055890966276\n",
      "Epoch: 12 Step: 451 Loss: 0.8212001461403593\n",
      "Epoch: 12 Step: 461 Loss: 0.8266203092391636\n",
      "Epoch: 12 Step: 471 Loss: 1.0721973976700592\n",
      "Epoch: 12 Step: 481 Loss: 1.2191854888642908\n",
      "Epoch: 12 Step: 491 Loss: 0.8246603359346394\n",
      "Epoch: 12 Step: 501 Loss: 0.980107235793613\n",
      "Epoch: 12 Step: 511 Loss: 0.8449871978087867\n",
      "Epoch: 12 Step: 521 Loss: 0.9188422655062858\n",
      "Epoch: 12 Step: 531 Loss: 0.8609301580555283\n",
      "Epoch: 12 Step: 541 Loss: 0.9410617751274996\n",
      "Epoch: 12 Step: 551 Loss: 0.822163005409299\n",
      "Epoch: 12 Step: 561 Loss: 0.7673155632097142\n",
      "Epoch: 12 Step: 571 Loss: 0.6623046318653222\n",
      "Epoch: 12 Step: 581 Loss: 0.9055234197765665\n",
      "Epoch: 12 Step: 591 Loss: 0.9307788976165746\n",
      "Epoch: 12 Step: 601 Loss: 0.77539085658795\n",
      "Epoch: 12 Step: 611 Loss: 0.8206246002008193\n",
      "Epoch: 12 Step: 621 Loss: 1.0040246803008623\n",
      "Epoch: 12 Step: 631 Loss: 0.5867034890714854\n",
      "Epoch: 12 Step: 641 Loss: 0.9400030064943428\n",
      "Epoch: 12 Step: 651 Loss: 0.7634609636180136\n",
      "Epoch: 12 Step: 661 Loss: 0.6734432752428025\n",
      "Epoch: 12 Step: 671 Loss: 1.283763484652198\n",
      "Epoch: 12 Step: 681 Loss: 1.0995008360374112\n",
      "Epoch: 12 Step: 691 Loss: 0.9933971818352303\n",
      "Epoch: 12 Step: 701 Loss: 0.9823089895173528\n",
      "Epoch: 12 Step: 711 Loss: 0.7784260702323752\n",
      "Epoch: 12 Step: 721 Loss: 0.7524717385551932\n",
      "Epoch: 12 Step: 731 Loss: 0.6776264661605272\n",
      "Epoch: 12 Step: 741 Loss: 0.8609653568905051\n",
      "Epoch: 12 Step: 751 Loss: 1.2260577430582098\n",
      "Epoch: 12 Step: 761 Loss: 0.8343380622510657\n",
      "Epoch: 12 Step: 771 Loss: 0.9978743710473817\n",
      "Epoch: 12 Step: 781 Loss: 0.8572596160354412\n",
      "Epoch: 13 Step: 1 Loss: 0.8118797739046555\n",
      "Epoch: 13 Step: 11 Loss: 1.0599455478943485\n",
      "Epoch: 13 Step: 21 Loss: 0.8351295967608777\n",
      "Epoch: 13 Step: 31 Loss: 1.029769728491757\n",
      "Epoch: 13 Step: 41 Loss: 0.703369414709675\n",
      "Epoch: 13 Step: 51 Loss: 0.6666857277332747\n",
      "Epoch: 13 Step: 61 Loss: 0.8428835782914877\n",
      "Epoch: 13 Step: 71 Loss: 1.3091971696423919\n",
      "Epoch: 13 Step: 81 Loss: 0.9509977667636229\n",
      "Epoch: 13 Step: 91 Loss: 0.9751345669090749\n",
      "Epoch: 13 Step: 101 Loss: 1.066128120415253\n",
      "Epoch: 13 Step: 111 Loss: 1.0982181938267401\n",
      "Epoch: 13 Step: 121 Loss: 0.7754406507872554\n",
      "Epoch: 13 Step: 131 Loss: 0.6577267100395237\n",
      "Epoch: 13 Step: 141 Loss: 1.1115849419233068\n",
      "Epoch: 13 Step: 151 Loss: 0.7880693905429557\n",
      "Epoch: 13 Step: 161 Loss: 0.8424913954603397\n",
      "Epoch: 13 Step: 171 Loss: 0.9891764335018627\n",
      "Epoch: 13 Step: 181 Loss: 0.6650200236062176\n",
      "Epoch: 13 Step: 191 Loss: 0.7850674697068064\n",
      "Epoch: 13 Step: 201 Loss: 0.7210711084100098\n",
      "Epoch: 13 Step: 211 Loss: 0.5296045768218667\n",
      "Epoch: 13 Step: 221 Loss: 0.869195654111921\n",
      "Epoch: 13 Step: 231 Loss: 0.7345580201725979\n",
      "Epoch: 13 Step: 241 Loss: 0.7291286002327637\n",
      "Epoch: 13 Step: 251 Loss: 0.7737797700108604\n",
      "Epoch: 13 Step: 261 Loss: 0.9440643812792144\n",
      "Epoch: 13 Step: 271 Loss: 1.0334958079166698\n",
      "Epoch: 13 Step: 281 Loss: 0.8730765337941211\n",
      "Epoch: 13 Step: 291 Loss: 0.8362295025831228\n",
      "Epoch: 13 Step: 301 Loss: 0.741780835929728\n",
      "Epoch: 13 Step: 311 Loss: 0.824932361506396\n",
      "Epoch: 13 Step: 321 Loss: 0.7474292472065698\n",
      "Epoch: 13 Step: 331 Loss: 0.7832084658648499\n",
      "Epoch: 13 Step: 341 Loss: 0.7509962393848788\n",
      "Epoch: 13 Step: 351 Loss: 0.8737877968452292\n",
      "Epoch: 13 Step: 361 Loss: 0.8482001743217116\n",
      "Epoch: 13 Step: 371 Loss: 0.5829480661352904\n",
      "Epoch: 13 Step: 381 Loss: 0.8919464611861089\n",
      "Epoch: 13 Step: 391 Loss: 0.6521491939200383\n",
      "Epoch: 13 Step: 401 Loss: 0.7547362085589753\n",
      "Epoch: 13 Step: 411 Loss: 1.0223853008994677\n",
      "Epoch: 13 Step: 421 Loss: 1.0197934022454653\n",
      "Epoch: 13 Step: 431 Loss: 0.9151108577123963\n",
      "Epoch: 13 Step: 441 Loss: 0.7127865426683753\n",
      "Epoch: 13 Step: 451 Loss: 0.8502711048274019\n",
      "Epoch: 13 Step: 461 Loss: 0.962517421674256\n",
      "Epoch: 13 Step: 471 Loss: 1.0054262501258318\n",
      "Epoch: 13 Step: 481 Loss: 0.9709451989391396\n",
      "Epoch: 13 Step: 491 Loss: 0.9961000121458441\n",
      "Epoch: 13 Step: 501 Loss: 0.8772975918520485\n",
      "Epoch: 13 Step: 511 Loss: 0.7580413522756293\n",
      "Epoch: 13 Step: 521 Loss: 0.8709607143346905\n",
      "Epoch: 13 Step: 531 Loss: 0.7555263389128363\n",
      "Epoch: 13 Step: 541 Loss: 0.9117378092416087\n",
      "Epoch: 13 Step: 551 Loss: 0.7517552459368175\n",
      "Epoch: 13 Step: 561 Loss: 0.7138897707575786\n",
      "Epoch: 13 Step: 571 Loss: 0.7133783162197767\n",
      "Epoch: 13 Step: 581 Loss: 0.9226739847839769\n",
      "Epoch: 13 Step: 591 Loss: 0.8919755644377437\n",
      "Epoch: 13 Step: 601 Loss: 0.8222995001890901\n",
      "Epoch: 13 Step: 611 Loss: 0.8621093985857057\n",
      "Epoch: 13 Step: 621 Loss: 1.069482289742298\n",
      "Epoch: 13 Step: 631 Loss: 0.8026405394409979\n",
      "Epoch: 13 Step: 641 Loss: 0.8977858255141054\n",
      "Epoch: 13 Step: 651 Loss: 0.7403143218328896\n",
      "Epoch: 13 Step: 661 Loss: 0.5052161299506754\n",
      "Epoch: 13 Step: 671 Loss: 0.8610560845230525\n",
      "Epoch: 13 Step: 681 Loss: 0.9574200294355294\n",
      "Epoch: 13 Step: 691 Loss: 0.7142336271653313\n",
      "Epoch: 13 Step: 701 Loss: 0.725415810353679\n",
      "Epoch: 13 Step: 711 Loss: 0.7119623658548573\n",
      "Epoch: 13 Step: 721 Loss: 0.6453861880607774\n",
      "Epoch: 13 Step: 731 Loss: 0.610564581484344\n",
      "Epoch: 13 Step: 741 Loss: 0.9048126286021148\n",
      "Epoch: 13 Step: 751 Loss: 0.870623566909196\n",
      "Epoch: 13 Step: 761 Loss: 0.6690106318791883\n",
      "Epoch: 13 Step: 771 Loss: 1.0897122072064473\n",
      "Epoch: 13 Step: 781 Loss: 0.8638605692922705\n",
      "Epoch: 14 Step: 1 Loss: 0.8636399196867249\n",
      "Epoch: 14 Step: 11 Loss: 0.9986254743499156\n",
      "Epoch: 14 Step: 21 Loss: 0.8420337891139827\n",
      "Epoch: 14 Step: 31 Loss: 1.1727193131932574\n",
      "Epoch: 14 Step: 41 Loss: 0.7343671503802212\n",
      "Epoch: 14 Step: 51 Loss: 0.6328435280011975\n",
      "Epoch: 14 Step: 61 Loss: 0.861068368883315\n",
      "Epoch: 14 Step: 71 Loss: 1.0836937609936728\n",
      "Epoch: 14 Step: 81 Loss: 0.7951478666651433\n",
      "Epoch: 14 Step: 91 Loss: 0.9212888345866664\n",
      "Epoch: 14 Step: 101 Loss: 0.7664315345323094\n",
      "Epoch: 14 Step: 111 Loss: 0.8988719145130452\n",
      "Epoch: 14 Step: 121 Loss: 0.7708724247513142\n",
      "Epoch: 14 Step: 131 Loss: 0.7311078345430557\n",
      "Epoch: 14 Step: 141 Loss: 1.0296447294431612\n",
      "Epoch: 14 Step: 151 Loss: 0.6665716424397404\n",
      "Epoch: 14 Step: 161 Loss: 0.6951800793327998\n",
      "Epoch: 14 Step: 171 Loss: 0.8622813097422164\n",
      "Epoch: 14 Step: 181 Loss: 0.6369922468606162\n",
      "Epoch: 14 Step: 191 Loss: 0.6420872338998069\n",
      "Epoch: 14 Step: 201 Loss: 0.7289172234562662\n",
      "Epoch: 14 Step: 211 Loss: 0.6626309764140004\n",
      "Epoch: 14 Step: 221 Loss: 0.9574920402600644\n",
      "Epoch: 14 Step: 231 Loss: 0.9102601385541518\n",
      "Epoch: 14 Step: 241 Loss: 0.6490714609166416\n",
      "Epoch: 14 Step: 251 Loss: 0.6648263571976947\n",
      "Epoch: 14 Step: 261 Loss: 0.7481852485111176\n",
      "Epoch: 14 Step: 271 Loss: 0.8241589226168622\n",
      "Epoch: 14 Step: 281 Loss: 0.6328037605555499\n",
      "Epoch: 14 Step: 291 Loss: 0.7602237847649422\n",
      "Epoch: 14 Step: 301 Loss: 0.7455791681647754\n",
      "Epoch: 14 Step: 311 Loss: 0.7318452507559658\n",
      "Epoch: 14 Step: 321 Loss: 0.8202273407896311\n",
      "Epoch: 14 Step: 331 Loss: 0.7349661217707006\n",
      "Epoch: 14 Step: 341 Loss: 0.7885621423746361\n",
      "Epoch: 14 Step: 351 Loss: 0.9335400862875398\n",
      "Epoch: 14 Step: 361 Loss: 0.643837976200553\n",
      "Epoch: 14 Step: 371 Loss: 0.6835103788393058\n",
      "Epoch: 14 Step: 381 Loss: 0.9862094830432562\n",
      "Epoch: 14 Step: 391 Loss: 0.6716241606015612\n",
      "Epoch: 14 Step: 401 Loss: 0.8567876264436083\n",
      "Epoch: 14 Step: 411 Loss: 1.0425555498202699\n",
      "Epoch: 14 Step: 421 Loss: 0.9692570233621132\n",
      "Epoch: 14 Step: 431 Loss: 0.6530507042939848\n",
      "Epoch: 14 Step: 441 Loss: 0.6206109742361222\n",
      "Epoch: 14 Step: 451 Loss: 0.6447310515718481\n",
      "Epoch: 14 Step: 461 Loss: 0.8202816735466322\n",
      "Epoch: 14 Step: 471 Loss: 0.9787216995966792\n",
      "Epoch: 14 Step: 481 Loss: 0.9241644998546146\n",
      "Epoch: 14 Step: 491 Loss: 0.765786404395562\n",
      "Epoch: 14 Step: 501 Loss: 0.860115187007375\n",
      "Epoch: 14 Step: 511 Loss: 0.7127267989577203\n",
      "Epoch: 14 Step: 521 Loss: 0.7913184068629733\n",
      "Epoch: 14 Step: 531 Loss: 0.8574423567704812\n",
      "Epoch: 14 Step: 541 Loss: 0.9139432446306843\n",
      "Epoch: 14 Step: 551 Loss: 0.6896426930835323\n",
      "Epoch: 14 Step: 561 Loss: 0.6682756024344441\n",
      "Epoch: 14 Step: 571 Loss: 0.6432245662554907\n",
      "Epoch: 14 Step: 581 Loss: 0.8798016684834726\n",
      "Epoch: 14 Step: 591 Loss: 1.131064763235122\n",
      "Epoch: 14 Step: 601 Loss: 0.7846853769373325\n",
      "Epoch: 14 Step: 611 Loss: 0.7618066703701841\n",
      "Epoch: 14 Step: 621 Loss: 0.766727912724964\n",
      "Epoch: 14 Step: 631 Loss: 0.7956996187668508\n",
      "Epoch: 14 Step: 641 Loss: 0.8469714265897914\n",
      "Epoch: 14 Step: 651 Loss: 0.557660421737901\n",
      "Epoch: 14 Step: 661 Loss: 0.4980171298209244\n",
      "Epoch: 14 Step: 671 Loss: 0.8010547970352049\n",
      "Epoch: 14 Step: 681 Loss: 0.9622226880358469\n",
      "Epoch: 14 Step: 691 Loss: 0.7153338071951896\n",
      "Epoch: 14 Step: 701 Loss: 0.79650027527821\n",
      "Epoch: 14 Step: 711 Loss: 0.7662062284852467\n",
      "Epoch: 14 Step: 721 Loss: 0.6333854741913714\n",
      "Epoch: 14 Step: 731 Loss: 0.6485047825916692\n",
      "Epoch: 14 Step: 741 Loss: 0.8922547477085792\n",
      "Epoch: 14 Step: 751 Loss: 1.1902293963864654\n",
      "Epoch: 14 Step: 761 Loss: 0.7982367600006507\n",
      "Epoch: 14 Step: 771 Loss: 1.2332256001571296\n",
      "Epoch: 14 Step: 781 Loss: 0.7552558971624206\n",
      "Epoch: 15 Step: 1 Loss: 0.7742547406954454\n",
      "Epoch: 15 Step: 11 Loss: 0.7897224188001764\n",
      "Epoch: 15 Step: 21 Loss: 0.923517675553527\n",
      "Epoch: 15 Step: 31 Loss: 1.0478439158206836\n",
      "Epoch: 15 Step: 41 Loss: 0.6364869995716066\n",
      "Epoch: 15 Step: 51 Loss: 0.6069563786939673\n",
      "Epoch: 15 Step: 61 Loss: 0.8449758162043316\n",
      "Epoch: 15 Step: 71 Loss: 0.8009068111340558\n",
      "Epoch: 15 Step: 81 Loss: 0.670879907310199\n",
      "Epoch: 15 Step: 91 Loss: 0.6892855080414699\n",
      "Epoch: 15 Step: 101 Loss: 0.7039707130210011\n",
      "Epoch: 15 Step: 111 Loss: 0.9662137988320203\n",
      "Epoch: 15 Step: 121 Loss: 0.7265584709492757\n",
      "Epoch: 15 Step: 131 Loss: 0.5946469701228876\n",
      "Epoch: 15 Step: 141 Loss: 1.237746305592509\n",
      "Epoch: 15 Step: 151 Loss: 0.5944380687829671\n",
      "Epoch: 15 Step: 161 Loss: 0.8607219197841545\n",
      "Epoch: 15 Step: 171 Loss: 0.9918844228774777\n",
      "Epoch: 15 Step: 181 Loss: 0.8298972570804277\n",
      "Epoch: 15 Step: 191 Loss: 0.7660308405186373\n",
      "Epoch: 15 Step: 201 Loss: 0.6901235060916169\n",
      "Epoch: 15 Step: 211 Loss: 0.548924129915715\n",
      "Epoch: 15 Step: 221 Loss: 0.8359439806978745\n",
      "Epoch: 15 Step: 231 Loss: 0.7037008132123506\n",
      "Epoch: 15 Step: 241 Loss: 0.549522427588794\n",
      "Epoch: 15 Step: 251 Loss: 0.5124143717979228\n",
      "Epoch: 15 Step: 261 Loss: 0.8068341046211164\n",
      "Epoch: 15 Step: 271 Loss: 0.628859946148719\n",
      "Epoch: 15 Step: 281 Loss: 0.5730990135660972\n",
      "Epoch: 15 Step: 291 Loss: 0.7741928406696261\n",
      "Epoch: 15 Step: 301 Loss: 0.6742719341008152\n",
      "Epoch: 15 Step: 311 Loss: 0.6014993180298195\n",
      "Epoch: 15 Step: 321 Loss: 0.9094309651127506\n",
      "Epoch: 15 Step: 331 Loss: 0.8052984141762203\n",
      "Epoch: 15 Step: 341 Loss: 0.732466148341767\n",
      "Epoch: 15 Step: 351 Loss: 0.8998842661969643\n",
      "Epoch: 15 Step: 361 Loss: 0.7983094194145592\n",
      "Epoch: 15 Step: 371 Loss: 0.5937502535459533\n",
      "Epoch: 15 Step: 381 Loss: 0.761822341675964\n",
      "Epoch: 15 Step: 391 Loss: 0.5507653095994985\n",
      "Epoch: 15 Step: 401 Loss: 0.7012972764404113\n",
      "Epoch: 15 Step: 411 Loss: 0.91639065233868\n",
      "Epoch: 15 Step: 421 Loss: 0.9118066873280884\n",
      "Epoch: 15 Step: 431 Loss: 0.5103837042167945\n",
      "Epoch: 15 Step: 441 Loss: 0.4734115821306787\n",
      "Epoch: 15 Step: 451 Loss: 0.8426286376056573\n",
      "Epoch: 15 Step: 461 Loss: 0.6421416599819746\n",
      "Epoch: 15 Step: 471 Loss: 0.8065958160517082\n",
      "Epoch: 15 Step: 481 Loss: 0.9775230130360073\n",
      "Epoch: 15 Step: 491 Loss: 1.043460123405691\n",
      "Epoch: 15 Step: 501 Loss: 0.83093326364079\n",
      "Epoch: 15 Step: 511 Loss: 0.7576238774721504\n",
      "Epoch: 15 Step: 521 Loss: 0.9568187172994135\n",
      "Epoch: 15 Step: 531 Loss: 0.8722160249732097\n",
      "Epoch: 15 Step: 541 Loss: 0.9034132984995256\n",
      "Epoch: 15 Step: 551 Loss: 0.6633746591142694\n",
      "Epoch: 15 Step: 561 Loss: 0.5427468089587543\n",
      "Epoch: 15 Step: 571 Loss: 0.555930806583635\n",
      "Epoch: 15 Step: 581 Loss: 0.782311514202214\n",
      "Epoch: 15 Step: 591 Loss: 0.7782504470303845\n",
      "Epoch: 15 Step: 601 Loss: 0.6371335551147408\n",
      "Epoch: 15 Step: 611 Loss: 0.6552906372808557\n",
      "Epoch: 15 Step: 621 Loss: 0.7242350827739636\n",
      "Epoch: 15 Step: 631 Loss: 0.6307950251790496\n",
      "Epoch: 15 Step: 641 Loss: 0.7792371397585475\n",
      "Epoch: 15 Step: 651 Loss: 0.6540279110669429\n",
      "Epoch: 15 Step: 661 Loss: 0.5724155976691537\n",
      "Epoch: 15 Step: 671 Loss: 0.9308636529777637\n",
      "Epoch: 15 Step: 681 Loss: 0.9697109549126148\n",
      "Epoch: 15 Step: 691 Loss: 0.7073566449939577\n",
      "Epoch: 15 Step: 701 Loss: 0.7237403787297634\n",
      "Epoch: 15 Step: 711 Loss: 0.8491148193377915\n",
      "Epoch: 15 Step: 721 Loss: 0.6203748091739927\n",
      "Epoch: 15 Step: 731 Loss: 0.5326926089876047\n",
      "Epoch: 15 Step: 741 Loss: 0.8004920101535459\n",
      "Epoch: 15 Step: 751 Loss: 0.9334456183429498\n",
      "Epoch: 15 Step: 761 Loss: 0.6572274978023774\n",
      "Epoch: 15 Step: 771 Loss: 1.0338262505318119\n",
      "Epoch: 15 Step: 781 Loss: 0.7932069458907123\n",
      "Epoch: 16 Step: 1 Loss: 0.7021976981261046\n",
      "Epoch: 16 Step: 11 Loss: 0.7675935305151222\n",
      "Epoch: 16 Step: 21 Loss: 0.6213462361955411\n",
      "Epoch: 16 Step: 31 Loss: 0.7573195727401099\n",
      "Epoch: 16 Step: 41 Loss: 0.5651937071698813\n",
      "Epoch: 16 Step: 51 Loss: 0.6045008800102195\n",
      "Epoch: 16 Step: 61 Loss: 0.5117863098848899\n",
      "Epoch: 16 Step: 71 Loss: 0.94251058170875\n",
      "Epoch: 16 Step: 81 Loss: 0.5837984655381879\n",
      "Epoch: 16 Step: 91 Loss: 0.7155615490794915\n",
      "Epoch: 16 Step: 101 Loss: 0.8737666384712224\n",
      "Epoch: 16 Step: 111 Loss: 0.9999179929888402\n",
      "Epoch: 16 Step: 121 Loss: 0.7618199911384687\n",
      "Epoch: 16 Step: 131 Loss: 0.5787658421590813\n",
      "Epoch: 16 Step: 141 Loss: 0.9200011658376603\n",
      "Epoch: 16 Step: 151 Loss: 0.5716148339708069\n",
      "Epoch: 16 Step: 161 Loss: 0.8315875784408195\n",
      "Epoch: 16 Step: 171 Loss: 0.7783377885099464\n",
      "Epoch: 16 Step: 181 Loss: 0.7038125794701895\n",
      "Epoch: 16 Step: 191 Loss: 0.45923427627442326\n",
      "Epoch: 16 Step: 201 Loss: 0.6703786582535982\n",
      "Epoch: 16 Step: 211 Loss: 0.4663470027677199\n",
      "Epoch: 16 Step: 221 Loss: 0.7479684567664178\n",
      "Epoch: 16 Step: 231 Loss: 0.6215938739631159\n",
      "Epoch: 16 Step: 241 Loss: 0.5657015217799216\n",
      "Epoch: 16 Step: 251 Loss: 0.48115971736100616\n",
      "Epoch: 16 Step: 261 Loss: 0.9112836302730222\n",
      "Epoch: 16 Step: 271 Loss: 0.73886677501699\n",
      "Epoch: 16 Step: 281 Loss: 0.6974894928048889\n",
      "Epoch: 16 Step: 291 Loss: 0.7502755850978157\n",
      "Epoch: 16 Step: 301 Loss: 0.7606558872841886\n",
      "Epoch: 16 Step: 311 Loss: 0.8729645339929488\n",
      "Epoch: 16 Step: 321 Loss: 0.7536900590904618\n",
      "Epoch: 16 Step: 331 Loss: 0.6864085227906944\n",
      "Epoch: 16 Step: 341 Loss: 0.7193314131338386\n",
      "Epoch: 16 Step: 351 Loss: 0.6723113653347957\n",
      "Epoch: 16 Step: 361 Loss: 0.6534654204903751\n",
      "Epoch: 16 Step: 371 Loss: 0.4937258691301203\n",
      "Epoch: 16 Step: 381 Loss: 0.7124266799948139\n",
      "Epoch: 16 Step: 391 Loss: 0.480686559155867\n",
      "Epoch: 16 Step: 401 Loss: 0.6263375319654125\n",
      "Epoch: 16 Step: 411 Loss: 0.7111950645721518\n",
      "Epoch: 16 Step: 421 Loss: 0.8748809582042394\n",
      "Epoch: 16 Step: 431 Loss: 0.532585299068767\n",
      "Epoch: 16 Step: 441 Loss: 0.5227762973975674\n",
      "Epoch: 16 Step: 451 Loss: 0.6771166932796553\n",
      "Epoch: 16 Step: 461 Loss: 0.8659262421719947\n",
      "Epoch: 16 Step: 471 Loss: 0.9594641056899652\n",
      "Epoch: 16 Step: 481 Loss: 1.0990355028299919\n",
      "Epoch: 16 Step: 491 Loss: 0.9502402355312682\n",
      "Epoch: 16 Step: 501 Loss: 0.9138847079946985\n",
      "Epoch: 16 Step: 511 Loss: 0.5345336143590838\n",
      "Epoch: 16 Step: 521 Loss: 0.8979592919612176\n",
      "Epoch: 16 Step: 531 Loss: 0.7756066788378471\n",
      "Epoch: 16 Step: 541 Loss: 0.7368591544255468\n",
      "Epoch: 16 Step: 551 Loss: 0.5181655567747404\n",
      "Epoch: 16 Step: 561 Loss: 0.5865427001588777\n",
      "Epoch: 16 Step: 571 Loss: 0.4019566119400463\n",
      "Epoch: 16 Step: 581 Loss: 0.7949439821367384\n",
      "Epoch: 16 Step: 591 Loss: 0.7999388322128054\n",
      "Epoch: 16 Step: 601 Loss: 0.5816446205519585\n",
      "Epoch: 16 Step: 611 Loss: 0.7360501008426021\n",
      "Epoch: 16 Step: 621 Loss: 0.6294672982334623\n",
      "Epoch: 16 Step: 631 Loss: 0.6543461981650496\n",
      "Epoch: 16 Step: 641 Loss: 0.7483342977359471\n",
      "Epoch: 16 Step: 651 Loss: 0.605704695870936\n",
      "Epoch: 16 Step: 661 Loss: 0.6647517993559967\n",
      "Epoch: 16 Step: 671 Loss: 1.085442968962342\n",
      "Epoch: 16 Step: 681 Loss: 0.9132014358507959\n",
      "Epoch: 16 Step: 691 Loss: 0.7019572704801871\n",
      "Epoch: 16 Step: 701 Loss: 0.7129399334129292\n",
      "Epoch: 16 Step: 711 Loss: 0.6817159884882595\n",
      "Epoch: 16 Step: 721 Loss: 0.5559272796135913\n",
      "Epoch: 16 Step: 731 Loss: 0.4904641587034798\n",
      "Epoch: 16 Step: 741 Loss: 0.6743256108826498\n",
      "Epoch: 16 Step: 751 Loss: 0.8060102818319401\n",
      "Epoch: 16 Step: 761 Loss: 0.6068475192869629\n",
      "Epoch: 16 Step: 771 Loss: 0.8304257698199631\n",
      "Epoch: 16 Step: 781 Loss: 0.6586392532784585\n",
      "Epoch: 17 Step: 1 Loss: 0.4813857337830551\n",
      "Epoch: 17 Step: 11 Loss: 0.7428748630865636\n",
      "Epoch: 17 Step: 21 Loss: 0.7147085755448388\n",
      "Epoch: 17 Step: 31 Loss: 0.710941197825999\n",
      "Epoch: 17 Step: 41 Loss: 0.660414593627552\n",
      "Epoch: 17 Step: 51 Loss: 0.6682983257845084\n",
      "Epoch: 17 Step: 61 Loss: 0.7118763611176564\n",
      "Epoch: 17 Step: 71 Loss: 1.1289341998660152\n",
      "Epoch: 17 Step: 81 Loss: 0.8609241540494366\n",
      "Epoch: 17 Step: 91 Loss: 0.6394645794150997\n",
      "Epoch: 17 Step: 101 Loss: 0.6501578382501318\n",
      "Epoch: 17 Step: 111 Loss: 0.8522336333474545\n",
      "Epoch: 17 Step: 121 Loss: 0.6110660557333004\n",
      "Epoch: 17 Step: 131 Loss: 0.6248797487989473\n",
      "Epoch: 17 Step: 141 Loss: 0.8538221083377826\n",
      "Epoch: 17 Step: 151 Loss: 0.46587373278406075\n",
      "Epoch: 17 Step: 161 Loss: 0.737199002663044\n",
      "Epoch: 17 Step: 171 Loss: 0.8181144415641561\n",
      "Epoch: 17 Step: 181 Loss: 0.5465264809703665\n",
      "Epoch: 17 Step: 191 Loss: 0.4590188602393499\n",
      "Epoch: 17 Step: 201 Loss: 0.5153505677610941\n",
      "Epoch: 17 Step: 211 Loss: 0.4515885901222474\n",
      "Epoch: 17 Step: 221 Loss: 0.7150621475396628\n",
      "Epoch: 17 Step: 231 Loss: 0.6151777860695151\n",
      "Epoch: 17 Step: 241 Loss: 0.5601405912314792\n",
      "Epoch: 17 Step: 251 Loss: 0.8083149905111766\n",
      "Epoch: 17 Step: 261 Loss: 0.7448733370142133\n",
      "Epoch: 17 Step: 271 Loss: 0.5339557095865395\n",
      "Epoch: 17 Step: 281 Loss: 0.5398035972310871\n",
      "Epoch: 17 Step: 291 Loss: 0.6808024182680541\n",
      "Epoch: 17 Step: 301 Loss: 0.6450853546132114\n",
      "Epoch: 17 Step: 311 Loss: 0.7670982889974718\n",
      "Epoch: 17 Step: 321 Loss: 0.8094546525148865\n",
      "Epoch: 17 Step: 331 Loss: 0.5872207203010165\n",
      "Epoch: 17 Step: 341 Loss: 0.6263501321610739\n",
      "Epoch: 17 Step: 351 Loss: 0.7032819898390843\n",
      "Epoch: 17 Step: 361 Loss: 0.525526397728082\n",
      "Epoch: 17 Step: 371 Loss: 0.5110902080143331\n",
      "Epoch: 17 Step: 381 Loss: 0.6153951420685803\n",
      "Epoch: 17 Step: 391 Loss: 0.5117333266463575\n",
      "Epoch: 17 Step: 401 Loss: 0.6672986334322766\n",
      "Epoch: 17 Step: 411 Loss: 0.72087530010367\n",
      "Epoch: 17 Step: 421 Loss: 1.0646355797782447\n",
      "Epoch: 17 Step: 431 Loss: 0.6235538121585225\n",
      "Epoch: 17 Step: 441 Loss: 0.6469987779457922\n",
      "Epoch: 17 Step: 451 Loss: 0.6199421596237749\n",
      "Epoch: 17 Step: 461 Loss: 0.6610729153465581\n",
      "Epoch: 17 Step: 471 Loss: 0.8118921409225899\n",
      "Epoch: 17 Step: 481 Loss: 0.8938272025438493\n",
      "Epoch: 17 Step: 491 Loss: 0.8542509449755515\n",
      "Epoch: 17 Step: 501 Loss: 0.5587443216792021\n",
      "Epoch: 17 Step: 511 Loss: 0.43478684526699285\n",
      "Epoch: 17 Step: 521 Loss: 0.6611903708032102\n",
      "Epoch: 17 Step: 531 Loss: 0.592111107985086\n",
      "Epoch: 17 Step: 541 Loss: 0.7620960707342795\n",
      "Epoch: 17 Step: 551 Loss: 0.6326379917970113\n",
      "Epoch: 17 Step: 561 Loss: 0.48117243539799515\n",
      "Epoch: 17 Step: 571 Loss: 0.3823511453661219\n",
      "Epoch: 17 Step: 581 Loss: 0.8664385349736364\n",
      "Epoch: 17 Step: 591 Loss: 0.9192289638778044\n",
      "Epoch: 17 Step: 601 Loss: 0.745950465768432\n",
      "Epoch: 17 Step: 611 Loss: 0.7242641860593997\n",
      "Epoch: 17 Step: 621 Loss: 0.7756085471271574\n",
      "Epoch: 17 Step: 631 Loss: 0.6934309852400018\n",
      "Epoch: 17 Step: 641 Loss: 0.8294549343635338\n",
      "Epoch: 17 Step: 651 Loss: 0.6022225245805559\n",
      "Epoch: 17 Step: 661 Loss: 0.38702179219189825\n",
      "Epoch: 17 Step: 671 Loss: 0.7445566989272199\n",
      "Epoch: 17 Step: 681 Loss: 0.7869933572818568\n",
      "Epoch: 17 Step: 691 Loss: 0.5093168876087975\n",
      "Epoch: 17 Step: 701 Loss: 0.6022002546547337\n",
      "Epoch: 17 Step: 711 Loss: 0.6332918263341116\n",
      "Epoch: 17 Step: 721 Loss: 0.6190745923859672\n",
      "Epoch: 17 Step: 731 Loss: 0.4342777194600128\n",
      "Epoch: 17 Step: 741 Loss: 0.5269850039421091\n",
      "Epoch: 17 Step: 751 Loss: 0.8327527066631631\n",
      "Epoch: 17 Step: 761 Loss: 0.5944498310782373\n",
      "Epoch: 17 Step: 771 Loss: 0.9612859294911822\n",
      "Epoch: 17 Step: 781 Loss: 0.685592424900763\n",
      "Epoch: 18 Step: 1 Loss: 0.7465152475850633\n",
      "Epoch: 18 Step: 11 Loss: 0.780988536939375\n",
      "Epoch: 18 Step: 21 Loss: 0.7403888396335521\n",
      "Epoch: 18 Step: 31 Loss: 0.8246002565098045\n",
      "Epoch: 18 Step: 41 Loss: 0.3657442704816358\n",
      "Epoch: 18 Step: 51 Loss: 0.5632460929928644\n",
      "Epoch: 18 Step: 61 Loss: 0.7037172190457819\n",
      "Epoch: 18 Step: 71 Loss: 0.9532531034652125\n",
      "Epoch: 18 Step: 81 Loss: 0.6478050352618288\n",
      "Epoch: 18 Step: 91 Loss: 0.615951186171817\n",
      "Epoch: 18 Step: 101 Loss: 0.530979468165145\n",
      "Epoch: 18 Step: 111 Loss: 0.7525227550562441\n",
      "Epoch: 18 Step: 121 Loss: 0.6698410247184494\n",
      "Epoch: 18 Step: 131 Loss: 0.5085643251725919\n",
      "Epoch: 18 Step: 141 Loss: 0.8467772644094884\n",
      "Epoch: 18 Step: 151 Loss: 0.5927658126176854\n",
      "Epoch: 18 Step: 161 Loss: 0.6290931043638662\n",
      "Epoch: 18 Step: 171 Loss: 0.7757062699760082\n",
      "Epoch: 18 Step: 181 Loss: 0.7943340258963583\n",
      "Epoch: 18 Step: 191 Loss: 0.6551057101940848\n",
      "Epoch: 18 Step: 201 Loss: 0.5915924038536851\n",
      "Epoch: 18 Step: 211 Loss: 0.5589500809176906\n",
      "Epoch: 18 Step: 221 Loss: 0.6844787118998923\n",
      "Epoch: 18 Step: 231 Loss: 0.4900126610847038\n",
      "Epoch: 18 Step: 241 Loss: 0.5716406232699434\n",
      "Epoch: 18 Step: 251 Loss: 0.5113868902754741\n",
      "Epoch: 18 Step: 261 Loss: 0.5651899530434294\n",
      "Epoch: 18 Step: 271 Loss: 0.531328565883611\n",
      "Epoch: 18 Step: 281 Loss: 0.464177684604687\n",
      "Epoch: 18 Step: 291 Loss: 0.5703464855901509\n",
      "Epoch: 18 Step: 301 Loss: 0.7294330944295069\n",
      "Epoch: 18 Step: 311 Loss: 0.4461182150313825\n",
      "Epoch: 18 Step: 321 Loss: 0.6643775020353604\n",
      "Epoch: 18 Step: 331 Loss: 0.6601875524953292\n",
      "Epoch: 18 Step: 341 Loss: 0.6882424276256431\n",
      "Epoch: 18 Step: 351 Loss: 0.703075629212144\n",
      "Epoch: 18 Step: 361 Loss: 0.6265652325916435\n",
      "Epoch: 18 Step: 371 Loss: 0.6314927507215716\n",
      "Epoch: 18 Step: 381 Loss: 0.7925656170160595\n",
      "Epoch: 18 Step: 391 Loss: 0.563308645413325\n",
      "Epoch: 18 Step: 401 Loss: 0.4425844272947258\n",
      "Epoch: 18 Step: 411 Loss: 0.6718603079862271\n",
      "Epoch: 18 Step: 421 Loss: 0.9039798201456772\n",
      "Epoch: 18 Step: 431 Loss: 0.3877299321153524\n",
      "Epoch: 18 Step: 441 Loss: 0.5802225051217903\n",
      "Epoch: 18 Step: 451 Loss: 0.3898302975627739\n",
      "Epoch: 18 Step: 461 Loss: 0.43996387633965145\n",
      "Epoch: 18 Step: 471 Loss: 0.8515531572080728\n",
      "Epoch: 18 Step: 481 Loss: 0.824392223816667\n",
      "Epoch: 18 Step: 491 Loss: 0.6805950958914055\n",
      "Epoch: 18 Step: 501 Loss: 0.7213471796281975\n",
      "Epoch: 18 Step: 511 Loss: 0.5199328135621916\n",
      "Epoch: 18 Step: 521 Loss: 0.7799991852764268\n",
      "Epoch: 18 Step: 531 Loss: 0.5774847282776755\n",
      "Epoch: 18 Step: 541 Loss: 0.7674997247120702\n",
      "Epoch: 18 Step: 551 Loss: 0.6525574901426388\n",
      "Epoch: 18 Step: 561 Loss: 0.5534431246183684\n",
      "Epoch: 18 Step: 571 Loss: 0.64540643574303\n",
      "Epoch: 18 Step: 581 Loss: 0.7602037761749829\n",
      "Epoch: 18 Step: 591 Loss: 0.7505147510797534\n",
      "Epoch: 18 Step: 601 Loss: 0.5967687355313067\n",
      "Epoch: 18 Step: 611 Loss: 0.7051695011367418\n",
      "Epoch: 18 Step: 621 Loss: 0.711995687805262\n",
      "Epoch: 18 Step: 631 Loss: 0.5178237678427521\n",
      "Epoch: 18 Step: 641 Loss: 0.5288662170777394\n",
      "Epoch: 18 Step: 651 Loss: 0.48784654459366183\n",
      "Epoch: 18 Step: 661 Loss: 0.4245359897456242\n",
      "Epoch: 18 Step: 671 Loss: 0.7397803168575485\n",
      "Epoch: 18 Step: 681 Loss: 0.7213934747515373\n",
      "Epoch: 18 Step: 691 Loss: 0.49406889358967376\n",
      "Epoch: 18 Step: 701 Loss: 0.6348603395657526\n",
      "Epoch: 18 Step: 711 Loss: 0.777223353035543\n",
      "Epoch: 18 Step: 721 Loss: 0.4667805881134328\n",
      "Epoch: 18 Step: 731 Loss: 0.4963521358433163\n",
      "Epoch: 18 Step: 741 Loss: 0.5602991213194779\n",
      "Epoch: 18 Step: 751 Loss: 0.8298611400488648\n",
      "Epoch: 18 Step: 761 Loss: 0.4679993673683256\n",
      "Epoch: 18 Step: 771 Loss: 0.7008480426593202\n",
      "Epoch: 18 Step: 781 Loss: 0.4651568746759627\n",
      "Epoch: 19 Step: 1 Loss: 0.6107969451335322\n",
      "Epoch: 19 Step: 11 Loss: 0.7188048616157787\n",
      "Epoch: 19 Step: 21 Loss: 0.6699828073292726\n",
      "Epoch: 19 Step: 31 Loss: 0.7942387646877254\n",
      "Epoch: 19 Step: 41 Loss: 0.433313143535648\n",
      "Epoch: 19 Step: 51 Loss: 0.4408197104561522\n",
      "Epoch: 19 Step: 61 Loss: 0.5583922888314657\n",
      "Epoch: 19 Step: 71 Loss: 0.8665192191047325\n",
      "Epoch: 19 Step: 81 Loss: 0.4668539174385129\n",
      "Epoch: 19 Step: 91 Loss: 0.5629317809860042\n",
      "Epoch: 19 Step: 101 Loss: 0.4951785363639219\n",
      "Epoch: 19 Step: 111 Loss: 0.8635880588822182\n",
      "Epoch: 19 Step: 121 Loss: 0.5509635360424718\n",
      "Epoch: 19 Step: 131 Loss: 0.5675224739840521\n",
      "Epoch: 19 Step: 141 Loss: 0.919807835349354\n",
      "Epoch: 19 Step: 151 Loss: 0.6699249442793698\n",
      "Epoch: 19 Step: 161 Loss: 0.599533433969305\n",
      "Epoch: 19 Step: 171 Loss: 0.7978564786815326\n",
      "Epoch: 19 Step: 181 Loss: 0.48457881106510725\n",
      "Epoch: 19 Step: 191 Loss: 0.4278254161262373\n",
      "Epoch: 19 Step: 201 Loss: 0.5786132043165683\n",
      "Epoch: 19 Step: 211 Loss: 0.3788913995596242\n",
      "Epoch: 19 Step: 221 Loss: 0.637979495888591\n",
      "Epoch: 19 Step: 231 Loss: 0.4510215574498232\n",
      "Epoch: 19 Step: 241 Loss: 0.41554597214091715\n",
      "Epoch: 19 Step: 251 Loss: 0.4279672409968682\n",
      "Epoch: 19 Step: 261 Loss: 0.5444587707560147\n",
      "Epoch: 19 Step: 271 Loss: 0.5268791895547454\n",
      "Epoch: 19 Step: 281 Loss: 0.42551265426675905\n",
      "Epoch: 19 Step: 291 Loss: 0.608318339691994\n",
      "Epoch: 19 Step: 301 Loss: 0.5784153813563782\n",
      "Epoch: 19 Step: 311 Loss: 0.6289968634663209\n",
      "Epoch: 19 Step: 321 Loss: 0.7681517072315054\n",
      "Epoch: 19 Step: 331 Loss: 0.7602476817915773\n",
      "Epoch: 19 Step: 341 Loss: 0.4803454956928682\n",
      "Epoch: 19 Step: 351 Loss: 0.5347657608267129\n",
      "Epoch: 19 Step: 361 Loss: 0.5507056778482988\n",
      "Epoch: 19 Step: 371 Loss: 0.4927738579926684\n",
      "Epoch: 19 Step: 381 Loss: 0.5598586665148547\n",
      "Epoch: 19 Step: 391 Loss: 0.3542126527064092\n",
      "Epoch: 19 Step: 401 Loss: 0.5449207476524326\n",
      "Epoch: 19 Step: 411 Loss: 0.6172096410122994\n",
      "Epoch: 19 Step: 421 Loss: 0.6287809094682755\n",
      "Epoch: 19 Step: 431 Loss: 0.4276094675809511\n",
      "Epoch: 19 Step: 441 Loss: 0.3296625825224509\n",
      "Epoch: 19 Step: 451 Loss: 0.46082510225545126\n",
      "Epoch: 19 Step: 461 Loss: 0.57539811649266\n",
      "Epoch: 19 Step: 471 Loss: 0.7109136312980536\n",
      "Epoch: 19 Step: 481 Loss: 0.6561951253734424\n",
      "Epoch: 19 Step: 491 Loss: 0.715536393020255\n",
      "Epoch: 19 Step: 501 Loss: 0.8265528267613521\n",
      "Epoch: 19 Step: 511 Loss: 0.47795549738919924\n",
      "Epoch: 19 Step: 521 Loss: 0.6930813279057225\n",
      "Epoch: 19 Step: 531 Loss: 0.5208502760257194\n",
      "Epoch: 19 Step: 541 Loss: 0.5568051161380683\n",
      "Epoch: 19 Step: 551 Loss: 0.3613855478115944\n",
      "Epoch: 19 Step: 561 Loss: 0.44838842305462573\n",
      "Epoch: 19 Step: 571 Loss: 0.36250891059254325\n",
      "Epoch: 19 Step: 581 Loss: 0.5578850468741448\n",
      "Epoch: 19 Step: 591 Loss: 0.5614405512398868\n",
      "Epoch: 19 Step: 601 Loss: 0.34545954535687506\n",
      "Epoch: 19 Step: 611 Loss: 0.5767743569694623\n",
      "Epoch: 19 Step: 621 Loss: 0.4898723262681539\n",
      "Epoch: 19 Step: 631 Loss: 0.49528726896737313\n",
      "Epoch: 19 Step: 641 Loss: 0.5363896233176633\n",
      "Epoch: 19 Step: 651 Loss: 0.6906037470555868\n",
      "Epoch: 19 Step: 661 Loss: 0.6799936416588197\n",
      "Epoch: 19 Step: 671 Loss: 0.636531554020024\n",
      "Epoch: 19 Step: 681 Loss: 0.8323898359516614\n",
      "Epoch: 19 Step: 691 Loss: 0.5677872328186453\n",
      "Epoch: 19 Step: 701 Loss: 0.6548292164909697\n",
      "Epoch: 19 Step: 711 Loss: 0.5134546424105015\n",
      "Epoch: 19 Step: 721 Loss: 0.44989496380702765\n",
      "Epoch: 19 Step: 731 Loss: 0.3941854834492926\n",
      "Epoch: 19 Step: 741 Loss: 0.49377895933424254\n",
      "Epoch: 19 Step: 751 Loss: 0.6635900946178406\n",
      "Epoch: 19 Step: 761 Loss: 0.4722733586435682\n",
      "Epoch: 19 Step: 771 Loss: 0.49742750634475297\n",
      "Epoch: 19 Step: 781 Loss: 0.5542367413988962\n",
      "Epoch: 20 Step: 1 Loss: 0.3934540781141358\n",
      "Epoch: 20 Step: 11 Loss: 0.5414170613960003\n",
      "Epoch: 20 Step: 21 Loss: 0.5953294288285078\n",
      "Epoch: 20 Step: 31 Loss: 0.5572394557037899\n",
      "Epoch: 20 Step: 41 Loss: 0.39073837221326313\n",
      "Epoch: 20 Step: 51 Loss: 0.4373753649473595\n",
      "Epoch: 20 Step: 61 Loss: 0.6984460065414388\n",
      "Epoch: 20 Step: 71 Loss: 0.7831941736562504\n",
      "Epoch: 20 Step: 81 Loss: 0.5763302141849014\n",
      "Epoch: 20 Step: 91 Loss: 0.7385101588670453\n",
      "Epoch: 20 Step: 101 Loss: 0.5827303954790365\n",
      "Epoch: 20 Step: 111 Loss: 0.7781719153625722\n",
      "Epoch: 20 Step: 121 Loss: 0.37253072109761876\n",
      "Epoch: 20 Step: 131 Loss: 0.44043094572304603\n",
      "Epoch: 20 Step: 141 Loss: 0.8253139920063945\n",
      "Epoch: 20 Step: 151 Loss: 0.5716459386334489\n",
      "Epoch: 20 Step: 161 Loss: 0.5950232867622273\n",
      "Epoch: 20 Step: 171 Loss: 0.5400141174744818\n",
      "Epoch: 20 Step: 181 Loss: 0.50597958147369\n",
      "Epoch: 20 Step: 191 Loss: 0.4230237601832458\n",
      "Epoch: 20 Step: 201 Loss: 0.4428575692622768\n",
      "Epoch: 20 Step: 211 Loss: 0.31414705500315915\n",
      "Epoch: 20 Step: 221 Loss: 0.5060697702188096\n",
      "Epoch: 20 Step: 231 Loss: 0.47327936147168714\n",
      "Epoch: 20 Step: 241 Loss: 0.5020823704713604\n",
      "Epoch: 20 Step: 251 Loss: 0.34953810454437384\n",
      "Epoch: 20 Step: 261 Loss: 0.7064030892944585\n",
      "Epoch: 20 Step: 271 Loss: 0.5484149406917518\n",
      "Epoch: 20 Step: 281 Loss: 0.4897343749751513\n",
      "Epoch: 20 Step: 291 Loss: 0.581800083779671\n",
      "Epoch: 20 Step: 301 Loss: 0.4451893470606723\n",
      "Epoch: 20 Step: 311 Loss: 0.5573913408228114\n",
      "Epoch: 20 Step: 321 Loss: 0.6507861451213182\n",
      "Epoch: 20 Step: 331 Loss: 0.6039876697554725\n",
      "Epoch: 20 Step: 341 Loss: 0.40759659865588704\n",
      "Epoch: 20 Step: 351 Loss: 0.4534793657218863\n",
      "Epoch: 20 Step: 361 Loss: 0.44622309142233196\n",
      "Epoch: 20 Step: 371 Loss: 0.4292270929348139\n",
      "Epoch: 20 Step: 381 Loss: 0.5746693885001938\n",
      "Epoch: 20 Step: 391 Loss: 0.42418466446034686\n",
      "Epoch: 20 Step: 401 Loss: 0.5836317687997978\n",
      "Epoch: 20 Step: 411 Loss: 0.7415255588018943\n",
      "Epoch: 20 Step: 421 Loss: 0.8094860841649861\n",
      "Epoch: 20 Step: 431 Loss: 0.5022641057898661\n",
      "Epoch: 20 Step: 441 Loss: 0.4508274303180904\n",
      "Epoch: 20 Step: 451 Loss: 0.616674102571204\n",
      "Epoch: 20 Step: 461 Loss: 0.5843218048143485\n",
      "Epoch: 20 Step: 471 Loss: 0.6590121355855916\n",
      "Epoch: 20 Step: 481 Loss: 0.7910455134078298\n",
      "Epoch: 20 Step: 491 Loss: 0.6943565656422782\n",
      "Epoch: 20 Step: 501 Loss: 0.6165250189934688\n",
      "Epoch: 20 Step: 511 Loss: 0.3334548277630312\n",
      "Epoch: 20 Step: 521 Loss: 0.6052243350319777\n",
      "Epoch: 20 Step: 531 Loss: 0.6015108597806192\n",
      "Epoch: 20 Step: 541 Loss: 0.6685431199192784\n",
      "Epoch: 20 Step: 551 Loss: 0.4154406125455764\n",
      "Epoch: 20 Step: 561 Loss: 0.37622917342309126\n",
      "Epoch: 20 Step: 571 Loss: 0.3272007881717741\n",
      "Epoch: 20 Step: 581 Loss: 0.5198811900749837\n",
      "Epoch: 20 Step: 591 Loss: 0.4561888081078067\n",
      "Epoch: 20 Step: 601 Loss: 0.398229579392826\n",
      "Epoch: 20 Step: 611 Loss: 0.6259615861217019\n",
      "Epoch: 20 Step: 621 Loss: 0.7149483881741152\n",
      "Epoch: 20 Step: 631 Loss: 0.5566193282447569\n",
      "Epoch: 20 Step: 641 Loss: 0.702738082563038\n",
      "Epoch: 20 Step: 651 Loss: 0.4561926820941559\n",
      "Epoch: 20 Step: 661 Loss: 0.4739442260673168\n",
      "Epoch: 20 Step: 671 Loss: 0.52259112029055\n",
      "Epoch: 20 Step: 681 Loss: 0.6488837374679857\n",
      "Epoch: 20 Step: 691 Loss: 0.48424367798964013\n",
      "Epoch: 20 Step: 701 Loss: 0.4968636464985212\n",
      "Epoch: 20 Step: 711 Loss: 0.5457590985997238\n",
      "Epoch: 20 Step: 721 Loss: 0.522070462616813\n",
      "Epoch: 20 Step: 731 Loss: 0.2757401921695176\n",
      "Epoch: 20 Step: 741 Loss: 0.5447548095001723\n",
      "Epoch: 20 Step: 751 Loss: 0.6040852866036792\n",
      "Epoch: 20 Step: 761 Loss: 0.2756932653411827\n",
      "Epoch: 20 Step: 771 Loss: 0.46084738072148634\n",
      "Epoch: 20 Step: 781 Loss: 0.5232836955213471\n",
      "Epoch: 21 Step: 1 Loss: 0.41526309965159736\n",
      "Epoch: 21 Step: 11 Loss: 0.531013884608762\n",
      "Epoch: 21 Step: 21 Loss: 0.6218853512076992\n",
      "Epoch: 21 Step: 31 Loss: 0.7928776398646186\n",
      "Epoch: 21 Step: 41 Loss: 0.41800279406910235\n",
      "Epoch: 21 Step: 51 Loss: 0.5225254024390633\n",
      "Epoch: 21 Step: 61 Loss: 0.6541436836737249\n",
      "Epoch: 21 Step: 71 Loss: 0.7254986035681344\n",
      "Epoch: 21 Step: 81 Loss: 0.5630859052319342\n",
      "Epoch: 21 Step: 91 Loss: 0.41166512929741095\n",
      "Epoch: 21 Step: 101 Loss: 0.4682678494596588\n",
      "Epoch: 21 Step: 111 Loss: 0.6481891853243604\n",
      "Epoch: 21 Step: 121 Loss: 0.4558796311082948\n",
      "Epoch: 21 Step: 131 Loss: 0.4508476814469558\n",
      "Epoch: 21 Step: 141 Loss: 0.6920437600093012\n",
      "Epoch: 21 Step: 151 Loss: 0.4773588853884667\n",
      "Epoch: 21 Step: 161 Loss: 0.37131264625616844\n",
      "Epoch: 21 Step: 171 Loss: 0.6604877963163269\n",
      "Epoch: 21 Step: 181 Loss: 0.4729319169889684\n",
      "Epoch: 21 Step: 191 Loss: 0.5371300949694765\n",
      "Epoch: 21 Step: 201 Loss: 0.46775250335201257\n",
      "Epoch: 21 Step: 211 Loss: 0.5794913239081646\n",
      "Epoch: 21 Step: 221 Loss: 0.683169569461495\n",
      "Epoch: 21 Step: 231 Loss: 0.41527892667864746\n",
      "Epoch: 21 Step: 241 Loss: 0.5743073136897665\n",
      "Epoch: 21 Step: 251 Loss: 0.3451815279850223\n",
      "Epoch: 21 Step: 261 Loss: 0.511276242086261\n",
      "Epoch: 21 Step: 271 Loss: 0.45290428002401995\n",
      "Epoch: 21 Step: 281 Loss: 0.4068618027429357\n",
      "Epoch: 21 Step: 291 Loss: 0.5035110317356325\n",
      "Epoch: 21 Step: 301 Loss: 0.3840968546763881\n",
      "Epoch: 21 Step: 311 Loss: 0.34303883748961606\n",
      "Epoch: 21 Step: 321 Loss: 0.6848311050302088\n",
      "Epoch: 21 Step: 331 Loss: 0.4622434864482633\n",
      "Epoch: 21 Step: 341 Loss: 0.4165397203163217\n",
      "Epoch: 21 Step: 351 Loss: 0.48372032084762684\n",
      "Epoch: 21 Step: 361 Loss: 0.3474469234272881\n",
      "Epoch: 21 Step: 371 Loss: 0.2860812225401713\n",
      "Epoch: 21 Step: 381 Loss: 0.60736087076905\n",
      "Epoch: 21 Step: 391 Loss: 0.5777418988340393\n",
      "Epoch: 21 Step: 401 Loss: 0.6238343507786326\n",
      "Epoch: 21 Step: 411 Loss: 0.5661101904739353\n",
      "Epoch: 21 Step: 421 Loss: 0.6236544239688282\n",
      "Epoch: 21 Step: 431 Loss: 0.37265018214765244\n",
      "Epoch: 21 Step: 441 Loss: 0.46804400465852314\n",
      "Epoch: 21 Step: 451 Loss: 0.3947933720189396\n",
      "Epoch: 21 Step: 461 Loss: 0.584213975699751\n",
      "Epoch: 21 Step: 471 Loss: 0.5965001780197673\n",
      "Epoch: 21 Step: 481 Loss: 0.5980844836019423\n",
      "Epoch: 21 Step: 491 Loss: 0.7378267227165545\n",
      "Epoch: 21 Step: 501 Loss: 0.5906806160334335\n",
      "Epoch: 21 Step: 511 Loss: 0.295223300984759\n",
      "Epoch: 21 Step: 521 Loss: 0.5200365293784923\n",
      "Epoch: 21 Step: 531 Loss: 0.4871252219178596\n",
      "Epoch: 21 Step: 541 Loss: 0.4358774465945249\n",
      "Epoch: 21 Step: 551 Loss: 0.44971575768236455\n",
      "Epoch: 21 Step: 561 Loss: 0.47319061074497526\n",
      "Epoch: 21 Step: 571 Loss: 0.39598343678220477\n",
      "Epoch: 21 Step: 581 Loss: 0.8427787993174696\n",
      "Epoch: 21 Step: 591 Loss: 0.6319087146351186\n",
      "Epoch: 21 Step: 601 Loss: 0.5150355247195442\n",
      "Epoch: 21 Step: 611 Loss: 0.4091211978358259\n",
      "Epoch: 21 Step: 621 Loss: 0.4450224993759785\n",
      "Epoch: 21 Step: 631 Loss: 0.49626578825307\n",
      "Epoch: 21 Step: 641 Loss: 0.498895799383012\n",
      "Epoch: 21 Step: 651 Loss: 0.45771322645437906\n",
      "Epoch: 21 Step: 661 Loss: 0.19926632000884884\n",
      "Epoch: 21 Step: 671 Loss: 0.4967297519304603\n",
      "Epoch: 21 Step: 681 Loss: 0.5875481919906613\n",
      "Epoch: 21 Step: 691 Loss: 0.43731715208011435\n",
      "Epoch: 21 Step: 701 Loss: 0.39646596228760217\n",
      "Epoch: 21 Step: 711 Loss: 0.44533522642532497\n",
      "Epoch: 21 Step: 721 Loss: 0.4320101489232464\n",
      "Epoch: 21 Step: 731 Loss: 0.33832813837252923\n",
      "Epoch: 21 Step: 741 Loss: 0.48125910355017304\n",
      "Epoch: 21 Step: 751 Loss: 0.6235264071865989\n",
      "Epoch: 21 Step: 761 Loss: 0.5396880208892524\n",
      "Epoch: 21 Step: 771 Loss: 0.7040712725765559\n",
      "Epoch: 21 Step: 781 Loss: 0.6591582390918367\n",
      "Epoch: 22 Step: 1 Loss: 0.4321085792171313\n",
      "Epoch: 22 Step: 11 Loss: 0.5840402849444504\n",
      "Epoch: 22 Step: 21 Loss: 0.5403839178885506\n",
      "Epoch: 22 Step: 31 Loss: 0.6228412725287665\n",
      "Epoch: 22 Step: 41 Loss: 0.4982001030993169\n",
      "Epoch: 22 Step: 51 Loss: 0.3645395055481166\n",
      "Epoch: 22 Step: 61 Loss: 0.4647099203076058\n",
      "Epoch: 22 Step: 71 Loss: 0.6003523437171505\n",
      "Epoch: 22 Step: 81 Loss: 0.34903585961610645\n",
      "Epoch: 22 Step: 91 Loss: 0.427763495925897\n",
      "Epoch: 22 Step: 101 Loss: 0.5467456108863831\n",
      "Epoch: 22 Step: 111 Loss: 0.6007044808353965\n",
      "Epoch: 22 Step: 121 Loss: 0.4171467808063436\n",
      "Epoch: 22 Step: 131 Loss: 0.44867528667363943\n",
      "Epoch: 22 Step: 141 Loss: 0.7887616817517755\n",
      "Epoch: 22 Step: 151 Loss: 0.31109880644811627\n",
      "Epoch: 22 Step: 161 Loss: 0.5640829080596133\n",
      "Epoch: 22 Step: 171 Loss: 0.8817472281747982\n",
      "Epoch: 22 Step: 181 Loss: 0.5066415298534752\n",
      "Epoch: 22 Step: 191 Loss: 0.4950364577505965\n",
      "Epoch: 22 Step: 201 Loss: 0.5063896003808637\n",
      "Epoch: 22 Step: 211 Loss: 0.4169697609114249\n",
      "Epoch: 22 Step: 221 Loss: 0.5416761037468448\n",
      "Epoch: 22 Step: 231 Loss: 0.3987499879300695\n",
      "Epoch: 22 Step: 241 Loss: 0.3297050377387485\n",
      "Epoch: 22 Step: 251 Loss: 0.2520222082912587\n",
      "Epoch: 22 Step: 261 Loss: 0.38538495349098845\n",
      "Epoch: 22 Step: 271 Loss: 0.3424981697910992\n",
      "Epoch: 22 Step: 281 Loss: 0.42907612812834567\n",
      "Epoch: 22 Step: 291 Loss: 0.4966908192351022\n",
      "Epoch: 22 Step: 301 Loss: 0.4268634595016939\n",
      "Epoch: 22 Step: 311 Loss: 0.4718531351190059\n",
      "Epoch: 22 Step: 321 Loss: 0.4021371970986621\n",
      "Epoch: 22 Step: 331 Loss: 0.633081839133675\n",
      "Epoch: 22 Step: 341 Loss: 0.608210766256723\n",
      "Epoch: 22 Step: 351 Loss: 0.6659027185529954\n",
      "Epoch: 22 Step: 361 Loss: 0.514726420808927\n",
      "Epoch: 22 Step: 371 Loss: 0.47085291675518\n",
      "Epoch: 22 Step: 381 Loss: 0.43440017260155694\n",
      "Epoch: 22 Step: 391 Loss: 0.5607904648095866\n",
      "Epoch: 22 Step: 401 Loss: 0.4013104919764122\n",
      "Epoch: 22 Step: 411 Loss: 0.46097030867908306\n",
      "Epoch: 22 Step: 421 Loss: 0.496588710668427\n",
      "Epoch: 22 Step: 431 Loss: 0.33207571744964093\n",
      "Epoch: 22 Step: 441 Loss: 0.2935993769410406\n",
      "Epoch: 22 Step: 451 Loss: 0.3963372479332898\n",
      "Epoch: 22 Step: 461 Loss: 0.4541164739004721\n",
      "Epoch: 22 Step: 471 Loss: 0.5201394946717943\n",
      "Epoch: 22 Step: 481 Loss: 0.5944042434289437\n",
      "Epoch: 22 Step: 491 Loss: 0.6327046803593288\n",
      "Epoch: 22 Step: 501 Loss: 0.7134472977628732\n",
      "Epoch: 22 Step: 511 Loss: 0.48474844025654346\n",
      "Epoch: 22 Step: 521 Loss: 0.7520468076797961\n",
      "Epoch: 22 Step: 531 Loss: 0.6136067245736898\n",
      "Epoch: 22 Step: 541 Loss: 0.6553285916674384\n",
      "Epoch: 22 Step: 551 Loss: 0.3905180009890045\n",
      "Epoch: 22 Step: 561 Loss: 0.410271211864952\n",
      "Epoch: 22 Step: 571 Loss: 0.3259766497321527\n",
      "Epoch: 22 Step: 581 Loss: 0.5577080810966619\n",
      "Epoch: 22 Step: 591 Loss: 0.4649338878229078\n",
      "Epoch: 22 Step: 601 Loss: 0.331351566890011\n",
      "Epoch: 22 Step: 611 Loss: 0.48342155640416345\n",
      "Epoch: 22 Step: 621 Loss: 0.3537906913517895\n",
      "Epoch: 22 Step: 631 Loss: 0.5122971894409766\n",
      "Epoch: 22 Step: 641 Loss: 0.5020242525219714\n",
      "Epoch: 22 Step: 651 Loss: 0.5581642167405769\n",
      "Epoch: 22 Step: 661 Loss: 0.2383009977415459\n",
      "Epoch: 22 Step: 671 Loss: 0.4576794987792562\n",
      "Epoch: 22 Step: 681 Loss: 0.7478994881679351\n",
      "Epoch: 22 Step: 691 Loss: 0.40818173283555853\n",
      "Epoch: 22 Step: 701 Loss: 0.6048436854106577\n",
      "Epoch: 22 Step: 711 Loss: 0.5955635395139012\n",
      "Epoch: 22 Step: 721 Loss: 0.44082570397252807\n",
      "Epoch: 22 Step: 731 Loss: 0.3249801547481087\n",
      "Epoch: 22 Step: 741 Loss: 0.5231756728255887\n",
      "Epoch: 22 Step: 751 Loss: 0.6533919285321024\n",
      "Epoch: 22 Step: 761 Loss: 0.3166176361033265\n",
      "Epoch: 22 Step: 771 Loss: 0.6016547462067448\n",
      "Epoch: 22 Step: 781 Loss: 0.3299711543793239\n",
      "Epoch: 23 Step: 1 Loss: 0.3770417770474512\n",
      "Epoch: 23 Step: 11 Loss: 0.30281650766290424\n",
      "Epoch: 23 Step: 21 Loss: 0.49099365678836204\n",
      "Epoch: 23 Step: 31 Loss: 0.3977826532583356\n",
      "Epoch: 23 Step: 41 Loss: 0.24017253250034654\n",
      "Epoch: 23 Step: 51 Loss: 0.38774427797712774\n",
      "Epoch: 23 Step: 61 Loss: 0.45434390105620986\n",
      "Epoch: 23 Step: 71 Loss: 0.790411000543502\n",
      "Epoch: 23 Step: 81 Loss: 0.3555577193767716\n",
      "Epoch: 23 Step: 91 Loss: 0.5178216836251438\n",
      "Epoch: 23 Step: 101 Loss: 0.5420678080243757\n",
      "Epoch: 23 Step: 111 Loss: 0.7736289731157966\n",
      "Epoch: 23 Step: 121 Loss: 0.42696933406642323\n",
      "Epoch: 23 Step: 131 Loss: 0.3761253572318807\n",
      "Epoch: 23 Step: 141 Loss: 0.7335007031561547\n",
      "Epoch: 23 Step: 151 Loss: 0.3373823005869907\n",
      "Epoch: 23 Step: 161 Loss: 0.5387570796510719\n",
      "Epoch: 23 Step: 171 Loss: 0.4805221369438179\n",
      "Epoch: 23 Step: 181 Loss: 0.4850482347443965\n",
      "Epoch: 23 Step: 191 Loss: 0.40874414648972496\n",
      "Epoch: 23 Step: 201 Loss: 0.23764413934337703\n",
      "Epoch: 23 Step: 211 Loss: 0.39332647081579747\n",
      "Epoch: 23 Step: 221 Loss: 0.3367173336451908\n",
      "Epoch: 23 Step: 231 Loss: 0.5675606088593266\n",
      "Epoch: 23 Step: 241 Loss: 0.3115936683758815\n",
      "Epoch: 23 Step: 251 Loss: 0.3305356584220644\n",
      "Epoch: 23 Step: 261 Loss: 0.47494793640251726\n",
      "Epoch: 23 Step: 271 Loss: 0.34950189508878116\n",
      "Epoch: 23 Step: 281 Loss: 0.36941075020418035\n",
      "Epoch: 23 Step: 291 Loss: 0.5353132108135148\n",
      "Epoch: 23 Step: 301 Loss: 0.4888638482022518\n",
      "Epoch: 23 Step: 311 Loss: 0.4028281204121137\n",
      "Epoch: 23 Step: 321 Loss: 0.6298944035440459\n",
      "Epoch: 23 Step: 331 Loss: 0.5390239278900446\n",
      "Epoch: 23 Step: 341 Loss: 0.22641772345633934\n",
      "Epoch: 23 Step: 351 Loss: 0.5128418419053566\n",
      "Epoch: 23 Step: 361 Loss: 0.37645788870506935\n",
      "Epoch: 23 Step: 371 Loss: 0.4431754281136182\n",
      "Epoch: 23 Step: 381 Loss: 0.330780960542448\n",
      "Epoch: 23 Step: 391 Loss: 0.2214239732011343\n",
      "Epoch: 23 Step: 401 Loss: 0.35369073240847637\n",
      "Epoch: 23 Step: 411 Loss: 0.4630935343686852\n",
      "Epoch: 23 Step: 421 Loss: 0.4937504734047894\n",
      "Epoch: 23 Step: 431 Loss: 0.30478330622123884\n",
      "Epoch: 23 Step: 441 Loss: 0.3791166042359718\n",
      "Epoch: 23 Step: 451 Loss: 0.44970559142650646\n",
      "Epoch: 23 Step: 461 Loss: 0.4429247468802631\n",
      "Epoch: 23 Step: 471 Loss: 0.7047381878735199\n",
      "Epoch: 23 Step: 481 Loss: 0.8151828606469754\n",
      "Epoch: 23 Step: 491 Loss: 0.5397470597651312\n",
      "Epoch: 23 Step: 501 Loss: 0.6340204191030633\n",
      "Epoch: 23 Step: 511 Loss: 0.43003994604342644\n",
      "Epoch: 23 Step: 521 Loss: 0.7010009659548917\n",
      "Epoch: 23 Step: 531 Loss: 0.42647060969148043\n",
      "Epoch: 23 Step: 541 Loss: 0.5252030517214692\n",
      "Epoch: 23 Step: 551 Loss: 0.3214528745847691\n",
      "Epoch: 23 Step: 561 Loss: 0.2520526508843662\n",
      "Epoch: 23 Step: 571 Loss: 0.4040627072591013\n",
      "Epoch: 23 Step: 581 Loss: 0.5168975020032045\n",
      "Epoch: 23 Step: 591 Loss: 0.4148808070419483\n",
      "Epoch: 23 Step: 601 Loss: 0.27466410458430895\n",
      "Epoch: 23 Step: 611 Loss: 0.43123751596299936\n",
      "Epoch: 23 Step: 621 Loss: 0.37604382447566453\n",
      "Epoch: 23 Step: 631 Loss: 0.44378838592335673\n",
      "Epoch: 23 Step: 641 Loss: 0.4314258500046941\n",
      "Epoch: 23 Step: 651 Loss: 0.6811710453352036\n",
      "Epoch: 23 Step: 661 Loss: 0.3077997568527501\n",
      "Epoch: 23 Step: 671 Loss: 0.6019560009543403\n",
      "Epoch: 23 Step: 681 Loss: 0.679556593990293\n",
      "Epoch: 23 Step: 691 Loss: 0.4492912629470992\n",
      "Epoch: 23 Step: 701 Loss: 0.3985571292087661\n",
      "Epoch: 23 Step: 711 Loss: 0.5374035005891495\n",
      "Epoch: 23 Step: 721 Loss: 0.42618437301906636\n",
      "Epoch: 23 Step: 731 Loss: 0.334871609205299\n",
      "Epoch: 23 Step: 741 Loss: 0.4680008135607732\n",
      "Epoch: 23 Step: 751 Loss: 0.4567121820335547\n",
      "Epoch: 23 Step: 761 Loss: 0.48368146426595293\n",
      "Epoch: 23 Step: 771 Loss: 0.43038178220949935\n",
      "Epoch: 23 Step: 781 Loss: 0.42726835122252804\n",
      "Epoch: 24 Step: 1 Loss: 0.2978663256398873\n",
      "Epoch: 24 Step: 11 Loss: 0.3797532059407406\n",
      "Epoch: 24 Step: 21 Loss: 0.3377167566357422\n",
      "Epoch: 24 Step: 31 Loss: 0.6649702297602462\n",
      "Epoch: 24 Step: 41 Loss: 0.29191974193348696\n",
      "Epoch: 24 Step: 51 Loss: 0.3774021223436539\n",
      "Epoch: 24 Step: 61 Loss: 0.40753921215425004\n",
      "Epoch: 24 Step: 71 Loss: 0.6646904791924143\n",
      "Epoch: 24 Step: 81 Loss: 0.45136117378964113\n",
      "Epoch: 24 Step: 91 Loss: 0.37802076740656076\n",
      "Epoch: 24 Step: 101 Loss: 0.36589873005043383\n",
      "Epoch: 24 Step: 111 Loss: 0.5306146324673617\n",
      "Epoch: 24 Step: 121 Loss: 0.26987091104131883\n",
      "Epoch: 24 Step: 131 Loss: 0.34403692171818534\n",
      "Epoch: 24 Step: 141 Loss: 0.5296601291008771\n",
      "Epoch: 24 Step: 151 Loss: 0.2958086215589405\n",
      "Epoch: 24 Step: 161 Loss: 0.3826711071720529\n",
      "Epoch: 24 Step: 171 Loss: 0.757112704840377\n",
      "Epoch: 24 Step: 181 Loss: 0.427039551404326\n",
      "Epoch: 24 Step: 191 Loss: 0.3804107740501601\n",
      "Epoch: 24 Step: 201 Loss: 0.34772473054056097\n",
      "Epoch: 24 Step: 211 Loss: 0.3368567881665451\n",
      "Epoch: 24 Step: 221 Loss: 0.5396859063554524\n",
      "Epoch: 24 Step: 231 Loss: 0.551122339336203\n",
      "Epoch: 24 Step: 241 Loss: 0.5295301089303264\n",
      "Epoch: 24 Step: 251 Loss: 0.4260126754320249\n",
      "Epoch: 24 Step: 261 Loss: 0.43671726498977137\n",
      "Epoch: 24 Step: 271 Loss: 0.3389895945407729\n",
      "Epoch: 24 Step: 281 Loss: 0.2034947905330674\n",
      "Epoch: 24 Step: 291 Loss: 0.38584499967702623\n",
      "Epoch: 24 Step: 301 Loss: 0.3864362702169984\n",
      "Epoch: 24 Step: 311 Loss: 0.22943091853057984\n",
      "Epoch: 24 Step: 321 Loss: 0.4848378160052817\n",
      "Epoch: 24 Step: 331 Loss: 0.4824076081660576\n",
      "Epoch: 24 Step: 341 Loss: 0.41575841206667474\n",
      "Epoch: 24 Step: 351 Loss: 0.525322167818101\n",
      "Epoch: 24 Step: 361 Loss: 0.3286380030674614\n",
      "Epoch: 24 Step: 371 Loss: 0.4119907438145045\n",
      "Epoch: 24 Step: 381 Loss: 0.3984590371579298\n",
      "Epoch: 24 Step: 391 Loss: 0.33281325177226206\n",
      "Epoch: 24 Step: 401 Loss: 0.49378922148033483\n",
      "Epoch: 24 Step: 411 Loss: 0.36598627585385096\n",
      "Epoch: 24 Step: 421 Loss: 0.7254774135414681\n",
      "Epoch: 24 Step: 431 Loss: 0.4418602073656309\n",
      "Epoch: 24 Step: 441 Loss: 0.6015491656117085\n",
      "Epoch: 24 Step: 451 Loss: 0.3722029280189474\n",
      "Epoch: 24 Step: 461 Loss: 0.606838511774185\n",
      "Epoch: 24 Step: 471 Loss: 0.47382295941658337\n",
      "Epoch: 24 Step: 481 Loss: 0.6978852288173178\n",
      "Epoch: 24 Step: 491 Loss: 0.5045634141508055\n",
      "Epoch: 24 Step: 501 Loss: 0.3126189639893265\n",
      "Epoch: 24 Step: 511 Loss: 0.31185005005821803\n",
      "Epoch: 24 Step: 521 Loss: 0.4603869341299498\n",
      "Epoch: 24 Step: 531 Loss: 0.37767778462382917\n",
      "Epoch: 24 Step: 541 Loss: 0.5141381451000442\n",
      "Epoch: 24 Step: 551 Loss: 0.3882455123320556\n",
      "Epoch: 24 Step: 561 Loss: 0.3177940150371354\n",
      "Epoch: 24 Step: 571 Loss: 0.25698125795300286\n",
      "Epoch: 24 Step: 581 Loss: 0.5321630473792968\n",
      "Epoch: 24 Step: 591 Loss: 0.4897211996010113\n",
      "Epoch: 24 Step: 601 Loss: 0.32133065279689177\n",
      "Epoch: 24 Step: 611 Loss: 0.4397549164419652\n",
      "Epoch: 24 Step: 621 Loss: 0.6205579223012913\n",
      "Epoch: 24 Step: 631 Loss: 0.3724842455027013\n",
      "Epoch: 24 Step: 641 Loss: 0.3021116165836064\n",
      "Epoch: 24 Step: 651 Loss: 0.34315112636736855\n",
      "Epoch: 24 Step: 661 Loss: 0.2479984655153591\n",
      "Epoch: 24 Step: 671 Loss: 0.4006751099382047\n",
      "Epoch: 24 Step: 681 Loss: 0.5936938761830457\n",
      "Epoch: 24 Step: 691 Loss: 0.3273502835328239\n",
      "Epoch: 24 Step: 701 Loss: 0.4734661521405023\n",
      "Epoch: 24 Step: 711 Loss: 0.5520865296351063\n",
      "Epoch: 24 Step: 721 Loss: 0.3322350964854352\n",
      "Epoch: 24 Step: 731 Loss: 0.22236854646030024\n",
      "Epoch: 24 Step: 741 Loss: 0.49068832181472066\n",
      "Epoch: 24 Step: 751 Loss: 0.4171149333020915\n",
      "Epoch: 24 Step: 761 Loss: 0.2952350087279505\n",
      "Epoch: 24 Step: 771 Loss: 0.44777432366492814\n",
      "Epoch: 24 Step: 781 Loss: 0.4010463389925946\n",
      "Epoch: 25 Step: 1 Loss: 0.37000430462717626\n",
      "Epoch: 25 Step: 11 Loss: 0.350908795888182\n",
      "Epoch: 25 Step: 21 Loss: 0.49227252169565583\n",
      "Epoch: 25 Step: 31 Loss: 0.2510915528659766\n",
      "Epoch: 25 Step: 41 Loss: 0.3342472277521187\n",
      "Epoch: 25 Step: 51 Loss: 0.3219844128149991\n",
      "Epoch: 25 Step: 61 Loss: 0.40345113801041893\n",
      "Epoch: 25 Step: 71 Loss: 0.6884093002254503\n",
      "Epoch: 25 Step: 81 Loss: 0.3370844124952823\n",
      "Epoch: 25 Step: 91 Loss: 0.4978400177599149\n",
      "Epoch: 25 Step: 101 Loss: 0.1634957621869531\n",
      "Epoch: 25 Step: 111 Loss: 0.5943745316609537\n",
      "Epoch: 25 Step: 121 Loss: 0.42685509172734204\n",
      "Epoch: 25 Step: 131 Loss: 0.4665048869315275\n",
      "Epoch: 25 Step: 141 Loss: 0.49733444545633065\n",
      "Epoch: 25 Step: 151 Loss: 0.377851656569653\n",
      "Epoch: 25 Step: 161 Loss: 0.35065855093516296\n",
      "Epoch: 25 Step: 171 Loss: 0.5249221079032\n",
      "Epoch: 25 Step: 181 Loss: 0.6412576411045114\n",
      "Epoch: 25 Step: 191 Loss: 0.39793859100279144\n",
      "Epoch: 25 Step: 201 Loss: 0.5060382771397343\n",
      "Epoch: 25 Step: 211 Loss: 0.4077565434079296\n",
      "Epoch: 25 Step: 221 Loss: 0.38656099550536904\n",
      "Epoch: 25 Step: 231 Loss: 0.3864914230714874\n",
      "Epoch: 25 Step: 241 Loss: 0.30567805213540494\n",
      "Epoch: 25 Step: 251 Loss: 0.3950099843886843\n",
      "Epoch: 25 Step: 261 Loss: 0.23149609889265704\n",
      "Epoch: 25 Step: 271 Loss: 0.22579719929572103\n",
      "Epoch: 25 Step: 281 Loss: 0.13563731436544682\n",
      "Epoch: 25 Step: 291 Loss: 0.5629186044104577\n",
      "Epoch: 25 Step: 301 Loss: 0.2913907136470024\n",
      "Epoch: 25 Step: 311 Loss: 0.3086961172500879\n",
      "Epoch: 25 Step: 321 Loss: 0.39259653625857466\n",
      "Epoch: 25 Step: 331 Loss: 0.5903378898679013\n",
      "Epoch: 25 Step: 341 Loss: 0.5792137869450533\n",
      "Epoch: 25 Step: 351 Loss: 0.3899806950053063\n",
      "Epoch: 25 Step: 361 Loss: 0.30259143994118254\n",
      "Epoch: 25 Step: 371 Loss: 0.5060934810862984\n",
      "Epoch: 25 Step: 381 Loss: 0.5029474313947601\n",
      "Epoch: 25 Step: 391 Loss: 0.49727684956232865\n",
      "Epoch: 25 Step: 401 Loss: 0.5036723450679023\n",
      "Epoch: 25 Step: 411 Loss: 0.5694611907217817\n",
      "Epoch: 25 Step: 421 Loss: 0.6934367441583965\n",
      "Epoch: 25 Step: 431 Loss: 0.2792016317090513\n",
      "Epoch: 25 Step: 441 Loss: 0.33670895648901444\n",
      "Epoch: 25 Step: 451 Loss: 0.3754956102149025\n",
      "Epoch: 25 Step: 461 Loss: 0.3084449653910765\n",
      "Epoch: 25 Step: 471 Loss: 0.4856830668002072\n",
      "Epoch: 25 Step: 481 Loss: 0.4845622304648648\n",
      "Epoch: 25 Step: 491 Loss: 0.499367278508814\n",
      "Epoch: 25 Step: 501 Loss: 0.46777468763376556\n",
      "Epoch: 25 Step: 511 Loss: 0.23405272381780456\n",
      "Epoch: 25 Step: 521 Loss: 0.5640416886782011\n",
      "Epoch: 25 Step: 531 Loss: 0.4798420666369877\n",
      "Epoch: 25 Step: 541 Loss: 0.6228246961758523\n",
      "Epoch: 25 Step: 551 Loss: 0.3988847069964887\n",
      "Epoch: 25 Step: 561 Loss: 0.43497882929556486\n",
      "Epoch: 25 Step: 571 Loss: 0.40331917158244246\n",
      "Epoch: 25 Step: 581 Loss: 0.49323479972029094\n",
      "Epoch: 25 Step: 591 Loss: 0.4230471476970464\n",
      "Epoch: 25 Step: 601 Loss: 0.33768209187298026\n",
      "Epoch: 25 Step: 611 Loss: 0.3795125010485726\n",
      "Epoch: 25 Step: 621 Loss: 0.2968203539403016\n",
      "Epoch: 25 Step: 631 Loss: 0.277000760981679\n",
      "Epoch: 25 Step: 641 Loss: 0.3107215114920995\n",
      "Epoch: 25 Step: 651 Loss: 0.21198360061399338\n",
      "Epoch: 25 Step: 661 Loss: 0.27758424629238265\n",
      "Epoch: 25 Step: 671 Loss: 0.4108561020535715\n",
      "Epoch: 25 Step: 681 Loss: 0.3671432259394761\n",
      "Epoch: 25 Step: 691 Loss: 0.38753528727978526\n",
      "Epoch: 25 Step: 701 Loss: 0.3449973577893393\n",
      "Epoch: 25 Step: 711 Loss: 0.46679177421348406\n",
      "Epoch: 25 Step: 721 Loss: 0.3106387837894463\n",
      "Epoch: 25 Step: 731 Loss: 0.36306443070381433\n",
      "Epoch: 25 Step: 741 Loss: 0.45847324991658844\n",
      "Epoch: 25 Step: 751 Loss: 0.6037670117936476\n",
      "Epoch: 25 Step: 761 Loss: 0.44704361712029417\n",
      "Epoch: 25 Step: 771 Loss: 0.48720389497555155\n",
      "Epoch: 25 Step: 781 Loss: 0.2662214043502585\n",
      "Epoch: 26 Step: 1 Loss: 0.20985056781745298\n",
      "Epoch: 26 Step: 11 Loss: 0.3545009110982936\n",
      "Epoch: 26 Step: 21 Loss: 0.34069458345340503\n",
      "Epoch: 26 Step: 31 Loss: 0.25683140226229517\n",
      "Epoch: 26 Step: 41 Loss: 0.2608390338290381\n",
      "Epoch: 26 Step: 51 Loss: 0.23633751787226542\n",
      "Epoch: 26 Step: 61 Loss: 0.34525162638157886\n",
      "Epoch: 26 Step: 71 Loss: 0.43430166370378137\n",
      "Epoch: 26 Step: 81 Loss: 0.2786795315607816\n",
      "Epoch: 26 Step: 91 Loss: 0.3190179503740743\n",
      "Epoch: 26 Step: 101 Loss: 0.2888247464849389\n",
      "Epoch: 26 Step: 111 Loss: 0.5088379245027901\n",
      "Epoch: 26 Step: 121 Loss: 0.4727933481158975\n",
      "Epoch: 26 Step: 131 Loss: 0.5037489275213517\n",
      "Epoch: 26 Step: 141 Loss: 0.7895454283038137\n",
      "Epoch: 26 Step: 151 Loss: 0.4083265084107141\n",
      "Epoch: 26 Step: 161 Loss: 0.3887524665583213\n",
      "Epoch: 26 Step: 171 Loss: 0.40248553728512987\n",
      "Epoch: 26 Step: 181 Loss: 0.14932147189560788\n",
      "Epoch: 26 Step: 191 Loss: 0.45250291134934256\n",
      "Epoch: 26 Step: 201 Loss: 0.22723744658839015\n",
      "Epoch: 26 Step: 211 Loss: 0.34834063242071234\n",
      "Epoch: 26 Step: 221 Loss: 0.36989286964131274\n",
      "Epoch: 26 Step: 231 Loss: 0.30035336255894596\n",
      "Epoch: 26 Step: 241 Loss: 0.2662299604542136\n",
      "Epoch: 26 Step: 251 Loss: 0.3199395107862854\n",
      "Epoch: 26 Step: 261 Loss: 0.29062592827926204\n",
      "Epoch: 26 Step: 271 Loss: 0.4218791707800743\n",
      "Epoch: 26 Step: 281 Loss: 0.3862473720096223\n",
      "Epoch: 26 Step: 291 Loss: 0.4920576764855066\n",
      "Epoch: 26 Step: 301 Loss: 0.7129147224216139\n",
      "Epoch: 26 Step: 311 Loss: 0.4354980968980605\n",
      "Epoch: 26 Step: 321 Loss: 0.6860009863580383\n",
      "Epoch: 26 Step: 331 Loss: 0.6439930448817368\n",
      "Epoch: 26 Step: 341 Loss: 0.27191899027017186\n",
      "Epoch: 26 Step: 351 Loss: 0.38028611095560616\n",
      "Epoch: 26 Step: 361 Loss: 0.45606936559170785\n",
      "Epoch: 26 Step: 371 Loss: 0.24918267362777288\n",
      "Epoch: 26 Step: 381 Loss: 0.30930065910437465\n",
      "Epoch: 26 Step: 391 Loss: 0.34292112738403613\n",
      "Epoch: 26 Step: 401 Loss: 0.31867485438242005\n",
      "Epoch: 26 Step: 411 Loss: 0.24974191149706224\n",
      "Epoch: 26 Step: 421 Loss: 0.554433698265517\n",
      "Epoch: 26 Step: 431 Loss: 0.4622437562739924\n",
      "Epoch: 26 Step: 441 Loss: 0.2653990319080153\n",
      "Epoch: 26 Step: 451 Loss: 0.33114306476677285\n",
      "Epoch: 26 Step: 461 Loss: 0.3462257581846403\n",
      "Epoch: 26 Step: 471 Loss: 0.5700718021942449\n",
      "Epoch: 26 Step: 481 Loss: 0.5635655314940897\n",
      "Epoch: 26 Step: 491 Loss: 0.47116229953650374\n",
      "Epoch: 26 Step: 501 Loss: 0.5212419455707827\n",
      "Epoch: 26 Step: 511 Loss: 0.46913363601107305\n",
      "Epoch: 26 Step: 521 Loss: 0.5485100715708002\n",
      "Epoch: 26 Step: 531 Loss: 0.3920409501641424\n",
      "Epoch: 26 Step: 541 Loss: 0.24530407804351428\n",
      "Epoch: 26 Step: 551 Loss: 0.3384384160420539\n",
      "Epoch: 26 Step: 561 Loss: 0.2854183913250926\n",
      "Epoch: 26 Step: 571 Loss: 0.18812449604584403\n",
      "Epoch: 26 Step: 581 Loss: 0.36200301641271054\n",
      "Epoch: 26 Step: 591 Loss: 0.45037498831872436\n",
      "Epoch: 26 Step: 601 Loss: 0.2679366115200148\n",
      "Epoch: 26 Step: 611 Loss: 0.18360297834758837\n",
      "Epoch: 26 Step: 621 Loss: 0.342866208111555\n",
      "Epoch: 26 Step: 631 Loss: 0.23279547363531938\n",
      "Epoch: 26 Step: 641 Loss: 0.3133395599140763\n",
      "Epoch: 26 Step: 651 Loss: 0.485735246729589\n",
      "Epoch: 26 Step: 661 Loss: 0.18035161458442006\n",
      "Epoch: 26 Step: 671 Loss: 0.5722380951905908\n",
      "Epoch: 26 Step: 681 Loss: 0.6353537851044029\n",
      "Epoch: 26 Step: 691 Loss: 0.4559033850481138\n",
      "Epoch: 26 Step: 701 Loss: 0.44326161502263783\n",
      "Epoch: 26 Step: 711 Loss: 0.34250477316195194\n",
      "Epoch: 26 Step: 721 Loss: 0.2626799970211326\n",
      "Epoch: 26 Step: 731 Loss: 0.31367325893212356\n",
      "Epoch: 26 Step: 741 Loss: 0.2744497466499151\n",
      "Epoch: 26 Step: 751 Loss: 0.3365702648815708\n",
      "Epoch: 26 Step: 761 Loss: 0.23739043636114113\n",
      "Epoch: 26 Step: 771 Loss: 0.1955066063617913\n",
      "Epoch: 26 Step: 781 Loss: 0.375225891581075\n",
      "Epoch: 27 Step: 1 Loss: 0.34110234486983826\n",
      "Epoch: 27 Step: 11 Loss: 0.300624666357577\n",
      "Epoch: 27 Step: 21 Loss: 0.3247255203164249\n",
      "Epoch: 27 Step: 31 Loss: 0.4433979833785785\n",
      "Epoch: 27 Step: 41 Loss: 0.2455824491182596\n",
      "Epoch: 27 Step: 51 Loss: 0.34294268634641223\n",
      "Epoch: 27 Step: 61 Loss: 0.47825256171214636\n",
      "Epoch: 27 Step: 71 Loss: 0.565544250839661\n",
      "Epoch: 27 Step: 81 Loss: 0.3322883828984724\n",
      "Epoch: 27 Step: 91 Loss: 0.4752435068621661\n",
      "Epoch: 27 Step: 101 Loss: 0.26380902235554693\n",
      "Epoch: 27 Step: 111 Loss: 0.28366165504699165\n",
      "Epoch: 27 Step: 121 Loss: 0.33616338149002134\n",
      "Epoch: 27 Step: 131 Loss: 0.3109638400375675\n",
      "Epoch: 27 Step: 141 Loss: 0.3282913228749941\n",
      "Epoch: 27 Step: 151 Loss: 0.2250490805471579\n",
      "Epoch: 27 Step: 161 Loss: 0.2899004903626719\n",
      "Epoch: 27 Step: 171 Loss: 0.2731252917283411\n",
      "Epoch: 27 Step: 181 Loss: 0.3270485941199368\n",
      "Epoch: 27 Step: 191 Loss: 0.36127980937018167\n",
      "Epoch: 27 Step: 201 Loss: 0.23487843401769853\n",
      "Epoch: 27 Step: 211 Loss: 0.23410185871799474\n",
      "Epoch: 27 Step: 221 Loss: 0.3521586535269213\n",
      "Epoch: 27 Step: 231 Loss: 0.26641596776141\n",
      "Epoch: 27 Step: 241 Loss: 0.377209108643854\n",
      "Epoch: 27 Step: 251 Loss: 0.35971693380216085\n",
      "Epoch: 27 Step: 261 Loss: 0.3687587810127017\n",
      "Epoch: 27 Step: 271 Loss: 0.4340657651498153\n",
      "Epoch: 27 Step: 281 Loss: 0.3389005602720245\n",
      "Epoch: 27 Step: 291 Loss: 0.377095997391678\n",
      "Epoch: 27 Step: 301 Loss: 0.3034207726325671\n",
      "Epoch: 27 Step: 311 Loss: 0.22215919959596955\n",
      "Epoch: 27 Step: 321 Loss: 0.38590529160017417\n",
      "Epoch: 27 Step: 331 Loss: 0.5088429738933381\n",
      "Epoch: 27 Step: 341 Loss: 0.3277015975720635\n",
      "Epoch: 27 Step: 351 Loss: 0.2985794294367395\n",
      "Epoch: 27 Step: 361 Loss: 0.20513618497976202\n",
      "Epoch: 27 Step: 371 Loss: 0.2805584282868973\n",
      "Epoch: 27 Step: 381 Loss: 0.2840198774845827\n",
      "Epoch: 27 Step: 391 Loss: 0.15366976393277926\n",
      "Epoch: 27 Step: 401 Loss: 0.25106508264902777\n",
      "Epoch: 27 Step: 411 Loss: 0.2818172998973534\n",
      "Epoch: 27 Step: 421 Loss: 0.41649509060345125\n",
      "Epoch: 27 Step: 431 Loss: 0.351015941321142\n",
      "Epoch: 27 Step: 441 Loss: 0.18506198281621167\n",
      "Epoch: 27 Step: 451 Loss: 0.3203015847490326\n",
      "Epoch: 27 Step: 461 Loss: 0.3713389199982467\n",
      "Epoch: 27 Step: 471 Loss: 0.3704713504353372\n",
      "Epoch: 27 Step: 481 Loss: 0.5498690356822217\n",
      "Epoch: 27 Step: 491 Loss: 0.3470837896521727\n",
      "Epoch: 27 Step: 501 Loss: 0.312458847730262\n",
      "Epoch: 27 Step: 511 Loss: 0.11698088260004229\n",
      "Epoch: 27 Step: 521 Loss: 0.4289306813591643\n",
      "Epoch: 27 Step: 531 Loss: 0.34767213213574577\n",
      "Epoch: 27 Step: 541 Loss: 0.30435561624786717\n",
      "Epoch: 27 Step: 551 Loss: 0.2187857286263464\n",
      "Epoch: 27 Step: 561 Loss: 0.2318021916008633\n",
      "Epoch: 27 Step: 571 Loss: 0.2636531292729811\n",
      "Epoch: 27 Step: 581 Loss: 0.3968155757388605\n",
      "Epoch: 27 Step: 591 Loss: 0.24383286511005736\n",
      "Epoch: 27 Step: 601 Loss: 0.32908152137193936\n",
      "Epoch: 27 Step: 611 Loss: 0.2991223430740855\n",
      "Epoch: 27 Step: 621 Loss: 0.3514107140907221\n",
      "Epoch: 27 Step: 631 Loss: 0.2371422418738098\n",
      "Epoch: 27 Step: 641 Loss: 0.4477196208442875\n",
      "Epoch: 27 Step: 651 Loss: 0.34293117253467176\n",
      "Epoch: 27 Step: 661 Loss: 0.3377546765301715\n",
      "Epoch: 27 Step: 671 Loss: 0.2726688157598379\n",
      "Epoch: 27 Step: 681 Loss: 0.4793410210987967\n",
      "Epoch: 27 Step: 691 Loss: 0.275090196740467\n",
      "Epoch: 27 Step: 701 Loss: 0.44692906179037395\n",
      "Epoch: 27 Step: 711 Loss: 0.37192471293694795\n",
      "Epoch: 27 Step: 721 Loss: 0.20909896817156176\n",
      "Epoch: 27 Step: 731 Loss: 0.19296549899711332\n",
      "Epoch: 27 Step: 741 Loss: 0.4366196528420939\n",
      "Epoch: 27 Step: 751 Loss: 0.3833830991458404\n",
      "Epoch: 27 Step: 761 Loss: 0.2467078121065005\n",
      "Epoch: 27 Step: 771 Loss: 0.3533793494504135\n",
      "Epoch: 27 Step: 781 Loss: 0.361906670923461\n",
      "Epoch: 28 Step: 1 Loss: 0.21159871280136897\n",
      "Epoch: 28 Step: 11 Loss: 0.47584743469043866\n",
      "Epoch: 28 Step: 21 Loss: 0.38648245014198856\n",
      "Epoch: 28 Step: 31 Loss: 0.45242739152432165\n",
      "Epoch: 28 Step: 41 Loss: 0.4217297260283062\n",
      "Epoch: 28 Step: 51 Loss: 0.3478188395229517\n",
      "Epoch: 28 Step: 61 Loss: 0.46382398522628276\n",
      "Epoch: 28 Step: 71 Loss: 0.46195847906674065\n",
      "Epoch: 28 Step: 81 Loss: 0.3864858992986636\n",
      "Epoch: 28 Step: 91 Loss: 0.22130164546019274\n",
      "Epoch: 28 Step: 101 Loss: 0.38231396106050086\n",
      "Epoch: 28 Step: 111 Loss: 0.4105987165628322\n",
      "Epoch: 28 Step: 121 Loss: 0.15501069056826675\n",
      "Epoch: 28 Step: 131 Loss: 0.32289300008943744\n",
      "Epoch: 28 Step: 141 Loss: 0.46606886705876344\n",
      "Epoch: 28 Step: 151 Loss: 0.17972533073677466\n",
      "Epoch: 28 Step: 161 Loss: 0.3054670843530411\n",
      "Epoch: 28 Step: 171 Loss: 0.3387634573814423\n",
      "Epoch: 28 Step: 181 Loss: 0.375237939696949\n",
      "Epoch: 28 Step: 191 Loss: 0.2990519536795851\n",
      "Epoch: 28 Step: 201 Loss: 0.2689224177227661\n",
      "Epoch: 28 Step: 211 Loss: 0.36190305206147816\n",
      "Epoch: 28 Step: 221 Loss: 0.4006956948414936\n",
      "Epoch: 28 Step: 231 Loss: 0.20898463912167395\n",
      "Epoch: 28 Step: 241 Loss: 0.22609434476287707\n",
      "Epoch: 28 Step: 251 Loss: 0.26731481097200993\n",
      "Epoch: 28 Step: 261 Loss: 0.4229205670700098\n",
      "Epoch: 28 Step: 271 Loss: 0.24589875152043322\n",
      "Epoch: 28 Step: 281 Loss: 0.30680009834399685\n",
      "Epoch: 28 Step: 291 Loss: 0.34433814262604545\n",
      "Epoch: 28 Step: 301 Loss: 0.19721099831115116\n",
      "Epoch: 28 Step: 311 Loss: 0.29028963620452286\n",
      "Epoch: 28 Step: 321 Loss: 0.6005763430814425\n",
      "Epoch: 28 Step: 331 Loss: 0.386867646134993\n",
      "Epoch: 28 Step: 341 Loss: 0.29143962389181743\n",
      "Epoch: 28 Step: 351 Loss: 0.31952120805375817\n",
      "Epoch: 28 Step: 361 Loss: 0.23158686251541527\n",
      "Epoch: 28 Step: 371 Loss: 0.3328831966211037\n",
      "Epoch: 28 Step: 381 Loss: 0.318561933857905\n",
      "Epoch: 28 Step: 391 Loss: 0.2699004102653281\n",
      "Epoch: 28 Step: 401 Loss: 0.3238052358565613\n",
      "Epoch: 28 Step: 411 Loss: 0.4201298828456079\n",
      "Epoch: 28 Step: 421 Loss: 0.4689240881974168\n",
      "Epoch: 28 Step: 431 Loss: 0.2877496513816744\n",
      "Epoch: 28 Step: 441 Loss: 0.321879278825298\n",
      "Epoch: 28 Step: 451 Loss: 0.30729610292541926\n",
      "Epoch: 28 Step: 461 Loss: 0.4754123278504501\n",
      "Epoch: 28 Step: 471 Loss: 0.2933419073407403\n",
      "Epoch: 28 Step: 481 Loss: 0.29884709027046497\n",
      "Epoch: 28 Step: 491 Loss: 0.2635048999735096\n",
      "Epoch: 28 Step: 501 Loss: 0.4055893230962127\n",
      "Epoch: 28 Step: 511 Loss: 0.17382690688788108\n",
      "Epoch: 28 Step: 521 Loss: 0.379889295183341\n",
      "Epoch: 28 Step: 531 Loss: 0.31009556724638043\n",
      "Epoch: 28 Step: 541 Loss: 0.3303943740392752\n",
      "Epoch: 28 Step: 551 Loss: 0.2736021189283103\n",
      "Epoch: 28 Step: 561 Loss: 0.2392584428897856\n",
      "Epoch: 28 Step: 571 Loss: 0.24479545573697262\n",
      "Epoch: 28 Step: 581 Loss: 0.439684043204443\n",
      "Epoch: 28 Step: 591 Loss: 0.5165139891581967\n",
      "Epoch: 28 Step: 601 Loss: 0.3109924188577418\n",
      "Epoch: 28 Step: 611 Loss: 0.27738987982783764\n",
      "Epoch: 28 Step: 621 Loss: 0.3445712179753988\n",
      "Epoch: 28 Step: 631 Loss: 0.2003607927188161\n",
      "Epoch: 28 Step: 641 Loss: 0.26596905131336945\n",
      "Epoch: 28 Step: 651 Loss: 0.2945801812662361\n",
      "Epoch: 28 Step: 661 Loss: 0.18478153990955112\n",
      "Epoch: 28 Step: 671 Loss: 0.22644531117403924\n",
      "Epoch: 28 Step: 681 Loss: 0.3386951054590549\n",
      "Epoch: 28 Step: 691 Loss: 0.3261324868886403\n",
      "Epoch: 28 Step: 701 Loss: 0.2833203566609621\n",
      "Epoch: 28 Step: 711 Loss: 0.18678149465108002\n",
      "Epoch: 28 Step: 721 Loss: 0.351855973224865\n",
      "Epoch: 28 Step: 731 Loss: 0.1987237649006187\n",
      "Epoch: 28 Step: 741 Loss: 0.22255655839577862\n",
      "Epoch: 28 Step: 751 Loss: 0.5719653261325723\n",
      "Epoch: 28 Step: 761 Loss: 0.33117284864152485\n",
      "Epoch: 28 Step: 771 Loss: 0.34497804988392927\n",
      "Epoch: 28 Step: 781 Loss: 0.27065000717363386\n",
      "Epoch: 29 Step: 1 Loss: 0.31335723433433615\n",
      "Epoch: 29 Step: 11 Loss: 0.2713817673908252\n",
      "Epoch: 29 Step: 21 Loss: 0.33259498230808865\n",
      "Epoch: 29 Step: 31 Loss: 0.327229043694816\n",
      "Epoch: 29 Step: 41 Loss: 0.24436491918579725\n",
      "Epoch: 29 Step: 51 Loss: 0.1569567996880416\n",
      "Epoch: 29 Step: 61 Loss: 0.2319122257814776\n",
      "Epoch: 29 Step: 71 Loss: 0.3775170659960275\n",
      "Epoch: 29 Step: 81 Loss: 0.2095931713455335\n",
      "Epoch: 29 Step: 91 Loss: 0.2381860109318733\n",
      "Epoch: 29 Step: 101 Loss: 0.22799626263646522\n",
      "Epoch: 29 Step: 111 Loss: 0.26620457292051036\n",
      "Epoch: 29 Step: 121 Loss: 0.2225939228657389\n",
      "Epoch: 29 Step: 131 Loss: 0.25501097296144704\n",
      "Epoch: 29 Step: 141 Loss: 0.6407583779132252\n",
      "Epoch: 29 Step: 151 Loss: 0.28823267105105\n",
      "Epoch: 29 Step: 161 Loss: 0.48765659000183353\n",
      "Epoch: 29 Step: 171 Loss: 0.518495233258836\n",
      "Epoch: 29 Step: 181 Loss: 0.39831651978631866\n",
      "Epoch: 29 Step: 191 Loss: 0.45387827196854025\n",
      "Epoch: 29 Step: 201 Loss: 0.17784050783431748\n",
      "Epoch: 29 Step: 211 Loss: 0.30989340011763844\n",
      "Epoch: 29 Step: 221 Loss: 0.3414130834865654\n",
      "Epoch: 29 Step: 231 Loss: 0.24709349306432965\n",
      "Epoch: 29 Step: 241 Loss: 0.22831450372812784\n",
      "Epoch: 29 Step: 251 Loss: 0.14598831928776002\n",
      "Epoch: 29 Step: 261 Loss: 0.28436594081487415\n",
      "Epoch: 29 Step: 271 Loss: 0.1946260456920066\n",
      "Epoch: 29 Step: 281 Loss: 0.19660118475418337\n",
      "Epoch: 29 Step: 291 Loss: 0.3499979707878209\n",
      "Epoch: 29 Step: 301 Loss: 0.258666379505363\n",
      "Epoch: 29 Step: 311 Loss: 0.30238971028821715\n",
      "Epoch: 29 Step: 321 Loss: 0.4777031057425086\n",
      "Epoch: 29 Step: 331 Loss: 0.42054835610885577\n",
      "Epoch: 29 Step: 341 Loss: 0.27443071218021364\n",
      "Epoch: 29 Step: 351 Loss: 0.3513376222219273\n",
      "Epoch: 29 Step: 361 Loss: 0.32304007805536844\n",
      "Epoch: 29 Step: 371 Loss: 0.4463975498459776\n",
      "Epoch: 29 Step: 381 Loss: 0.2584822823666165\n",
      "Epoch: 29 Step: 391 Loss: 0.2325036536474948\n",
      "Epoch: 29 Step: 401 Loss: 0.21678075060125993\n",
      "Epoch: 29 Step: 411 Loss: 0.30314744313588327\n",
      "Epoch: 29 Step: 421 Loss: 0.37975802814977944\n",
      "Epoch: 29 Step: 431 Loss: 0.19919530897948412\n",
      "Epoch: 29 Step: 441 Loss: 0.2362529202418867\n",
      "Epoch: 29 Step: 451 Loss: 0.24605600709980613\n",
      "Epoch: 29 Step: 461 Loss: 0.29029081010947955\n",
      "Epoch: 29 Step: 471 Loss: 0.40872726503848467\n",
      "Epoch: 29 Step: 481 Loss: 0.24903846364999443\n",
      "Epoch: 29 Step: 491 Loss: 0.4729298392270566\n",
      "Epoch: 29 Step: 501 Loss: 0.457254322283818\n",
      "Epoch: 29 Step: 511 Loss: 0.11833380344928375\n",
      "Epoch: 29 Step: 521 Loss: 0.4338472970104512\n",
      "Epoch: 29 Step: 531 Loss: 0.33619468469378927\n",
      "Epoch: 29 Step: 541 Loss: 0.4677110910043175\n",
      "Epoch: 29 Step: 551 Loss: 0.19720152880789044\n",
      "Epoch: 29 Step: 561 Loss: 0.24964042695440009\n",
      "Epoch: 29 Step: 571 Loss: 0.19741118304703476\n",
      "Epoch: 29 Step: 581 Loss: 0.3346434414066548\n",
      "Epoch: 29 Step: 591 Loss: 0.3927519876985681\n",
      "Epoch: 29 Step: 601 Loss: 0.22118773663347158\n",
      "Epoch: 29 Step: 611 Loss: 0.23910272588592865\n",
      "Epoch: 29 Step: 621 Loss: 0.1613747710452279\n",
      "Epoch: 29 Step: 631 Loss: 0.21503824460033222\n",
      "Epoch: 29 Step: 641 Loss: 0.2580547260545053\n",
      "Epoch: 29 Step: 651 Loss: 0.24429451287015885\n",
      "Epoch: 29 Step: 661 Loss: 0.09695573485060684\n",
      "Epoch: 29 Step: 671 Loss: 0.3166885651218307\n",
      "Epoch: 29 Step: 681 Loss: 0.502411538915392\n",
      "Epoch: 29 Step: 691 Loss: 0.3528917640286845\n",
      "Epoch: 29 Step: 701 Loss: 0.4451367134041211\n",
      "Epoch: 29 Step: 711 Loss: 0.4038626494006855\n",
      "Epoch: 29 Step: 721 Loss: 0.30635401399868856\n",
      "Epoch: 29 Step: 731 Loss: 0.2652123803696838\n",
      "Epoch: 29 Step: 741 Loss: 0.24326346647070113\n",
      "Epoch: 29 Step: 751 Loss: 0.4062372125725089\n",
      "Epoch: 29 Step: 761 Loss: 0.2788085221183325\n",
      "Epoch: 29 Step: 771 Loss: 0.21993814391525152\n",
      "Epoch: 29 Step: 781 Loss: 0.34481745370626754\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2263/4270478181.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/oneran/Downloads/sgd_cifar_ResNet_history.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/oneran/机器学习课设/cifar-10/Photon/sgd_cifar_ResNet.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/机器学习课设/cifar-10/Photon/ResidualModel.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X_test, Y_test)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mdatas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_GPU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_CPU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Score is {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/机器学习课设/cifar-10/Photon/ResidualModel.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mget_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mx_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mx_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mx_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mx_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/机器学习课设/cifar-10/Photon/layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mFilter_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFilter_H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFilter_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFilter_channel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0mSamples_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;31m# 计算输出的尺寸\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "model = ResNet('cifar_10', opt='sgd')\n",
    "model.load_model('/home/oneran/机器学习课设/cifar-10/Photon/sgd_cifar_ResNet.pkl')\n",
    "score, pred = model.score(X_train, Y_train)\n",
    "score, pred = model.score(X_test, Y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score is 0.8396486875800256\n",
      "Score is 0.6153846153846154\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cifar数据集 "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "model = ConvNet(datasets='cifar_10', opt='sgd')\n",
    "model.datas = [data, label]\n",
    "model.train(30)\n",
    "plt.plot(np.arange(len(model.history)), model.history)\n",
    "plt.show()\n",
    "np.savetxt('/home/oneran/Downloads/sgd_cifar_ConvNet_history.txt', model.history)\n",
    "model.save_model('/home/oneran/机器学习课设/cifar-10/Photon/sgd_cifar_ConvNet.pkl')\n",
    "score, pred = model.score(X_train, Y_train)\n",
    "score, pred = model.score(X_test, Y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 0 Step: 1 Loss: 2.302198497337784\n",
      "Epoch: 0 Step: 11 Loss: 2.2941209385511536\n",
      "Epoch: 0 Step: 21 Loss: 2.3676486491415245\n",
      "Epoch: 0 Step: 31 Loss: 2.317250169730839\n",
      "Epoch: 0 Step: 41 Loss: 2.313184019750444\n",
      "Epoch: 0 Step: 51 Loss: 2.240961586021591\n",
      "Epoch: 0 Step: 61 Loss: 2.3009356718599556\n",
      "Epoch: 0 Step: 71 Loss: 2.348367209402832\n",
      "Epoch: 0 Step: 81 Loss: 2.2322179123548764\n",
      "Epoch: 0 Step: 91 Loss: 2.3208661619049122\n",
      "Epoch: 0 Step: 101 Loss: 2.2251975609606225\n",
      "Epoch: 0 Step: 111 Loss: 2.2473436590946516\n",
      "Epoch: 0 Step: 121 Loss: 2.244464809052661\n",
      "Epoch: 0 Step: 131 Loss: 2.2393856777350107\n",
      "Epoch: 0 Step: 141 Loss: 2.3159147354141405\n",
      "Epoch: 0 Step: 151 Loss: 2.2231281676362857\n",
      "Epoch: 0 Step: 161 Loss: 2.217623472759496\n",
      "Epoch: 0 Step: 171 Loss: 2.1683150640656494\n",
      "Epoch: 0 Step: 181 Loss: 2.183780294796272\n",
      "Epoch: 0 Step: 191 Loss: 2.271454695846306\n",
      "Epoch: 0 Step: 201 Loss: 2.1194082786822435\n",
      "Epoch: 0 Step: 211 Loss: 2.211706065959497\n",
      "Epoch: 0 Step: 221 Loss: 2.252048838321432\n",
      "Epoch: 0 Step: 231 Loss: 2.220936872820033\n",
      "Epoch: 0 Step: 241 Loss: 2.2733602245236377\n",
      "Epoch: 0 Step: 251 Loss: 2.191112482302558\n",
      "Epoch: 0 Step: 261 Loss: 2.155426046421085\n",
      "Epoch: 0 Step: 271 Loss: 2.1552197231376766\n",
      "Epoch: 0 Step: 281 Loss: 2.2603527502001928\n",
      "Epoch: 0 Step: 291 Loss: 2.133794053395944\n",
      "Epoch: 0 Step: 301 Loss: 2.2842824480594244\n",
      "Epoch: 0 Step: 311 Loss: 2.2508467989401284\n",
      "Epoch: 0 Step: 321 Loss: 2.275033616709712\n",
      "Epoch: 0 Step: 331 Loss: 2.315091327878439\n",
      "Epoch: 0 Step: 341 Loss: 2.3036659610700756\n",
      "Epoch: 0 Step: 351 Loss: 2.299767029210113\n",
      "Epoch: 0 Step: 361 Loss: 2.238635491638055\n",
      "Epoch: 0 Step: 371 Loss: 2.301536658442944\n",
      "Epoch: 0 Step: 381 Loss: 2.213541203929544\n",
      "Epoch: 0 Step: 391 Loss: 2.231087770738961\n",
      "Epoch: 0 Step: 401 Loss: 2.279319652561517\n",
      "Epoch: 0 Step: 411 Loss: 2.2483331300429166\n",
      "Epoch: 0 Step: 421 Loss: 2.282532652885209\n",
      "Epoch: 0 Step: 431 Loss: 2.3865661946992622\n",
      "Epoch: 0 Step: 441 Loss: 2.3245107181996754\n",
      "Epoch: 0 Step: 451 Loss: 2.2136592148532284\n",
      "Epoch: 0 Step: 461 Loss: 2.270219197871394\n",
      "Epoch: 0 Step: 471 Loss: 2.2752031294797375\n",
      "Epoch: 0 Step: 481 Loss: 2.2241840356643805\n",
      "Epoch: 0 Step: 491 Loss: 2.2694402663005917\n",
      "Epoch: 0 Step: 501 Loss: 2.270354246761734\n",
      "Epoch: 0 Step: 511 Loss: 2.193943843987986\n",
      "Epoch: 0 Step: 521 Loss: 2.2254030858015494\n",
      "Epoch: 0 Step: 531 Loss: 2.271453564604212\n",
      "Epoch: 0 Step: 541 Loss: 2.193737631823935\n",
      "Epoch: 0 Step: 551 Loss: 2.28046172407139\n",
      "Epoch: 0 Step: 561 Loss: 2.2453794253765746\n",
      "Epoch: 0 Step: 571 Loss: 2.2359065573803725\n",
      "Epoch: 0 Step: 581 Loss: 2.2744533936220277\n",
      "Epoch: 0 Step: 591 Loss: 2.2540926990182486\n",
      "Epoch: 0 Step: 601 Loss: 2.2829135401981215\n",
      "Epoch: 0 Step: 611 Loss: 2.1526932508577055\n",
      "Epoch: 0 Step: 621 Loss: 2.220607135320514\n",
      "Epoch: 0 Step: 631 Loss: 2.245578817096135\n",
      "Epoch: 0 Step: 641 Loss: 2.301533951475467\n",
      "Epoch: 0 Step: 651 Loss: 2.2302471747628276\n",
      "Epoch: 0 Step: 661 Loss: 2.203126809565541\n",
      "Epoch: 0 Step: 671 Loss: 2.2634569901850035\n",
      "Epoch: 0 Step: 681 Loss: 2.23396322994934\n",
      "Epoch: 0 Step: 691 Loss: 2.25822961643776\n",
      "Epoch: 0 Step: 701 Loss: 2.121384244191174\n",
      "Epoch: 0 Step: 711 Loss: 2.2267557975168173\n",
      "Epoch: 0 Step: 721 Loss: 2.1748935140683305\n",
      "Epoch: 0 Step: 731 Loss: 2.153693440923867\n",
      "Epoch: 0 Step: 741 Loss: 2.287113248988754\n",
      "Epoch: 0 Step: 751 Loss: 2.1843341271021983\n",
      "Epoch: 0 Step: 761 Loss: 2.2331367971914715\n",
      "Epoch: 0 Step: 771 Loss: 2.1826800464445073\n",
      "Epoch: 0 Step: 781 Loss: 2.299413045963096\n",
      "Epoch: 1 Step: 1 Loss: 2.2838284232126878\n",
      "Epoch: 1 Step: 11 Loss: 2.1256816304347828\n",
      "Epoch: 1 Step: 21 Loss: 2.1897428308415794\n",
      "Epoch: 1 Step: 31 Loss: 2.218408454738276\n",
      "Epoch: 1 Step: 41 Loss: 2.214952542664583\n",
      "Epoch: 1 Step: 51 Loss: 2.0402955092428274\n",
      "Epoch: 1 Step: 61 Loss: 2.2895461440179727\n",
      "Epoch: 1 Step: 71 Loss: 2.2065751612080633\n",
      "Epoch: 1 Step: 81 Loss: 2.2452296545562547\n",
      "Epoch: 1 Step: 91 Loss: 2.1674137516272616\n",
      "Epoch: 1 Step: 101 Loss: 2.0865936950808965\n",
      "Epoch: 1 Step: 111 Loss: 2.0063317392181013\n",
      "Epoch: 1 Step: 121 Loss: 2.033496770948501\n",
      "Epoch: 1 Step: 131 Loss: 2.1608686837817466\n",
      "Epoch: 1 Step: 141 Loss: 2.341893556609086\n",
      "Epoch: 1 Step: 151 Loss: 1.9831405324718436\n",
      "Epoch: 1 Step: 161 Loss: 2.0896573614447482\n",
      "Epoch: 1 Step: 171 Loss: 2.042445480229606\n",
      "Epoch: 1 Step: 181 Loss: 1.956906770071496\n",
      "Epoch: 1 Step: 191 Loss: 1.9400924130569575\n",
      "Epoch: 1 Step: 201 Loss: 1.979925644706097\n",
      "Epoch: 1 Step: 211 Loss: 1.8823893288585065\n",
      "Epoch: 1 Step: 221 Loss: 2.1555983195969732\n",
      "Epoch: 1 Step: 231 Loss: 2.1508827874441856\n",
      "Epoch: 1 Step: 241 Loss: 2.0859637829326485\n",
      "Epoch: 1 Step: 251 Loss: 1.985843258548339\n",
      "Epoch: 1 Step: 261 Loss: 1.9558760596794778\n",
      "Epoch: 1 Step: 271 Loss: 2.031629312644358\n",
      "Epoch: 1 Step: 281 Loss: 1.9335036109535984\n",
      "Epoch: 1 Step: 291 Loss: 2.028847368383909\n",
      "Epoch: 1 Step: 301 Loss: 2.0398174376594564\n",
      "Epoch: 1 Step: 311 Loss: 2.0639118154385923\n",
      "Epoch: 1 Step: 321 Loss: 1.9142324044966634\n",
      "Epoch: 1 Step: 331 Loss: 1.955906033953827\n",
      "Epoch: 1 Step: 341 Loss: 2.014226482811282\n",
      "Epoch: 1 Step: 351 Loss: 2.1125577658543673\n",
      "Epoch: 1 Step: 361 Loss: 1.9923730154854893\n",
      "Epoch: 1 Step: 371 Loss: 1.8068006201758346\n",
      "Epoch: 1 Step: 381 Loss: 1.9193792780621155\n",
      "Epoch: 1 Step: 391 Loss: 2.048356189620996\n",
      "Epoch: 1 Step: 401 Loss: 2.0561205851281796\n",
      "Epoch: 1 Step: 411 Loss: 2.0314904540220855\n",
      "Epoch: 1 Step: 421 Loss: 2.08284669099642\n",
      "Epoch: 1 Step: 431 Loss: 1.9382260079723632\n",
      "Epoch: 1 Step: 441 Loss: 2.11709884121643\n",
      "Epoch: 1 Step: 451 Loss: 1.9619094853716863\n",
      "Epoch: 1 Step: 461 Loss: 1.9240896339895277\n",
      "Epoch: 1 Step: 471 Loss: 1.9891151567715246\n",
      "Epoch: 1 Step: 481 Loss: 2.1418226635275683\n",
      "Epoch: 1 Step: 491 Loss: 2.0197749548476076\n",
      "Epoch: 1 Step: 501 Loss: 1.9905421997302235\n",
      "Epoch: 1 Step: 511 Loss: 2.0894310293286975\n",
      "Epoch: 1 Step: 521 Loss: 1.9584715299094413\n",
      "Epoch: 1 Step: 531 Loss: 1.9615166271036657\n",
      "Epoch: 1 Step: 541 Loss: 1.9048111507484125\n",
      "Epoch: 1 Step: 551 Loss: 1.8958586140697173\n",
      "Epoch: 1 Step: 561 Loss: 1.8856987536702858\n",
      "Epoch: 1 Step: 571 Loss: 1.910792375705923\n",
      "Epoch: 1 Step: 581 Loss: 1.9990512150870337\n",
      "Epoch: 1 Step: 591 Loss: 1.91216364476829\n",
      "Epoch: 1 Step: 601 Loss: 2.09030423438567\n",
      "Epoch: 1 Step: 611 Loss: 1.9782898703752902\n",
      "Epoch: 1 Step: 621 Loss: 1.9494008715597275\n",
      "Epoch: 1 Step: 631 Loss: 2.0107763435692587\n",
      "Epoch: 1 Step: 641 Loss: 1.952559790466596\n",
      "Epoch: 1 Step: 651 Loss: 1.8970323488708063\n",
      "Epoch: 1 Step: 661 Loss: 1.9426902869926341\n",
      "Epoch: 1 Step: 671 Loss: 2.0465029194963904\n",
      "Epoch: 1 Step: 681 Loss: 1.9614111429869396\n",
      "Epoch: 1 Step: 691 Loss: 2.031235358001381\n",
      "Epoch: 1 Step: 701 Loss: 1.7761637220621505\n",
      "Epoch: 1 Step: 711 Loss: 2.0075229587125167\n",
      "Epoch: 1 Step: 721 Loss: 1.7948246841285425\n",
      "Epoch: 1 Step: 731 Loss: 1.8040962615274407\n",
      "Epoch: 1 Step: 741 Loss: 2.0738951890541473\n",
      "Epoch: 1 Step: 751 Loss: 2.2019472816895638\n",
      "Epoch: 1 Step: 761 Loss: 1.9572566491670091\n",
      "Epoch: 1 Step: 771 Loss: 2.0074290937009995\n",
      "Epoch: 1 Step: 781 Loss: 2.1282667962813093\n",
      "Epoch: 2 Step: 1 Loss: 2.0350531015276276\n",
      "Epoch: 2 Step: 11 Loss: 1.8994110780107882\n",
      "Epoch: 2 Step: 21 Loss: 2.0842578249309236\n",
      "Epoch: 2 Step: 31 Loss: 2.028178479368046\n",
      "Epoch: 2 Step: 41 Loss: 1.9884810462091325\n",
      "Epoch: 2 Step: 51 Loss: 1.8596610584959725\n",
      "Epoch: 2 Step: 61 Loss: 2.1338031998291926\n",
      "Epoch: 2 Step: 71 Loss: 1.9878550178535581\n",
      "Epoch: 2 Step: 81 Loss: 2.0931002950446254\n",
      "Epoch: 2 Step: 91 Loss: 2.0363753683089785\n",
      "Epoch: 2 Step: 101 Loss: 1.9133984421661892\n",
      "Epoch: 2 Step: 111 Loss: 1.777315041925624\n",
      "Epoch: 2 Step: 121 Loss: 1.9955241528278158\n",
      "Epoch: 2 Step: 131 Loss: 2.1313336569781725\n",
      "Epoch: 2 Step: 141 Loss: 2.115171780786032\n",
      "Epoch: 2 Step: 151 Loss: 1.7855962466182485\n",
      "Epoch: 2 Step: 161 Loss: 1.9442786749476935\n",
      "Epoch: 2 Step: 171 Loss: 2.0401568334541533\n",
      "Epoch: 2 Step: 181 Loss: 1.7803247793950794\n",
      "Epoch: 2 Step: 191 Loss: 1.7292950285252595\n",
      "Epoch: 2 Step: 201 Loss: 1.8850050474670614\n",
      "Epoch: 2 Step: 211 Loss: 1.9214594704823893\n",
      "Epoch: 2 Step: 221 Loss: 2.0447208693718384\n",
      "Epoch: 2 Step: 231 Loss: 1.8958994793261925\n",
      "Epoch: 2 Step: 241 Loss: 2.02537094708597\n",
      "Epoch: 2 Step: 251 Loss: 1.8268985092889913\n",
      "Epoch: 2 Step: 261 Loss: 1.8529974440804324\n",
      "Epoch: 2 Step: 271 Loss: 1.8821378774095563\n",
      "Epoch: 2 Step: 281 Loss: 1.8884942317873032\n",
      "Epoch: 2 Step: 291 Loss: 1.8778552757426472\n",
      "Epoch: 2 Step: 301 Loss: 2.013156424298871\n",
      "Epoch: 2 Step: 311 Loss: 1.8913666145934083\n",
      "Epoch: 2 Step: 321 Loss: 1.822254363137377\n",
      "Epoch: 2 Step: 331 Loss: 1.900585954282194\n",
      "Epoch: 2 Step: 341 Loss: 2.0065883520177894\n",
      "Epoch: 2 Step: 351 Loss: 1.8812691124750054\n",
      "Epoch: 2 Step: 361 Loss: 1.9038229534703066\n",
      "Epoch: 2 Step: 371 Loss: 1.8185773489857207\n",
      "Epoch: 2 Step: 381 Loss: 1.8142051748615506\n",
      "Epoch: 2 Step: 391 Loss: 1.9938846101495495\n",
      "Epoch: 2 Step: 401 Loss: 2.025196046294599\n",
      "Epoch: 2 Step: 411 Loss: 1.949598649296502\n",
      "Epoch: 2 Step: 421 Loss: 1.976071199171414\n",
      "Epoch: 2 Step: 431 Loss: 1.9228850670868558\n",
      "Epoch: 2 Step: 441 Loss: 2.133132391604664\n",
      "Epoch: 2 Step: 451 Loss: 1.8803384130110985\n",
      "Epoch: 2 Step: 461 Loss: 1.863657252617736\n",
      "Epoch: 2 Step: 471 Loss: 1.9282409876861215\n",
      "Epoch: 2 Step: 481 Loss: 2.0238542225468694\n",
      "Epoch: 2 Step: 491 Loss: 2.0586344737188886\n",
      "Epoch: 2 Step: 501 Loss: 1.9816285736721908\n",
      "Epoch: 2 Step: 511 Loss: 1.9789190164439088\n",
      "Epoch: 2 Step: 521 Loss: 1.9577615149632313\n",
      "Epoch: 2 Step: 531 Loss: 1.961420401523533\n",
      "Epoch: 2 Step: 541 Loss: 1.824823291434083\n",
      "Epoch: 2 Step: 551 Loss: 1.808894823219581\n",
      "Epoch: 2 Step: 561 Loss: 1.769296098725249\n",
      "Epoch: 2 Step: 571 Loss: 1.7968505080966355\n",
      "Epoch: 2 Step: 581 Loss: 2.0514764836400303\n",
      "Epoch: 2 Step: 591 Loss: 1.8624051263559411\n",
      "Epoch: 2 Step: 601 Loss: 2.0975351616089912\n",
      "Epoch: 2 Step: 611 Loss: 1.8372694481912435\n",
      "Epoch: 2 Step: 621 Loss: 1.8159761717389997\n",
      "Epoch: 2 Step: 631 Loss: 1.8895459703575477\n",
      "Epoch: 2 Step: 641 Loss: 1.9082825058011044\n",
      "Epoch: 2 Step: 651 Loss: 1.9055269602264562\n",
      "Epoch: 2 Step: 661 Loss: 1.9986062727730367\n",
      "Epoch: 2 Step: 671 Loss: 1.962308039341818\n",
      "Epoch: 2 Step: 681 Loss: 1.9791500708377607\n",
      "Epoch: 2 Step: 691 Loss: 1.9586300367808844\n",
      "Epoch: 2 Step: 701 Loss: 1.9102298636820572\n",
      "Epoch: 2 Step: 711 Loss: 2.0625235295528226\n",
      "Epoch: 2 Step: 721 Loss: 1.7027522892922702\n",
      "Epoch: 2 Step: 731 Loss: 1.6995386176817489\n",
      "Epoch: 2 Step: 741 Loss: 1.9504119372057453\n",
      "Epoch: 2 Step: 751 Loss: 2.127927410815021\n",
      "Epoch: 2 Step: 761 Loss: 1.8383133850282194\n",
      "Epoch: 2 Step: 771 Loss: 1.9661087516113658\n",
      "Epoch: 2 Step: 781 Loss: 2.0677616782702652\n",
      "Epoch: 3 Step: 1 Loss: 1.9538168869201213\n",
      "Epoch: 3 Step: 11 Loss: 1.8762037798800557\n",
      "Epoch: 3 Step: 21 Loss: 1.9428619502682993\n",
      "Epoch: 3 Step: 31 Loss: 1.8555520935838392\n",
      "Epoch: 3 Step: 41 Loss: 1.8722144161549925\n",
      "Epoch: 3 Step: 51 Loss: 1.8425261817742213\n",
      "Epoch: 3 Step: 61 Loss: 1.9985608483270394\n",
      "Epoch: 3 Step: 71 Loss: 1.908992633081273\n",
      "Epoch: 3 Step: 81 Loss: 1.9963504746690348\n",
      "Epoch: 3 Step: 91 Loss: 1.892494495035237\n",
      "Epoch: 3 Step: 101 Loss: 1.7944442688630025\n",
      "Epoch: 3 Step: 111 Loss: 1.8380098925380368\n",
      "Epoch: 3 Step: 121 Loss: 1.9573444103618647\n",
      "Epoch: 3 Step: 131 Loss: 1.9822726265224189\n",
      "Epoch: 3 Step: 141 Loss: 2.076867072369819\n",
      "Epoch: 3 Step: 151 Loss: 1.6928869682680998\n",
      "Epoch: 3 Step: 161 Loss: 1.9776669368951822\n",
      "Epoch: 3 Step: 171 Loss: 2.0123423453209126\n",
      "Epoch: 3 Step: 181 Loss: 1.8169534863631287\n",
      "Epoch: 3 Step: 191 Loss: 1.7081008451509632\n",
      "Epoch: 3 Step: 201 Loss: 1.7399257985673144\n",
      "Epoch: 3 Step: 211 Loss: 1.8263963590275958\n",
      "Epoch: 3 Step: 221 Loss: 2.068902673682662\n",
      "Epoch: 3 Step: 231 Loss: 1.8847328447298168\n",
      "Epoch: 3 Step: 241 Loss: 1.996969044335674\n",
      "Epoch: 3 Step: 251 Loss: 1.8258908748783764\n",
      "Epoch: 3 Step: 261 Loss: 1.8916540776239745\n",
      "Epoch: 3 Step: 271 Loss: 1.823346528288724\n",
      "Epoch: 3 Step: 281 Loss: 1.7816405138651268\n",
      "Epoch: 3 Step: 291 Loss: 1.843825812686555\n",
      "Epoch: 3 Step: 301 Loss: 1.8847809645154596\n",
      "Epoch: 3 Step: 311 Loss: 1.8653995365186644\n",
      "Epoch: 3 Step: 321 Loss: 1.7452809765379618\n",
      "Epoch: 3 Step: 331 Loss: 1.8148761955005908\n",
      "Epoch: 3 Step: 341 Loss: 1.8903250948303119\n",
      "Epoch: 3 Step: 351 Loss: 1.8237586141082112\n",
      "Epoch: 3 Step: 361 Loss: 1.8637771009177633\n",
      "Epoch: 3 Step: 371 Loss: 1.6760558299067103\n",
      "Epoch: 3 Step: 381 Loss: 1.8241949887962343\n",
      "Epoch: 3 Step: 391 Loss: 1.8420324885492125\n",
      "Epoch: 3 Step: 401 Loss: 2.058979759286847\n",
      "Epoch: 3 Step: 411 Loss: 1.9550280016180643\n",
      "Epoch: 3 Step: 421 Loss: 2.040123286599747\n",
      "Epoch: 3 Step: 431 Loss: 1.876797971374829\n",
      "Epoch: 3 Step: 441 Loss: 2.016402178577195\n",
      "Epoch: 3 Step: 451 Loss: 1.810460085751008\n",
      "Epoch: 3 Step: 461 Loss: 1.8426804050614252\n",
      "Epoch: 3 Step: 471 Loss: 1.7887269205225977\n",
      "Epoch: 3 Step: 481 Loss: 1.9694189821552748\n",
      "Epoch: 3 Step: 491 Loss: 2.0037580500182326\n",
      "Epoch: 3 Step: 501 Loss: 1.954682233080112\n",
      "Epoch: 3 Step: 511 Loss: 1.9067541161704464\n",
      "Epoch: 3 Step: 521 Loss: 1.865585056581804\n",
      "Epoch: 3 Step: 531 Loss: 1.8884757373125713\n",
      "Epoch: 3 Step: 541 Loss: 1.7973569587040465\n",
      "Epoch: 3 Step: 551 Loss: 1.6743236466591576\n",
      "Epoch: 3 Step: 561 Loss: 1.7069296168531662\n",
      "Epoch: 3 Step: 571 Loss: 1.7853150863064675\n",
      "Epoch: 3 Step: 581 Loss: 1.9524281430883086\n",
      "Epoch: 3 Step: 591 Loss: 1.7957725361735233\n",
      "Epoch: 3 Step: 601 Loss: 1.9999797924181555\n",
      "Epoch: 3 Step: 611 Loss: 1.830253062462981\n",
      "Epoch: 3 Step: 621 Loss: 1.7908870195708608\n",
      "Epoch: 3 Step: 631 Loss: 1.7691540233367689\n",
      "Epoch: 3 Step: 641 Loss: 1.8199105636170958\n",
      "Epoch: 3 Step: 651 Loss: 1.7892543107208627\n",
      "Epoch: 3 Step: 661 Loss: 1.9716352539811142\n",
      "Epoch: 3 Step: 671 Loss: 1.9388210969665944\n",
      "Epoch: 3 Step: 681 Loss: 2.034569953311282\n",
      "Epoch: 3 Step: 691 Loss: 1.8962896501171378\n",
      "Epoch: 3 Step: 701 Loss: 1.7692831860320453\n",
      "Epoch: 3 Step: 711 Loss: 1.9632937571246756\n",
      "Epoch: 3 Step: 721 Loss: 1.7212856280575883\n",
      "Epoch: 3 Step: 731 Loss: 1.7140561169509458\n",
      "Epoch: 3 Step: 741 Loss: 1.9276442937787328\n",
      "Epoch: 3 Step: 751 Loss: 1.990519781974887\n",
      "Epoch: 3 Step: 761 Loss: 1.9488460428541954\n",
      "Epoch: 3 Step: 771 Loss: 1.9949192820212072\n",
      "Epoch: 3 Step: 781 Loss: 2.0344355280600426\n",
      "Epoch: 4 Step: 1 Loss: 1.9863911974576336\n",
      "Epoch: 4 Step: 11 Loss: 1.7461255248429428\n",
      "Epoch: 4 Step: 21 Loss: 1.9997917348412362\n",
      "Epoch: 4 Step: 31 Loss: 1.8290434256425216\n",
      "Epoch: 4 Step: 41 Loss: 1.7290581268485012\n",
      "Epoch: 4 Step: 51 Loss: 1.779165717859932\n",
      "Epoch: 4 Step: 61 Loss: 1.8369175924262398\n",
      "Epoch: 4 Step: 71 Loss: 1.9080701657076098\n",
      "Epoch: 4 Step: 81 Loss: 1.9138875010476957\n",
      "Epoch: 4 Step: 91 Loss: 1.8496396066340512\n",
      "Epoch: 4 Step: 101 Loss: 1.7547669695339319\n",
      "Epoch: 4 Step: 111 Loss: 1.7878886096891704\n",
      "Epoch: 4 Step: 121 Loss: 1.9543804758162124\n",
      "Epoch: 4 Step: 131 Loss: 2.061528002831376\n",
      "Epoch: 4 Step: 141 Loss: 2.254226228971437\n",
      "Epoch: 4 Step: 151 Loss: 1.7423175530121249\n",
      "Epoch: 4 Step: 161 Loss: 1.9391354064635833\n",
      "Epoch: 4 Step: 171 Loss: 1.9645747769011106\n",
      "Epoch: 4 Step: 181 Loss: 1.8404512228504808\n",
      "Epoch: 4 Step: 191 Loss: 1.723524124614938\n",
      "Epoch: 4 Step: 201 Loss: 1.7768934628929145\n",
      "Epoch: 4 Step: 211 Loss: 1.9574120533431003\n",
      "Epoch: 4 Step: 221 Loss: 2.006096364029895\n",
      "Epoch: 4 Step: 231 Loss: 1.8224592015480432\n",
      "Epoch: 4 Step: 241 Loss: 1.9092898376417717\n",
      "Epoch: 4 Step: 251 Loss: 1.8416916491938848\n",
      "Epoch: 4 Step: 261 Loss: 1.7177808668811552\n",
      "Epoch: 4 Step: 271 Loss: 1.8453244086716745\n",
      "Epoch: 4 Step: 281 Loss: 1.6555313603210016\n",
      "Epoch: 4 Step: 291 Loss: 1.8265741546964431\n",
      "Epoch: 4 Step: 301 Loss: 1.8312411959609967\n",
      "Epoch: 4 Step: 311 Loss: 1.7919525959466214\n",
      "Epoch: 4 Step: 321 Loss: 1.8237882950659676\n",
      "Epoch: 4 Step: 331 Loss: 1.780858733646662\n",
      "Epoch: 4 Step: 341 Loss: 1.8610219397501957\n",
      "Epoch: 4 Step: 351 Loss: 1.7416812487765667\n",
      "Epoch: 4 Step: 361 Loss: 1.8616468267768034\n",
      "Epoch: 4 Step: 371 Loss: 1.6349467226483496\n",
      "Epoch: 4 Step: 381 Loss: 1.8590693587398905\n",
      "Epoch: 4 Step: 391 Loss: 1.8645006790345358\n",
      "Epoch: 4 Step: 401 Loss: 1.9573750118221485\n",
      "Epoch: 4 Step: 411 Loss: 1.852283428307373\n",
      "Epoch: 4 Step: 421 Loss: 1.9129176910953867\n",
      "Epoch: 4 Step: 431 Loss: 1.7917894225079536\n",
      "Epoch: 4 Step: 441 Loss: 2.052321208366547\n",
      "Epoch: 4 Step: 451 Loss: 1.7064922899642978\n",
      "Epoch: 4 Step: 461 Loss: 1.853303253015643\n",
      "Epoch: 4 Step: 471 Loss: 1.8302184780203932\n",
      "Epoch: 4 Step: 481 Loss: 1.8044931789799745\n",
      "Epoch: 4 Step: 491 Loss: 2.042042793196622\n",
      "Epoch: 4 Step: 501 Loss: 1.9190692100072377\n",
      "Epoch: 4 Step: 511 Loss: 1.8383666588005103\n",
      "Epoch: 4 Step: 521 Loss: 1.8081886333367096\n",
      "Epoch: 4 Step: 531 Loss: 1.7621204934724641\n",
      "Epoch: 4 Step: 541 Loss: 1.743139066002818\n",
      "Epoch: 4 Step: 551 Loss: 1.6342382181208086\n",
      "Epoch: 4 Step: 561 Loss: 1.7603526644903198\n",
      "Epoch: 4 Step: 571 Loss: 1.7341492740327777\n",
      "Epoch: 4 Step: 581 Loss: 1.8529029053346378\n",
      "Epoch: 4 Step: 591 Loss: 1.781532320989907\n",
      "Epoch: 4 Step: 601 Loss: 1.9446451401470886\n",
      "Epoch: 4 Step: 611 Loss: 1.8348057278885095\n",
      "Epoch: 4 Step: 621 Loss: 1.7690519281351285\n",
      "Epoch: 4 Step: 631 Loss: 1.8514472492484966\n",
      "Epoch: 4 Step: 641 Loss: 1.9264022464315325\n",
      "Epoch: 4 Step: 651 Loss: 1.744591686512731\n",
      "Epoch: 4 Step: 661 Loss: 2.0020508694272285\n",
      "Epoch: 4 Step: 671 Loss: 1.7784134357120502\n",
      "Epoch: 4 Step: 681 Loss: 1.880570622336685\n",
      "Epoch: 4 Step: 691 Loss: 1.8634885897478943\n",
      "Epoch: 4 Step: 701 Loss: 1.7205613222737843\n",
      "Epoch: 4 Step: 711 Loss: 1.8835131988614904\n",
      "Epoch: 4 Step: 721 Loss: 1.6162791599503852\n",
      "Epoch: 4 Step: 731 Loss: 1.6024747572996956\n",
      "Epoch: 4 Step: 741 Loss: 1.8873248482280554\n",
      "Epoch: 4 Step: 751 Loss: 1.978959694393629\n",
      "Epoch: 4 Step: 761 Loss: 1.7455489499632675\n",
      "Epoch: 4 Step: 771 Loss: 1.9004019321999808\n",
      "Epoch: 4 Step: 781 Loss: 1.9277320880465503\n",
      "Epoch: 5 Step: 1 Loss: 1.9224908078276337\n",
      "Epoch: 5 Step: 11 Loss: 1.8345946437564844\n",
      "Epoch: 5 Step: 21 Loss: 1.997735560582791\n",
      "Epoch: 5 Step: 31 Loss: 1.8785764279618886\n",
      "Epoch: 5 Step: 41 Loss: 1.7386329797335116\n",
      "Epoch: 5 Step: 51 Loss: 1.709833422698896\n",
      "Epoch: 5 Step: 61 Loss: 1.8425095052647982\n",
      "Epoch: 5 Step: 71 Loss: 1.943833033461234\n",
      "Epoch: 5 Step: 81 Loss: 1.9123488825622146\n",
      "Epoch: 5 Step: 91 Loss: 1.774964600435212\n",
      "Epoch: 5 Step: 101 Loss: 1.937917693427258\n",
      "Epoch: 5 Step: 111 Loss: 1.901013292080333\n",
      "Epoch: 5 Step: 121 Loss: 1.855102918786039\n",
      "Epoch: 5 Step: 131 Loss: 1.9056370273969248\n",
      "Epoch: 5 Step: 141 Loss: 2.2978243614355005\n",
      "Epoch: 5 Step: 151 Loss: 1.5925985674943544\n",
      "Epoch: 5 Step: 161 Loss: 1.7517528642230902\n",
      "Epoch: 5 Step: 171 Loss: 1.8542550515885206\n",
      "Epoch: 5 Step: 181 Loss: 1.6592754485118162\n",
      "Epoch: 5 Step: 191 Loss: 1.6929230676690148\n",
      "Epoch: 5 Step: 201 Loss: 1.5580733982113497\n",
      "Epoch: 5 Step: 211 Loss: 1.6268269078792508\n",
      "Epoch: 5 Step: 221 Loss: 2.0058176526771887\n",
      "Epoch: 5 Step: 231 Loss: 1.7831183227750353\n",
      "Epoch: 5 Step: 241 Loss: 1.8529750944042054\n",
      "Epoch: 5 Step: 251 Loss: 1.7763911013539806\n",
      "Epoch: 5 Step: 261 Loss: 1.6096288298787496\n",
      "Epoch: 5 Step: 271 Loss: 1.7869638732792468\n",
      "Epoch: 5 Step: 281 Loss: 1.6604091849264961\n",
      "Epoch: 5 Step: 291 Loss: 1.7138231249157174\n",
      "Epoch: 5 Step: 301 Loss: 1.7477859941671738\n",
      "Epoch: 5 Step: 311 Loss: 1.749916187342211\n",
      "Epoch: 5 Step: 321 Loss: 1.7334806086731207\n",
      "Epoch: 5 Step: 331 Loss: 1.6829961827459001\n",
      "Epoch: 5 Step: 341 Loss: 1.9389202773771474\n",
      "Epoch: 5 Step: 351 Loss: 1.880292862557422\n",
      "Epoch: 5 Step: 361 Loss: 1.8836881660292157\n",
      "Epoch: 5 Step: 371 Loss: 1.6147172708129833\n",
      "Epoch: 5 Step: 381 Loss: 1.8484947702315297\n",
      "Epoch: 5 Step: 391 Loss: 1.8497583018152532\n",
      "Epoch: 5 Step: 401 Loss: 1.842048652628983\n",
      "Epoch: 5 Step: 411 Loss: 1.870096854515042\n",
      "Epoch: 5 Step: 421 Loss: 1.8351993293472857\n",
      "Epoch: 5 Step: 431 Loss: 1.6984725644572465\n",
      "Epoch: 5 Step: 441 Loss: 1.9901312349538944\n",
      "Epoch: 5 Step: 451 Loss: 1.6362854808431635\n",
      "Epoch: 5 Step: 461 Loss: 1.7646448610608232\n",
      "Epoch: 5 Step: 471 Loss: 1.689192638049597\n",
      "Epoch: 5 Step: 481 Loss: 1.8444811751426506\n",
      "Epoch: 5 Step: 491 Loss: 1.9987467576024796\n",
      "Epoch: 5 Step: 501 Loss: 1.7905273104875101\n",
      "Epoch: 5 Step: 511 Loss: 1.7630228283767808\n",
      "Epoch: 5 Step: 521 Loss: 1.7591874879385503\n",
      "Epoch: 5 Step: 531 Loss: 1.9167625743723542\n",
      "Epoch: 5 Step: 541 Loss: 1.7208046498626262\n",
      "Epoch: 5 Step: 551 Loss: 1.6060239835681265\n",
      "Epoch: 5 Step: 561 Loss: 1.7012130360118274\n",
      "Epoch: 5 Step: 571 Loss: 1.6780234851419085\n",
      "Epoch: 5 Step: 581 Loss: 1.8135360844248187\n",
      "Epoch: 5 Step: 591 Loss: 1.878709692056237\n",
      "Epoch: 5 Step: 601 Loss: 1.9632934548860121\n",
      "Epoch: 5 Step: 611 Loss: 1.724104790473541\n",
      "Epoch: 5 Step: 621 Loss: 1.7063845768293149\n",
      "Epoch: 5 Step: 631 Loss: 1.8009860525818833\n",
      "Epoch: 5 Step: 641 Loss: 1.9076421438695448\n",
      "Epoch: 5 Step: 651 Loss: 1.742728922531449\n",
      "Epoch: 5 Step: 661 Loss: 1.9279044679472137\n",
      "Epoch: 5 Step: 671 Loss: 1.8740084714472913\n",
      "Epoch: 5 Step: 681 Loss: 1.96198737688464\n",
      "Epoch: 5 Step: 691 Loss: 1.878514244962964\n",
      "Epoch: 5 Step: 701 Loss: 1.7003391497801486\n",
      "Epoch: 5 Step: 711 Loss: 1.9588767296540652\n",
      "Epoch: 5 Step: 721 Loss: 1.7468827680986405\n",
      "Epoch: 5 Step: 731 Loss: 1.5535989960692578\n",
      "Epoch: 5 Step: 741 Loss: 1.8426967356236947\n",
      "Epoch: 5 Step: 751 Loss: 1.965517782798137\n",
      "Epoch: 5 Step: 761 Loss: 1.8021991898460878\n",
      "Epoch: 5 Step: 771 Loss: 1.89999298020538\n",
      "Epoch: 5 Step: 781 Loss: 1.8017148379153598\n",
      "Epoch: 6 Step: 1 Loss: 1.9304904589400056\n",
      "Epoch: 6 Step: 11 Loss: 1.8295346216760642\n",
      "Epoch: 6 Step: 21 Loss: 1.8968326289578323\n",
      "Epoch: 6 Step: 31 Loss: 1.8803233455419788\n",
      "Epoch: 6 Step: 41 Loss: 1.777969469143205\n",
      "Epoch: 6 Step: 51 Loss: 1.7584486835167836\n",
      "Epoch: 6 Step: 61 Loss: 1.9029396798046936\n",
      "Epoch: 6 Step: 71 Loss: 1.8744366084786837\n",
      "Epoch: 6 Step: 81 Loss: 1.99704922824251\n",
      "Epoch: 6 Step: 91 Loss: 1.7289474881170497\n",
      "Epoch: 6 Step: 101 Loss: 1.8916248005751048\n",
      "Epoch: 6 Step: 111 Loss: 1.9015734016307386\n",
      "Epoch: 6 Step: 121 Loss: 1.859946358399999\n",
      "Epoch: 6 Step: 131 Loss: 1.9518509313936088\n",
      "Epoch: 6 Step: 141 Loss: 2.1708355489754467\n",
      "Epoch: 6 Step: 151 Loss: 1.7056839603268745\n",
      "Epoch: 6 Step: 161 Loss: 1.8486536978835126\n",
      "Epoch: 6 Step: 171 Loss: 1.8585580568997564\n",
      "Epoch: 6 Step: 181 Loss: 1.691813557042472\n",
      "Epoch: 6 Step: 191 Loss: 1.7056114477664246\n",
      "Epoch: 6 Step: 201 Loss: 1.5848809780585023\n",
      "Epoch: 6 Step: 211 Loss: 1.7067784746674097\n",
      "Epoch: 6 Step: 221 Loss: 1.9347089699813493\n",
      "Epoch: 6 Step: 231 Loss: 1.7534934118663945\n",
      "Epoch: 6 Step: 241 Loss: 1.8696067407646313\n",
      "Epoch: 6 Step: 251 Loss: 1.7512552395454446\n",
      "Epoch: 6 Step: 261 Loss: 1.697500579040808\n",
      "Epoch: 6 Step: 271 Loss: 1.7931362213045468\n",
      "Epoch: 6 Step: 281 Loss: 1.7158744787635158\n",
      "Epoch: 6 Step: 291 Loss: 1.7473952194761342\n",
      "Epoch: 6 Step: 301 Loss: 1.828523767851514\n",
      "Epoch: 6 Step: 311 Loss: 1.7822794125380232\n",
      "Epoch: 6 Step: 321 Loss: 1.7462771001271917\n",
      "Epoch: 6 Step: 331 Loss: 1.7418749015061472\n",
      "Epoch: 6 Step: 341 Loss: 1.8726115327988606\n",
      "Epoch: 6 Step: 351 Loss: 1.7533734050661043\n",
      "Epoch: 6 Step: 361 Loss: 1.80872058206123\n",
      "Epoch: 6 Step: 371 Loss: 1.7128749125778844\n",
      "Epoch: 6 Step: 381 Loss: 1.7309188030971703\n",
      "Epoch: 6 Step: 391 Loss: 1.7481671272155426\n",
      "Epoch: 6 Step: 401 Loss: 1.7412650695764131\n",
      "Epoch: 6 Step: 411 Loss: 1.8967332214959496\n",
      "Epoch: 6 Step: 421 Loss: 1.717058077185741\n",
      "Epoch: 6 Step: 431 Loss: 1.796242390090086\n",
      "Epoch: 6 Step: 441 Loss: 1.9221740014947803\n",
      "Epoch: 6 Step: 451 Loss: 1.635161986910068\n",
      "Epoch: 6 Step: 461 Loss: 1.6869182266264455\n",
      "Epoch: 6 Step: 471 Loss: 1.7081944497982688\n",
      "Epoch: 6 Step: 481 Loss: 1.8083435545985618\n",
      "Epoch: 6 Step: 491 Loss: 2.0119488430759187\n",
      "Epoch: 6 Step: 501 Loss: 1.7397702219454045\n",
      "Epoch: 6 Step: 511 Loss: 1.8190761266021491\n",
      "Epoch: 6 Step: 521 Loss: 1.73499761508516\n",
      "Epoch: 6 Step: 531 Loss: 1.8304160633367905\n",
      "Epoch: 6 Step: 541 Loss: 1.829749528745419\n",
      "Epoch: 6 Step: 551 Loss: 1.635536076607012\n",
      "Epoch: 6 Step: 561 Loss: 1.7289299538502965\n",
      "Epoch: 6 Step: 571 Loss: 1.7673535816017463\n",
      "Epoch: 6 Step: 581 Loss: 1.840605979213415\n",
      "Epoch: 6 Step: 591 Loss: 1.7398434449293516\n",
      "Epoch: 6 Step: 601 Loss: 1.987658498601331\n",
      "Epoch: 6 Step: 611 Loss: 1.6849378256619845\n",
      "Epoch: 6 Step: 621 Loss: 1.8370566657488079\n",
      "Epoch: 6 Step: 631 Loss: 1.8048082848210534\n",
      "Epoch: 6 Step: 641 Loss: 1.8364031641130576\n",
      "Epoch: 6 Step: 651 Loss: 1.714356623151359\n",
      "Epoch: 6 Step: 661 Loss: 1.8341976768310193\n",
      "Epoch: 6 Step: 671 Loss: 1.8677010133681278\n",
      "Epoch: 6 Step: 681 Loss: 1.9582736639804463\n",
      "Epoch: 6 Step: 691 Loss: 1.6749936464550583\n",
      "Epoch: 6 Step: 701 Loss: 1.6522003999717054\n",
      "Epoch: 6 Step: 711 Loss: 1.8682201868189459\n",
      "Epoch: 6 Step: 721 Loss: 1.6062535527030652\n",
      "Epoch: 6 Step: 731 Loss: 1.5143529205272552\n",
      "Epoch: 6 Step: 741 Loss: 1.6815888350407266\n",
      "Epoch: 6 Step: 751 Loss: 1.9174461627018238\n",
      "Epoch: 6 Step: 761 Loss: 1.7524047665267077\n",
      "Epoch: 6 Step: 771 Loss: 1.7828630318008463\n",
      "Epoch: 6 Step: 781 Loss: 1.7476139523602094\n",
      "Epoch: 7 Step: 1 Loss: 1.8320279397811812\n",
      "Epoch: 7 Step: 11 Loss: 1.8197937822438939\n",
      "Epoch: 7 Step: 21 Loss: 1.8780382189566556\n",
      "Epoch: 7 Step: 31 Loss: 1.8601312600620918\n",
      "Epoch: 7 Step: 41 Loss: 1.696066063207488\n",
      "Epoch: 7 Step: 51 Loss: 1.6037275234451747\n",
      "Epoch: 7 Step: 61 Loss: 1.7395206471790652\n",
      "Epoch: 7 Step: 71 Loss: 1.804153460958553\n",
      "Epoch: 7 Step: 81 Loss: 1.8200330547706982\n",
      "Epoch: 7 Step: 91 Loss: 1.706346845572398\n",
      "Epoch: 7 Step: 101 Loss: 1.9738348723968484\n",
      "Epoch: 7 Step: 111 Loss: 1.6651612987974456\n",
      "Epoch: 7 Step: 121 Loss: 1.755055126176277\n",
      "Epoch: 7 Step: 131 Loss: 1.7303669152214105\n",
      "Epoch: 7 Step: 141 Loss: 2.148624833857826\n",
      "Epoch: 7 Step: 151 Loss: 1.5642684814969416\n",
      "Epoch: 7 Step: 161 Loss: 1.6364610566599789\n",
      "Epoch: 7 Step: 171 Loss: 1.7255254165146228\n",
      "Epoch: 7 Step: 181 Loss: 1.6327546703762188\n",
      "Epoch: 7 Step: 191 Loss: 1.5630260126883322\n",
      "Epoch: 7 Step: 201 Loss: 1.4511896794866406\n",
      "Epoch: 7 Step: 211 Loss: 1.5681799643967802\n",
      "Epoch: 7 Step: 221 Loss: 1.8022828820192824\n",
      "Epoch: 7 Step: 231 Loss: 1.6965897563157188\n",
      "Epoch: 7 Step: 241 Loss: 1.7413065163058794\n",
      "Epoch: 7 Step: 251 Loss: 1.5862837873001463\n",
      "Epoch: 7 Step: 261 Loss: 1.7067777818401626\n",
      "Epoch: 7 Step: 271 Loss: 1.7196684405239813\n",
      "Epoch: 7 Step: 281 Loss: 1.6175976647332524\n",
      "Epoch: 7 Step: 291 Loss: 1.7386237075175774\n",
      "Epoch: 7 Step: 301 Loss: 1.7751903560747202\n",
      "Epoch: 7 Step: 311 Loss: 1.7726025997306523\n",
      "Epoch: 7 Step: 321 Loss: 1.6339709020733189\n",
      "Epoch: 7 Step: 331 Loss: 1.7123698447353595\n",
      "Epoch: 7 Step: 341 Loss: 1.9123846569363296\n",
      "Epoch: 7 Step: 351 Loss: 1.7726335104801636\n",
      "Epoch: 7 Step: 361 Loss: 1.8252000314757881\n",
      "Epoch: 7 Step: 371 Loss: 1.5878561929078967\n",
      "Epoch: 7 Step: 381 Loss: 1.6962241958132027\n",
      "Epoch: 7 Step: 391 Loss: 1.7185521946470201\n",
      "Epoch: 7 Step: 401 Loss: 1.696292533133245\n",
      "Epoch: 7 Step: 411 Loss: 1.7039211474251683\n",
      "Epoch: 7 Step: 421 Loss: 1.7431622687335238\n",
      "Epoch: 7 Step: 431 Loss: 1.695324764295987\n",
      "Epoch: 7 Step: 441 Loss: 1.8461053403296042\n",
      "Epoch: 7 Step: 451 Loss: 1.521531963989322\n",
      "Epoch: 7 Step: 461 Loss: 1.6683408716934518\n",
      "Epoch: 7 Step: 471 Loss: 1.6594043440219908\n",
      "Epoch: 7 Step: 481 Loss: 1.754828223650882\n",
      "Epoch: 7 Step: 491 Loss: 1.8445397912222283\n",
      "Epoch: 7 Step: 501 Loss: 1.7829253990557685\n",
      "Epoch: 7 Step: 511 Loss: 1.7474968797894517\n",
      "Epoch: 7 Step: 521 Loss: 1.8703785759604579\n",
      "Epoch: 7 Step: 531 Loss: 1.7807250456638493\n",
      "Epoch: 7 Step: 541 Loss: 1.6983019428560575\n",
      "Epoch: 7 Step: 551 Loss: 1.6523640427010386\n",
      "Epoch: 7 Step: 561 Loss: 1.6937904780224076\n",
      "Epoch: 7 Step: 571 Loss: 1.6388955276468866\n",
      "Epoch: 7 Step: 581 Loss: 1.807996905102688\n",
      "Epoch: 7 Step: 591 Loss: 1.657302335427855\n",
      "Epoch: 7 Step: 601 Loss: 1.8993582035023397\n",
      "Epoch: 7 Step: 611 Loss: 1.6915179684763924\n",
      "Epoch: 7 Step: 621 Loss: 1.684795252454686\n",
      "Epoch: 7 Step: 631 Loss: 1.7077738638262425\n",
      "Epoch: 7 Step: 641 Loss: 1.9486913068001734\n",
      "Epoch: 7 Step: 651 Loss: 1.6842350546380112\n",
      "Epoch: 7 Step: 661 Loss: 1.7968233052887297\n",
      "Epoch: 7 Step: 671 Loss: 1.8084838756403043\n",
      "Epoch: 7 Step: 681 Loss: 1.9083419583174455\n",
      "Epoch: 7 Step: 691 Loss: 1.6669641566200442\n",
      "Epoch: 7 Step: 701 Loss: 1.7317952116974165\n",
      "Epoch: 7 Step: 711 Loss: 1.7231048471846138\n",
      "Epoch: 7 Step: 721 Loss: 1.591028633846943\n",
      "Epoch: 7 Step: 731 Loss: 1.4291957921947378\n",
      "Epoch: 7 Step: 741 Loss: 1.655408965004714\n",
      "Epoch: 7 Step: 751 Loss: 2.0060668683235785\n",
      "Epoch: 7 Step: 761 Loss: 1.6832859337956525\n",
      "Epoch: 7 Step: 771 Loss: 1.8023995949578278\n",
      "Epoch: 7 Step: 781 Loss: 1.7686417719349552\n",
      "Epoch: 8 Step: 1 Loss: 1.7698572176708725\n",
      "Epoch: 8 Step: 11 Loss: 1.6501580690767992\n",
      "Epoch: 8 Step: 21 Loss: 1.9065770724632094\n",
      "Epoch: 8 Step: 31 Loss: 1.783392658128542\n",
      "Epoch: 8 Step: 41 Loss: 1.5905253001992146\n",
      "Epoch: 8 Step: 51 Loss: 1.4912150315716943\n",
      "Epoch: 8 Step: 61 Loss: 1.5795894059523048\n",
      "Epoch: 8 Step: 71 Loss: 1.8513456036785465\n",
      "Epoch: 8 Step: 81 Loss: 1.8169959587647606\n",
      "Epoch: 8 Step: 91 Loss: 1.6020193690182207\n",
      "Epoch: 8 Step: 101 Loss: 1.7917065834478558\n",
      "Epoch: 8 Step: 111 Loss: 1.6538646488713957\n",
      "Epoch: 8 Step: 121 Loss: 1.7542760509118747\n",
      "Epoch: 8 Step: 131 Loss: 1.640507680854892\n",
      "Epoch: 8 Step: 141 Loss: 2.0562361991238083\n",
      "Epoch: 8 Step: 151 Loss: 1.5268167783034403\n",
      "Epoch: 8 Step: 161 Loss: 1.6241272910954234\n",
      "Epoch: 8 Step: 171 Loss: 1.7656996370697087\n",
      "Epoch: 8 Step: 181 Loss: 1.5221982584589764\n",
      "Epoch: 8 Step: 191 Loss: 1.4246098702152765\n",
      "Epoch: 8 Step: 201 Loss: 1.4795147842919394\n",
      "Epoch: 8 Step: 211 Loss: 1.4263656045819917\n",
      "Epoch: 8 Step: 221 Loss: 1.798554758800303\n",
      "Epoch: 8 Step: 231 Loss: 1.7555052905993027\n",
      "Epoch: 8 Step: 241 Loss: 1.704067864368509\n",
      "Epoch: 8 Step: 251 Loss: 1.700714867709126\n",
      "Epoch: 8 Step: 261 Loss: 1.5728152855985287\n",
      "Epoch: 8 Step: 271 Loss: 1.6528852683070383\n",
      "Epoch: 8 Step: 281 Loss: 1.5395637358609027\n",
      "Epoch: 8 Step: 291 Loss: 1.5445373794759383\n",
      "Epoch: 8 Step: 301 Loss: 1.7424328419231785\n",
      "Epoch: 8 Step: 311 Loss: 1.6531641159598789\n",
      "Epoch: 8 Step: 321 Loss: 1.4788250134810936\n",
      "Epoch: 8 Step: 331 Loss: 1.5123947892577019\n",
      "Epoch: 8 Step: 341 Loss: 1.7942043788611612\n",
      "Epoch: 8 Step: 351 Loss: 1.585163887206979\n",
      "Epoch: 8 Step: 361 Loss: 1.7319721936752128\n",
      "Epoch: 8 Step: 371 Loss: 1.4091862477665145\n",
      "Epoch: 8 Step: 381 Loss: 1.5699549262394257\n",
      "Epoch: 8 Step: 391 Loss: 1.5899401696211604\n",
      "Epoch: 8 Step: 401 Loss: 1.5857986276384324\n",
      "Epoch: 8 Step: 411 Loss: 1.551289300451609\n",
      "Epoch: 8 Step: 421 Loss: 1.6846413250212269\n",
      "Epoch: 8 Step: 431 Loss: 1.637327500542412\n",
      "Epoch: 8 Step: 441 Loss: 1.758156879434945\n",
      "Epoch: 8 Step: 451 Loss: 1.4266027879534713\n",
      "Epoch: 8 Step: 461 Loss: 1.5783147665006079\n",
      "Epoch: 8 Step: 471 Loss: 1.6485836625175216\n",
      "Epoch: 8 Step: 481 Loss: 1.8564903394127459\n",
      "Epoch: 8 Step: 491 Loss: 1.831290743230098\n",
      "Epoch: 8 Step: 501 Loss: 1.7925693659115358\n",
      "Epoch: 8 Step: 511 Loss: 1.7594523865404486\n",
      "Epoch: 8 Step: 521 Loss: 1.6729614794284706\n",
      "Epoch: 8 Step: 531 Loss: 1.72111870459746\n",
      "Epoch: 8 Step: 541 Loss: 1.4993762867204887\n",
      "Epoch: 8 Step: 551 Loss: 1.5522370802222085\n",
      "Epoch: 8 Step: 561 Loss: 1.6234224254120972\n",
      "Epoch: 8 Step: 571 Loss: 1.515638150046837\n",
      "Epoch: 8 Step: 581 Loss: 1.66428967170562\n",
      "Epoch: 8 Step: 591 Loss: 1.5039356818326737\n",
      "Epoch: 8 Step: 601 Loss: 1.7019827762511885\n",
      "Epoch: 8 Step: 611 Loss: 1.5950711083855031\n",
      "Epoch: 8 Step: 621 Loss: 1.6092035903578181\n",
      "Epoch: 8 Step: 631 Loss: 1.6511119139718473\n",
      "Epoch: 8 Step: 641 Loss: 1.9155678825330713\n",
      "Epoch: 8 Step: 651 Loss: 1.6071742567529692\n",
      "Epoch: 8 Step: 661 Loss: 1.6621201239527617\n",
      "Epoch: 8 Step: 671 Loss: 1.758753281733088\n",
      "Epoch: 8 Step: 681 Loss: 1.8098195027861137\n",
      "Epoch: 8 Step: 691 Loss: 1.5244162766041065\n",
      "Epoch: 8 Step: 701 Loss: 1.647930964565142\n",
      "Epoch: 8 Step: 711 Loss: 1.6849324359958675\n",
      "Epoch: 8 Step: 721 Loss: 1.4203588732378776\n",
      "Epoch: 8 Step: 731 Loss: 1.4247953185306685\n",
      "Epoch: 8 Step: 741 Loss: 1.5505803848394344\n",
      "Epoch: 8 Step: 751 Loss: 1.8823624660350546\n",
      "Epoch: 8 Step: 761 Loss: 1.7127104164166822\n",
      "Epoch: 8 Step: 771 Loss: 1.6932954988543558\n",
      "Epoch: 8 Step: 781 Loss: 1.6541880100748074\n",
      "Epoch: 9 Step: 1 Loss: 1.64484180180659\n",
      "Epoch: 9 Step: 11 Loss: 1.6686568908773736\n",
      "Epoch: 9 Step: 21 Loss: 1.7894790114228638\n",
      "Epoch: 9 Step: 31 Loss: 1.7507551432666066\n",
      "Epoch: 9 Step: 41 Loss: 1.5620576719411892\n",
      "Epoch: 9 Step: 51 Loss: 1.571525681107853\n",
      "Epoch: 9 Step: 61 Loss: 1.550417154093565\n",
      "Epoch: 9 Step: 71 Loss: 1.7662853468927908\n",
      "Epoch: 9 Step: 81 Loss: 1.788735343078991\n",
      "Epoch: 9 Step: 91 Loss: 1.590970599179253\n",
      "Epoch: 9 Step: 101 Loss: 1.7405059233165825\n",
      "Epoch: 9 Step: 111 Loss: 1.6641019668128885\n",
      "Epoch: 9 Step: 121 Loss: 1.7006386593761598\n",
      "Epoch: 9 Step: 131 Loss: 1.5454758019393477\n",
      "Epoch: 9 Step: 141 Loss: 1.9578364847005625\n",
      "Epoch: 9 Step: 151 Loss: 1.5210066087413299\n",
      "Epoch: 9 Step: 161 Loss: 1.637665045727032\n",
      "Epoch: 9 Step: 171 Loss: 1.6889099614379224\n",
      "Epoch: 9 Step: 181 Loss: 1.5407633198589155\n",
      "Epoch: 9 Step: 191 Loss: 1.3816690324546974\n",
      "Epoch: 9 Step: 201 Loss: 1.486829513851386\n",
      "Epoch: 9 Step: 211 Loss: 1.5739090978766201\n",
      "Epoch: 9 Step: 221 Loss: 1.773296184948384\n",
      "Epoch: 9 Step: 231 Loss: 1.6625475798822045\n",
      "Epoch: 9 Step: 241 Loss: 1.627406987408728\n",
      "Epoch: 9 Step: 251 Loss: 1.604500124695698\n",
      "Epoch: 9 Step: 261 Loss: 1.4730936271432014\n",
      "Epoch: 9 Step: 271 Loss: 1.6084155461103156\n",
      "Epoch: 9 Step: 281 Loss: 1.4816392662287148\n",
      "Epoch: 9 Step: 291 Loss: 1.5587398420615464\n",
      "Epoch: 9 Step: 301 Loss: 1.70100647572932\n",
      "Epoch: 9 Step: 311 Loss: 1.5889605958500845\n",
      "Epoch: 9 Step: 321 Loss: 1.5268922323940646\n",
      "Epoch: 9 Step: 331 Loss: 1.647937215017567\n",
      "Epoch: 9 Step: 341 Loss: 1.6926765222244682\n",
      "Epoch: 9 Step: 351 Loss: 1.4934311270125322\n",
      "Epoch: 9 Step: 361 Loss: 1.6345987196019494\n",
      "Epoch: 9 Step: 371 Loss: 1.3575153642104465\n",
      "Epoch: 9 Step: 381 Loss: 1.5471710904744451\n",
      "Epoch: 9 Step: 391 Loss: 1.4898694262502026\n",
      "Epoch: 9 Step: 401 Loss: 1.5691551556322918\n",
      "Epoch: 9 Step: 411 Loss: 1.6146083627863062\n",
      "Epoch: 9 Step: 421 Loss: 1.7092005670776387\n",
      "Epoch: 9 Step: 431 Loss: 1.5415646973097368\n",
      "Epoch: 9 Step: 441 Loss: 1.8652586319018767\n",
      "Epoch: 9 Step: 451 Loss: 1.3695812071697495\n",
      "Epoch: 9 Step: 461 Loss: 1.6819178834510207\n",
      "Epoch: 9 Step: 471 Loss: 1.7102053310567942\n",
      "Epoch: 9 Step: 481 Loss: 1.7478688745209296\n",
      "Epoch: 9 Step: 491 Loss: 1.739546208281749\n",
      "Epoch: 9 Step: 501 Loss: 1.7506925210688078\n",
      "Epoch: 9 Step: 511 Loss: 1.6936594195542058\n",
      "Epoch: 9 Step: 521 Loss: 1.5876481692010571\n",
      "Epoch: 9 Step: 531 Loss: 1.6506343431978396\n",
      "Epoch: 9 Step: 541 Loss: 1.4800924714542893\n",
      "Epoch: 9 Step: 551 Loss: 1.4345368348485552\n",
      "Epoch: 9 Step: 561 Loss: 1.5317017658688061\n",
      "Epoch: 9 Step: 571 Loss: 1.466686500795074\n",
      "Epoch: 9 Step: 581 Loss: 1.7024832037661102\n",
      "Epoch: 9 Step: 591 Loss: 1.5300322350777655\n",
      "Epoch: 9 Step: 601 Loss: 1.6272323976769036\n",
      "Epoch: 9 Step: 611 Loss: 1.6076777042273624\n",
      "Epoch: 9 Step: 621 Loss: 1.5833099125149355\n",
      "Epoch: 9 Step: 631 Loss: 1.6561423168101195\n",
      "Epoch: 9 Step: 641 Loss: 1.788943034509471\n",
      "Epoch: 9 Step: 651 Loss: 1.5496464441323372\n",
      "Epoch: 9 Step: 661 Loss: 1.6061208943141423\n",
      "Epoch: 9 Step: 671 Loss: 1.5859273709428527\n",
      "Epoch: 9 Step: 681 Loss: 1.7167422947392317\n",
      "Epoch: 9 Step: 691 Loss: 1.6007907485791115\n",
      "Epoch: 9 Step: 701 Loss: 1.5589231900658704\n",
      "Epoch: 9 Step: 711 Loss: 1.6475666726037783\n",
      "Epoch: 9 Step: 721 Loss: 1.4632637814505824\n",
      "Epoch: 9 Step: 731 Loss: 1.3431350404238964\n",
      "Epoch: 9 Step: 741 Loss: 1.53374076717247\n",
      "Epoch: 9 Step: 751 Loss: 1.975639505039535\n",
      "Epoch: 9 Step: 761 Loss: 1.5767120015773548\n",
      "Epoch: 9 Step: 771 Loss: 1.6832617895414042\n",
      "Epoch: 9 Step: 781 Loss: 1.562486502165554\n",
      "Epoch: 10 Step: 1 Loss: 1.5217469527656968\n",
      "Epoch: 10 Step: 11 Loss: 1.6809360627134589\n",
      "Epoch: 10 Step: 21 Loss: 1.7640203573916107\n",
      "Epoch: 10 Step: 31 Loss: 1.6013207168190773\n",
      "Epoch: 10 Step: 41 Loss: 1.582079524873513\n",
      "Epoch: 10 Step: 51 Loss: 1.4196514720308075\n",
      "Epoch: 10 Step: 61 Loss: 1.534145257435914\n",
      "Epoch: 10 Step: 71 Loss: 1.8099307020404902\n",
      "Epoch: 10 Step: 81 Loss: 1.7131759334717325\n",
      "Epoch: 10 Step: 91 Loss: 1.4376716343365272\n",
      "Epoch: 10 Step: 101 Loss: 1.6259335842970442\n",
      "Epoch: 10 Step: 111 Loss: 1.6260070725071425\n",
      "Epoch: 10 Step: 121 Loss: 1.7008427905728063\n",
      "Epoch: 10 Step: 131 Loss: 1.5479571830156424\n",
      "Epoch: 10 Step: 141 Loss: 2.020829371294254\n",
      "Epoch: 10 Step: 151 Loss: 1.5191908611811555\n",
      "Epoch: 10 Step: 161 Loss: 1.5527669985253096\n",
      "Epoch: 10 Step: 171 Loss: 1.787279116713588\n",
      "Epoch: 10 Step: 181 Loss: 1.6628114159254173\n",
      "Epoch: 10 Step: 191 Loss: 1.4753190676057373\n",
      "Epoch: 10 Step: 201 Loss: 1.4480559227978356\n",
      "Epoch: 10 Step: 211 Loss: 1.5257114841749615\n",
      "Epoch: 10 Step: 221 Loss: 1.76772138864749\n",
      "Epoch: 10 Step: 231 Loss: 1.7188789414768508\n",
      "Epoch: 10 Step: 241 Loss: 1.6119615755877346\n",
      "Epoch: 10 Step: 251 Loss: 1.5563873770127261\n",
      "Epoch: 10 Step: 261 Loss: 1.6088952320263594\n",
      "Epoch: 10 Step: 271 Loss: 1.55361800266107\n",
      "Epoch: 10 Step: 281 Loss: 1.423713661827661\n",
      "Epoch: 10 Step: 291 Loss: 1.595185926587182\n",
      "Epoch: 10 Step: 301 Loss: 1.5447265089798026\n",
      "Epoch: 10 Step: 311 Loss: 1.7099552818811972\n",
      "Epoch: 10 Step: 321 Loss: 1.6586789724175457\n",
      "Epoch: 10 Step: 331 Loss: 1.551652306002545\n",
      "Epoch: 10 Step: 341 Loss: 1.6464326777325038\n",
      "Epoch: 10 Step: 351 Loss: 1.5071661379921388\n",
      "Epoch: 10 Step: 361 Loss: 1.628713905468294\n",
      "Epoch: 10 Step: 371 Loss: 1.3388368352348055\n",
      "Epoch: 10 Step: 381 Loss: 1.5712051502993987\n",
      "Epoch: 10 Step: 391 Loss: 1.5364427058914567\n",
      "Epoch: 10 Step: 401 Loss: 1.6213217462340883\n",
      "Epoch: 10 Step: 411 Loss: 1.6533789480393741\n",
      "Epoch: 10 Step: 421 Loss: 1.7129225399493444\n",
      "Epoch: 10 Step: 431 Loss: 1.6777462255027173\n",
      "Epoch: 10 Step: 441 Loss: 1.7330569708661177\n",
      "Epoch: 10 Step: 451 Loss: 1.3571087867103615\n",
      "Epoch: 10 Step: 461 Loss: 1.6311594920845498\n",
      "Epoch: 10 Step: 471 Loss: 1.5559695088504233\n",
      "Epoch: 10 Step: 481 Loss: 1.7447992033015591\n",
      "Epoch: 10 Step: 491 Loss: 1.7401234585538095\n",
      "Epoch: 10 Step: 501 Loss: 1.742588927377837\n",
      "Epoch: 10 Step: 511 Loss: 1.6138984042156195\n",
      "Epoch: 10 Step: 521 Loss: 1.4569326126756388\n",
      "Epoch: 10 Step: 531 Loss: 1.5871014101023202\n",
      "Epoch: 10 Step: 541 Loss: 1.4944313348060856\n",
      "Epoch: 10 Step: 551 Loss: 1.450725207241082\n",
      "Epoch: 10 Step: 561 Loss: 1.4645278980362004\n",
      "Epoch: 10 Step: 571 Loss: 1.4833699446122992\n",
      "Epoch: 10 Step: 581 Loss: 1.5717542322139915\n",
      "Epoch: 10 Step: 591 Loss: 1.4666930553870308\n",
      "Epoch: 10 Step: 601 Loss: 1.6765766222610945\n",
      "Epoch: 10 Step: 611 Loss: 1.57155524242022\n",
      "Epoch: 10 Step: 621 Loss: 1.4741119437814807\n",
      "Epoch: 10 Step: 631 Loss: 1.6042170605915802\n",
      "Epoch: 10 Step: 641 Loss: 1.7000217145585204\n",
      "Epoch: 10 Step: 651 Loss: 1.505037223727452\n",
      "Epoch: 10 Step: 661 Loss: 1.5534872827826314\n",
      "Epoch: 10 Step: 671 Loss: 1.5249510201416485\n",
      "Epoch: 10 Step: 681 Loss: 1.6861447060873984\n",
      "Epoch: 10 Step: 691 Loss: 1.5402593379141531\n",
      "Epoch: 10 Step: 701 Loss: 1.591465638207616\n",
      "Epoch: 10 Step: 711 Loss: 1.7782063612209402\n",
      "Epoch: 10 Step: 721 Loss: 1.459457512233848\n",
      "Epoch: 10 Step: 731 Loss: 1.3396925467904222\n",
      "Epoch: 10 Step: 741 Loss: 1.5178613968423074\n",
      "Epoch: 10 Step: 751 Loss: 1.7617425572231995\n",
      "Epoch: 10 Step: 761 Loss: 1.4661251039975274\n",
      "Epoch: 10 Step: 771 Loss: 1.651890422843393\n",
      "Epoch: 10 Step: 781 Loss: 1.4703860363335277\n",
      "Epoch: 11 Step: 1 Loss: 1.4758367118165046\n",
      "Epoch: 11 Step: 11 Loss: 1.593198113074694\n",
      "Epoch: 11 Step: 21 Loss: 1.915355574387219\n",
      "Epoch: 11 Step: 31 Loss: 1.6117458670119398\n",
      "Epoch: 11 Step: 41 Loss: 1.4796594299759205\n",
      "Epoch: 11 Step: 51 Loss: 1.3496135937975664\n",
      "Epoch: 11 Step: 61 Loss: 1.440957948994353\n",
      "Epoch: 11 Step: 71 Loss: 1.7230686586873023\n",
      "Epoch: 11 Step: 81 Loss: 1.70294569149622\n",
      "Epoch: 11 Step: 91 Loss: 1.5385298351194596\n",
      "Epoch: 11 Step: 101 Loss: 1.5986448740569261\n",
      "Epoch: 11 Step: 111 Loss: 1.6224130291726857\n",
      "Epoch: 11 Step: 121 Loss: 1.659395743326669\n",
      "Epoch: 11 Step: 131 Loss: 1.6214605742432506\n",
      "Epoch: 11 Step: 141 Loss: 2.0041400972257715\n",
      "Epoch: 11 Step: 151 Loss: 1.428310493277758\n",
      "Epoch: 11 Step: 161 Loss: 1.667357655864175\n",
      "Epoch: 11 Step: 171 Loss: 1.5157010926777335\n",
      "Epoch: 11 Step: 181 Loss: 1.640129454500677\n",
      "Epoch: 11 Step: 191 Loss: 1.3685545396137573\n",
      "Epoch: 11 Step: 201 Loss: 1.3881470472972417\n",
      "Epoch: 11 Step: 211 Loss: 1.4731568756883204\n",
      "Epoch: 11 Step: 221 Loss: 1.744319060474344\n",
      "Epoch: 11 Step: 231 Loss: 1.6060694337239168\n",
      "Epoch: 11 Step: 241 Loss: 1.7255183365635298\n",
      "Epoch: 11 Step: 251 Loss: 1.588648751018378\n",
      "Epoch: 11 Step: 261 Loss: 1.4934909456225647\n",
      "Epoch: 11 Step: 271 Loss: 1.615065797177952\n",
      "Epoch: 11 Step: 281 Loss: 1.4477984045218546\n",
      "Epoch: 11 Step: 291 Loss: 1.5550050400892204\n",
      "Epoch: 11 Step: 301 Loss: 1.7044482182356167\n",
      "Epoch: 11 Step: 311 Loss: 1.4624490694592591\n",
      "Epoch: 11 Step: 321 Loss: 1.6115567772846413\n",
      "Epoch: 11 Step: 331 Loss: 1.5417564932253782\n",
      "Epoch: 11 Step: 341 Loss: 1.5983023287495208\n",
      "Epoch: 11 Step: 351 Loss: 1.4771952038403247\n",
      "Epoch: 11 Step: 361 Loss: 1.5920236140416497\n",
      "Epoch: 11 Step: 371 Loss: 1.2431561453065438\n",
      "Epoch: 11 Step: 381 Loss: 1.5494796973531382\n",
      "Epoch: 11 Step: 391 Loss: 1.4023619182735716\n",
      "Epoch: 11 Step: 401 Loss: 1.5671599007243828\n",
      "Epoch: 11 Step: 411 Loss: 1.5955739453643214\n",
      "Epoch: 11 Step: 421 Loss: 1.779312270286252\n",
      "Epoch: 11 Step: 431 Loss: 1.5507761353514042\n",
      "Epoch: 11 Step: 441 Loss: 1.7038365825907493\n",
      "Epoch: 11 Step: 451 Loss: 1.302727044369198\n",
      "Epoch: 11 Step: 461 Loss: 1.5806783505510391\n",
      "Epoch: 11 Step: 471 Loss: 1.5149874619893349\n",
      "Epoch: 11 Step: 481 Loss: 1.6583185186941973\n",
      "Epoch: 11 Step: 491 Loss: 1.7219358107827683\n",
      "Epoch: 11 Step: 501 Loss: 1.6871588716435504\n",
      "Epoch: 11 Step: 511 Loss: 1.6629184128540935\n",
      "Epoch: 11 Step: 521 Loss: 1.4769759096024555\n",
      "Epoch: 11 Step: 531 Loss: 1.5175166468164853\n",
      "Epoch: 11 Step: 541 Loss: 1.4667967366497474\n",
      "Epoch: 11 Step: 551 Loss: 1.4888628783290079\n",
      "Epoch: 11 Step: 561 Loss: 1.3992230859263035\n",
      "Epoch: 11 Step: 571 Loss: 1.5067212024985785\n",
      "Epoch: 11 Step: 581 Loss: 1.4395593597165344\n",
      "Epoch: 11 Step: 591 Loss: 1.5465266823426487\n",
      "Epoch: 11 Step: 601 Loss: 1.6361681441582565\n",
      "Epoch: 11 Step: 611 Loss: 1.4358804880364235\n",
      "Epoch: 11 Step: 621 Loss: 1.4835147559449202\n",
      "Epoch: 11 Step: 631 Loss: 1.6187228306406145\n",
      "Epoch: 11 Step: 641 Loss: 1.701402200291807\n",
      "Epoch: 11 Step: 651 Loss: 1.2975192937900037\n",
      "Epoch: 11 Step: 661 Loss: 1.5625855075745552\n",
      "Epoch: 11 Step: 671 Loss: 1.6686851942976817\n",
      "Epoch: 11 Step: 681 Loss: 1.740146532431251\n",
      "Epoch: 11 Step: 691 Loss: 1.5286065272984377\n",
      "Epoch: 11 Step: 701 Loss: 1.5829399757593323\n",
      "Epoch: 11 Step: 711 Loss: 1.670956514959128\n",
      "Epoch: 11 Step: 721 Loss: 1.4095762845047997\n",
      "Epoch: 11 Step: 731 Loss: 1.2975071391323143\n",
      "Epoch: 11 Step: 741 Loss: 1.4680060692800103\n",
      "Epoch: 11 Step: 751 Loss: 1.7377842999895026\n",
      "Epoch: 11 Step: 761 Loss: 1.3365838021255092\n",
      "Epoch: 11 Step: 771 Loss: 1.595052510273425\n",
      "Epoch: 11 Step: 781 Loss: 1.4774836827426028\n",
      "Epoch: 12 Step: 1 Loss: 1.4965120490156263\n",
      "Epoch: 12 Step: 11 Loss: 1.5580793174300607\n",
      "Epoch: 12 Step: 21 Loss: 1.8855659332284174\n",
      "Epoch: 12 Step: 31 Loss: 1.5567443776915375\n",
      "Epoch: 12 Step: 41 Loss: 1.5320804809090727\n",
      "Epoch: 12 Step: 51 Loss: 1.2663124091950664\n",
      "Epoch: 12 Step: 61 Loss: 1.4210451691091888\n",
      "Epoch: 12 Step: 71 Loss: 1.8117626750465845\n",
      "Epoch: 12 Step: 81 Loss: 1.7114744784044515\n",
      "Epoch: 12 Step: 91 Loss: 1.5331872355774143\n",
      "Epoch: 12 Step: 101 Loss: 1.6526527968350426\n",
      "Epoch: 12 Step: 111 Loss: 1.5316995391714165\n",
      "Epoch: 12 Step: 121 Loss: 1.6301893129754579\n",
      "Epoch: 12 Step: 131 Loss: 1.5368140555299212\n",
      "Epoch: 12 Step: 141 Loss: 2.0188987281582174\n",
      "Epoch: 12 Step: 151 Loss: 1.2751495795231387\n",
      "Epoch: 12 Step: 161 Loss: 1.6242535393201134\n",
      "Epoch: 12 Step: 171 Loss: 1.6448074794951044\n",
      "Epoch: 12 Step: 181 Loss: 1.5791943675117648\n",
      "Epoch: 12 Step: 191 Loss: 1.2556775610663915\n",
      "Epoch: 12 Step: 201 Loss: 1.2946066444541735\n",
      "Epoch: 12 Step: 211 Loss: 1.4335702958792136\n",
      "Epoch: 12 Step: 221 Loss: 1.7140773371079112\n",
      "Epoch: 12 Step: 231 Loss: 1.5350955437427896\n",
      "Epoch: 12 Step: 241 Loss: 1.6223426980983846\n",
      "Epoch: 12 Step: 251 Loss: 1.5305782902288025\n",
      "Epoch: 12 Step: 261 Loss: 1.330096529138582\n",
      "Epoch: 12 Step: 271 Loss: 1.5223849215163323\n",
      "Epoch: 12 Step: 281 Loss: 1.424669669842985\n",
      "Epoch: 12 Step: 291 Loss: 1.5109224364978275\n",
      "Epoch: 12 Step: 301 Loss: 1.581210112047952\n",
      "Epoch: 12 Step: 311 Loss: 1.4707990331072351\n",
      "Epoch: 12 Step: 321 Loss: 1.4714053610939097\n",
      "Epoch: 12 Step: 331 Loss: 1.5429816869462465\n",
      "Epoch: 12 Step: 341 Loss: 1.8144305934821494\n",
      "Epoch: 12 Step: 351 Loss: 1.5422456358095062\n",
      "Epoch: 12 Step: 361 Loss: 1.3678006255899977\n",
      "Epoch: 12 Step: 371 Loss: 1.17600832613858\n",
      "Epoch: 12 Step: 381 Loss: 1.5446080643596485\n",
      "Epoch: 12 Step: 391 Loss: 1.4224724732452754\n",
      "Epoch: 12 Step: 401 Loss: 1.517775609618491\n",
      "Epoch: 12 Step: 411 Loss: 1.625886522086362\n",
      "Epoch: 12 Step: 421 Loss: 1.6386828172349155\n",
      "Epoch: 12 Step: 431 Loss: 1.463852637725328\n",
      "Epoch: 12 Step: 441 Loss: 1.5299090189852622\n",
      "Epoch: 12 Step: 451 Loss: 1.3133330121181208\n",
      "Epoch: 12 Step: 461 Loss: 1.589799221447333\n",
      "Epoch: 12 Step: 471 Loss: 1.5370825026519601\n",
      "Epoch: 12 Step: 481 Loss: 1.5908984173808405\n",
      "Epoch: 12 Step: 491 Loss: 1.6579456124041385\n",
      "Epoch: 12 Step: 501 Loss: 1.6717890787365508\n",
      "Epoch: 12 Step: 511 Loss: 1.4753094180508395\n",
      "Epoch: 12 Step: 521 Loss: 1.3247870031229811\n",
      "Epoch: 12 Step: 531 Loss: 1.5250186877475558\n",
      "Epoch: 12 Step: 541 Loss: 1.4190863402749812\n",
      "Epoch: 12 Step: 551 Loss: 1.3804248153319514\n",
      "Epoch: 12 Step: 561 Loss: 1.5051848070957972\n",
      "Epoch: 12 Step: 571 Loss: 1.5498999111813383\n",
      "Epoch: 12 Step: 581 Loss: 1.5633862973243737\n",
      "Epoch: 12 Step: 591 Loss: 1.5202658662491837\n",
      "Epoch: 12 Step: 601 Loss: 1.8161562569587688\n",
      "Epoch: 12 Step: 611 Loss: 1.4819400360901067\n",
      "Epoch: 12 Step: 621 Loss: 1.4834120721302853\n",
      "Epoch: 12 Step: 631 Loss: 1.5956157813283998\n",
      "Epoch: 12 Step: 641 Loss: 1.6419541125230384\n",
      "Epoch: 12 Step: 651 Loss: 1.3630490527496526\n",
      "Epoch: 12 Step: 661 Loss: 1.4515782721771524\n",
      "Epoch: 12 Step: 671 Loss: 1.4969011806590893\n",
      "Epoch: 12 Step: 681 Loss: 1.681198731428988\n",
      "Epoch: 12 Step: 691 Loss: 1.4304457186354063\n",
      "Epoch: 12 Step: 701 Loss: 1.472730570457681\n",
      "Epoch: 12 Step: 711 Loss: 1.6181328823082988\n",
      "Epoch: 12 Step: 721 Loss: 1.3953097831683146\n",
      "Epoch: 12 Step: 731 Loss: 1.1947623979483288\n",
      "Epoch: 12 Step: 741 Loss: 1.4571051053665482\n",
      "Epoch: 12 Step: 751 Loss: 1.6269700328379657\n",
      "Epoch: 12 Step: 761 Loss: 1.3600293287398075\n",
      "Epoch: 12 Step: 771 Loss: 1.5913686477397488\n",
      "Epoch: 12 Step: 781 Loss: 1.3739129554637277\n",
      "Epoch: 13 Step: 1 Loss: 1.491288187959175\n",
      "Epoch: 13 Step: 11 Loss: 1.643142752786336\n",
      "Epoch: 13 Step: 21 Loss: 1.78932789597921\n",
      "Epoch: 13 Step: 31 Loss: 1.5809166387564777\n",
      "Epoch: 13 Step: 41 Loss: 1.3503509641680902\n",
      "Epoch: 13 Step: 51 Loss: 1.342344290066615\n",
      "Epoch: 13 Step: 61 Loss: 1.4886051928272532\n",
      "Epoch: 13 Step: 71 Loss: 1.7448877007379655\n",
      "Epoch: 13 Step: 81 Loss: 1.6469253205264955\n",
      "Epoch: 13 Step: 91 Loss: 1.4584359612294928\n",
      "Epoch: 13 Step: 101 Loss: 1.623735345271526\n",
      "Epoch: 13 Step: 111 Loss: 1.5843035068407119\n",
      "Epoch: 13 Step: 121 Loss: 1.7222024391346036\n",
      "Epoch: 13 Step: 131 Loss: 1.5677049823210658\n",
      "Epoch: 13 Step: 141 Loss: 1.8808681426502323\n",
      "Epoch: 13 Step: 151 Loss: 1.380710075269757\n",
      "Epoch: 13 Step: 161 Loss: 1.5072844320932717\n",
      "Epoch: 13 Step: 171 Loss: 1.5437298305045108\n",
      "Epoch: 13 Step: 181 Loss: 1.4581707713144634\n",
      "Epoch: 13 Step: 191 Loss: 1.2029706698011486\n",
      "Epoch: 13 Step: 201 Loss: 1.1848643573641133\n",
      "Epoch: 13 Step: 211 Loss: 1.287587370642921\n",
      "Epoch: 13 Step: 221 Loss: 1.716026918011449\n",
      "Epoch: 13 Step: 231 Loss: 1.6293991186682337\n",
      "Epoch: 13 Step: 241 Loss: 1.54077573277835\n",
      "Epoch: 13 Step: 251 Loss: 1.5610055463827246\n",
      "Epoch: 13 Step: 261 Loss: 1.3617253458388885\n",
      "Epoch: 13 Step: 271 Loss: 1.5100803304728856\n",
      "Epoch: 13 Step: 281 Loss: 1.3454477870046277\n",
      "Epoch: 13 Step: 291 Loss: 1.6127095503467435\n",
      "Epoch: 13 Step: 301 Loss: 1.596695325072643\n",
      "Epoch: 13 Step: 311 Loss: 1.5768495358334937\n",
      "Epoch: 13 Step: 321 Loss: 1.4090150550486098\n",
      "Epoch: 13 Step: 331 Loss: 1.4351179015550013\n",
      "Epoch: 13 Step: 341 Loss: 1.7318969525470134\n",
      "Epoch: 13 Step: 351 Loss: 1.4377835857056054\n",
      "Epoch: 13 Step: 361 Loss: 1.4208130743413359\n",
      "Epoch: 13 Step: 371 Loss: 1.1765282777491886\n",
      "Epoch: 13 Step: 381 Loss: 1.4163979116381122\n",
      "Epoch: 13 Step: 391 Loss: 1.3509992909466981\n",
      "Epoch: 13 Step: 401 Loss: 1.447441389982477\n",
      "Epoch: 13 Step: 411 Loss: 1.6338246843272617\n",
      "Epoch: 13 Step: 421 Loss: 1.5833182277285354\n",
      "Epoch: 13 Step: 431 Loss: 1.4164457468634337\n",
      "Epoch: 13 Step: 441 Loss: 1.585252238686106\n",
      "Epoch: 13 Step: 451 Loss: 1.2472325205854773\n",
      "Epoch: 13 Step: 461 Loss: 1.4872695153655116\n",
      "Epoch: 13 Step: 471 Loss: 1.6013592089649449\n",
      "Epoch: 13 Step: 481 Loss: 1.5372477463174368\n",
      "Epoch: 13 Step: 491 Loss: 1.673814653155052\n",
      "Epoch: 13 Step: 501 Loss: 1.5370122199468128\n",
      "Epoch: 13 Step: 511 Loss: 1.503959563544745\n",
      "Epoch: 13 Step: 521 Loss: 1.3562764031906\n",
      "Epoch: 13 Step: 531 Loss: 1.551705486317816\n",
      "Epoch: 13 Step: 541 Loss: 1.3946926297713\n",
      "Epoch: 13 Step: 551 Loss: 1.372483290487228\n",
      "Epoch: 13 Step: 561 Loss: 1.4973125802642795\n",
      "Epoch: 13 Step: 571 Loss: 1.4260784760179699\n",
      "Epoch: 13 Step: 581 Loss: 1.5328728555040958\n",
      "Epoch: 13 Step: 591 Loss: 1.5493822452281663\n",
      "Epoch: 13 Step: 601 Loss: 1.6342877025949707\n",
      "Epoch: 13 Step: 611 Loss: 1.4443095388851654\n",
      "Epoch: 13 Step: 621 Loss: 1.3901881124927564\n",
      "Epoch: 13 Step: 631 Loss: 1.5072880409549336\n",
      "Epoch: 13 Step: 641 Loss: 1.5930046149111325\n",
      "Epoch: 13 Step: 651 Loss: 1.27375142533708\n",
      "Epoch: 13 Step: 661 Loss: 1.3837899905991158\n",
      "Epoch: 13 Step: 671 Loss: 1.6075512212596026\n",
      "Epoch: 13 Step: 681 Loss: 1.613004867399376\n",
      "Epoch: 13 Step: 691 Loss: 1.4186651891425452\n",
      "Epoch: 13 Step: 701 Loss: 1.4347153145748348\n",
      "Epoch: 13 Step: 711 Loss: 1.5151319014108733\n",
      "Epoch: 13 Step: 721 Loss: 1.3148413791804268\n",
      "Epoch: 13 Step: 731 Loss: 1.1515548565692015\n",
      "Epoch: 13 Step: 741 Loss: 1.3560289972857715\n",
      "Epoch: 13 Step: 751 Loss: 1.5237043657975433\n",
      "Epoch: 13 Step: 761 Loss: 1.4498888487109567\n",
      "Epoch: 13 Step: 771 Loss: 1.6697062514277121\n",
      "Epoch: 13 Step: 781 Loss: 1.4534563747645999\n",
      "Epoch: 14 Step: 1 Loss: 1.4422449281984209\n",
      "Epoch: 14 Step: 11 Loss: 1.6152967034348742\n",
      "Epoch: 14 Step: 21 Loss: 1.860492627935865\n",
      "Epoch: 14 Step: 31 Loss: 1.6477766451089415\n",
      "Epoch: 14 Step: 41 Loss: 1.3229443506496636\n",
      "Epoch: 14 Step: 51 Loss: 1.3696349430489647\n",
      "Epoch: 14 Step: 61 Loss: 1.4616479264818636\n",
      "Epoch: 14 Step: 71 Loss: 1.6849428896479313\n",
      "Epoch: 14 Step: 81 Loss: 1.6407040347227055\n",
      "Epoch: 14 Step: 91 Loss: 1.5931129104106658\n",
      "Epoch: 14 Step: 101 Loss: 1.4536754879731588\n",
      "Epoch: 14 Step: 111 Loss: 1.5051971716705679\n",
      "Epoch: 14 Step: 121 Loss: 1.6061241231595647\n",
      "Epoch: 14 Step: 131 Loss: 1.3919079072068086\n",
      "Epoch: 14 Step: 141 Loss: 1.8202745101809596\n",
      "Epoch: 14 Step: 151 Loss: 1.334919907847278\n",
      "Epoch: 14 Step: 161 Loss: 1.4241096524381938\n",
      "Epoch: 14 Step: 171 Loss: 1.509471878566032\n",
      "Epoch: 14 Step: 181 Loss: 1.4676717122060172\n",
      "Epoch: 14 Step: 191 Loss: 1.2541862577953413\n",
      "Epoch: 14 Step: 201 Loss: 1.2143769658195565\n",
      "Epoch: 14 Step: 211 Loss: 1.199917115874578\n",
      "Epoch: 14 Step: 221 Loss: 1.5710473100120919\n",
      "Epoch: 14 Step: 231 Loss: 1.5998127363283452\n",
      "Epoch: 14 Step: 241 Loss: 1.5370597410993487\n",
      "Epoch: 14 Step: 251 Loss: 1.5769550938290626\n",
      "Epoch: 14 Step: 261 Loss: 1.3563065110601356\n",
      "Epoch: 14 Step: 271 Loss: 1.4603232402561956\n",
      "Epoch: 14 Step: 281 Loss: 1.386719176377407\n",
      "Epoch: 14 Step: 291 Loss: 1.4547957667253\n",
      "Epoch: 14 Step: 301 Loss: 1.487991121633324\n",
      "Epoch: 14 Step: 311 Loss: 1.4751597260519609\n",
      "Epoch: 14 Step: 321 Loss: 1.4071627746188113\n",
      "Epoch: 14 Step: 331 Loss: 1.3914437395024812\n",
      "Epoch: 14 Step: 341 Loss: 1.7520186455336377\n",
      "Epoch: 14 Step: 351 Loss: 1.3433851782629047\n",
      "Epoch: 14 Step: 361 Loss: 1.369324012323729\n",
      "Epoch: 14 Step: 371 Loss: 1.10298387868084\n",
      "Epoch: 14 Step: 381 Loss: 1.4446672403441925\n",
      "Epoch: 14 Step: 391 Loss: 1.2860089419354241\n",
      "Epoch: 14 Step: 401 Loss: 1.4327162857933295\n",
      "Epoch: 14 Step: 411 Loss: 1.4803144967244046\n",
      "Epoch: 14 Step: 421 Loss: 1.6032158347724517\n",
      "Epoch: 14 Step: 431 Loss: 1.4529792272997901\n",
      "Epoch: 14 Step: 441 Loss: 1.4840257156013663\n",
      "Epoch: 14 Step: 451 Loss: 1.2089854675661589\n",
      "Epoch: 14 Step: 461 Loss: 1.433680428909514\n",
      "Epoch: 14 Step: 471 Loss: 1.5481037843951833\n",
      "Epoch: 14 Step: 481 Loss: 1.4957141852628753\n",
      "Epoch: 14 Step: 491 Loss: 1.641725455696676\n",
      "Epoch: 14 Step: 501 Loss: 1.5690579140953085\n",
      "Epoch: 14 Step: 511 Loss: 1.391658932873051\n",
      "Epoch: 14 Step: 521 Loss: 1.489246819107332\n",
      "Epoch: 14 Step: 531 Loss: 1.5678090879727902\n",
      "Epoch: 14 Step: 541 Loss: 1.357031678171242\n",
      "Epoch: 14 Step: 551 Loss: 1.3899080240840291\n",
      "Epoch: 14 Step: 561 Loss: 1.3748146114015367\n",
      "Epoch: 14 Step: 571 Loss: 1.3597715135954744\n",
      "Epoch: 14 Step: 581 Loss: 1.4860878246093527\n",
      "Epoch: 14 Step: 591 Loss: 1.5012047460197624\n",
      "Epoch: 14 Step: 601 Loss: 1.5559492192933242\n",
      "Epoch: 14 Step: 611 Loss: 1.3638942568890335\n",
      "Epoch: 14 Step: 621 Loss: 1.4717401090438902\n",
      "Epoch: 14 Step: 631 Loss: 1.5513154187449318\n",
      "Epoch: 14 Step: 641 Loss: 1.540992064001578\n",
      "Epoch: 14 Step: 651 Loss: 1.3468746330753858\n",
      "Epoch: 14 Step: 661 Loss: 1.3059554193625997\n",
      "Epoch: 14 Step: 671 Loss: 1.4108926549886138\n",
      "Epoch: 14 Step: 681 Loss: 1.5960477147147993\n",
      "Epoch: 14 Step: 691 Loss: 1.4009545489413102\n",
      "Epoch: 14 Step: 701 Loss: 1.440088054328427\n",
      "Epoch: 14 Step: 711 Loss: 1.468716816617447\n",
      "Epoch: 14 Step: 721 Loss: 1.440942950011635\n",
      "Epoch: 14 Step: 731 Loss: 1.1682465473853743\n",
      "Epoch: 14 Step: 741 Loss: 1.3449675962273249\n",
      "Epoch: 14 Step: 751 Loss: 1.554213259372601\n",
      "Epoch: 14 Step: 761 Loss: 1.4357411496441168\n",
      "Epoch: 14 Step: 771 Loss: 1.6109732535928682\n",
      "Epoch: 14 Step: 781 Loss: 1.514809248168126\n",
      "Epoch: 15 Step: 1 Loss: 1.480962996230965\n",
      "Epoch: 15 Step: 11 Loss: 1.5309101782059433\n",
      "Epoch: 15 Step: 21 Loss: 1.700734483022271\n",
      "Epoch: 15 Step: 31 Loss: 1.570590665716292\n",
      "Epoch: 15 Step: 41 Loss: 1.4207239226803239\n",
      "Epoch: 15 Step: 51 Loss: 1.3450360609360064\n",
      "Epoch: 15 Step: 61 Loss: 1.4491950834012282\n",
      "Epoch: 15 Step: 71 Loss: 1.827583385598103\n",
      "Epoch: 15 Step: 81 Loss: 1.6811582391238924\n",
      "Epoch: 15 Step: 91 Loss: 1.4636179729246621\n",
      "Epoch: 15 Step: 101 Loss: 1.449493645883135\n",
      "Epoch: 15 Step: 111 Loss: 1.4836923297584663\n",
      "Epoch: 15 Step: 121 Loss: 1.5624291958309215\n",
      "Epoch: 15 Step: 131 Loss: 1.3077802716862643\n",
      "Epoch: 15 Step: 141 Loss: 1.7491114108252375\n",
      "Epoch: 15 Step: 151 Loss: 1.2785347434819938\n",
      "Epoch: 15 Step: 161 Loss: 1.4027522309669274\n",
      "Epoch: 15 Step: 171 Loss: 1.5230405554425053\n",
      "Epoch: 15 Step: 181 Loss: 1.3689871391754256\n",
      "Epoch: 15 Step: 191 Loss: 1.176008366757943\n",
      "Epoch: 15 Step: 201 Loss: 1.1051936539458715\n",
      "Epoch: 15 Step: 211 Loss: 1.2322858450128646\n",
      "Epoch: 15 Step: 221 Loss: 1.649137208899439\n",
      "Epoch: 15 Step: 231 Loss: 1.572178795604589\n",
      "Epoch: 15 Step: 241 Loss: 1.5749695294984132\n",
      "Epoch: 15 Step: 251 Loss: 1.4935795718248106\n",
      "Epoch: 15 Step: 261 Loss: 1.3991354702611865\n",
      "Epoch: 15 Step: 271 Loss: 1.4792990011922444\n",
      "Epoch: 15 Step: 281 Loss: 1.3471130474866944\n",
      "Epoch: 15 Step: 291 Loss: 1.4812625979732275\n",
      "Epoch: 15 Step: 301 Loss: 1.4518582910422846\n",
      "Epoch: 15 Step: 311 Loss: 1.4001850063407129\n",
      "Epoch: 15 Step: 321 Loss: 1.4475993056484344\n",
      "Epoch: 15 Step: 331 Loss: 1.3191946652704936\n",
      "Epoch: 15 Step: 341 Loss: 1.5594411734495157\n",
      "Epoch: 15 Step: 351 Loss: 1.3245019792645958\n",
      "Epoch: 15 Step: 361 Loss: 1.372761997828118\n",
      "Epoch: 15 Step: 371 Loss: 1.1568248659147082\n",
      "Epoch: 15 Step: 381 Loss: 1.3380128076177555\n",
      "Epoch: 15 Step: 391 Loss: 1.2459446151963989\n",
      "Epoch: 15 Step: 401 Loss: 1.295224145139637\n",
      "Epoch: 15 Step: 411 Loss: 1.4674482807397489\n",
      "Epoch: 15 Step: 421 Loss: 1.5319132136337967\n",
      "Epoch: 15 Step: 431 Loss: 1.3689809107873208\n",
      "Epoch: 15 Step: 441 Loss: 1.442466912727317\n",
      "Epoch: 15 Step: 451 Loss: 1.242296327390191\n",
      "Epoch: 15 Step: 461 Loss: 1.413760410548233\n",
      "Epoch: 15 Step: 471 Loss: 1.5384093740277769\n",
      "Epoch: 15 Step: 481 Loss: 1.6388283951553815\n",
      "Epoch: 15 Step: 491 Loss: 1.6667347620043182\n",
      "Epoch: 15 Step: 501 Loss: 1.5698122541840123\n",
      "Epoch: 15 Step: 511 Loss: 1.3868650479700593\n",
      "Epoch: 15 Step: 521 Loss: 1.4077820789363775\n",
      "Epoch: 15 Step: 531 Loss: 1.3041072385446153\n",
      "Epoch: 15 Step: 541 Loss: 1.3099938643073357\n",
      "Epoch: 15 Step: 551 Loss: 1.2578048181955799\n",
      "Epoch: 15 Step: 561 Loss: 1.4630605575354951\n",
      "Epoch: 15 Step: 571 Loss: 1.374581597331586\n",
      "Epoch: 15 Step: 581 Loss: 1.4452987059747002\n",
      "Epoch: 15 Step: 591 Loss: 1.3616780175678853\n",
      "Epoch: 15 Step: 601 Loss: 1.4699701947769919\n",
      "Epoch: 15 Step: 611 Loss: 1.3569373141013963\n",
      "Epoch: 15 Step: 621 Loss: 1.4405105550199537\n",
      "Epoch: 15 Step: 631 Loss: 1.4447847135651763\n",
      "Epoch: 15 Step: 641 Loss: 1.425887612899425\n",
      "Epoch: 15 Step: 651 Loss: 1.2465128018370542\n",
      "Epoch: 15 Step: 661 Loss: 1.2740561009696734\n",
      "Epoch: 15 Step: 671 Loss: 1.3931861647968689\n",
      "Epoch: 15 Step: 681 Loss: 1.5361560806636934\n",
      "Epoch: 15 Step: 691 Loss: 1.2776587944703426\n",
      "Epoch: 15 Step: 701 Loss: 1.4677575777476575\n",
      "Epoch: 15 Step: 711 Loss: 1.3071081572751506\n",
      "Epoch: 15 Step: 721 Loss: 1.3282639757289383\n",
      "Epoch: 15 Step: 731 Loss: 1.2838020373077332\n",
      "Epoch: 15 Step: 741 Loss: 1.4772806794547155\n",
      "Epoch: 15 Step: 751 Loss: 1.7535179685124347\n",
      "Epoch: 15 Step: 761 Loss: 1.4265349043512154\n",
      "Epoch: 15 Step: 771 Loss: 1.6602884895166992\n",
      "Epoch: 15 Step: 781 Loss: 1.4541924732041243\n",
      "Epoch: 16 Step: 1 Loss: 1.4162911944672114\n",
      "Epoch: 16 Step: 11 Loss: 1.5326637570866688\n",
      "Epoch: 16 Step: 21 Loss: 1.7326607410899002\n",
      "Epoch: 16 Step: 31 Loss: 1.469579635257857\n",
      "Epoch: 16 Step: 41 Loss: 1.4005584494991283\n",
      "Epoch: 16 Step: 51 Loss: 1.2980062136281671\n",
      "Epoch: 16 Step: 61 Loss: 1.3837735699787772\n",
      "Epoch: 16 Step: 71 Loss: 1.6722087062078748\n",
      "Epoch: 16 Step: 81 Loss: 1.5062562947819913\n",
      "Epoch: 16 Step: 91 Loss: 1.3831513103554904\n",
      "Epoch: 16 Step: 101 Loss: 1.347027557843975\n",
      "Epoch: 16 Step: 111 Loss: 1.4387876770847936\n",
      "Epoch: 16 Step: 121 Loss: 1.5114867490312507\n",
      "Epoch: 16 Step: 131 Loss: 1.2583483491797316\n",
      "Epoch: 16 Step: 141 Loss: 1.7459673377297982\n",
      "Epoch: 16 Step: 151 Loss: 1.2742975692891032\n",
      "Epoch: 16 Step: 161 Loss: 1.4090564200097737\n",
      "Epoch: 16 Step: 171 Loss: 1.5315736368153565\n",
      "Epoch: 16 Step: 181 Loss: 1.4521612220537339\n",
      "Epoch: 16 Step: 191 Loss: 1.2812985432783155\n",
      "Epoch: 16 Step: 201 Loss: 1.1164729926803552\n",
      "Epoch: 16 Step: 211 Loss: 1.348169146309243\n",
      "Epoch: 16 Step: 221 Loss: 1.5785625602629523\n",
      "Epoch: 16 Step: 231 Loss: 1.528283836033093\n",
      "Epoch: 16 Step: 241 Loss: 1.5362670573305306\n",
      "Epoch: 16 Step: 251 Loss: 1.453462992417492\n",
      "Epoch: 16 Step: 261 Loss: 1.3962764452702836\n",
      "Epoch: 16 Step: 271 Loss: 1.4996488816212292\n",
      "Epoch: 16 Step: 281 Loss: 1.2627698341469276\n",
      "Epoch: 16 Step: 291 Loss: 1.35633759251062\n",
      "Epoch: 16 Step: 301 Loss: 1.565353300318629\n",
      "Epoch: 16 Step: 311 Loss: 1.3405978671188625\n",
      "Epoch: 16 Step: 321 Loss: 1.3388865248879622\n",
      "Epoch: 16 Step: 331 Loss: 1.402174453088261\n",
      "Epoch: 16 Step: 341 Loss: 1.5175313191799829\n",
      "Epoch: 16 Step: 351 Loss: 1.3260504402724473\n",
      "Epoch: 16 Step: 361 Loss: 1.3613898779395415\n",
      "Epoch: 16 Step: 371 Loss: 1.1842308322612507\n",
      "Epoch: 16 Step: 381 Loss: 1.3070563307094032\n",
      "Epoch: 16 Step: 391 Loss: 1.1938708292054758\n",
      "Epoch: 16 Step: 401 Loss: 1.3887641367020191\n",
      "Epoch: 16 Step: 411 Loss: 1.3996478733140758\n",
      "Epoch: 16 Step: 421 Loss: 1.5013852152330385\n",
      "Epoch: 16 Step: 431 Loss: 1.4921009296550825\n",
      "Epoch: 16 Step: 441 Loss: 1.623649136547658\n",
      "Epoch: 16 Step: 451 Loss: 1.2275836158662554\n",
      "Epoch: 16 Step: 461 Loss: 1.5275376677674928\n",
      "Epoch: 16 Step: 471 Loss: 1.4809588747300984\n",
      "Epoch: 16 Step: 481 Loss: 1.5391386258473034\n",
      "Epoch: 16 Step: 491 Loss: 1.6947386844026666\n",
      "Epoch: 16 Step: 501 Loss: 1.678981501477328\n",
      "Epoch: 16 Step: 511 Loss: 1.3991950059076104\n",
      "Epoch: 16 Step: 521 Loss: 1.3266284959580381\n",
      "Epoch: 16 Step: 531 Loss: 1.4264506352766624\n",
      "Epoch: 16 Step: 541 Loss: 1.3110689390787789\n",
      "Epoch: 16 Step: 551 Loss: 1.2688371555690083\n",
      "Epoch: 16 Step: 561 Loss: 1.366439529728475\n",
      "Epoch: 16 Step: 571 Loss: 1.3605153445224714\n",
      "Epoch: 16 Step: 581 Loss: 1.435612615071138\n",
      "Epoch: 16 Step: 591 Loss: 1.468570610388491\n",
      "Epoch: 16 Step: 601 Loss: 1.4598791336322647\n",
      "Epoch: 16 Step: 611 Loss: 1.3408346887038396\n",
      "Epoch: 16 Step: 621 Loss: 1.3938102879697245\n",
      "Epoch: 16 Step: 631 Loss: 1.4008368797871091\n",
      "Epoch: 16 Step: 641 Loss: 1.4632437981705277\n",
      "Epoch: 16 Step: 651 Loss: 1.3180338344899099\n",
      "Epoch: 16 Step: 661 Loss: 1.412701140836929\n",
      "Epoch: 16 Step: 671 Loss: 1.3512598674080079\n",
      "Epoch: 16 Step: 681 Loss: 1.5545745023905084\n",
      "Epoch: 16 Step: 691 Loss: 1.4443872155148292\n",
      "Epoch: 16 Step: 701 Loss: 1.4395963141363706\n",
      "Epoch: 16 Step: 711 Loss: 1.3803261612265048\n",
      "Epoch: 16 Step: 721 Loss: 1.3224695056299778\n",
      "Epoch: 16 Step: 731 Loss: 1.19088606415104\n",
      "Epoch: 16 Step: 741 Loss: 1.3503270248084054\n",
      "Epoch: 16 Step: 751 Loss: 1.6727827628700744\n",
      "Epoch: 16 Step: 761 Loss: 1.3687170111731584\n",
      "Epoch: 16 Step: 771 Loss: 1.6433586076017543\n",
      "Epoch: 16 Step: 781 Loss: 1.4201453892344371\n",
      "Epoch: 17 Step: 1 Loss: 1.2811947749281067\n",
      "Epoch: 17 Step: 11 Loss: 1.5408671089508588\n",
      "Epoch: 17 Step: 21 Loss: 1.6396217696689745\n",
      "Epoch: 17 Step: 31 Loss: 1.3882224558053209\n",
      "Epoch: 17 Step: 41 Loss: 1.3351370580117696\n",
      "Epoch: 17 Step: 51 Loss: 1.2563701292147047\n",
      "Epoch: 17 Step: 61 Loss: 1.3639978735592786\n",
      "Epoch: 17 Step: 71 Loss: 1.710505075488467\n",
      "Epoch: 17 Step: 81 Loss: 1.5790997468889465\n",
      "Epoch: 17 Step: 91 Loss: 1.3846702140115066\n",
      "Epoch: 17 Step: 101 Loss: 1.3021361591489733\n",
      "Epoch: 17 Step: 111 Loss: 1.4321496112923\n",
      "Epoch: 17 Step: 121 Loss: 1.4731060703101475\n",
      "Epoch: 17 Step: 131 Loss: 1.3445430437183128\n",
      "Epoch: 17 Step: 141 Loss: 1.7305277316901626\n",
      "Epoch: 17 Step: 151 Loss: 1.2208179603063596\n",
      "Epoch: 17 Step: 161 Loss: 1.3973358061329848\n",
      "Epoch: 17 Step: 171 Loss: 1.678050526344081\n",
      "Epoch: 17 Step: 181 Loss: 1.4048937649387279\n",
      "Epoch: 17 Step: 191 Loss: 1.2536847629950085\n",
      "Epoch: 17 Step: 201 Loss: 1.1053489727965955\n",
      "Epoch: 17 Step: 211 Loss: 1.3420295944735505\n",
      "Epoch: 17 Step: 221 Loss: 1.6748101531229707\n",
      "Epoch: 17 Step: 231 Loss: 1.6188831557993273\n",
      "Epoch: 17 Step: 241 Loss: 1.5278430761561763\n",
      "Epoch: 17 Step: 251 Loss: 1.2792458518879002\n",
      "Epoch: 17 Step: 261 Loss: 1.3574042370223882\n",
      "Epoch: 17 Step: 271 Loss: 1.3746759252326304\n",
      "Epoch: 17 Step: 281 Loss: 1.1678732903842812\n",
      "Epoch: 17 Step: 291 Loss: 1.3922255758999786\n",
      "Epoch: 17 Step: 301 Loss: 1.4142837823865342\n",
      "Epoch: 17 Step: 311 Loss: 1.348451985844778\n",
      "Epoch: 17 Step: 321 Loss: 1.439037478230286\n",
      "Epoch: 17 Step: 331 Loss: 1.3003938970310986\n",
      "Epoch: 17 Step: 341 Loss: 1.437488609821807\n",
      "Epoch: 17 Step: 351 Loss: 1.3079536041189697\n",
      "Epoch: 17 Step: 361 Loss: 1.3268153507817722\n",
      "Epoch: 17 Step: 371 Loss: 1.086886932987595\n",
      "Epoch: 17 Step: 381 Loss: 1.3791912330932603\n",
      "Epoch: 17 Step: 391 Loss: 1.2306246660074955\n",
      "Epoch: 17 Step: 401 Loss: 1.3699757723384585\n",
      "Epoch: 17 Step: 411 Loss: 1.4657495976323527\n",
      "Epoch: 17 Step: 421 Loss: 1.6273187337014607\n",
      "Epoch: 17 Step: 431 Loss: 1.4094874285546624\n",
      "Epoch: 17 Step: 441 Loss: 1.5184413950714646\n",
      "Epoch: 17 Step: 451 Loss: 1.153388694369085\n",
      "Epoch: 17 Step: 461 Loss: 1.4721154365355882\n",
      "Epoch: 17 Step: 471 Loss: 1.3469755597124478\n",
      "Epoch: 17 Step: 481 Loss: 1.513996303832258\n",
      "Epoch: 17 Step: 491 Loss: 1.6608020792780454\n",
      "Epoch: 17 Step: 501 Loss: 1.6572723320453076\n",
      "Epoch: 17 Step: 511 Loss: 1.2849726318056753\n",
      "Epoch: 17 Step: 521 Loss: 1.3723241805109496\n",
      "Epoch: 17 Step: 531 Loss: 1.3291902441123458\n",
      "Epoch: 17 Step: 541 Loss: 1.262647737500198\n",
      "Epoch: 17 Step: 551 Loss: 1.1581024190907043\n",
      "Epoch: 17 Step: 561 Loss: 1.228689527987937\n",
      "Epoch: 17 Step: 571 Loss: 1.207141214358257\n",
      "Epoch: 17 Step: 581 Loss: 1.3691074159962073\n",
      "Epoch: 17 Step: 591 Loss: 1.4107709419691872\n",
      "Epoch: 17 Step: 601 Loss: 1.4378200943035755\n",
      "Epoch: 17 Step: 611 Loss: 1.253232428315334\n",
      "Epoch: 17 Step: 621 Loss: 1.3269662011716639\n",
      "Epoch: 17 Step: 631 Loss: 1.3250100992078495\n",
      "Epoch: 17 Step: 641 Loss: 1.448025250026493\n",
      "Epoch: 17 Step: 651 Loss: 1.3864248667873507\n",
      "Epoch: 17 Step: 661 Loss: 1.4099405017413322\n",
      "Epoch: 17 Step: 671 Loss: 1.3985638732311934\n",
      "Epoch: 17 Step: 681 Loss: 1.5759930998668468\n",
      "Epoch: 17 Step: 691 Loss: 1.379052508390962\n",
      "Epoch: 17 Step: 701 Loss: 1.3808469050642016\n",
      "Epoch: 17 Step: 711 Loss: 1.4654627444954458\n",
      "Epoch: 17 Step: 721 Loss: 1.3274822811313425\n",
      "Epoch: 17 Step: 731 Loss: 1.254384749270347\n",
      "Epoch: 17 Step: 741 Loss: 1.4731735486939757\n",
      "Epoch: 17 Step: 751 Loss: 1.5142813621960616\n",
      "Epoch: 17 Step: 761 Loss: 1.3482460270008632\n",
      "Epoch: 17 Step: 771 Loss: 1.5270313599830152\n",
      "Epoch: 17 Step: 781 Loss: 1.4569486265049423\n",
      "Epoch: 18 Step: 1 Loss: 1.3915240424656852\n",
      "Epoch: 18 Step: 11 Loss: 1.2809297582258998\n",
      "Epoch: 18 Step: 21 Loss: 1.5604382806790404\n",
      "Epoch: 18 Step: 31 Loss: 1.3625781530554377\n",
      "Epoch: 18 Step: 41 Loss: 1.217465778027051\n",
      "Epoch: 18 Step: 51 Loss: 1.2743038319514897\n",
      "Epoch: 18 Step: 61 Loss: 1.3625271130713836\n",
      "Epoch: 18 Step: 71 Loss: 1.6802165245549123\n",
      "Epoch: 18 Step: 81 Loss: 1.5383947028911575\n",
      "Epoch: 18 Step: 91 Loss: 1.2982517828109845\n",
      "Epoch: 18 Step: 101 Loss: 1.434410857667275\n",
      "Epoch: 18 Step: 111 Loss: 1.52196716232615\n",
      "Epoch: 18 Step: 121 Loss: 1.4708250549194108\n",
      "Epoch: 18 Step: 131 Loss: 1.3164675929654943\n",
      "Epoch: 18 Step: 141 Loss: 1.7614738435743056\n",
      "Epoch: 18 Step: 151 Loss: 1.2279858736390294\n",
      "Epoch: 18 Step: 161 Loss: 1.4592668668211035\n",
      "Epoch: 18 Step: 171 Loss: 1.5957284550176103\n",
      "Epoch: 18 Step: 181 Loss: 1.447380225932626\n",
      "Epoch: 18 Step: 191 Loss: 1.1597075105273236\n",
      "Epoch: 18 Step: 201 Loss: 0.9506830820164208\n",
      "Epoch: 18 Step: 211 Loss: 1.0962622491668041\n",
      "Epoch: 18 Step: 221 Loss: 1.466153805160702\n",
      "Epoch: 18 Step: 231 Loss: 1.4081312377225934\n",
      "Epoch: 18 Step: 241 Loss: 1.4344751914171465\n",
      "Epoch: 18 Step: 251 Loss: 1.3038804824088368\n",
      "Epoch: 18 Step: 261 Loss: 1.2718690117591602\n",
      "Epoch: 18 Step: 271 Loss: 1.4514376911523594\n",
      "Epoch: 18 Step: 281 Loss: 1.2151280586679958\n",
      "Epoch: 18 Step: 291 Loss: 1.2917739850901078\n",
      "Epoch: 18 Step: 301 Loss: 1.448484852276677\n",
      "Epoch: 18 Step: 311 Loss: 1.2856093339149357\n",
      "Epoch: 18 Step: 321 Loss: 1.3254226143580812\n",
      "Epoch: 18 Step: 331 Loss: 1.2479120597677953\n",
      "Epoch: 18 Step: 341 Loss: 1.3935850578314097\n",
      "Epoch: 18 Step: 351 Loss: 1.335847187057913\n",
      "Epoch: 18 Step: 361 Loss: 1.3657110871527096\n",
      "Epoch: 18 Step: 371 Loss: 1.0617405848721233\n",
      "Epoch: 18 Step: 381 Loss: 1.2082273772861356\n",
      "Epoch: 18 Step: 391 Loss: 1.2375275553173464\n",
      "Epoch: 18 Step: 401 Loss: 1.4389641932818105\n",
      "Epoch: 18 Step: 411 Loss: 1.4008605896051454\n",
      "Epoch: 18 Step: 421 Loss: 1.5079983243443449\n",
      "Epoch: 18 Step: 431 Loss: 1.529204110066577\n",
      "Epoch: 18 Step: 441 Loss: 1.471068925145781\n",
      "Epoch: 18 Step: 451 Loss: 1.1571126436031707\n",
      "Epoch: 18 Step: 461 Loss: 1.4467452286075742\n",
      "Epoch: 18 Step: 471 Loss: 1.2334135634986552\n",
      "Epoch: 18 Step: 481 Loss: 1.434999861641932\n",
      "Epoch: 18 Step: 491 Loss: 1.5563142490110384\n",
      "Epoch: 18 Step: 501 Loss: 1.5016205914684502\n",
      "Epoch: 18 Step: 511 Loss: 1.3118577757871148\n",
      "Epoch: 18 Step: 521 Loss: 1.309019547260346\n",
      "Epoch: 18 Step: 531 Loss: 1.1364849828705708\n",
      "Epoch: 18 Step: 541 Loss: 1.2569874808191992\n",
      "Epoch: 18 Step: 551 Loss: 1.1045891826309666\n",
      "Epoch: 18 Step: 561 Loss: 1.2448458260678996\n",
      "Epoch: 18 Step: 571 Loss: 1.1320781181961026\n",
      "Epoch: 18 Step: 581 Loss: 1.3958962768702365\n",
      "Epoch: 18 Step: 591 Loss: 1.2493359505802903\n",
      "Epoch: 18 Step: 601 Loss: 1.449779205432236\n",
      "Epoch: 18 Step: 611 Loss: 1.2838727750155459\n",
      "Epoch: 18 Step: 621 Loss: 1.3188458587786396\n",
      "Epoch: 18 Step: 631 Loss: 1.3885812474029107\n",
      "Epoch: 18 Step: 641 Loss: 1.4696867133460785\n",
      "Epoch: 18 Step: 651 Loss: 1.3033636313930907\n",
      "Epoch: 18 Step: 661 Loss: 1.2065785776761402\n",
      "Epoch: 18 Step: 671 Loss: 1.2920781361218472\n",
      "Epoch: 18 Step: 681 Loss: 1.470295675533949\n",
      "Epoch: 18 Step: 691 Loss: 1.3019487385389312\n",
      "Epoch: 18 Step: 701 Loss: 1.205488166554641\n",
      "Epoch: 18 Step: 711 Loss: 1.3732209489552565\n",
      "Epoch: 18 Step: 721 Loss: 1.1739432642680376\n",
      "Epoch: 18 Step: 731 Loss: 1.1330858005575226\n",
      "Epoch: 18 Step: 741 Loss: 1.3667255973531764\n",
      "Epoch: 18 Step: 751 Loss: 1.4148718612474125\n",
      "Epoch: 18 Step: 761 Loss: 1.1390139306262461\n",
      "Epoch: 18 Step: 771 Loss: 1.4695445803911866\n",
      "Epoch: 18 Step: 781 Loss: 1.3739399519552928\n",
      "Epoch: 19 Step: 1 Loss: 1.293793029203927\n",
      "Epoch: 19 Step: 11 Loss: 1.4414467622663385\n",
      "Epoch: 19 Step: 21 Loss: 1.4578668087414166\n",
      "Epoch: 19 Step: 31 Loss: 1.4508424397174577\n",
      "Epoch: 19 Step: 41 Loss: 1.245904818449473\n",
      "Epoch: 19 Step: 51 Loss: 1.116695617889932\n",
      "Epoch: 19 Step: 61 Loss: 1.3417971840287843\n",
      "Epoch: 19 Step: 71 Loss: 1.634143817166309\n",
      "Epoch: 19 Step: 81 Loss: 1.4315324411221337\n",
      "Epoch: 19 Step: 91 Loss: 1.3537671998544925\n",
      "Epoch: 19 Step: 101 Loss: 1.5369569383314894\n",
      "Epoch: 19 Step: 111 Loss: 1.4508330663137945\n",
      "Epoch: 19 Step: 121 Loss: 1.4324732551046244\n",
      "Epoch: 19 Step: 131 Loss: 1.290520419489645\n",
      "Epoch: 19 Step: 141 Loss: 1.742895296991374\n",
      "Epoch: 19 Step: 151 Loss: 1.160346020105347\n",
      "Epoch: 19 Step: 161 Loss: 1.3905383523757013\n",
      "Epoch: 19 Step: 171 Loss: 1.5124412722202627\n",
      "Epoch: 19 Step: 181 Loss: 1.2859852932679687\n",
      "Epoch: 19 Step: 191 Loss: 1.1524338434239279\n",
      "Epoch: 19 Step: 201 Loss: 1.081332705911106\n",
      "Epoch: 19 Step: 211 Loss: 1.1407484538331625\n",
      "Epoch: 19 Step: 221 Loss: 1.4277335382259684\n",
      "Epoch: 19 Step: 231 Loss: 1.3680355864476665\n",
      "Epoch: 19 Step: 241 Loss: 1.2932360567630545\n",
      "Epoch: 19 Step: 251 Loss: 1.2618886529467517\n",
      "Epoch: 19 Step: 261 Loss: 1.2555190780212218\n",
      "Epoch: 19 Step: 271 Loss: 1.350439755859321\n",
      "Epoch: 19 Step: 281 Loss: 1.1584065777182913\n",
      "Epoch: 19 Step: 291 Loss: 1.3953536760378569\n",
      "Epoch: 19 Step: 301 Loss: 1.4460813546323292\n",
      "Epoch: 19 Step: 311 Loss: 1.3315405414574626\n",
      "Epoch: 19 Step: 321 Loss: 1.4217261793237634\n",
      "Epoch: 19 Step: 331 Loss: 1.2410683080629812\n",
      "Epoch: 19 Step: 341 Loss: 1.3706333423265975\n",
      "Epoch: 19 Step: 351 Loss: 1.4356056164826085\n",
      "Epoch: 19 Step: 361 Loss: 1.3637814142397584\n",
      "Epoch: 19 Step: 371 Loss: 0.9643759813199164\n",
      "Epoch: 19 Step: 381 Loss: 1.3050439861269023\n",
      "Epoch: 19 Step: 391 Loss: 1.1099003074179195\n",
      "Epoch: 19 Step: 401 Loss: 1.246679732985792\n",
      "Epoch: 19 Step: 411 Loss: 1.3837099342293124\n",
      "Epoch: 19 Step: 421 Loss: 1.5408401720993752\n",
      "Epoch: 19 Step: 431 Loss: 1.4737893770458417\n",
      "Epoch: 19 Step: 441 Loss: 1.3284894590312963\n",
      "Epoch: 19 Step: 451 Loss: 1.1917465189907168\n",
      "Epoch: 19 Step: 461 Loss: 1.279188857150718\n",
      "Epoch: 19 Step: 471 Loss: 1.4507808869538046\n",
      "Epoch: 19 Step: 481 Loss: 1.4060739455968836\n",
      "Epoch: 19 Step: 491 Loss: 1.5134043165923696\n",
      "Epoch: 19 Step: 501 Loss: 1.3639331426023111\n",
      "Epoch: 19 Step: 511 Loss: 1.2093403551132744\n",
      "Epoch: 19 Step: 521 Loss: 1.2879870551758592\n",
      "Epoch: 19 Step: 531 Loss: 1.1171589524106622\n",
      "Epoch: 19 Step: 541 Loss: 1.3264207552980491\n",
      "Epoch: 19 Step: 551 Loss: 1.061900365771737\n",
      "Epoch: 19 Step: 561 Loss: 1.2529269066594457\n",
      "Epoch: 19 Step: 571 Loss: 1.2578917981527429\n",
      "Epoch: 19 Step: 581 Loss: 1.37801441472262\n",
      "Epoch: 19 Step: 591 Loss: 1.2816422060771604\n",
      "Epoch: 19 Step: 601 Loss: 1.4697144101163468\n",
      "Epoch: 19 Step: 611 Loss: 1.38325387651249\n",
      "Epoch: 19 Step: 621 Loss: 1.3665769092758655\n",
      "Epoch: 19 Step: 631 Loss: 1.3350546370913854\n",
      "Epoch: 19 Step: 641 Loss: 1.4252757793354816\n",
      "Epoch: 19 Step: 651 Loss: 1.2174301814574362\n",
      "Epoch: 19 Step: 661 Loss: 1.1464634101959774\n",
      "Epoch: 19 Step: 671 Loss: 1.230601459892402\n",
      "Epoch: 19 Step: 681 Loss: 1.533212796167409\n",
      "Epoch: 19 Step: 691 Loss: 1.3131319895626008\n",
      "Epoch: 19 Step: 701 Loss: 1.223600487343889\n",
      "Epoch: 19 Step: 711 Loss: 1.2732828157536373\n",
      "Epoch: 19 Step: 721 Loss: 1.1519722783867161\n",
      "Epoch: 19 Step: 731 Loss: 1.0343441475051056\n",
      "Epoch: 19 Step: 741 Loss: 1.3194438949586442\n",
      "Epoch: 19 Step: 751 Loss: 1.5109658964210047\n",
      "Epoch: 19 Step: 761 Loss: 1.275281138569223\n",
      "Epoch: 19 Step: 771 Loss: 1.4667833920857447\n",
      "Epoch: 19 Step: 781 Loss: 1.3730835729460118\n",
      "Epoch: 20 Step: 1 Loss: 1.2869522843623238\n",
      "Epoch: 20 Step: 11 Loss: 1.504696238182873\n",
      "Epoch: 20 Step: 21 Loss: 1.351671075343857\n",
      "Epoch: 20 Step: 31 Loss: 1.5090198599048712\n",
      "Epoch: 20 Step: 41 Loss: 1.3302954228182018\n",
      "Epoch: 20 Step: 51 Loss: 1.2378731902963274\n",
      "Epoch: 20 Step: 61 Loss: 1.638127759522937\n",
      "Epoch: 20 Step: 71 Loss: 1.7564147371261767\n",
      "Epoch: 20 Step: 81 Loss: 1.3773227255879035\n",
      "Epoch: 20 Step: 91 Loss: 1.4688309731752136\n",
      "Epoch: 20 Step: 101 Loss: 1.4163058735291947\n",
      "Epoch: 20 Step: 111 Loss: 1.3075911560955826\n",
      "Epoch: 20 Step: 121 Loss: 1.3180602856456773\n",
      "Epoch: 20 Step: 131 Loss: 1.207226034096705\n",
      "Epoch: 20 Step: 141 Loss: 1.4697228216724487\n",
      "Epoch: 20 Step: 151 Loss: 1.1180527744782562\n",
      "Epoch: 20 Step: 161 Loss: 1.206034649468933\n",
      "Epoch: 20 Step: 171 Loss: 1.4909058576444323\n",
      "Epoch: 20 Step: 181 Loss: 1.1639660989015557\n",
      "Epoch: 20 Step: 191 Loss: 1.1598079115748523\n",
      "Epoch: 20 Step: 201 Loss: 1.0146960024326273\n",
      "Epoch: 20 Step: 211 Loss: 1.1786903789813445\n",
      "Epoch: 20 Step: 221 Loss: 1.4446416814432521\n",
      "Epoch: 20 Step: 231 Loss: 1.3752343668082636\n",
      "Epoch: 20 Step: 241 Loss: 1.341817290192444\n",
      "Epoch: 20 Step: 251 Loss: 1.2271962959788387\n",
      "Epoch: 20 Step: 261 Loss: 1.211294736253123\n",
      "Epoch: 20 Step: 271 Loss: 1.2762887247163017\n",
      "Epoch: 20 Step: 281 Loss: 1.231448898122036\n",
      "Epoch: 20 Step: 291 Loss: 1.3595334931012641\n",
      "Epoch: 20 Step: 301 Loss: 1.334481926400869\n",
      "Epoch: 20 Step: 311 Loss: 1.3878048337065354\n",
      "Epoch: 20 Step: 321 Loss: 1.4817378129030505\n",
      "Epoch: 20 Step: 331 Loss: 1.251500758241855\n",
      "Epoch: 20 Step: 341 Loss: 1.3363974782077959\n",
      "Epoch: 20 Step: 351 Loss: 1.3353582614403479\n",
      "Epoch: 20 Step: 361 Loss: 1.3279252865219306\n",
      "Epoch: 20 Step: 371 Loss: 0.9257156330837901\n",
      "Epoch: 20 Step: 381 Loss: 1.1547847300171918\n",
      "Epoch: 20 Step: 391 Loss: 1.004171438287365\n",
      "Epoch: 20 Step: 401 Loss: 1.205522018539356\n",
      "Epoch: 20 Step: 411 Loss: 1.2414537385146807\n",
      "Epoch: 20 Step: 421 Loss: 1.416983405652703\n",
      "Epoch: 20 Step: 431 Loss: 1.2197173977366287\n",
      "Epoch: 20 Step: 441 Loss: 1.1181247576753544\n",
      "Epoch: 20 Step: 451 Loss: 1.055575673776219\n",
      "Epoch: 20 Step: 461 Loss: 1.2163491264689772\n",
      "Epoch: 20 Step: 471 Loss: 1.4350181202607608\n",
      "Epoch: 20 Step: 481 Loss: 1.282505908370065\n",
      "Epoch: 20 Step: 491 Loss: 1.4256883736212376\n",
      "Epoch: 20 Step: 501 Loss: 1.389230348554369\n",
      "Epoch: 20 Step: 511 Loss: 1.2575889186796765\n",
      "Epoch: 20 Step: 521 Loss: 1.2894035792775183\n",
      "Epoch: 20 Step: 531 Loss: 1.2088744796668738\n",
      "Epoch: 20 Step: 541 Loss: 1.3225977438875398\n",
      "Epoch: 20 Step: 551 Loss: 1.1536060335662204\n",
      "Epoch: 20 Step: 561 Loss: 1.3957086212788319\n",
      "Epoch: 20 Step: 571 Loss: 1.0830795295340208\n",
      "Epoch: 20 Step: 581 Loss: 1.279661266979555\n",
      "Epoch: 20 Step: 591 Loss: 1.2943239795728985\n",
      "Epoch: 20 Step: 601 Loss: 1.4193898915089034\n",
      "Epoch: 20 Step: 611 Loss: 1.334212163523644\n",
      "Epoch: 20 Step: 621 Loss: 1.3704225941862405\n",
      "Epoch: 20 Step: 631 Loss: 1.2477965102618795\n",
      "Epoch: 20 Step: 641 Loss: 1.3030101220773869\n",
      "Epoch: 20 Step: 651 Loss: 1.197408655938919\n",
      "Epoch: 20 Step: 661 Loss: 1.0505487617180678\n",
      "Epoch: 20 Step: 671 Loss: 1.2975320408542825\n",
      "Epoch: 20 Step: 681 Loss: 1.4969914550541108\n",
      "Epoch: 20 Step: 691 Loss: 1.257109210017383\n",
      "Epoch: 20 Step: 701 Loss: 1.2481184708287207\n",
      "Epoch: 20 Step: 711 Loss: 1.270113871512366\n",
      "Epoch: 20 Step: 721 Loss: 1.156182036749353\n",
      "Epoch: 20 Step: 731 Loss: 0.9725650063465071\n",
      "Epoch: 20 Step: 741 Loss: 1.3005209267784184\n",
      "Epoch: 20 Step: 751 Loss: 1.4846929633674797\n",
      "Epoch: 20 Step: 761 Loss: 1.1084826311072207\n",
      "Epoch: 20 Step: 771 Loss: 1.4468335319738073\n",
      "Epoch: 20 Step: 781 Loss: 1.2970933863588034\n",
      "Epoch: 21 Step: 1 Loss: 1.389741500022161\n",
      "Epoch: 21 Step: 11 Loss: 1.5304550148412275\n",
      "Epoch: 21 Step: 21 Loss: 1.4775256083301131\n",
      "Epoch: 21 Step: 31 Loss: 1.4267823796907684\n",
      "Epoch: 21 Step: 41 Loss: 1.2552415959540635\n",
      "Epoch: 21 Step: 51 Loss: 1.2020932748029847\n",
      "Epoch: 21 Step: 61 Loss: 1.2827422988295272\n",
      "Epoch: 21 Step: 71 Loss: 1.581261721280755\n",
      "Epoch: 21 Step: 81 Loss: 1.3973636561220864\n",
      "Epoch: 21 Step: 91 Loss: 1.2514745530567963\n",
      "Epoch: 21 Step: 101 Loss: 1.361082534049931\n",
      "Epoch: 21 Step: 111 Loss: 1.306981875265889\n",
      "Epoch: 21 Step: 121 Loss: 1.3337318489884373\n",
      "Epoch: 21 Step: 131 Loss: 1.294074666036229\n",
      "Epoch: 21 Step: 141 Loss: 1.5559785941263873\n",
      "Epoch: 21 Step: 151 Loss: 1.1343298992350932\n",
      "Epoch: 21 Step: 161 Loss: 1.162856176714718\n",
      "Epoch: 21 Step: 171 Loss: 1.333466185701278\n",
      "Epoch: 21 Step: 181 Loss: 1.15039142765352\n",
      "Epoch: 21 Step: 191 Loss: 1.2094779524966328\n",
      "Epoch: 21 Step: 201 Loss: 1.033293264875442\n",
      "Epoch: 21 Step: 211 Loss: 1.0400193163889302\n",
      "Epoch: 21 Step: 221 Loss: 1.3551716822845958\n",
      "Epoch: 21 Step: 231 Loss: 1.274174741988726\n",
      "Epoch: 21 Step: 241 Loss: 1.3301248194876818\n",
      "Epoch: 21 Step: 251 Loss: 1.1876266817725714\n",
      "Epoch: 21 Step: 261 Loss: 1.164028739397947\n",
      "Epoch: 21 Step: 271 Loss: 1.3489575307608035\n",
      "Epoch: 21 Step: 281 Loss: 1.1457611400025145\n",
      "Epoch: 21 Step: 291 Loss: 1.4064832170728603\n",
      "Epoch: 21 Step: 301 Loss: 1.3535086553534992\n",
      "Epoch: 21 Step: 311 Loss: 1.1855976665859225\n",
      "Epoch: 21 Step: 321 Loss: 1.282922900775667\n",
      "Epoch: 21 Step: 331 Loss: 1.1683125093806237\n",
      "Epoch: 21 Step: 341 Loss: 1.386912757573227\n",
      "Epoch: 21 Step: 351 Loss: 1.390349190479723\n",
      "Epoch: 21 Step: 361 Loss: 1.2222505848819505\n",
      "Epoch: 21 Step: 371 Loss: 0.9420364781072533\n",
      "Epoch: 21 Step: 381 Loss: 1.1464832229874935\n",
      "Epoch: 21 Step: 391 Loss: 1.0483891000236298\n",
      "Epoch: 21 Step: 401 Loss: 1.2141966600357599\n",
      "Epoch: 21 Step: 411 Loss: 1.2947956785380557\n",
      "Epoch: 21 Step: 421 Loss: 1.4152718645970617\n",
      "Epoch: 21 Step: 431 Loss: 1.244168776372713\n",
      "Epoch: 21 Step: 441 Loss: 1.2769396990146369\n",
      "Epoch: 21 Step: 451 Loss: 1.089549877038822\n",
      "Epoch: 21 Step: 461 Loss: 1.4186054336749863\n",
      "Epoch: 21 Step: 471 Loss: 1.4351574346528277\n",
      "Epoch: 21 Step: 481 Loss: 1.318015583736785\n",
      "Epoch: 21 Step: 491 Loss: 1.414467175632068\n",
      "Epoch: 21 Step: 501 Loss: 1.3402245473552301\n",
      "Epoch: 21 Step: 511 Loss: 1.261516961867533\n",
      "Epoch: 21 Step: 521 Loss: 1.245537536009974\n",
      "Epoch: 21 Step: 531 Loss: 1.2468464602943035\n",
      "Epoch: 21 Step: 541 Loss: 1.0914291306282649\n",
      "Epoch: 21 Step: 551 Loss: 1.1923373426068438\n",
      "Epoch: 21 Step: 561 Loss: 1.2235950749860662\n",
      "Epoch: 21 Step: 571 Loss: 1.1218444617416967\n",
      "Epoch: 21 Step: 581 Loss: 1.1505150099396988\n",
      "Epoch: 21 Step: 591 Loss: 1.1517986034948167\n",
      "Epoch: 21 Step: 601 Loss: 1.3932076288747468\n",
      "Epoch: 21 Step: 611 Loss: 1.2232824389294055\n",
      "Epoch: 21 Step: 621 Loss: 1.2887324208261073\n",
      "Epoch: 21 Step: 631 Loss: 1.258390275719426\n",
      "Epoch: 21 Step: 641 Loss: 1.3665872787589979\n",
      "Epoch: 21 Step: 651 Loss: 1.1203647456141708\n",
      "Epoch: 21 Step: 661 Loss: 1.049266018803519\n",
      "Epoch: 21 Step: 671 Loss: 1.1998810186730628\n",
      "Epoch: 21 Step: 681 Loss: 1.3088351670664047\n",
      "Epoch: 21 Step: 691 Loss: 1.2561464622726952\n",
      "Epoch: 21 Step: 701 Loss: 1.1603988537235839\n",
      "Epoch: 21 Step: 711 Loss: 1.3498655019793748\n",
      "Epoch: 21 Step: 721 Loss: 1.0091593354144677\n",
      "Epoch: 21 Step: 731 Loss: 1.060306900074443\n",
      "Epoch: 21 Step: 741 Loss: 1.2381685239671403\n",
      "Epoch: 21 Step: 751 Loss: 1.4904435430114982\n",
      "Epoch: 21 Step: 761 Loss: 1.2767154318066527\n",
      "Epoch: 21 Step: 771 Loss: 1.5139878748336317\n",
      "Epoch: 21 Step: 781 Loss: 1.2537995351659785\n",
      "Epoch: 22 Step: 1 Loss: 1.2412684158813225\n",
      "Epoch: 22 Step: 11 Loss: 1.3923204035888652\n",
      "Epoch: 22 Step: 21 Loss: 1.3302128565594589\n",
      "Epoch: 22 Step: 31 Loss: 1.3700086614112617\n",
      "Epoch: 22 Step: 41 Loss: 1.2063152074776562\n",
      "Epoch: 22 Step: 51 Loss: 1.104299227734523\n",
      "Epoch: 22 Step: 61 Loss: 1.2498673341862754\n",
      "Epoch: 22 Step: 71 Loss: 1.4774104098735474\n",
      "Epoch: 22 Step: 81 Loss: 1.346433795516158\n",
      "Epoch: 22 Step: 91 Loss: 1.4535003541457467\n",
      "Epoch: 22 Step: 101 Loss: 1.2939774233268664\n",
      "Epoch: 22 Step: 111 Loss: 1.3955547210473465\n",
      "Epoch: 22 Step: 121 Loss: 1.2928415037527219\n",
      "Epoch: 22 Step: 131 Loss: 1.1817742223082939\n",
      "Epoch: 22 Step: 141 Loss: 1.6604578348280263\n",
      "Epoch: 22 Step: 151 Loss: 1.1200900294269243\n",
      "Epoch: 22 Step: 161 Loss: 1.365685159455148\n",
      "Epoch: 22 Step: 171 Loss: 1.4279000616171182\n",
      "Epoch: 22 Step: 181 Loss: 1.1098730198438536\n",
      "Epoch: 22 Step: 191 Loss: 1.0724417776383341\n",
      "Epoch: 22 Step: 201 Loss: 1.0376625287570782\n",
      "Epoch: 22 Step: 211 Loss: 1.0004317591727132\n",
      "Epoch: 22 Step: 221 Loss: 1.4850140161438778\n",
      "Epoch: 22 Step: 231 Loss: 1.4360676527788285\n",
      "Epoch: 22 Step: 241 Loss: 1.404539367067264\n",
      "Epoch: 22 Step: 251 Loss: 1.32493753961586\n",
      "Epoch: 22 Step: 261 Loss: 1.190924841218997\n",
      "Epoch: 22 Step: 271 Loss: 1.3109657990804067\n",
      "Epoch: 22 Step: 281 Loss: 1.005569786035061\n",
      "Epoch: 22 Step: 291 Loss: 1.31391184782066\n",
      "Epoch: 22 Step: 301 Loss: 1.3595899225279378\n",
      "Epoch: 22 Step: 311 Loss: 1.247118998722179\n",
      "Epoch: 22 Step: 321 Loss: 1.3457930738968402\n",
      "Epoch: 22 Step: 331 Loss: 1.0347416490382395\n",
      "Epoch: 22 Step: 341 Loss: 1.1200894598363589\n",
      "Epoch: 22 Step: 351 Loss: 1.271630065940555\n",
      "Epoch: 22 Step: 361 Loss: 1.1930222612599606\n",
      "Epoch: 22 Step: 371 Loss: 0.8934686929525313\n",
      "Epoch: 22 Step: 381 Loss: 1.2579241338254208\n",
      "Epoch: 22 Step: 391 Loss: 0.9690539553096545\n",
      "Epoch: 22 Step: 401 Loss: 1.1830313023954262\n",
      "Epoch: 22 Step: 411 Loss: 1.2733486307993878\n",
      "Epoch: 22 Step: 421 Loss: 1.184572767386693\n",
      "Epoch: 22 Step: 431 Loss: 1.0970488794359803\n",
      "Epoch: 22 Step: 441 Loss: 1.196951905481042\n",
      "Epoch: 22 Step: 451 Loss: 1.0262930358311837\n",
      "Epoch: 22 Step: 461 Loss: 1.2814535970523395\n",
      "Epoch: 22 Step: 471 Loss: 1.3928678672443289\n",
      "Epoch: 22 Step: 481 Loss: 1.305463614040532\n",
      "Epoch: 22 Step: 491 Loss: 1.4672597156253913\n",
      "Epoch: 22 Step: 501 Loss: 1.2891668553580868\n",
      "Epoch: 22 Step: 511 Loss: 1.1720247549231362\n",
      "Epoch: 22 Step: 521 Loss: 1.3403690500624463\n",
      "Epoch: 22 Step: 531 Loss: 1.1408861551995868\n",
      "Epoch: 22 Step: 541 Loss: 1.2106301588865769\n",
      "Epoch: 22 Step: 551 Loss: 1.0348939447647427\n",
      "Epoch: 22 Step: 561 Loss: 1.141088081720538\n",
      "Epoch: 22 Step: 571 Loss: 1.076498622646058\n",
      "Epoch: 22 Step: 581 Loss: 1.271334062627995\n",
      "Epoch: 22 Step: 591 Loss: 1.2360560811614474\n",
      "Epoch: 22 Step: 601 Loss: 1.2733769812788274\n",
      "Epoch: 22 Step: 611 Loss: 1.2427829806193142\n",
      "Epoch: 22 Step: 621 Loss: 1.2496717061463434\n",
      "Epoch: 22 Step: 631 Loss: 1.22213594339863\n",
      "Epoch: 22 Step: 641 Loss: 1.2097987803506296\n",
      "Epoch: 22 Step: 651 Loss: 1.1488292853017856\n",
      "Epoch: 22 Step: 661 Loss: 1.0232086243726777\n",
      "Epoch: 22 Step: 671 Loss: 1.2557047207434697\n",
      "Epoch: 22 Step: 681 Loss: 1.3136964199764365\n",
      "Epoch: 22 Step: 691 Loss: 1.289800588874897\n",
      "Epoch: 22 Step: 701 Loss: 1.171400342124965\n",
      "Epoch: 22 Step: 711 Loss: 1.318766948697538\n",
      "Epoch: 22 Step: 721 Loss: 1.2415296477218702\n",
      "Epoch: 22 Step: 731 Loss: 1.1470965949094218\n",
      "Epoch: 22 Step: 741 Loss: 1.4990002714356607\n",
      "Epoch: 22 Step: 751 Loss: 1.5480247704914447\n",
      "Epoch: 22 Step: 761 Loss: 1.2193068106113527\n",
      "Epoch: 22 Step: 771 Loss: 1.552604058493158\n",
      "Epoch: 22 Step: 781 Loss: 1.2214659898110172\n",
      "Epoch: 23 Step: 1 Loss: 1.0686354616279168\n",
      "Epoch: 23 Step: 11 Loss: 1.2599920047087019\n",
      "Epoch: 23 Step: 21 Loss: 1.4876337472389793\n",
      "Epoch: 23 Step: 31 Loss: 1.340373889011962\n",
      "Epoch: 23 Step: 41 Loss: 1.2026754799739514\n",
      "Epoch: 23 Step: 51 Loss: 1.1653397873643356\n",
      "Epoch: 23 Step: 61 Loss: 1.1511739099081142\n",
      "Epoch: 23 Step: 71 Loss: 1.4288765729369475\n",
      "Epoch: 23 Step: 81 Loss: 1.2843873342453747\n",
      "Epoch: 23 Step: 91 Loss: 1.1253822607989332\n",
      "Epoch: 23 Step: 101 Loss: 1.333189712815215\n",
      "Epoch: 23 Step: 111 Loss: 1.3455455912287704\n",
      "Epoch: 23 Step: 121 Loss: 1.1774128945503435\n",
      "Epoch: 23 Step: 131 Loss: 1.2063308539199278\n",
      "Epoch: 23 Step: 141 Loss: 1.5098613355348558\n",
      "Epoch: 23 Step: 151 Loss: 1.1067400434091275\n",
      "Epoch: 23 Step: 161 Loss: 1.062352513672338\n",
      "Epoch: 23 Step: 171 Loss: 1.4052465283151387\n",
      "Epoch: 23 Step: 181 Loss: 1.1200102146006832\n",
      "Epoch: 23 Step: 191 Loss: 1.2878474906904223\n",
      "Epoch: 23 Step: 201 Loss: 0.9693046288074075\n",
      "Epoch: 23 Step: 211 Loss: 1.0180306792704052\n",
      "Epoch: 23 Step: 221 Loss: 1.360234146481418\n",
      "Epoch: 23 Step: 231 Loss: 1.3090840497713283\n",
      "Epoch: 23 Step: 241 Loss: 1.1172157252132173\n",
      "Epoch: 23 Step: 251 Loss: 1.1547255077236174\n",
      "Epoch: 23 Step: 261 Loss: 1.2876012141144766\n",
      "Epoch: 23 Step: 271 Loss: 1.1513812896301183\n",
      "Epoch: 23 Step: 281 Loss: 1.1377610935193412\n",
      "Epoch: 23 Step: 291 Loss: 1.2385627804626131\n",
      "Epoch: 23 Step: 301 Loss: 1.201822820771206\n",
      "Epoch: 23 Step: 311 Loss: 1.238360244496668\n",
      "Epoch: 23 Step: 321 Loss: 1.2415024113277178\n",
      "Epoch: 23 Step: 331 Loss: 1.1691850935408241\n",
      "Epoch: 23 Step: 341 Loss: 1.2167440806684906\n",
      "Epoch: 23 Step: 351 Loss: 1.1697769829226283\n",
      "Epoch: 23 Step: 361 Loss: 1.0333220443037092\n",
      "Epoch: 23 Step: 371 Loss: 0.8507728374410588\n",
      "Epoch: 23 Step: 381 Loss: 1.173825873945467\n",
      "Epoch: 23 Step: 391 Loss: 0.9698356267171735\n",
      "Epoch: 23 Step: 401 Loss: 1.111192459986673\n",
      "Epoch: 23 Step: 411 Loss: 1.2999773181939829\n",
      "Epoch: 23 Step: 421 Loss: 1.1920430816394276\n",
      "Epoch: 23 Step: 431 Loss: 1.1787661517592016\n",
      "Epoch: 23 Step: 441 Loss: 1.4177549839952206\n",
      "Epoch: 23 Step: 451 Loss: 1.2310610238806827\n",
      "Epoch: 23 Step: 461 Loss: 1.4140168867982328\n",
      "Epoch: 23 Step: 471 Loss: 1.464349582816698\n",
      "Epoch: 23 Step: 481 Loss: 1.4367849008726048\n",
      "Epoch: 23 Step: 491 Loss: 1.4269201151547704\n",
      "Epoch: 23 Step: 501 Loss: 1.4566482304127013\n",
      "Epoch: 23 Step: 511 Loss: 1.1123276741393515\n",
      "Epoch: 23 Step: 521 Loss: 1.185130558269333\n",
      "Epoch: 23 Step: 531 Loss: 1.0962736300666749\n",
      "Epoch: 23 Step: 541 Loss: 1.0902287092786436\n",
      "Epoch: 23 Step: 551 Loss: 1.1370986604083968\n",
      "Epoch: 23 Step: 561 Loss: 1.1076121268181605\n",
      "Epoch: 23 Step: 571 Loss: 1.1363642196598234\n",
      "Epoch: 23 Step: 581 Loss: 1.2483535368057517\n",
      "Epoch: 23 Step: 591 Loss: 1.2968968241616026\n",
      "Epoch: 23 Step: 601 Loss: 1.2528928234339816\n",
      "Epoch: 23 Step: 611 Loss: 1.3428986631621955\n",
      "Epoch: 23 Step: 621 Loss: 1.1185814546269621\n",
      "Epoch: 23 Step: 631 Loss: 1.22522503620847\n",
      "Epoch: 23 Step: 641 Loss: 1.3347661301939544\n",
      "Epoch: 23 Step: 651 Loss: 1.1491490420028665\n",
      "Epoch: 23 Step: 661 Loss: 1.2292472738984692\n",
      "Epoch: 23 Step: 671 Loss: 1.1405022866940273\n",
      "Epoch: 23 Step: 681 Loss: 1.3883501464390102\n",
      "Epoch: 23 Step: 691 Loss: 1.205863990069044\n",
      "Epoch: 23 Step: 701 Loss: 1.362720271008774\n",
      "Epoch: 23 Step: 711 Loss: 1.2633232010422772\n",
      "Epoch: 23 Step: 721 Loss: 1.121006737833655\n",
      "Epoch: 23 Step: 731 Loss: 1.027739547244574\n",
      "Epoch: 23 Step: 741 Loss: 1.2705407784548441\n",
      "Epoch: 23 Step: 751 Loss: 1.5175370154390175\n",
      "Epoch: 23 Step: 761 Loss: 1.0384569431092419\n",
      "Epoch: 23 Step: 771 Loss: 1.3800926758147045\n",
      "Epoch: 23 Step: 781 Loss: 1.1129156920140186\n",
      "Epoch: 24 Step: 1 Loss: 1.185988056157327\n",
      "Epoch: 24 Step: 11 Loss: 1.1994452312364825\n",
      "Epoch: 24 Step: 21 Loss: 1.342025088559644\n",
      "Epoch: 24 Step: 31 Loss: 1.2113754458660462\n",
      "Epoch: 24 Step: 41 Loss: 1.1700023878814991\n",
      "Epoch: 24 Step: 51 Loss: 1.1335716386865167\n",
      "Epoch: 24 Step: 61 Loss: 1.3157070866825258\n",
      "Epoch: 24 Step: 71 Loss: 1.3970786384802025\n",
      "Epoch: 24 Step: 81 Loss: 1.2780275791824343\n",
      "Epoch: 24 Step: 91 Loss: 1.0935426922287177\n",
      "Epoch: 24 Step: 101 Loss: 1.0754231112216897\n",
      "Epoch: 24 Step: 111 Loss: 1.4300217346050186\n",
      "Epoch: 24 Step: 121 Loss: 1.3855606578907231\n",
      "Epoch: 24 Step: 131 Loss: 1.1815115631828799\n",
      "Epoch: 24 Step: 141 Loss: 1.3632261584888736\n",
      "Epoch: 24 Step: 151 Loss: 1.0358782927486025\n",
      "Epoch: 24 Step: 161 Loss: 1.2320385961185045\n",
      "Epoch: 24 Step: 171 Loss: 1.4553062010643023\n",
      "Epoch: 24 Step: 181 Loss: 1.2813764990466447\n",
      "Epoch: 24 Step: 191 Loss: 1.1080031072323098\n",
      "Epoch: 24 Step: 201 Loss: 0.971821407734879\n",
      "Epoch: 24 Step: 211 Loss: 1.0396404712840355\n",
      "Epoch: 24 Step: 221 Loss: 1.3314519534775326\n",
      "Epoch: 24 Step: 231 Loss: 1.2386992761881404\n",
      "Epoch: 24 Step: 241 Loss: 1.4082015670440469\n",
      "Epoch: 24 Step: 251 Loss: 1.048412475277987\n",
      "Epoch: 24 Step: 261 Loss: 1.157369780441913\n",
      "Epoch: 24 Step: 271 Loss: 1.2168531213503813\n",
      "Epoch: 24 Step: 281 Loss: 1.0091536512379298\n",
      "Epoch: 24 Step: 291 Loss: 1.3840594210471031\n",
      "Epoch: 24 Step: 301 Loss: 1.3132923970706285\n",
      "Epoch: 24 Step: 311 Loss: 1.245094399910132\n",
      "Epoch: 24 Step: 321 Loss: 1.2112756641640012\n",
      "Epoch: 24 Step: 331 Loss: 1.0237141770256288\n",
      "Epoch: 24 Step: 341 Loss: 1.175810225659332\n",
      "Epoch: 24 Step: 351 Loss: 1.1685499029879893\n",
      "Epoch: 24 Step: 361 Loss: 1.298793733463713\n",
      "Epoch: 24 Step: 371 Loss: 0.9042142022430317\n",
      "Epoch: 24 Step: 381 Loss: 1.0908922038034572\n",
      "Epoch: 24 Step: 391 Loss: 1.093344887466975\n",
      "Epoch: 24 Step: 401 Loss: 1.159026830079436\n",
      "Epoch: 24 Step: 411 Loss: 1.416707486334846\n",
      "Epoch: 24 Step: 421 Loss: 1.4329565773906516\n",
      "Epoch: 24 Step: 431 Loss: 1.1756505553624712\n",
      "Epoch: 24 Step: 441 Loss: 1.2980505210719369\n",
      "Epoch: 24 Step: 451 Loss: 1.1219058130184787\n",
      "Epoch: 24 Step: 461 Loss: 1.264210361802049\n",
      "Epoch: 24 Step: 471 Loss: 1.321467087584798\n",
      "Epoch: 24 Step: 481 Loss: 1.3263963496972955\n",
      "Epoch: 24 Step: 491 Loss: 1.311879819130421\n",
      "Epoch: 24 Step: 501 Loss: 1.2365915226520228\n",
      "Epoch: 24 Step: 511 Loss: 1.0863003006769012\n",
      "Epoch: 24 Step: 521 Loss: 1.2295525154762759\n",
      "Epoch: 24 Step: 531 Loss: 1.0477040849893988\n",
      "Epoch: 24 Step: 541 Loss: 1.1086417917806015\n",
      "Epoch: 24 Step: 551 Loss: 0.9418881730423464\n",
      "Epoch: 24 Step: 561 Loss: 0.9886182425910954\n",
      "Epoch: 24 Step: 571 Loss: 1.0128203269667848\n",
      "Epoch: 24 Step: 581 Loss: 1.3435154591404574\n",
      "Epoch: 24 Step: 591 Loss: 1.1373653184019372\n",
      "Epoch: 24 Step: 601 Loss: 1.2219263516018795\n",
      "Epoch: 24 Step: 611 Loss: 1.0735443963416216\n",
      "Epoch: 24 Step: 621 Loss: 1.1477294026414655\n",
      "Epoch: 24 Step: 631 Loss: 1.0308857988911067\n",
      "Epoch: 24 Step: 641 Loss: 1.3441192398465778\n",
      "Epoch: 24 Step: 651 Loss: 1.1213380454665325\n",
      "Epoch: 24 Step: 661 Loss: 1.105624263883013\n",
      "Epoch: 24 Step: 671 Loss: 1.1595628357697167\n",
      "Epoch: 24 Step: 681 Loss: 1.3459242569648955\n",
      "Epoch: 24 Step: 691 Loss: 1.2585572005582524\n",
      "Epoch: 24 Step: 701 Loss: 1.3526249361003266\n",
      "Epoch: 24 Step: 711 Loss: 1.335412039545707\n",
      "Epoch: 24 Step: 721 Loss: 0.9437631806711159\n",
      "Epoch: 24 Step: 731 Loss: 0.9588914882651869\n",
      "Epoch: 24 Step: 741 Loss: 1.1289526687249762\n",
      "Epoch: 24 Step: 751 Loss: 1.3881609483705675\n",
      "Epoch: 24 Step: 761 Loss: 1.0462550267927688\n",
      "Epoch: 24 Step: 771 Loss: 1.2727782815998312\n",
      "Epoch: 24 Step: 781 Loss: 1.0034842833145332\n",
      "Epoch: 25 Step: 1 Loss: 1.10572877685919\n",
      "Epoch: 25 Step: 11 Loss: 1.0698079382852184\n",
      "Epoch: 25 Step: 21 Loss: 1.1955990470274003\n",
      "Epoch: 25 Step: 31 Loss: 1.2754299303957601\n",
      "Epoch: 25 Step: 41 Loss: 1.1491749322645834\n",
      "Epoch: 25 Step: 51 Loss: 0.9919174805976768\n",
      "Epoch: 25 Step: 61 Loss: 1.0889068934119484\n",
      "Epoch: 25 Step: 71 Loss: 1.3682341049884412\n",
      "Epoch: 25 Step: 81 Loss: 1.2915394880866158\n",
      "Epoch: 25 Step: 91 Loss: 1.0725647263810958\n",
      "Epoch: 25 Step: 101 Loss: 1.2458888548368974\n",
      "Epoch: 25 Step: 111 Loss: 1.419685339635973\n",
      "Epoch: 25 Step: 121 Loss: 1.3292487203258707\n",
      "Epoch: 25 Step: 131 Loss: 1.3360295617304014\n",
      "Epoch: 25 Step: 141 Loss: 1.5033858050081168\n",
      "Epoch: 25 Step: 151 Loss: 1.0456010686657036\n",
      "Epoch: 25 Step: 161 Loss: 1.1136842083707157\n",
      "Epoch: 25 Step: 171 Loss: 1.4549983510472528\n",
      "Epoch: 25 Step: 181 Loss: 1.2082054817507761\n",
      "Epoch: 25 Step: 191 Loss: 1.029538113713774\n",
      "Epoch: 25 Step: 201 Loss: 0.8846548930611023\n",
      "Epoch: 25 Step: 211 Loss: 1.080697280511581\n",
      "Epoch: 25 Step: 221 Loss: 1.4129967168718025\n",
      "Epoch: 25 Step: 231 Loss: 1.309130913797841\n",
      "Epoch: 25 Step: 241 Loss: 1.2277754521444466\n",
      "Epoch: 25 Step: 251 Loss: 1.146252450546993\n",
      "Epoch: 25 Step: 261 Loss: 1.1145308522001007\n",
      "Epoch: 25 Step: 271 Loss: 1.0540957377947289\n",
      "Epoch: 25 Step: 281 Loss: 1.0054864728364952\n",
      "Epoch: 25 Step: 291 Loss: 1.1379672107678362\n",
      "Epoch: 25 Step: 301 Loss: 1.2649943529151622\n",
      "Epoch: 25 Step: 311 Loss: 1.2820828159727724\n",
      "Epoch: 25 Step: 321 Loss: 1.205717579856818\n",
      "Epoch: 25 Step: 331 Loss: 1.0551550146925055\n",
      "Epoch: 25 Step: 341 Loss: 1.1085371986271904\n",
      "Epoch: 25 Step: 351 Loss: 1.2701448042851564\n",
      "Epoch: 25 Step: 361 Loss: 1.0800730685154512\n",
      "Epoch: 25 Step: 371 Loss: 0.9699842874202557\n",
      "Epoch: 25 Step: 381 Loss: 1.0464251671345544\n",
      "Epoch: 25 Step: 391 Loss: 1.0127643642396333\n",
      "Epoch: 25 Step: 401 Loss: 1.2663473437064716\n",
      "Epoch: 25 Step: 411 Loss: 1.39036408966275\n",
      "Epoch: 25 Step: 421 Loss: 1.1499875680245961\n",
      "Epoch: 25 Step: 431 Loss: 1.1597112042288613\n",
      "Epoch: 25 Step: 441 Loss: 1.1831715389670117\n",
      "Epoch: 25 Step: 451 Loss: 0.9634262580254742\n",
      "Epoch: 25 Step: 461 Loss: 1.2143695210719538\n",
      "Epoch: 25 Step: 471 Loss: 1.2365467338182654\n",
      "Epoch: 25 Step: 481 Loss: 1.1937455689732899\n",
      "Epoch: 25 Step: 491 Loss: 1.236685946804369\n",
      "Epoch: 25 Step: 501 Loss: 1.2545745721216588\n",
      "Epoch: 25 Step: 511 Loss: 1.0801089018617676\n",
      "Epoch: 25 Step: 521 Loss: 1.0934531070334463\n",
      "Epoch: 25 Step: 531 Loss: 0.9868692945856747\n",
      "Epoch: 25 Step: 541 Loss: 0.9187367766627363\n",
      "Epoch: 25 Step: 551 Loss: 0.8974603665825814\n",
      "Epoch: 25 Step: 561 Loss: 1.0249567337160832\n",
      "Epoch: 25 Step: 571 Loss: 1.001601510482485\n",
      "Epoch: 25 Step: 581 Loss: 1.3566198283741844\n",
      "Epoch: 25 Step: 591 Loss: 1.2668986723190434\n",
      "Epoch: 25 Step: 601 Loss: 1.245468757269954\n",
      "Epoch: 25 Step: 611 Loss: 1.2382253173937547\n",
      "Epoch: 25 Step: 621 Loss: 1.1831633567482553\n",
      "Epoch: 25 Step: 631 Loss: 1.2978379703284815\n",
      "Epoch: 25 Step: 641 Loss: 1.325991360583886\n",
      "Epoch: 25 Step: 651 Loss: 1.0799500954132357\n",
      "Epoch: 25 Step: 661 Loss: 1.0316440165484488\n",
      "Epoch: 25 Step: 671 Loss: 1.1462969197987922\n",
      "Epoch: 25 Step: 681 Loss: 1.440083804957088\n",
      "Epoch: 25 Step: 691 Loss: 1.230319899283678\n",
      "Epoch: 25 Step: 701 Loss: 1.2052203911471726\n",
      "Epoch: 25 Step: 711 Loss: 1.2592084653916815\n",
      "Epoch: 25 Step: 721 Loss: 0.9247419140673487\n",
      "Epoch: 25 Step: 731 Loss: 0.8990751940914076\n",
      "Epoch: 25 Step: 741 Loss: 1.2075643211713318\n",
      "Epoch: 25 Step: 751 Loss: 1.1960063933008585\n",
      "Epoch: 25 Step: 761 Loss: 1.0661589476719167\n",
      "Epoch: 25 Step: 771 Loss: 1.3999224176885716\n",
      "Epoch: 25 Step: 781 Loss: 0.9967239085366023\n",
      "Epoch: 26 Step: 1 Loss: 1.0725246075040298\n",
      "Epoch: 26 Step: 11 Loss: 1.2613014848257142\n",
      "Epoch: 26 Step: 21 Loss: 1.096280194182088\n",
      "Epoch: 26 Step: 31 Loss: 1.3204092740652744\n",
      "Epoch: 26 Step: 41 Loss: 1.163144579962995\n",
      "Epoch: 26 Step: 51 Loss: 1.1222355705051004\n",
      "Epoch: 26 Step: 61 Loss: 1.209068877585992\n",
      "Epoch: 26 Step: 71 Loss: 1.4500759767071552\n",
      "Epoch: 26 Step: 81 Loss: 1.408199593333621\n",
      "Epoch: 26 Step: 91 Loss: 1.337534755055132\n",
      "Epoch: 26 Step: 101 Loss: 1.3462792082607236\n",
      "Epoch: 26 Step: 111 Loss: 1.3095928911840005\n",
      "Epoch: 26 Step: 121 Loss: 1.2260182818541256\n",
      "Epoch: 26 Step: 131 Loss: 1.1443245530454185\n",
      "Epoch: 26 Step: 141 Loss: 1.4231796840628341\n",
      "Epoch: 26 Step: 151 Loss: 1.0727238991271506\n",
      "Epoch: 26 Step: 161 Loss: 1.2454292039651107\n",
      "Epoch: 26 Step: 171 Loss: 1.4704956309526935\n",
      "Epoch: 26 Step: 181 Loss: 1.1096602332739085\n",
      "Epoch: 26 Step: 191 Loss: 1.072467227599493\n",
      "Epoch: 26 Step: 201 Loss: 0.7903461657640103\n",
      "Epoch: 26 Step: 211 Loss: 0.9376756424363177\n",
      "Epoch: 26 Step: 221 Loss: 1.1729120913256286\n",
      "Epoch: 26 Step: 231 Loss: 1.1201494409571153\n",
      "Epoch: 26 Step: 241 Loss: 1.2184357663705856\n",
      "Epoch: 26 Step: 251 Loss: 0.9930439866079896\n",
      "Epoch: 26 Step: 261 Loss: 1.1581231600741673\n",
      "Epoch: 26 Step: 271 Loss: 1.1431793852110812\n",
      "Epoch: 26 Step: 281 Loss: 1.021239858646572\n",
      "Epoch: 26 Step: 291 Loss: 1.072156792151954\n",
      "Epoch: 26 Step: 301 Loss: 1.3293522287185573\n",
      "Epoch: 26 Step: 311 Loss: 1.324243900705882\n",
      "Epoch: 26 Step: 321 Loss: 1.364394792713068\n",
      "Epoch: 26 Step: 331 Loss: 0.9887831285388445\n",
      "Epoch: 26 Step: 341 Loss: 1.1555551858253388\n",
      "Epoch: 26 Step: 351 Loss: 1.262476130931674\n",
      "Epoch: 26 Step: 361 Loss: 1.1111327790936476\n",
      "Epoch: 26 Step: 371 Loss: 0.7095354767832825\n",
      "Epoch: 26 Step: 381 Loss: 1.1274783902709724\n",
      "Epoch: 26 Step: 391 Loss: 0.9534780858364698\n",
      "Epoch: 26 Step: 401 Loss: 1.0617159276472519\n",
      "Epoch: 26 Step: 411 Loss: 1.378970935765739\n",
      "Epoch: 26 Step: 421 Loss: 1.4171640984758493\n",
      "Epoch: 26 Step: 431 Loss: 1.0674995249812786\n",
      "Epoch: 26 Step: 441 Loss: 0.9973322813976413\n",
      "Epoch: 26 Step: 451 Loss: 1.007865105907421\n",
      "Epoch: 26 Step: 461 Loss: 1.153565458655422\n",
      "Epoch: 26 Step: 471 Loss: 1.189743615707735\n",
      "Epoch: 26 Step: 481 Loss: 1.1486985923179427\n",
      "Epoch: 26 Step: 491 Loss: 1.1359156933086743\n",
      "Epoch: 26 Step: 501 Loss: 1.2965024622355412\n",
      "Epoch: 26 Step: 511 Loss: 1.1189976669255124\n",
      "Epoch: 26 Step: 521 Loss: 1.1825623991623004\n",
      "Epoch: 26 Step: 531 Loss: 0.9774866684000818\n",
      "Epoch: 26 Step: 541 Loss: 0.9485334366018885\n",
      "Epoch: 26 Step: 551 Loss: 1.0133710543417982\n",
      "Epoch: 26 Step: 561 Loss: 1.1294169151538878\n",
      "Epoch: 26 Step: 571 Loss: 1.0568091020225079\n",
      "Epoch: 26 Step: 581 Loss: 1.2552275097692753\n",
      "Epoch: 26 Step: 591 Loss: 1.2268490371665035\n",
      "Epoch: 26 Step: 601 Loss: 1.4304292339295088\n",
      "Epoch: 26 Step: 611 Loss: 1.17154061464707\n",
      "Epoch: 26 Step: 621 Loss: 1.1824897295082304\n",
      "Epoch: 26 Step: 631 Loss: 1.2058994175702984\n",
      "Epoch: 26 Step: 641 Loss: 1.0241027369686826\n",
      "Epoch: 26 Step: 651 Loss: 0.983882459576964\n",
      "Epoch: 26 Step: 661 Loss: 0.8904842850789729\n",
      "Epoch: 26 Step: 671 Loss: 0.9192073929587072\n",
      "Epoch: 26 Step: 681 Loss: 1.1992177073181705\n",
      "Epoch: 26 Step: 691 Loss: 1.0453896441646817\n",
      "Epoch: 26 Step: 701 Loss: 1.1140615820099735\n",
      "Epoch: 26 Step: 711 Loss: 1.144500109630656\n",
      "Epoch: 26 Step: 721 Loss: 0.9566949472553123\n",
      "Epoch: 26 Step: 731 Loss: 0.8608006314340644\n",
      "Epoch: 26 Step: 741 Loss: 1.1807583728863815\n",
      "Epoch: 26 Step: 751 Loss: 1.1815253633148919\n",
      "Epoch: 26 Step: 761 Loss: 1.1602729890756045\n",
      "Epoch: 26 Step: 771 Loss: 1.414966683783434\n",
      "Epoch: 26 Step: 781 Loss: 1.0394779396091853\n",
      "Epoch: 27 Step: 1 Loss: 1.2743665182667079\n",
      "Epoch: 27 Step: 11 Loss: 1.190070808116685\n",
      "Epoch: 27 Step: 21 Loss: 1.175253813675605\n",
      "Epoch: 27 Step: 31 Loss: 1.2703610941472903\n",
      "Epoch: 27 Step: 41 Loss: 0.9563301095784045\n",
      "Epoch: 27 Step: 51 Loss: 1.1545321008131428\n",
      "Epoch: 27 Step: 61 Loss: 1.2840675063054956\n",
      "Epoch: 27 Step: 71 Loss: 1.4717192601019842\n",
      "Epoch: 27 Step: 81 Loss: 1.2616192562852102\n",
      "Epoch: 27 Step: 91 Loss: 1.0991769738804793\n",
      "Epoch: 27 Step: 101 Loss: 1.1443782993167522\n",
      "Epoch: 27 Step: 111 Loss: 1.3084073598062411\n",
      "Epoch: 27 Step: 121 Loss: 1.2037688258897004\n",
      "Epoch: 27 Step: 131 Loss: 1.187854430568788\n",
      "Epoch: 27 Step: 141 Loss: 1.334399806947108\n",
      "Epoch: 27 Step: 151 Loss: 0.8510208915562726\n",
      "Epoch: 27 Step: 161 Loss: 1.2008279779289572\n",
      "Epoch: 27 Step: 171 Loss: 1.3368799318786395\n",
      "Epoch: 27 Step: 181 Loss: 1.141281918500792\n",
      "Epoch: 27 Step: 191 Loss: 0.8772785371697335\n",
      "Epoch: 27 Step: 201 Loss: 0.7600052934827868\n",
      "Epoch: 27 Step: 211 Loss: 0.8189734683513621\n",
      "Epoch: 27 Step: 221 Loss: 1.2217494487458718\n",
      "Epoch: 27 Step: 231 Loss: 1.0242765014816406\n",
      "Epoch: 27 Step: 241 Loss: 1.1086040128671328\n",
      "Epoch: 27 Step: 251 Loss: 1.0204833152377129\n",
      "Epoch: 27 Step: 261 Loss: 1.2267516205637974\n",
      "Epoch: 27 Step: 271 Loss: 1.329834907327991\n",
      "Epoch: 27 Step: 281 Loss: 1.0762746138175616\n",
      "Epoch: 27 Step: 291 Loss: 1.0508341723494632\n",
      "Epoch: 27 Step: 301 Loss: 1.2555039283307217\n",
      "Epoch: 27 Step: 311 Loss: 1.071528630344345\n",
      "Epoch: 27 Step: 321 Loss: 1.0952346035526812\n",
      "Epoch: 27 Step: 331 Loss: 1.0831696756967468\n",
      "Epoch: 27 Step: 341 Loss: 1.1017483313057703\n",
      "Epoch: 27 Step: 351 Loss: 1.1610718473794215\n",
      "Epoch: 27 Step: 361 Loss: 1.012003211161825\n",
      "Epoch: 27 Step: 371 Loss: 0.8030975471163707\n",
      "Epoch: 27 Step: 381 Loss: 1.164277026115633\n",
      "Epoch: 27 Step: 391 Loss: 0.8471853090826124\n",
      "Epoch: 27 Step: 401 Loss: 0.9358814784184619\n",
      "Epoch: 27 Step: 411 Loss: 1.0922304010768265\n",
      "Epoch: 27 Step: 421 Loss: 1.0686231344100772\n",
      "Epoch: 27 Step: 431 Loss: 0.9209229409920741\n",
      "Epoch: 27 Step: 441 Loss: 0.9292157822023256\n",
      "Epoch: 27 Step: 451 Loss: 0.8789439795718204\n",
      "Epoch: 27 Step: 461 Loss: 1.085721484182213\n",
      "Epoch: 27 Step: 471 Loss: 1.126331946519124\n",
      "Epoch: 27 Step: 481 Loss: 1.1838008504379034\n",
      "Epoch: 27 Step: 491 Loss: 0.9978107111927667\n",
      "Epoch: 27 Step: 501 Loss: 1.271291067412423\n",
      "Epoch: 27 Step: 511 Loss: 1.0767123254006161\n",
      "Epoch: 27 Step: 521 Loss: 1.1666687924346308\n",
      "Epoch: 27 Step: 531 Loss: 0.9602345773848425\n",
      "Epoch: 27 Step: 541 Loss: 1.0602234850342664\n",
      "Epoch: 27 Step: 551 Loss: 1.0831418083391329\n",
      "Epoch: 27 Step: 561 Loss: 0.9989872001700955\n",
      "Epoch: 27 Step: 571 Loss: 1.0261657418125052\n",
      "Epoch: 27 Step: 581 Loss: 1.2682407782752072\n",
      "Epoch: 27 Step: 591 Loss: 1.0767221134629976\n",
      "Epoch: 27 Step: 601 Loss: 1.3538990474832537\n",
      "Epoch: 27 Step: 611 Loss: 1.1615656302814288\n",
      "Epoch: 27 Step: 621 Loss: 1.081949457065192\n",
      "Epoch: 27 Step: 631 Loss: 1.165376502642286\n",
      "Epoch: 27 Step: 641 Loss: 1.34718909570707\n",
      "Epoch: 27 Step: 651 Loss: 0.9687658553580013\n",
      "Epoch: 27 Step: 661 Loss: 0.7637246813229189\n",
      "Epoch: 27 Step: 671 Loss: 1.0047621808933154\n",
      "Epoch: 27 Step: 681 Loss: 1.121446838219195\n",
      "Epoch: 27 Step: 691 Loss: 1.0650684571010944\n",
      "Epoch: 27 Step: 701 Loss: 1.1361912648319668\n",
      "Epoch: 27 Step: 711 Loss: 1.2096918661065819\n",
      "Epoch: 27 Step: 721 Loss: 0.8573341243044067\n",
      "Epoch: 27 Step: 731 Loss: 0.7231495821007172\n",
      "Epoch: 27 Step: 741 Loss: 1.156094700610884\n",
      "Epoch: 27 Step: 751 Loss: 1.1765035954995255\n",
      "Epoch: 27 Step: 761 Loss: 1.037738249833843\n",
      "Epoch: 27 Step: 771 Loss: 1.3416713412889485\n",
      "Epoch: 27 Step: 781 Loss: 0.9631436370615769\n",
      "Epoch: 28 Step: 1 Loss: 1.2550486816328097\n",
      "Epoch: 28 Step: 11 Loss: 1.2471358269293669\n",
      "Epoch: 28 Step: 21 Loss: 1.3884760452064655\n",
      "Epoch: 28 Step: 31 Loss: 1.3354768522241458\n",
      "Epoch: 28 Step: 41 Loss: 1.0880802222846642\n",
      "Epoch: 28 Step: 51 Loss: 1.1586963581448173\n",
      "Epoch: 28 Step: 61 Loss: 1.072559124719508\n",
      "Epoch: 28 Step: 71 Loss: 1.3421352948840237\n",
      "Epoch: 28 Step: 81 Loss: 0.9599861125334068\n",
      "Epoch: 28 Step: 91 Loss: 1.1423563669279715\n",
      "Epoch: 28 Step: 101 Loss: 1.056368312939861\n",
      "Epoch: 28 Step: 111 Loss: 1.2523347491099264\n",
      "Epoch: 28 Step: 121 Loss: 1.1009433371168846\n",
      "Epoch: 28 Step: 131 Loss: 1.1425329934414328\n",
      "Epoch: 28 Step: 141 Loss: 1.4058789745192162\n",
      "Epoch: 28 Step: 151 Loss: 1.0611346927149474\n",
      "Epoch: 28 Step: 161 Loss: 0.9998059162512184\n",
      "Epoch: 28 Step: 171 Loss: 1.162040791974146\n",
      "Epoch: 28 Step: 181 Loss: 1.047168902033269\n",
      "Epoch: 28 Step: 191 Loss: 0.9727373252510519\n",
      "Epoch: 28 Step: 201 Loss: 0.6974484813171428\n",
      "Epoch: 28 Step: 211 Loss: 0.9507133243637143\n",
      "Epoch: 28 Step: 221 Loss: 1.330271370818874\n",
      "Epoch: 28 Step: 231 Loss: 1.1285554629729355\n",
      "Epoch: 28 Step: 241 Loss: 1.1487547927254882\n",
      "Epoch: 28 Step: 251 Loss: 1.1117238703297903\n",
      "Epoch: 28 Step: 261 Loss: 1.1243183727591717\n",
      "Epoch: 28 Step: 271 Loss: 1.3323630357976275\n",
      "Epoch: 28 Step: 281 Loss: 1.2248225510057809\n",
      "Epoch: 28 Step: 291 Loss: 1.1300176990103625\n",
      "Epoch: 28 Step: 301 Loss: 1.0253498196098745\n",
      "Epoch: 28 Step: 311 Loss: 1.0014795695019685\n",
      "Epoch: 28 Step: 321 Loss: 0.9838123425787015\n",
      "Epoch: 28 Step: 331 Loss: 0.9256217308965065\n",
      "Epoch: 28 Step: 341 Loss: 0.9898324444920351\n",
      "Epoch: 28 Step: 351 Loss: 1.0377503235747265\n",
      "Epoch: 28 Step: 361 Loss: 1.037206611766429\n",
      "Epoch: 28 Step: 371 Loss: 0.70842465033923\n",
      "Epoch: 28 Step: 381 Loss: 1.012850503932971\n",
      "Epoch: 28 Step: 391 Loss: 0.8178090113597972\n",
      "Epoch: 28 Step: 401 Loss: 1.0261757942075396\n",
      "Epoch: 28 Step: 411 Loss: 1.0971985082427924\n",
      "Epoch: 28 Step: 421 Loss: 0.995864807194468\n",
      "Epoch: 28 Step: 431 Loss: 1.064590448061423\n",
      "Epoch: 28 Step: 441 Loss: 0.9165960341327463\n",
      "Epoch: 28 Step: 451 Loss: 0.9460555524111909\n",
      "Epoch: 28 Step: 461 Loss: 1.0856404519449907\n",
      "Epoch: 28 Step: 471 Loss: 1.4126431344397286\n",
      "Epoch: 28 Step: 481 Loss: 1.1808942734801775\n",
      "Epoch: 28 Step: 491 Loss: 1.2030698087634246\n",
      "Epoch: 28 Step: 501 Loss: 1.2538734701351701\n",
      "Epoch: 28 Step: 511 Loss: 1.0340313125827163\n",
      "Epoch: 28 Step: 521 Loss: 1.3423807240407482\n",
      "Epoch: 28 Step: 531 Loss: 1.2392010369904036\n",
      "Epoch: 28 Step: 541 Loss: 0.9304937670983916\n",
      "Epoch: 28 Step: 551 Loss: 0.942940190451237\n",
      "Epoch: 28 Step: 561 Loss: 0.8744370461383464\n",
      "Epoch: 28 Step: 571 Loss: 0.9264271804024177\n",
      "Epoch: 28 Step: 581 Loss: 1.225176602644811\n",
      "Epoch: 28 Step: 591 Loss: 1.1892971280950007\n",
      "Epoch: 28 Step: 601 Loss: 1.0452674417159435\n",
      "Epoch: 28 Step: 611 Loss: 1.1606488694105872\n",
      "Epoch: 28 Step: 621 Loss: 1.0408507951060182\n",
      "Epoch: 28 Step: 631 Loss: 1.0012313299847235\n",
      "Epoch: 28 Step: 641 Loss: 1.2708240511213331\n",
      "Epoch: 28 Step: 651 Loss: 0.9085339771378451\n",
      "Epoch: 28 Step: 661 Loss: 0.810773991102886\n",
      "Epoch: 28 Step: 671 Loss: 0.9047715186606591\n",
      "Epoch: 28 Step: 681 Loss: 1.195301635747232\n",
      "Epoch: 28 Step: 691 Loss: 0.9771179763879149\n",
      "Epoch: 28 Step: 701 Loss: 1.136323461666742\n",
      "Epoch: 28 Step: 711 Loss: 1.1105755787596934\n",
      "Epoch: 28 Step: 721 Loss: 0.8157484741433323\n",
      "Epoch: 28 Step: 731 Loss: 0.795877966826805\n",
      "Epoch: 28 Step: 741 Loss: 1.145242395743257\n",
      "Epoch: 28 Step: 751 Loss: 1.338181318345149\n",
      "Epoch: 28 Step: 761 Loss: 1.1675075363373892\n",
      "Epoch: 28 Step: 771 Loss: 1.342865231991068\n",
      "Epoch: 28 Step: 781 Loss: 1.0380822841138855\n",
      "Epoch: 29 Step: 1 Loss: 1.0172343901924774\n",
      "Epoch: 29 Step: 11 Loss: 1.139741117926223\n",
      "Epoch: 29 Step: 21 Loss: 1.1528628726489527\n",
      "Epoch: 29 Step: 31 Loss: 1.2626046088171137\n",
      "Epoch: 29 Step: 41 Loss: 1.1050999510151942\n",
      "Epoch: 29 Step: 51 Loss: 1.0682367605540817\n",
      "Epoch: 29 Step: 61 Loss: 1.1190836272114821\n",
      "Epoch: 29 Step: 71 Loss: 1.3704434133163232\n",
      "Epoch: 29 Step: 81 Loss: 1.1789005382394622\n",
      "Epoch: 29 Step: 91 Loss: 1.0389756340562113\n",
      "Epoch: 29 Step: 101 Loss: 1.0191950297136632\n",
      "Epoch: 29 Step: 111 Loss: 1.192793067127957\n",
      "Epoch: 29 Step: 121 Loss: 1.1549813950749426\n",
      "Epoch: 29 Step: 131 Loss: 1.0566246605648635\n",
      "Epoch: 29 Step: 141 Loss: 1.2710741066430606\n",
      "Epoch: 29 Step: 151 Loss: 1.005659285994102\n",
      "Epoch: 29 Step: 161 Loss: 0.9131071684565643\n",
      "Epoch: 29 Step: 171 Loss: 1.1770554423821014\n",
      "Epoch: 29 Step: 181 Loss: 1.0488135161470349\n",
      "Epoch: 29 Step: 191 Loss: 0.8172259464205507\n",
      "Epoch: 29 Step: 201 Loss: 0.644964365954152\n",
      "Epoch: 29 Step: 211 Loss: 0.8650932798841623\n",
      "Epoch: 29 Step: 221 Loss: 1.1342240714843654\n",
      "Epoch: 29 Step: 231 Loss: 1.1681306638010658\n",
      "Epoch: 29 Step: 241 Loss: 1.2676916140564396\n",
      "Epoch: 29 Step: 251 Loss: 0.912629688675887\n",
      "Epoch: 29 Step: 261 Loss: 1.1750873368029218\n",
      "Epoch: 29 Step: 271 Loss: 1.153911639124008\n",
      "Epoch: 29 Step: 281 Loss: 1.0589061478920474\n",
      "Epoch: 29 Step: 291 Loss: 0.9720122904972386\n",
      "Epoch: 29 Step: 301 Loss: 1.047440147700029\n",
      "Epoch: 29 Step: 311 Loss: 1.1023314474394716\n",
      "Epoch: 29 Step: 321 Loss: 1.0796858149020505\n",
      "Epoch: 29 Step: 331 Loss: 0.8798491036271849\n",
      "Epoch: 29 Step: 341 Loss: 0.9825261637858285\n",
      "Epoch: 29 Step: 351 Loss: 0.9025637588904212\n",
      "Epoch: 29 Step: 361 Loss: 0.9133065767846413\n",
      "Epoch: 29 Step: 371 Loss: 0.7533241675025447\n",
      "Epoch: 29 Step: 381 Loss: 0.9696904287743162\n",
      "Epoch: 29 Step: 391 Loss: 0.928632836343466\n",
      "Epoch: 29 Step: 401 Loss: 1.0660287383538178\n",
      "Epoch: 29 Step: 411 Loss: 1.1667169464478095\n",
      "Epoch: 29 Step: 421 Loss: 1.1207259250065862\n",
      "Epoch: 29 Step: 431 Loss: 1.0808800998382595\n",
      "Epoch: 29 Step: 441 Loss: 1.078141939641351\n",
      "Epoch: 29 Step: 451 Loss: 0.9801199213436065\n",
      "Epoch: 29 Step: 461 Loss: 1.2149008072809702\n",
      "Epoch: 29 Step: 471 Loss: 1.1957165566481063\n",
      "Epoch: 29 Step: 481 Loss: 1.2871770626748666\n",
      "Epoch: 29 Step: 491 Loss: 1.2104614065738484\n",
      "Epoch: 29 Step: 501 Loss: 1.352198128416092\n",
      "Epoch: 29 Step: 511 Loss: 1.117734134396375\n",
      "Epoch: 29 Step: 521 Loss: 1.062682640024553\n",
      "Epoch: 29 Step: 531 Loss: 1.0308734344230133\n",
      "Epoch: 29 Step: 541 Loss: 0.8818288974146732\n",
      "Epoch: 29 Step: 551 Loss: 0.9426009778618116\n",
      "Epoch: 29 Step: 561 Loss: 0.893662746464871\n",
      "Epoch: 29 Step: 571 Loss: 0.7952526058829592\n",
      "Epoch: 29 Step: 581 Loss: 1.034308382660498\n",
      "Epoch: 29 Step: 591 Loss: 0.9785424955571156\n",
      "Epoch: 29 Step: 601 Loss: 1.0121524406502185\n",
      "Epoch: 29 Step: 611 Loss: 1.0964494065811863\n",
      "Epoch: 29 Step: 621 Loss: 0.9873488725818702\n",
      "Epoch: 29 Step: 631 Loss: 1.0579355306094944\n",
      "Epoch: 29 Step: 641 Loss: 1.1383038729221697\n",
      "Epoch: 29 Step: 651 Loss: 0.7145760883550268\n",
      "Epoch: 29 Step: 661 Loss: 0.7805586334988164\n",
      "Epoch: 29 Step: 671 Loss: 1.116767741089063\n",
      "Epoch: 29 Step: 681 Loss: 1.3061393791133975\n",
      "Epoch: 29 Step: 691 Loss: 1.0194195579714054\n",
      "Epoch: 29 Step: 701 Loss: 1.1774194117088623\n",
      "Epoch: 29 Step: 711 Loss: 0.997750158263466\n",
      "Epoch: 29 Step: 721 Loss: 0.8624556966609965\n",
      "Epoch: 29 Step: 731 Loss: 0.8929900060102647\n",
      "Epoch: 29 Step: 741 Loss: 1.257827459351283\n",
      "Epoch: 29 Step: 751 Loss: 1.3090669582576402\n",
      "Epoch: 29 Step: 761 Loss: 1.0080965713000054\n",
      "Epoch: 29 Step: 771 Loss: 1.212599383107281\n",
      "Epoch: 29 Step: 781 Loss: 1.056876512797237\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score is 0.5899887964148528\n",
      "Score is 0.5048076923076923\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "model = DenseNet(datasets='cifar_10', opt='sgd')\n",
    "model.datas = [data, label]\n",
    "model.train(30)\n",
    "plt.plot(np.arange(len(model.history)), model.history)\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 0 Step: 1 Loss: 2.3034792587407815\n",
      "Epoch: 0 Step: 11 Loss: 2.2245911324851892\n",
      "Epoch: 0 Step: 21 Loss: 2.211808113451973\n",
      "Epoch: 0 Step: 31 Loss: 2.327209005250241\n",
      "Epoch: 0 Step: 41 Loss: 2.2319318883309927\n",
      "Epoch: 0 Step: 51 Loss: 2.294719458136324\n",
      "Epoch: 0 Step: 61 Loss: 2.258798667022867\n",
      "Epoch: 0 Step: 71 Loss: 2.223196322667733\n",
      "Epoch: 0 Step: 81 Loss: 2.276926794565632\n",
      "Epoch: 0 Step: 91 Loss: 2.2607011228332916\n",
      "Epoch: 0 Step: 101 Loss: 2.2417500901176486\n",
      "Epoch: 0 Step: 111 Loss: 2.1441854119933828\n",
      "Epoch: 0 Step: 121 Loss: 2.1950606159681296\n",
      "Epoch: 0 Step: 131 Loss: 2.2356172012123086\n",
      "Epoch: 0 Step: 141 Loss: 2.2314743024694876\n",
      "Epoch: 0 Step: 151 Loss: 2.3323989249768644\n",
      "Epoch: 0 Step: 161 Loss: 2.17648172014861\n",
      "Epoch: 0 Step: 171 Loss: 2.22092836464189\n",
      "Epoch: 0 Step: 181 Loss: 2.1617478213670185\n",
      "Epoch: 0 Step: 191 Loss: 2.159667632675195\n",
      "Epoch: 0 Step: 201 Loss: 2.1792803058070236\n",
      "Epoch: 0 Step: 211 Loss: 2.2738051029903157\n",
      "Epoch: 0 Step: 221 Loss: 2.2616023809686663\n",
      "Epoch: 0 Step: 231 Loss: 2.183176655174152\n",
      "Epoch: 0 Step: 241 Loss: 2.277311506714828\n",
      "Epoch: 0 Step: 251 Loss: 2.215314574572653\n",
      "Epoch: 0 Step: 261 Loss: 2.2260647245991594\n",
      "Epoch: 0 Step: 271 Loss: 2.1920218775904146\n",
      "Epoch: 0 Step: 281 Loss: 2.2032030637236906\n",
      "Epoch: 0 Step: 291 Loss: 2.2217277579605414\n",
      "Epoch: 0 Step: 301 Loss: 2.171834583593396\n",
      "Epoch: 0 Step: 311 Loss: 2.262978549981148\n",
      "Epoch: 0 Step: 321 Loss: 2.2199352108118235\n",
      "Epoch: 0 Step: 331 Loss: 2.105511499203142\n",
      "Epoch: 0 Step: 341 Loss: 2.1683597737801104\n",
      "Epoch: 0 Step: 351 Loss: 2.1470561399550387\n",
      "Epoch: 0 Step: 361 Loss: 2.188517539367308\n",
      "Epoch: 0 Step: 371 Loss: 2.1827458831186757\n",
      "Epoch: 0 Step: 381 Loss: 2.207915528509675\n",
      "Epoch: 0 Step: 391 Loss: 2.253960778927043\n",
      "Epoch: 0 Step: 401 Loss: 2.2256649093842693\n",
      "Epoch: 0 Step: 411 Loss: 2.220077083866421\n",
      "Epoch: 0 Step: 421 Loss: 2.241612786952969\n",
      "Epoch: 0 Step: 431 Loss: 2.175843708637447\n",
      "Epoch: 0 Step: 441 Loss: 2.2408783424751997\n",
      "Epoch: 0 Step: 451 Loss: 2.237268851467895\n",
      "Epoch: 0 Step: 461 Loss: 2.165963312517057\n",
      "Epoch: 0 Step: 471 Loss: 2.1506518415959555\n",
      "Epoch: 0 Step: 481 Loss: 2.2706293999208373\n",
      "Epoch: 0 Step: 491 Loss: 2.1667573268944054\n",
      "Epoch: 0 Step: 501 Loss: 2.2953063514877488\n",
      "Epoch: 0 Step: 511 Loss: 2.2101245378178027\n",
      "Epoch: 0 Step: 521 Loss: 2.2272330679673598\n",
      "Epoch: 0 Step: 531 Loss: 2.2014677591556056\n",
      "Epoch: 0 Step: 541 Loss: 2.1279465619113376\n",
      "Epoch: 0 Step: 551 Loss: 2.120778754800616\n",
      "Epoch: 0 Step: 561 Loss: 2.1245731343185303\n",
      "Epoch: 0 Step: 571 Loss: 2.10411676927033\n",
      "Epoch: 0 Step: 581 Loss: 2.13106913394038\n",
      "Epoch: 0 Step: 591 Loss: 2.1761442245426235\n",
      "Epoch: 0 Step: 601 Loss: 2.208730503323591\n",
      "Epoch: 0 Step: 611 Loss: 2.053519788405803\n",
      "Epoch: 0 Step: 621 Loss: 2.138170890016146\n",
      "Epoch: 0 Step: 631 Loss: 2.1368503796478273\n",
      "Epoch: 0 Step: 641 Loss: 2.0457244596925523\n",
      "Epoch: 0 Step: 651 Loss: 2.0452096713062375\n",
      "Epoch: 0 Step: 661 Loss: 2.015977467718097\n",
      "Epoch: 0 Step: 671 Loss: 2.0485516343092676\n",
      "Epoch: 0 Step: 681 Loss: 2.12346161832583\n",
      "Epoch: 0 Step: 691 Loss: 1.9359465743330082\n",
      "Epoch: 0 Step: 701 Loss: 1.9508767034092673\n",
      "Epoch: 0 Step: 711 Loss: 2.0115825090023742\n",
      "Epoch: 0 Step: 721 Loss: 1.9812295233156554\n",
      "Epoch: 0 Step: 731 Loss: 1.97453588348862\n",
      "Epoch: 0 Step: 741 Loss: 1.9606728296367448\n",
      "Epoch: 0 Step: 751 Loss: 2.205014657331363\n",
      "Epoch: 0 Step: 761 Loss: 2.0044569623858157\n",
      "Epoch: 0 Step: 771 Loss: 2.1429407750449507\n",
      "Epoch: 0 Step: 781 Loss: 2.1066153494800437\n",
      "Epoch: 1 Step: 1 Loss: 2.1571525240955447\n",
      "Epoch: 1 Step: 11 Loss: 1.953737534696323\n",
      "Epoch: 1 Step: 21 Loss: 1.9804487809467308\n",
      "Epoch: 1 Step: 31 Loss: 2.203623275176049\n",
      "Epoch: 1 Step: 41 Loss: 1.9267529991598153\n",
      "Epoch: 1 Step: 51 Loss: 2.033520420966287\n",
      "Epoch: 1 Step: 61 Loss: 1.971099276304115\n",
      "Epoch: 1 Step: 71 Loss: 2.0060457525130593\n",
      "Epoch: 1 Step: 81 Loss: 1.9863695351025386\n",
      "Epoch: 1 Step: 91 Loss: 2.1218920461469226\n",
      "Epoch: 1 Step: 101 Loss: 2.0246121290112864\n",
      "Epoch: 1 Step: 111 Loss: 1.9022171515452557\n",
      "Epoch: 1 Step: 121 Loss: 1.8422565523097725\n",
      "Epoch: 1 Step: 131 Loss: 2.030652871392715\n",
      "Epoch: 1 Step: 141 Loss: 2.2197925442582847\n",
      "Epoch: 1 Step: 151 Loss: 2.028006326741849\n",
      "Epoch: 1 Step: 161 Loss: 1.9529615420574151\n",
      "Epoch: 1 Step: 171 Loss: 2.040473936764019\n",
      "Epoch: 1 Step: 181 Loss: 1.8896213679590093\n",
      "Epoch: 1 Step: 191 Loss: 1.8857386955932796\n",
      "Epoch: 1 Step: 201 Loss: 1.8233403363933323\n",
      "Epoch: 1 Step: 211 Loss: 1.9320122594809623\n",
      "Epoch: 1 Step: 221 Loss: 2.0446958908884687\n",
      "Epoch: 1 Step: 231 Loss: 1.9637262064438352\n",
      "Epoch: 1 Step: 241 Loss: 2.0530889478466667\n",
      "Epoch: 1 Step: 251 Loss: 1.839985765240925\n",
      "Epoch: 1 Step: 261 Loss: 1.8395145226703828\n",
      "Epoch: 1 Step: 271 Loss: 2.0231512909746594\n",
      "Epoch: 1 Step: 281 Loss: 1.984839205615821\n",
      "Epoch: 1 Step: 291 Loss: 1.9380184120539645\n",
      "Epoch: 1 Step: 301 Loss: 1.9987562931713878\n",
      "Epoch: 1 Step: 311 Loss: 1.8774190073699164\n",
      "Epoch: 1 Step: 321 Loss: 1.9305918760813416\n",
      "Epoch: 1 Step: 331 Loss: 1.8174298957733481\n",
      "Epoch: 1 Step: 341 Loss: 1.8444290240848435\n",
      "Epoch: 1 Step: 351 Loss: 1.8954951764033003\n",
      "Epoch: 1 Step: 361 Loss: 1.9436107322319176\n",
      "Epoch: 1 Step: 371 Loss: 1.8586913451934808\n",
      "Epoch: 1 Step: 381 Loss: 1.846037300774638\n",
      "Epoch: 1 Step: 391 Loss: 1.797705749067366\n",
      "Epoch: 1 Step: 401 Loss: 1.9183277775863867\n",
      "Epoch: 1 Step: 411 Loss: 1.986476732749146\n",
      "Epoch: 1 Step: 421 Loss: 2.0213422641451837\n",
      "Epoch: 1 Step: 431 Loss: 1.8010550648820969\n",
      "Epoch: 1 Step: 441 Loss: 1.9212943778354448\n",
      "Epoch: 1 Step: 451 Loss: 1.832817241241397\n",
      "Epoch: 1 Step: 461 Loss: 1.8703792227751248\n",
      "Epoch: 1 Step: 471 Loss: 1.8214536810204818\n",
      "Epoch: 1 Step: 481 Loss: 1.932645064506567\n",
      "Epoch: 1 Step: 491 Loss: 2.0699026998364287\n",
      "Epoch: 1 Step: 501 Loss: 1.9635654810481844\n",
      "Epoch: 1 Step: 511 Loss: 1.841042395022653\n",
      "Epoch: 1 Step: 521 Loss: 1.891463334698444\n",
      "Epoch: 1 Step: 531 Loss: 1.919796708588919\n",
      "Epoch: 1 Step: 541 Loss: 1.7983632495498794\n",
      "Epoch: 1 Step: 551 Loss: 1.7175901635148683\n",
      "Epoch: 1 Step: 561 Loss: 1.776009399788415\n",
      "Epoch: 1 Step: 571 Loss: 1.832735303151284\n",
      "Epoch: 1 Step: 581 Loss: 1.9666309225753111\n",
      "Epoch: 1 Step: 591 Loss: 1.8606222215668873\n",
      "Epoch: 1 Step: 601 Loss: 1.895370220832267\n",
      "Epoch: 1 Step: 611 Loss: 1.7298597538743639\n",
      "Epoch: 1 Step: 621 Loss: 1.7656081401922505\n",
      "Epoch: 1 Step: 631 Loss: 1.9645031278065606\n",
      "Epoch: 1 Step: 641 Loss: 1.8836419302776601\n",
      "Epoch: 1 Step: 651 Loss: 1.8371856041482633\n",
      "Epoch: 1 Step: 661 Loss: 1.8041826150436258\n",
      "Epoch: 1 Step: 671 Loss: 1.795762139617675\n",
      "Epoch: 1 Step: 681 Loss: 1.9989643497027094\n",
      "Epoch: 1 Step: 691 Loss: 1.7530782021710305\n",
      "Epoch: 1 Step: 701 Loss: 1.7068891602761007\n",
      "Epoch: 1 Step: 711 Loss: 1.8912578119051777\n",
      "Epoch: 1 Step: 721 Loss: 1.7569617911782962\n",
      "Epoch: 1 Step: 731 Loss: 1.8322082688204466\n",
      "Epoch: 1 Step: 741 Loss: 1.8671810582357438\n",
      "Epoch: 1 Step: 751 Loss: 2.0220259812012387\n",
      "Epoch: 1 Step: 761 Loss: 1.7578668429069375\n",
      "Epoch: 1 Step: 771 Loss: 1.8462978810899973\n",
      "Epoch: 1 Step: 781 Loss: 1.9099983513571075\n",
      "Epoch: 2 Step: 1 Loss: 1.9261309526351509\n",
      "Epoch: 2 Step: 11 Loss: 1.9524956829984326\n",
      "Epoch: 2 Step: 21 Loss: 1.8423997068814002\n",
      "Epoch: 2 Step: 31 Loss: 2.0016691992031665\n",
      "Epoch: 2 Step: 41 Loss: 1.8173695350385908\n",
      "Epoch: 2 Step: 51 Loss: 1.7923059084633377\n",
      "Epoch: 2 Step: 61 Loss: 1.8720282239929933\n",
      "Epoch: 2 Step: 71 Loss: 1.9518687324983333\n",
      "Epoch: 2 Step: 81 Loss: 1.8904326438519539\n",
      "Epoch: 2 Step: 91 Loss: 1.925162190352395\n",
      "Epoch: 2 Step: 101 Loss: 1.8478594556669206\n",
      "Epoch: 2 Step: 111 Loss: 1.7912407028719308\n",
      "Epoch: 2 Step: 121 Loss: 1.7404235079022534\n",
      "Epoch: 2 Step: 131 Loss: 1.925974625840893\n",
      "Epoch: 2 Step: 141 Loss: 2.135973662105574\n",
      "Epoch: 2 Step: 151 Loss: 1.5992666476787427\n",
      "Epoch: 2 Step: 161 Loss: 1.7003297122022274\n",
      "Epoch: 2 Step: 171 Loss: 1.8206408112421226\n",
      "Epoch: 2 Step: 181 Loss: 1.6727386261168278\n",
      "Epoch: 2 Step: 191 Loss: 1.6217804849399857\n",
      "Epoch: 2 Step: 201 Loss: 1.5120704654847001\n",
      "Epoch: 2 Step: 211 Loss: 1.600640193589593\n",
      "Epoch: 2 Step: 221 Loss: 1.805319337226603\n",
      "Epoch: 2 Step: 231 Loss: 1.7791800053370928\n",
      "Epoch: 2 Step: 241 Loss: 1.9034395062760563\n",
      "Epoch: 2 Step: 251 Loss: 1.7016692338291624\n",
      "Epoch: 2 Step: 261 Loss: 1.7327483147589953\n",
      "Epoch: 2 Step: 271 Loss: 1.8195438522978602\n",
      "Epoch: 2 Step: 281 Loss: 1.7754403472177303\n",
      "Epoch: 2 Step: 291 Loss: 1.8353931330436635\n",
      "Epoch: 2 Step: 301 Loss: 1.8857495981794752\n",
      "Epoch: 2 Step: 311 Loss: 1.8111630396436826\n",
      "Epoch: 2 Step: 321 Loss: 1.8261355410547861\n",
      "Epoch: 2 Step: 331 Loss: 1.7126949468650317\n",
      "Epoch: 2 Step: 341 Loss: 1.7987803754057414\n",
      "Epoch: 2 Step: 351 Loss: 1.7905016722021414\n",
      "Epoch: 2 Step: 361 Loss: 1.8440401362934193\n",
      "Epoch: 2 Step: 371 Loss: 1.6272168664370332\n",
      "Epoch: 2 Step: 381 Loss: 1.9083722519731086\n",
      "Epoch: 2 Step: 391 Loss: 1.6969851919109775\n",
      "Epoch: 2 Step: 401 Loss: 1.7139207384259363\n",
      "Epoch: 2 Step: 411 Loss: 1.9537450091210853\n",
      "Epoch: 2 Step: 421 Loss: 1.7676807830311243\n",
      "Epoch: 2 Step: 431 Loss: 1.6571121500932597\n",
      "Epoch: 2 Step: 441 Loss: 1.921829924549177\n",
      "Epoch: 2 Step: 451 Loss: 1.6176155487360693\n",
      "Epoch: 2 Step: 461 Loss: 1.622492713079251\n",
      "Epoch: 2 Step: 471 Loss: 1.6919501236115213\n",
      "Epoch: 2 Step: 481 Loss: 1.8329663670100345\n",
      "Epoch: 2 Step: 491 Loss: 1.8979626644481173\n",
      "Epoch: 2 Step: 501 Loss: 1.818375726346653\n",
      "Epoch: 2 Step: 511 Loss: 1.739822668081616\n",
      "Epoch: 2 Step: 521 Loss: 1.6844528799206098\n",
      "Epoch: 2 Step: 531 Loss: 1.6386591256936374\n",
      "Epoch: 2 Step: 541 Loss: 1.6554553477801202\n",
      "Epoch: 2 Step: 551 Loss: 1.5716786502731177\n",
      "Epoch: 2 Step: 561 Loss: 1.558560256539506\n",
      "Epoch: 2 Step: 571 Loss: 1.5461865798441883\n",
      "Epoch: 2 Step: 581 Loss: 1.7406866030528667\n",
      "Epoch: 2 Step: 591 Loss: 1.758940807346712\n",
      "Epoch: 2 Step: 601 Loss: 1.7752412907361887\n",
      "Epoch: 2 Step: 611 Loss: 1.4931789074585518\n",
      "Epoch: 2 Step: 621 Loss: 1.6098379056569758\n",
      "Epoch: 2 Step: 631 Loss: 1.7509759169690802\n",
      "Epoch: 2 Step: 641 Loss: 1.690737395238468\n",
      "Epoch: 2 Step: 651 Loss: 1.6256607176615367\n",
      "Epoch: 2 Step: 661 Loss: 1.5475105455035567\n",
      "Epoch: 2 Step: 671 Loss: 1.6461427856155941\n",
      "Epoch: 2 Step: 681 Loss: 1.7048201952102233\n",
      "Epoch: 2 Step: 691 Loss: 1.6031312981080355\n",
      "Epoch: 2 Step: 701 Loss: 1.5366168400782045\n",
      "Epoch: 2 Step: 711 Loss: 1.7285572569601118\n",
      "Epoch: 2 Step: 721 Loss: 1.5003204249746567\n",
      "Epoch: 2 Step: 731 Loss: 1.583367659372629\n",
      "Epoch: 2 Step: 741 Loss: 1.7666209041748362\n",
      "Epoch: 2 Step: 751 Loss: 1.9321640044557251\n",
      "Epoch: 2 Step: 761 Loss: 1.641066648743006\n",
      "Epoch: 2 Step: 771 Loss: 1.9110244996723453\n",
      "Epoch: 2 Step: 781 Loss: 1.6380094777136607\n",
      "Epoch: 3 Step: 1 Loss: 1.8450573907698824\n",
      "Epoch: 3 Step: 11 Loss: 1.817983832355575\n",
      "Epoch: 3 Step: 21 Loss: 1.7553252459864224\n",
      "Epoch: 3 Step: 31 Loss: 1.7852716279742047\n",
      "Epoch: 3 Step: 41 Loss: 1.6259239332438769\n",
      "Epoch: 3 Step: 51 Loss: 1.6395955718359922\n",
      "Epoch: 3 Step: 61 Loss: 1.7597617074415228\n",
      "Epoch: 3 Step: 71 Loss: 1.8061892295341584\n",
      "Epoch: 3 Step: 81 Loss: 1.8888525225675865\n",
      "Epoch: 3 Step: 91 Loss: 1.6578263730211225\n",
      "Epoch: 3 Step: 101 Loss: 1.5968354517848757\n",
      "Epoch: 3 Step: 111 Loss: 1.6703840565302528\n",
      "Epoch: 3 Step: 121 Loss: 1.6574741140565314\n",
      "Epoch: 3 Step: 131 Loss: 1.784021498413464\n",
      "Epoch: 3 Step: 141 Loss: 1.9592028787802473\n",
      "Epoch: 3 Step: 151 Loss: 1.4796794373537745\n",
      "Epoch: 3 Step: 161 Loss: 1.7156738418807749\n",
      "Epoch: 3 Step: 171 Loss: 1.6910813994436062\n",
      "Epoch: 3 Step: 181 Loss: 1.5784450562771468\n",
      "Epoch: 3 Step: 191 Loss: 1.5489788048283508\n",
      "Epoch: 3 Step: 201 Loss: 1.3415097970268157\n",
      "Epoch: 3 Step: 211 Loss: 1.5270499766690924\n",
      "Epoch: 3 Step: 221 Loss: 1.6037987764849617\n",
      "Epoch: 3 Step: 231 Loss: 1.5409399231893979\n",
      "Epoch: 3 Step: 241 Loss: 1.756987558171533\n",
      "Epoch: 3 Step: 251 Loss: 1.5127781432395482\n",
      "Epoch: 3 Step: 261 Loss: 1.5250831347857918\n",
      "Epoch: 3 Step: 271 Loss: 1.7076633319385501\n",
      "Epoch: 3 Step: 281 Loss: 1.5077996098707476\n",
      "Epoch: 3 Step: 291 Loss: 1.611942484615456\n",
      "Epoch: 3 Step: 301 Loss: 1.729012643716173\n",
      "Epoch: 3 Step: 311 Loss: 1.5480821179414417\n",
      "Epoch: 3 Step: 321 Loss: 1.7089040223179264\n",
      "Epoch: 3 Step: 331 Loss: 1.5259671295928539\n",
      "Epoch: 3 Step: 341 Loss: 1.6312419911565446\n",
      "Epoch: 3 Step: 351 Loss: 1.6667553498043546\n",
      "Epoch: 3 Step: 361 Loss: 1.6024268857931738\n",
      "Epoch: 3 Step: 371 Loss: 1.2878348667241601\n",
      "Epoch: 3 Step: 381 Loss: 1.6907319403113281\n",
      "Epoch: 3 Step: 391 Loss: 1.406258773552968\n",
      "Epoch: 3 Step: 401 Loss: 1.6881443205538078\n",
      "Epoch: 3 Step: 411 Loss: 1.8058377541837376\n",
      "Epoch: 3 Step: 421 Loss: 1.7792195658983427\n",
      "Epoch: 3 Step: 431 Loss: 1.5829441156450654\n",
      "Epoch: 3 Step: 441 Loss: 1.7151876308218656\n",
      "Epoch: 3 Step: 451 Loss: 1.5471501536788037\n",
      "Epoch: 3 Step: 461 Loss: 1.6073636750043236\n",
      "Epoch: 3 Step: 471 Loss: 1.5814636046556396\n",
      "Epoch: 3 Step: 481 Loss: 1.6294141920135887\n",
      "Epoch: 3 Step: 491 Loss: 1.9782163425743664\n",
      "Epoch: 3 Step: 501 Loss: 1.726310813022116\n",
      "Epoch: 3 Step: 511 Loss: 1.5544237170774187\n",
      "Epoch: 3 Step: 521 Loss: 1.6698285788252165\n",
      "Epoch: 3 Step: 531 Loss: 1.5501459395888846\n",
      "Epoch: 3 Step: 541 Loss: 1.6035370655137244\n",
      "Epoch: 3 Step: 551 Loss: 1.503423451445772\n",
      "Epoch: 3 Step: 561 Loss: 1.554656022943484\n",
      "Epoch: 3 Step: 571 Loss: 1.5534500707499328\n",
      "Epoch: 3 Step: 581 Loss: 1.664265151817978\n",
      "Epoch: 3 Step: 591 Loss: 1.623579264966991\n",
      "Epoch: 3 Step: 601 Loss: 1.6484055675401006\n",
      "Epoch: 3 Step: 611 Loss: 1.4522895369825923\n",
      "Epoch: 3 Step: 621 Loss: 1.5018234457755217\n",
      "Epoch: 3 Step: 631 Loss: 1.7296422923093326\n",
      "Epoch: 3 Step: 641 Loss: 1.67570933794432\n",
      "Epoch: 3 Step: 651 Loss: 1.6339527112058843\n",
      "Epoch: 3 Step: 661 Loss: 1.4805291310686772\n",
      "Epoch: 3 Step: 671 Loss: 1.5604650072860782\n",
      "Epoch: 3 Step: 681 Loss: 1.831759570299516\n",
      "Epoch: 3 Step: 691 Loss: 1.4467643818936524\n",
      "Epoch: 3 Step: 701 Loss: 1.4407977164704877\n",
      "Epoch: 3 Step: 711 Loss: 1.7050266736869926\n",
      "Epoch: 3 Step: 721 Loss: 1.3861824100799407\n",
      "Epoch: 3 Step: 731 Loss: 1.3803871846426838\n",
      "Epoch: 3 Step: 741 Loss: 1.6610691869354635\n",
      "Epoch: 3 Step: 751 Loss: 1.8914878538698587\n",
      "Epoch: 3 Step: 761 Loss: 1.4130745766630983\n",
      "Epoch: 3 Step: 771 Loss: 1.505770995030576\n",
      "Epoch: 3 Step: 781 Loss: 1.5348930365173543\n",
      "Epoch: 4 Step: 1 Loss: 1.6709732982634757\n",
      "Epoch: 4 Step: 11 Loss: 1.6020173514610607\n",
      "Epoch: 4 Step: 21 Loss: 1.4915368912473146\n",
      "Epoch: 4 Step: 31 Loss: 1.6359609141758722\n",
      "Epoch: 4 Step: 41 Loss: 1.4497722525143986\n",
      "Epoch: 4 Step: 51 Loss: 1.435995685612991\n",
      "Epoch: 4 Step: 61 Loss: 1.5654509634443585\n",
      "Epoch: 4 Step: 71 Loss: 1.6606413978572538\n",
      "Epoch: 4 Step: 81 Loss: 1.775090632814812\n",
      "Epoch: 4 Step: 91 Loss: 1.7019111864509813\n",
      "Epoch: 4 Step: 101 Loss: 1.5952745514434366\n",
      "Epoch: 4 Step: 111 Loss: 1.5651124791360473\n",
      "Epoch: 4 Step: 121 Loss: 1.6166528554439181\n",
      "Epoch: 4 Step: 131 Loss: 1.7518016548308144\n",
      "Epoch: 4 Step: 141 Loss: 1.9406592959132505\n",
      "Epoch: 4 Step: 151 Loss: 1.4527299435345895\n",
      "Epoch: 4 Step: 161 Loss: 1.6767278921109137\n",
      "Epoch: 4 Step: 171 Loss: 1.7327288799840534\n",
      "Epoch: 4 Step: 181 Loss: 1.5419542208764057\n",
      "Epoch: 4 Step: 191 Loss: 1.4821062761659456\n",
      "Epoch: 4 Step: 201 Loss: 1.2612143971802077\n",
      "Epoch: 4 Step: 211 Loss: 1.5542541599155488\n",
      "Epoch: 4 Step: 221 Loss: 1.6617526400872615\n",
      "Epoch: 4 Step: 231 Loss: 1.5089826585334913\n",
      "Epoch: 4 Step: 241 Loss: 1.6301307048093463\n",
      "Epoch: 4 Step: 251 Loss: 1.4460129955412313\n",
      "Epoch: 4 Step: 261 Loss: 1.4945616098572254\n",
      "Epoch: 4 Step: 271 Loss: 1.7990222976096466\n",
      "Epoch: 4 Step: 281 Loss: 1.4802994486633332\n",
      "Epoch: 4 Step: 291 Loss: 1.609649580380141\n",
      "Epoch: 4 Step: 301 Loss: 1.6829161356445357\n",
      "Epoch: 4 Step: 311 Loss: 1.5218855866909164\n",
      "Epoch: 4 Step: 321 Loss: 1.6334292984903769\n",
      "Epoch: 4 Step: 331 Loss: 1.501329315500044\n",
      "Epoch: 4 Step: 341 Loss: 1.5463979712765066\n",
      "Epoch: 4 Step: 351 Loss: 1.6762933359619079\n",
      "Epoch: 4 Step: 361 Loss: 1.5955799263710824\n",
      "Epoch: 4 Step: 371 Loss: 1.3245984678367042\n",
      "Epoch: 4 Step: 381 Loss: 1.638580444296068\n",
      "Epoch: 4 Step: 391 Loss: 1.3327408128709215\n",
      "Epoch: 4 Step: 401 Loss: 1.5939523387877463\n",
      "Epoch: 4 Step: 411 Loss: 1.5662548594300905\n",
      "Epoch: 4 Step: 421 Loss: 1.596319344697588\n",
      "Epoch: 4 Step: 431 Loss: 1.536853317344765\n",
      "Epoch: 4 Step: 441 Loss: 1.5923946844984513\n",
      "Epoch: 4 Step: 451 Loss: 1.4378331317483057\n",
      "Epoch: 4 Step: 461 Loss: 1.4670373244376724\n",
      "Epoch: 4 Step: 471 Loss: 1.472680133695746\n",
      "Epoch: 4 Step: 481 Loss: 1.5852674313355046\n",
      "Epoch: 4 Step: 491 Loss: 1.808827070474801\n",
      "Epoch: 4 Step: 501 Loss: 1.7050611260422501\n",
      "Epoch: 4 Step: 511 Loss: 1.5350004205638221\n",
      "Epoch: 4 Step: 521 Loss: 1.4914466172751428\n",
      "Epoch: 4 Step: 531 Loss: 1.4725379218229502\n",
      "Epoch: 4 Step: 541 Loss: 1.5022686155805265\n",
      "Epoch: 4 Step: 551 Loss: 1.4742698386090405\n",
      "Epoch: 4 Step: 561 Loss: 1.4430211480779094\n",
      "Epoch: 4 Step: 571 Loss: 1.4177883461283174\n",
      "Epoch: 4 Step: 581 Loss: 1.5798482469943815\n",
      "Epoch: 4 Step: 591 Loss: 1.6138417897947668\n",
      "Epoch: 4 Step: 601 Loss: 1.7488634166104915\n",
      "Epoch: 4 Step: 611 Loss: 1.33783924736733\n",
      "Epoch: 4 Step: 621 Loss: 1.4703060154569305\n",
      "Epoch: 4 Step: 631 Loss: 1.6554010485535033\n",
      "Epoch: 4 Step: 641 Loss: 1.5281975140675719\n",
      "Epoch: 4 Step: 651 Loss: 1.41678730424585\n",
      "Epoch: 4 Step: 661 Loss: 1.5834309054592706\n",
      "Epoch: 4 Step: 671 Loss: 1.5045458186397265\n",
      "Epoch: 4 Step: 681 Loss: 1.776066387571569\n",
      "Epoch: 4 Step: 691 Loss: 1.4666552920442688\n",
      "Epoch: 4 Step: 701 Loss: 1.4137817581592105\n",
      "Epoch: 4 Step: 711 Loss: 1.5452345256469333\n",
      "Epoch: 4 Step: 721 Loss: 1.463479070482948\n",
      "Epoch: 4 Step: 731 Loss: 1.3469468370684536\n",
      "Epoch: 4 Step: 741 Loss: 1.6907723565718666\n",
      "Epoch: 4 Step: 751 Loss: 1.8325680159423299\n",
      "Epoch: 4 Step: 761 Loss: 1.3566528865958165\n",
      "Epoch: 4 Step: 771 Loss: 1.5571995276325639\n",
      "Epoch: 4 Step: 781 Loss: 1.4563523909508773\n",
      "Epoch: 5 Step: 1 Loss: 1.591904379310681\n",
      "Epoch: 5 Step: 11 Loss: 1.7033597830725822\n",
      "Epoch: 5 Step: 21 Loss: 1.5348768117182485\n",
      "Epoch: 5 Step: 31 Loss: 1.743674269200893\n",
      "Epoch: 5 Step: 41 Loss: 1.4662259128592625\n",
      "Epoch: 5 Step: 51 Loss: 1.3707452545226748\n",
      "Epoch: 5 Step: 61 Loss: 1.597525603839773\n",
      "Epoch: 5 Step: 71 Loss: 1.5665876207787477\n",
      "Epoch: 5 Step: 81 Loss: 1.7150226382324956\n",
      "Epoch: 5 Step: 91 Loss: 1.5888299806792454\n",
      "Epoch: 5 Step: 101 Loss: 1.4366565065208075\n",
      "Epoch: 5 Step: 111 Loss: 1.435530702704876\n",
      "Epoch: 5 Step: 121 Loss: 1.5663237651822588\n",
      "Epoch: 5 Step: 131 Loss: 1.3695913031314562\n",
      "Epoch: 5 Step: 141 Loss: 1.8897679308523303\n",
      "Epoch: 5 Step: 151 Loss: 1.373348391564353\n",
      "Epoch: 5 Step: 161 Loss: 1.499997410048609\n",
      "Epoch: 5 Step: 171 Loss: 1.5878739168066387\n",
      "Epoch: 5 Step: 181 Loss: 1.345670664638027\n",
      "Epoch: 5 Step: 191 Loss: 1.3932657993808826\n",
      "Epoch: 5 Step: 201 Loss: 1.1935726186012496\n",
      "Epoch: 5 Step: 211 Loss: 1.4101073243953555\n",
      "Epoch: 5 Step: 221 Loss: 1.5716455641940315\n",
      "Epoch: 5 Step: 231 Loss: 1.5004696035502436\n",
      "Epoch: 5 Step: 241 Loss: 1.7089435847957106\n",
      "Epoch: 5 Step: 251 Loss: 1.438931000438136\n",
      "Epoch: 5 Step: 261 Loss: 1.500828716105866\n",
      "Epoch: 5 Step: 271 Loss: 1.6418597383493818\n",
      "Epoch: 5 Step: 281 Loss: 1.5110258984732987\n",
      "Epoch: 5 Step: 291 Loss: 1.5195502720419016\n",
      "Epoch: 5 Step: 301 Loss: 1.5940745139671\n",
      "Epoch: 5 Step: 311 Loss: 1.4927653418727203\n",
      "Epoch: 5 Step: 321 Loss: 1.6712709985837828\n",
      "Epoch: 5 Step: 331 Loss: 1.53345844046155\n",
      "Epoch: 5 Step: 341 Loss: 1.7490501048634624\n",
      "Epoch: 5 Step: 351 Loss: 1.7026847147075976\n",
      "Epoch: 5 Step: 361 Loss: 1.586291993109945\n",
      "Epoch: 5 Step: 371 Loss: 1.3487873151653327\n",
      "Epoch: 5 Step: 381 Loss: 1.6225127216274915\n",
      "Epoch: 5 Step: 391 Loss: 1.3335871426689097\n",
      "Epoch: 5 Step: 401 Loss: 1.646185832519845\n",
      "Epoch: 5 Step: 411 Loss: 1.6953616294009524\n",
      "Epoch: 5 Step: 421 Loss: 1.5848254849644454\n",
      "Epoch: 5 Step: 431 Loss: 1.489789793936217\n",
      "Epoch: 5 Step: 441 Loss: 1.6841160119787397\n",
      "Epoch: 5 Step: 451 Loss: 1.3444076354364896\n",
      "Epoch: 5 Step: 461 Loss: 1.5793500594925596\n",
      "Epoch: 5 Step: 471 Loss: 1.4927115979763363\n",
      "Epoch: 5 Step: 481 Loss: 1.55871898999507\n",
      "Epoch: 5 Step: 491 Loss: 1.7438619072021129\n",
      "Epoch: 5 Step: 501 Loss: 1.638652222562368\n",
      "Epoch: 5 Step: 511 Loss: 1.5486348802816763\n",
      "Epoch: 5 Step: 521 Loss: 1.5356426234399811\n",
      "Epoch: 5 Step: 531 Loss: 1.3982303972522065\n",
      "Epoch: 5 Step: 541 Loss: 1.4602548758416405\n",
      "Epoch: 5 Step: 551 Loss: 1.3533770205189941\n",
      "Epoch: 5 Step: 561 Loss: 1.2746413553138563\n",
      "Epoch: 5 Step: 571 Loss: 1.4040626935696428\n",
      "Epoch: 5 Step: 581 Loss: 1.482240824415252\n",
      "Epoch: 5 Step: 591 Loss: 1.5850809303023126\n",
      "Epoch: 5 Step: 601 Loss: 1.581870913473883\n",
      "Epoch: 5 Step: 611 Loss: 1.3192851030602482\n",
      "Epoch: 5 Step: 621 Loss: 1.3404229923700655\n",
      "Epoch: 5 Step: 631 Loss: 1.5322764403267288\n",
      "Epoch: 5 Step: 641 Loss: 1.479448467471221\n",
      "Epoch: 5 Step: 651 Loss: 1.5218037391419181\n",
      "Epoch: 5 Step: 661 Loss: 1.380722772384873\n",
      "Epoch: 5 Step: 671 Loss: 1.5752754582858106\n",
      "Epoch: 5 Step: 681 Loss: 1.6030545444759126\n",
      "Epoch: 5 Step: 691 Loss: 1.430450235097808\n",
      "Epoch: 5 Step: 701 Loss: 1.3772107396624702\n",
      "Epoch: 5 Step: 711 Loss: 1.4128673639129372\n",
      "Epoch: 5 Step: 721 Loss: 1.3006384781190932\n",
      "Epoch: 5 Step: 731 Loss: 1.3046981367968076\n",
      "Epoch: 5 Step: 741 Loss: 1.5889098214481285\n",
      "Epoch: 5 Step: 751 Loss: 1.7445051059048735\n",
      "Epoch: 5 Step: 761 Loss: 1.353369189164923\n",
      "Epoch: 5 Step: 771 Loss: 1.5514435748119815\n",
      "Epoch: 5 Step: 781 Loss: 1.3638502021176149\n",
      "Epoch: 6 Step: 1 Loss: 1.4897589712248265\n",
      "Epoch: 6 Step: 11 Loss: 1.670646522918318\n",
      "Epoch: 6 Step: 21 Loss: 1.5938861607214834\n",
      "Epoch: 6 Step: 31 Loss: 1.524892857484176\n",
      "Epoch: 6 Step: 41 Loss: 1.5254453662891767\n",
      "Epoch: 6 Step: 51 Loss: 1.3133252272071951\n",
      "Epoch: 6 Step: 61 Loss: 1.5505457592524137\n",
      "Epoch: 6 Step: 71 Loss: 1.7233004273290113\n",
      "Epoch: 6 Step: 81 Loss: 1.6725056474079725\n",
      "Epoch: 6 Step: 91 Loss: 1.642539476242575\n",
      "Epoch: 6 Step: 101 Loss: 1.4478673252943828\n",
      "Epoch: 6 Step: 111 Loss: 1.5118284711666032\n",
      "Epoch: 6 Step: 121 Loss: 1.4959697586883722\n",
      "Epoch: 6 Step: 131 Loss: 1.4449733943588494\n",
      "Epoch: 6 Step: 141 Loss: 1.6329386206946643\n",
      "Epoch: 6 Step: 151 Loss: 1.2105555879022112\n",
      "Epoch: 6 Step: 161 Loss: 1.51046755031969\n",
      "Epoch: 6 Step: 171 Loss: 1.5395159153997642\n",
      "Epoch: 6 Step: 181 Loss: 1.5216404154327823\n",
      "Epoch: 6 Step: 191 Loss: 1.3134808841946608\n",
      "Epoch: 6 Step: 201 Loss: 1.2200593054940947\n",
      "Epoch: 6 Step: 211 Loss: 1.2657284828701623\n",
      "Epoch: 6 Step: 221 Loss: 1.524146249357714\n",
      "Epoch: 6 Step: 231 Loss: 1.3319917112638113\n",
      "Epoch: 6 Step: 241 Loss: 1.6601214736396215\n",
      "Epoch: 6 Step: 251 Loss: 1.3599323854322747\n",
      "Epoch: 6 Step: 261 Loss: 1.347956285983563\n",
      "Epoch: 6 Step: 271 Loss: 1.5568571678846728\n",
      "Epoch: 6 Step: 281 Loss: 1.5182570187534663\n",
      "Epoch: 6 Step: 291 Loss: 1.5314587283550987\n",
      "Epoch: 6 Step: 301 Loss: 1.398165861294144\n",
      "Epoch: 6 Step: 311 Loss: 1.495000406846611\n",
      "Epoch: 6 Step: 321 Loss: 1.5855265791205593\n",
      "Epoch: 6 Step: 331 Loss: 1.4824578486438023\n",
      "Epoch: 6 Step: 341 Loss: 1.6187920457978255\n",
      "Epoch: 6 Step: 351 Loss: 1.6047617296982017\n",
      "Epoch: 6 Step: 361 Loss: 1.4694171097643043\n",
      "Epoch: 6 Step: 371 Loss: 1.2447541745150068\n",
      "Epoch: 6 Step: 381 Loss: 1.6496209764457836\n",
      "Epoch: 6 Step: 391 Loss: 1.2955438099388599\n",
      "Epoch: 6 Step: 401 Loss: 1.659332081589223\n",
      "Epoch: 6 Step: 411 Loss: 1.4955136470266832\n",
      "Epoch: 6 Step: 421 Loss: 1.5509999445111025\n",
      "Epoch: 6 Step: 431 Loss: 1.4669578562793175\n",
      "Epoch: 6 Step: 441 Loss: 1.4843051783118755\n",
      "Epoch: 6 Step: 451 Loss: 1.4085147240492035\n",
      "Epoch: 6 Step: 461 Loss: 1.5107323666012833\n",
      "Epoch: 6 Step: 471 Loss: 1.4766049292791081\n",
      "Epoch: 6 Step: 481 Loss: 1.5747538279675135\n",
      "Epoch: 6 Step: 491 Loss: 1.8193246592689885\n",
      "Epoch: 6 Step: 501 Loss: 1.6623541384387865\n",
      "Epoch: 6 Step: 511 Loss: 1.4781605152552943\n",
      "Epoch: 6 Step: 521 Loss: 1.517319379924902\n",
      "Epoch: 6 Step: 531 Loss: 1.453027812334146\n",
      "Epoch: 6 Step: 541 Loss: 1.4911088254568516\n",
      "Epoch: 6 Step: 551 Loss: 1.3742489588104745\n",
      "Epoch: 6 Step: 561 Loss: 1.3053927625080104\n",
      "Epoch: 6 Step: 571 Loss: 1.5272151648903862\n",
      "Epoch: 6 Step: 581 Loss: 1.4943778037986948\n",
      "Epoch: 6 Step: 591 Loss: 1.5340612641044875\n",
      "Epoch: 6 Step: 601 Loss: 1.5401614527687637\n",
      "Epoch: 6 Step: 611 Loss: 1.3227995338141452\n",
      "Epoch: 6 Step: 621 Loss: 1.4610550098448822\n",
      "Epoch: 6 Step: 631 Loss: 1.59829338305022\n",
      "Epoch: 6 Step: 641 Loss: 1.5107329746871792\n",
      "Epoch: 6 Step: 651 Loss: 1.4929160986017662\n",
      "Epoch: 6 Step: 661 Loss: 1.276653754128927\n",
      "Epoch: 6 Step: 671 Loss: 1.4293840785547536\n",
      "Epoch: 6 Step: 681 Loss: 1.6175002967744203\n",
      "Epoch: 6 Step: 691 Loss: 1.4353396907582234\n",
      "Epoch: 6 Step: 701 Loss: 1.2768123605204262\n",
      "Epoch: 6 Step: 711 Loss: 1.4274817486745899\n",
      "Epoch: 6 Step: 721 Loss: 1.1787150101867376\n",
      "Epoch: 6 Step: 731 Loss: 1.1914894419168816\n",
      "Epoch: 6 Step: 741 Loss: 1.4645266177051495\n",
      "Epoch: 6 Step: 751 Loss: 1.7365997604450287\n",
      "Epoch: 6 Step: 761 Loss: 1.3753828863112074\n",
      "Epoch: 6 Step: 771 Loss: 1.477452688914767\n",
      "Epoch: 6 Step: 781 Loss: 1.4040097108165874\n",
      "Epoch: 7 Step: 1 Loss: 1.52717076123858\n",
      "Epoch: 7 Step: 11 Loss: 1.5660008521591844\n",
      "Epoch: 7 Step: 21 Loss: 1.4904168496840797\n",
      "Epoch: 7 Step: 31 Loss: 1.731752604039905\n",
      "Epoch: 7 Step: 41 Loss: 1.4276155147267398\n",
      "Epoch: 7 Step: 51 Loss: 1.3291007557629773\n",
      "Epoch: 7 Step: 61 Loss: 1.5310207083427332\n",
      "Epoch: 7 Step: 71 Loss: 1.568341383490695\n",
      "Epoch: 7 Step: 81 Loss: 1.5252825674566315\n",
      "Epoch: 7 Step: 91 Loss: 1.5893118650223705\n",
      "Epoch: 7 Step: 101 Loss: 1.5045078151236528\n",
      "Epoch: 7 Step: 111 Loss: 1.4885177092973851\n",
      "Epoch: 7 Step: 121 Loss: 1.6228700338770878\n",
      "Epoch: 7 Step: 131 Loss: 1.4334989050167053\n",
      "Epoch: 7 Step: 141 Loss: 1.7834415362586247\n",
      "Epoch: 7 Step: 151 Loss: 1.2267937851071316\n",
      "Epoch: 7 Step: 161 Loss: 1.513941883195772\n",
      "Epoch: 7 Step: 171 Loss: 1.4800712755134566\n",
      "Epoch: 7 Step: 181 Loss: 1.4155898624574053\n",
      "Epoch: 7 Step: 191 Loss: 1.4151766654105333\n",
      "Epoch: 7 Step: 201 Loss: 1.1644716619300717\n",
      "Epoch: 7 Step: 211 Loss: 1.213527913387241\n",
      "Epoch: 7 Step: 221 Loss: 1.4502954533029984\n",
      "Epoch: 7 Step: 231 Loss: 1.2586772291457247\n",
      "Epoch: 7 Step: 241 Loss: 1.5752899160020457\n",
      "Epoch: 7 Step: 251 Loss: 1.261723371412598\n",
      "Epoch: 7 Step: 261 Loss: 1.3908664764845218\n",
      "Epoch: 7 Step: 271 Loss: 1.614839546904525\n",
      "Epoch: 7 Step: 281 Loss: 1.4454601021656432\n",
      "Epoch: 7 Step: 291 Loss: 1.5550362256960197\n",
      "Epoch: 7 Step: 301 Loss: 1.4854096709038418\n",
      "Epoch: 7 Step: 311 Loss: 1.476941508946529\n",
      "Epoch: 7 Step: 321 Loss: 1.5196901198929695\n",
      "Epoch: 7 Step: 331 Loss: 1.4065846771498203\n",
      "Epoch: 7 Step: 341 Loss: 1.4560014971318571\n",
      "Epoch: 7 Step: 351 Loss: 1.471407826373356\n",
      "Epoch: 7 Step: 361 Loss: 1.3317087298782657\n",
      "Epoch: 7 Step: 371 Loss: 1.041748591832933\n",
      "Epoch: 7 Step: 381 Loss: 1.6031287165760657\n",
      "Epoch: 7 Step: 391 Loss: 1.185218750775913\n",
      "Epoch: 7 Step: 401 Loss: 1.3602542331513765\n",
      "Epoch: 7 Step: 411 Loss: 1.4796624505638256\n",
      "Epoch: 7 Step: 421 Loss: 1.45726797369647\n",
      "Epoch: 7 Step: 431 Loss: 1.380435964724453\n",
      "Epoch: 7 Step: 441 Loss: 1.420533391952426\n",
      "Epoch: 7 Step: 451 Loss: 1.351500488444898\n",
      "Epoch: 7 Step: 461 Loss: 1.4361223227693316\n",
      "Epoch: 7 Step: 471 Loss: 1.4134981833498637\n",
      "Epoch: 7 Step: 481 Loss: 1.5538938745939044\n",
      "Epoch: 7 Step: 491 Loss: 1.8377478524064852\n",
      "Epoch: 7 Step: 501 Loss: 1.6268974412671544\n",
      "Epoch: 7 Step: 511 Loss: 1.3593499586959\n",
      "Epoch: 7 Step: 521 Loss: 1.4293330401417337\n",
      "Epoch: 7 Step: 531 Loss: 1.4703470295279253\n",
      "Epoch: 7 Step: 541 Loss: 1.402153265239106\n",
      "Epoch: 7 Step: 551 Loss: 1.3656406584514618\n",
      "Epoch: 7 Step: 561 Loss: 1.2705048168446733\n",
      "Epoch: 7 Step: 571 Loss: 1.373529986544758\n",
      "Epoch: 7 Step: 581 Loss: 1.4516821774224695\n",
      "Epoch: 7 Step: 591 Loss: 1.4961722035821023\n",
      "Epoch: 7 Step: 601 Loss: 1.646389984998379\n",
      "Epoch: 7 Step: 611 Loss: 1.379847738747884\n",
      "Epoch: 7 Step: 621 Loss: 1.3532808665146732\n",
      "Epoch: 7 Step: 631 Loss: 1.629416808526108\n",
      "Epoch: 7 Step: 641 Loss: 1.428728221350553\n",
      "Epoch: 7 Step: 651 Loss: 1.4318527486173607\n",
      "Epoch: 7 Step: 661 Loss: 1.432428130095676\n",
      "Epoch: 7 Step: 671 Loss: 1.5007173432648164\n",
      "Epoch: 7 Step: 681 Loss: 1.5139438296817473\n",
      "Epoch: 7 Step: 691 Loss: 1.3580768420092477\n",
      "Epoch: 7 Step: 701 Loss: 1.3586087822071793\n",
      "Epoch: 7 Step: 711 Loss: 1.3990019267153346\n",
      "Epoch: 7 Step: 721 Loss: 1.1642569482610892\n",
      "Epoch: 7 Step: 731 Loss: 1.1717505232102585\n",
      "Epoch: 7 Step: 741 Loss: 1.4226543728914716\n",
      "Epoch: 7 Step: 751 Loss: 1.696445728831083\n",
      "Epoch: 7 Step: 761 Loss: 1.2485141672381497\n",
      "Epoch: 7 Step: 771 Loss: 1.4986504982191382\n",
      "Epoch: 7 Step: 781 Loss: 1.390498463752394\n",
      "Epoch: 8 Step: 1 Loss: 1.439271335500236\n",
      "Epoch: 8 Step: 11 Loss: 1.5034748258331447\n",
      "Epoch: 8 Step: 21 Loss: 1.335553797957364\n",
      "Epoch: 8 Step: 31 Loss: 1.5597588834444382\n",
      "Epoch: 8 Step: 41 Loss: 1.2782189383856284\n",
      "Epoch: 8 Step: 51 Loss: 1.365507100778446\n",
      "Epoch: 8 Step: 61 Loss: 1.3428447694711005\n",
      "Epoch: 8 Step: 71 Loss: 1.4654053080378202\n",
      "Epoch: 8 Step: 81 Loss: 1.5198936182502294\n",
      "Epoch: 8 Step: 91 Loss: 1.537224756694341\n",
      "Epoch: 8 Step: 101 Loss: 1.292402792895629\n",
      "Epoch: 8 Step: 111 Loss: 1.3834361745656836\n",
      "Epoch: 8 Step: 121 Loss: 1.4365665673217072\n",
      "Epoch: 8 Step: 131 Loss: 1.3453959445242418\n",
      "Epoch: 8 Step: 141 Loss: 1.7184640252151415\n",
      "Epoch: 8 Step: 151 Loss: 1.2475172961553511\n",
      "Epoch: 8 Step: 161 Loss: 1.448952318053778\n",
      "Epoch: 8 Step: 171 Loss: 1.400896618233626\n",
      "Epoch: 8 Step: 181 Loss: 1.4437038925091081\n",
      "Epoch: 8 Step: 191 Loss: 1.4035444016740855\n",
      "Epoch: 8 Step: 201 Loss: 1.0832340877810247\n",
      "Epoch: 8 Step: 211 Loss: 1.2538563367977926\n",
      "Epoch: 8 Step: 221 Loss: 1.5314829946706494\n",
      "Epoch: 8 Step: 231 Loss: 1.2021265025056849\n",
      "Epoch: 8 Step: 241 Loss: 1.5126899398985598\n",
      "Epoch: 8 Step: 251 Loss: 1.398669029690901\n",
      "Epoch: 8 Step: 261 Loss: 1.3097852948049558\n",
      "Epoch: 8 Step: 271 Loss: 1.7222728849079052\n",
      "Epoch: 8 Step: 281 Loss: 1.352996487971176\n",
      "Epoch: 8 Step: 291 Loss: 1.4695392969586227\n",
      "Epoch: 8 Step: 301 Loss: 1.5994667630070185\n",
      "Epoch: 8 Step: 311 Loss: 1.4975216771646767\n",
      "Epoch: 8 Step: 321 Loss: 1.5316664110572016\n",
      "Epoch: 8 Step: 331 Loss: 1.4612995122534191\n",
      "Epoch: 8 Step: 341 Loss: 1.4140275163297833\n",
      "Epoch: 8 Step: 351 Loss: 1.5223648987381921\n",
      "Epoch: 8 Step: 361 Loss: 1.4093076545514167\n",
      "Epoch: 8 Step: 371 Loss: 1.2614240650474897\n",
      "Epoch: 8 Step: 381 Loss: 1.570732750290031\n",
      "Epoch: 8 Step: 391 Loss: 1.2667402641145613\n",
      "Epoch: 8 Step: 401 Loss: 1.4368752712258284\n",
      "Epoch: 8 Step: 411 Loss: 1.4511669590741705\n",
      "Epoch: 8 Step: 421 Loss: 1.5435582644474524\n",
      "Epoch: 8 Step: 431 Loss: 1.4038105997250927\n",
      "Epoch: 8 Step: 441 Loss: 1.4183629327285336\n",
      "Epoch: 8 Step: 451 Loss: 1.3592641760560729\n",
      "Epoch: 8 Step: 461 Loss: 1.4738365752828155\n",
      "Epoch: 8 Step: 471 Loss: 1.38287688230395\n",
      "Epoch: 8 Step: 481 Loss: 1.4743023047098387\n",
      "Epoch: 8 Step: 491 Loss: 1.6812952444387188\n",
      "Epoch: 8 Step: 501 Loss: 1.3533468850231931\n",
      "Epoch: 8 Step: 511 Loss: 1.2967902582661446\n",
      "Epoch: 8 Step: 521 Loss: 1.4052381733619441\n",
      "Epoch: 8 Step: 531 Loss: 1.3981579874684424\n",
      "Epoch: 8 Step: 541 Loss: 1.4388131606348726\n",
      "Epoch: 8 Step: 551 Loss: 1.3016741804943406\n",
      "Epoch: 8 Step: 561 Loss: 1.3427024207145877\n",
      "Epoch: 8 Step: 571 Loss: 1.2618652737238372\n",
      "Epoch: 8 Step: 581 Loss: 1.3636690456587397\n",
      "Epoch: 8 Step: 591 Loss: 1.5075466486167084\n",
      "Epoch: 8 Step: 601 Loss: 1.5120355175403668\n",
      "Epoch: 8 Step: 611 Loss: 1.3231365384524723\n",
      "Epoch: 8 Step: 621 Loss: 1.3739761004176003\n",
      "Epoch: 8 Step: 631 Loss: 1.4997147770119788\n",
      "Epoch: 8 Step: 641 Loss: 1.4788003465338746\n",
      "Epoch: 8 Step: 651 Loss: 1.4415900138915223\n",
      "Epoch: 8 Step: 661 Loss: 1.3831120861937598\n",
      "Epoch: 8 Step: 671 Loss: 1.4588667928188384\n",
      "Epoch: 8 Step: 681 Loss: 1.610286910756316\n",
      "Epoch: 8 Step: 691 Loss: 1.362253342764443\n",
      "Epoch: 8 Step: 701 Loss: 1.2437121710356975\n",
      "Epoch: 8 Step: 711 Loss: 1.3591401174444167\n",
      "Epoch: 8 Step: 721 Loss: 1.2830574845058298\n",
      "Epoch: 8 Step: 731 Loss: 1.1921435757946846\n",
      "Epoch: 8 Step: 741 Loss: 1.4684648743257531\n",
      "Epoch: 8 Step: 751 Loss: 1.7275241269732449\n",
      "Epoch: 8 Step: 761 Loss: 1.3427458377018975\n",
      "Epoch: 8 Step: 771 Loss: 1.51809209264243\n",
      "Epoch: 8 Step: 781 Loss: 1.4424730475441725\n",
      "Epoch: 9 Step: 1 Loss: 1.517253222034491\n",
      "Epoch: 9 Step: 11 Loss: 1.57402283316098\n",
      "Epoch: 9 Step: 21 Loss: 1.454739619293864\n",
      "Epoch: 9 Step: 31 Loss: 1.762105348917026\n",
      "Epoch: 9 Step: 41 Loss: 1.3667765350995937\n",
      "Epoch: 9 Step: 51 Loss: 1.2997710488824823\n",
      "Epoch: 9 Step: 61 Loss: 1.5171123856598834\n",
      "Epoch: 9 Step: 71 Loss: 1.4677131083874972\n",
      "Epoch: 9 Step: 81 Loss: 1.5619205318618652\n",
      "Epoch: 9 Step: 91 Loss: 1.500301819277382\n",
      "Epoch: 9 Step: 101 Loss: 1.3955799745560713\n",
      "Epoch: 9 Step: 111 Loss: 1.3961737149553235\n",
      "Epoch: 9 Step: 121 Loss: 1.5376590529558203\n",
      "Epoch: 9 Step: 131 Loss: 1.2904536483257976\n",
      "Epoch: 9 Step: 141 Loss: 1.5454771373740464\n",
      "Epoch: 9 Step: 151 Loss: 1.2031436070290353\n",
      "Epoch: 9 Step: 161 Loss: 1.3896298051000322\n",
      "Epoch: 9 Step: 171 Loss: 1.416947916751182\n",
      "Epoch: 9 Step: 181 Loss: 1.2882857579133642\n",
      "Epoch: 9 Step: 191 Loss: 1.262484270411267\n",
      "Epoch: 9 Step: 201 Loss: 1.0550531200181528\n",
      "Epoch: 9 Step: 211 Loss: 1.1711744813807388\n",
      "Epoch: 9 Step: 221 Loss: 1.4622213411776186\n",
      "Epoch: 9 Step: 231 Loss: 1.2401409081745731\n",
      "Epoch: 9 Step: 241 Loss: 1.5095426077699337\n",
      "Epoch: 9 Step: 251 Loss: 1.2149320619218658\n",
      "Epoch: 9 Step: 261 Loss: 1.3019741015994877\n",
      "Epoch: 9 Step: 271 Loss: 1.618100852037096\n",
      "Epoch: 9 Step: 281 Loss: 1.4011881862129152\n",
      "Epoch: 9 Step: 291 Loss: 1.4843717862514283\n",
      "Epoch: 9 Step: 301 Loss: 1.5277164408418722\n",
      "Epoch: 9 Step: 311 Loss: 1.4103208428985623\n",
      "Epoch: 9 Step: 321 Loss: 1.4185422112649437\n",
      "Epoch: 9 Step: 331 Loss: 1.4545075743294813\n",
      "Epoch: 9 Step: 341 Loss: 1.5077719284394548\n",
      "Epoch: 9 Step: 351 Loss: 1.495202245404523\n",
      "Epoch: 9 Step: 361 Loss: 1.424194236064488\n",
      "Epoch: 9 Step: 371 Loss: 1.1489683987760655\n",
      "Epoch: 9 Step: 381 Loss: 1.5412725796775735\n",
      "Epoch: 9 Step: 391 Loss: 1.2636741247838124\n",
      "Epoch: 9 Step: 401 Loss: 1.3668462318219448\n",
      "Epoch: 9 Step: 411 Loss: 1.5596323621665786\n",
      "Epoch: 9 Step: 421 Loss: 1.546129164477346\n",
      "Epoch: 9 Step: 431 Loss: 1.386885143711179\n",
      "Epoch: 9 Step: 441 Loss: 1.3284448394476487\n",
      "Epoch: 9 Step: 451 Loss: 1.525933652803733\n",
      "Epoch: 9 Step: 461 Loss: 1.4517055056160313\n",
      "Epoch: 9 Step: 471 Loss: 1.32446956092602\n",
      "Epoch: 9 Step: 481 Loss: 1.509162318634197\n",
      "Epoch: 9 Step: 491 Loss: 1.715985094576793\n",
      "Epoch: 9 Step: 501 Loss: 1.5321588412662461\n",
      "Epoch: 9 Step: 511 Loss: 1.3347692529242838\n",
      "Epoch: 9 Step: 521 Loss: 1.3983030769345515\n",
      "Epoch: 9 Step: 531 Loss: 1.3636645879541787\n",
      "Epoch: 9 Step: 541 Loss: 1.3437007097162195\n",
      "Epoch: 9 Step: 551 Loss: 1.3115850360941073\n",
      "Epoch: 9 Step: 561 Loss: 1.195080903865147\n",
      "Epoch: 9 Step: 571 Loss: 1.330242040912649\n",
      "Epoch: 9 Step: 581 Loss: 1.2844671904226495\n",
      "Epoch: 9 Step: 591 Loss: 1.4150861780786914\n",
      "Epoch: 9 Step: 601 Loss: 1.4351802894942431\n",
      "Epoch: 9 Step: 611 Loss: 1.147577106763631\n",
      "Epoch: 9 Step: 621 Loss: 1.3974882860509759\n",
      "Epoch: 9 Step: 631 Loss: 1.340726473249129\n",
      "Epoch: 9 Step: 641 Loss: 1.3407204956013006\n",
      "Epoch: 9 Step: 651 Loss: 1.4092467081180966\n",
      "Epoch: 9 Step: 661 Loss: 1.143651168317168\n",
      "Epoch: 9 Step: 671 Loss: 1.2744354130053888\n",
      "Epoch: 9 Step: 681 Loss: 1.4159145575606278\n",
      "Epoch: 9 Step: 691 Loss: 1.3855767374744115\n",
      "Epoch: 9 Step: 701 Loss: 1.2567531033520563\n",
      "Epoch: 9 Step: 711 Loss: 1.2572627047258682\n",
      "Epoch: 9 Step: 721 Loss: 1.1106792898564877\n",
      "Epoch: 9 Step: 731 Loss: 1.2175870092828212\n",
      "Epoch: 9 Step: 741 Loss: 1.6142150583985457\n",
      "Epoch: 9 Step: 751 Loss: 1.6506794052072262\n",
      "Epoch: 9 Step: 761 Loss: 1.3606406169414966\n",
      "Epoch: 9 Step: 771 Loss: 1.4996792445689093\n",
      "Epoch: 9 Step: 781 Loss: 1.4131472456640293\n",
      "Epoch: 10 Step: 1 Loss: 1.427873470360438\n",
      "Epoch: 10 Step: 11 Loss: 1.5992747731821768\n",
      "Epoch: 10 Step: 21 Loss: 1.3482768276761012\n",
      "Epoch: 10 Step: 31 Loss: 1.4266552890505082\n",
      "Epoch: 10 Step: 41 Loss: 1.3942969702670163\n",
      "Epoch: 10 Step: 51 Loss: 1.3631658681274301\n",
      "Epoch: 10 Step: 61 Loss: 1.482060569332377\n",
      "Epoch: 10 Step: 71 Loss: 1.5169470488058716\n",
      "Epoch: 10 Step: 81 Loss: 1.5568296999200908\n",
      "Epoch: 10 Step: 91 Loss: 1.4994736020712858\n",
      "Epoch: 10 Step: 101 Loss: 1.307410753356696\n",
      "Epoch: 10 Step: 111 Loss: 1.4492902309161837\n",
      "Epoch: 10 Step: 121 Loss: 1.5931259269652953\n",
      "Epoch: 10 Step: 131 Loss: 1.284977626582135\n",
      "Epoch: 10 Step: 141 Loss: 1.7406245421064663\n",
      "Epoch: 10 Step: 151 Loss: 1.1573986578413016\n",
      "Epoch: 10 Step: 161 Loss: 1.3655286335234025\n",
      "Epoch: 10 Step: 171 Loss: 1.364650458184514\n",
      "Epoch: 10 Step: 181 Loss: 1.3595001664015078\n",
      "Epoch: 10 Step: 191 Loss: 1.4111079040087071\n",
      "Epoch: 10 Step: 201 Loss: 1.145658207342179\n",
      "Epoch: 10 Step: 211 Loss: 1.1745502804950139\n",
      "Epoch: 10 Step: 221 Loss: 1.2931446114951548\n",
      "Epoch: 10 Step: 231 Loss: 1.2860150434923066\n",
      "Epoch: 10 Step: 241 Loss: 1.5474763886915532\n",
      "Epoch: 10 Step: 251 Loss: 1.1776466938965968\n",
      "Epoch: 10 Step: 261 Loss: 1.4215495604103037\n",
      "Epoch: 10 Step: 271 Loss: 1.3431216644534496\n",
      "Epoch: 10 Step: 281 Loss: 1.3790045479834525\n",
      "Epoch: 10 Step: 291 Loss: 1.4811693018897696\n",
      "Epoch: 10 Step: 301 Loss: 1.3175590009283864\n",
      "Epoch: 10 Step: 311 Loss: 1.4878624582293616\n",
      "Epoch: 10 Step: 321 Loss: 1.368879091939227\n",
      "Epoch: 10 Step: 331 Loss: 1.2918790201660755\n",
      "Epoch: 10 Step: 341 Loss: 1.4489412143565001\n",
      "Epoch: 10 Step: 351 Loss: 1.444936119506071\n",
      "Epoch: 10 Step: 361 Loss: 1.3357012352848776\n",
      "Epoch: 10 Step: 371 Loss: 1.0686017941282644\n",
      "Epoch: 10 Step: 381 Loss: 1.5857900770143543\n",
      "Epoch: 10 Step: 391 Loss: 1.1618936343229516\n",
      "Epoch: 10 Step: 401 Loss: 1.1738979830384497\n",
      "Epoch: 10 Step: 411 Loss: 1.4011001586453804\n",
      "Epoch: 10 Step: 421 Loss: 1.5454739903277819\n",
      "Epoch: 10 Step: 431 Loss: 1.4289645575463925\n",
      "Epoch: 10 Step: 441 Loss: 1.5737858282317694\n",
      "Epoch: 10 Step: 451 Loss: 1.2752532352577044\n",
      "Epoch: 10 Step: 461 Loss: 1.4143081109777844\n",
      "Epoch: 10 Step: 471 Loss: 1.409230105134261\n",
      "Epoch: 10 Step: 481 Loss: 1.5366452982956618\n",
      "Epoch: 10 Step: 491 Loss: 1.6904715040865887\n",
      "Epoch: 10 Step: 501 Loss: 1.4277645773063885\n",
      "Epoch: 10 Step: 511 Loss: 1.3302122122667548\n",
      "Epoch: 10 Step: 521 Loss: 1.4529745383200172\n",
      "Epoch: 10 Step: 531 Loss: 1.4832467043375457\n",
      "Epoch: 10 Step: 541 Loss: 1.3497112455103841\n",
      "Epoch: 10 Step: 551 Loss: 1.2407614249390486\n",
      "Epoch: 10 Step: 561 Loss: 1.2806232660878147\n",
      "Epoch: 10 Step: 571 Loss: 1.424343498747613\n",
      "Epoch: 10 Step: 581 Loss: 1.4895859158164184\n",
      "Epoch: 10 Step: 591 Loss: 1.5382788624969743\n",
      "Epoch: 10 Step: 601 Loss: 1.4744642664259755\n",
      "Epoch: 10 Step: 611 Loss: 1.2241363379259351\n",
      "Epoch: 10 Step: 621 Loss: 1.2879650367152662\n",
      "Epoch: 10 Step: 631 Loss: 1.5493583576925005\n",
      "Epoch: 10 Step: 641 Loss: 1.3967418307818174\n",
      "Epoch: 10 Step: 651 Loss: 1.3124858210108452\n",
      "Epoch: 10 Step: 661 Loss: 1.2437131889026456\n",
      "Epoch: 10 Step: 671 Loss: 1.40148708342252\n",
      "Epoch: 10 Step: 681 Loss: 1.5326640075604978\n",
      "Epoch: 10 Step: 691 Loss: 1.397443590119087\n",
      "Epoch: 10 Step: 701 Loss: 1.210663423048381\n",
      "Epoch: 10 Step: 711 Loss: 1.4906256998127472\n",
      "Epoch: 10 Step: 721 Loss: 1.1748348574491556\n",
      "Epoch: 10 Step: 731 Loss: 1.0305886074632298\n",
      "Epoch: 10 Step: 741 Loss: 1.3732192442483957\n",
      "Epoch: 10 Step: 751 Loss: 1.65979243156328\n",
      "Epoch: 10 Step: 761 Loss: 1.2459339244479741\n",
      "Epoch: 10 Step: 771 Loss: 1.3980769173923562\n",
      "Epoch: 10 Step: 781 Loss: 1.3027911535499461\n",
      "Epoch: 11 Step: 1 Loss: 1.368848896733359\n",
      "Epoch: 11 Step: 11 Loss: 1.5485955895954033\n",
      "Epoch: 11 Step: 21 Loss: 1.3554883312806782\n",
      "Epoch: 11 Step: 31 Loss: 1.577365864704321\n",
      "Epoch: 11 Step: 41 Loss: 1.2739347767300306\n",
      "Epoch: 11 Step: 51 Loss: 1.1301367322943154\n",
      "Epoch: 11 Step: 61 Loss: 1.2976632939949895\n",
      "Epoch: 11 Step: 71 Loss: 1.3394153869801895\n",
      "Epoch: 11 Step: 81 Loss: 1.6147465900675333\n",
      "Epoch: 11 Step: 91 Loss: 1.2837261955298844\n",
      "Epoch: 11 Step: 101 Loss: 1.374069452324084\n",
      "Epoch: 11 Step: 111 Loss: 1.4409883102543508\n",
      "Epoch: 11 Step: 121 Loss: 1.3974677003647542\n",
      "Epoch: 11 Step: 131 Loss: 1.3275485016797774\n",
      "Epoch: 11 Step: 141 Loss: 1.669542592683237\n",
      "Epoch: 11 Step: 151 Loss: 1.1942790758677828\n",
      "Epoch: 11 Step: 161 Loss: 1.4349454213323267\n",
      "Epoch: 11 Step: 171 Loss: 1.4029077135584178\n",
      "Epoch: 11 Step: 181 Loss: 1.2675697556991645\n",
      "Epoch: 11 Step: 191 Loss: 1.3264527809874558\n",
      "Epoch: 11 Step: 201 Loss: 1.0759077172343448\n",
      "Epoch: 11 Step: 211 Loss: 1.2061177131868943\n",
      "Epoch: 11 Step: 221 Loss: 1.418856486002905\n",
      "Epoch: 11 Step: 231 Loss: 1.4037602099706121\n",
      "Epoch: 11 Step: 241 Loss: 1.3592862497256317\n",
      "Epoch: 11 Step: 251 Loss: 1.2333442962227696\n",
      "Epoch: 11 Step: 261 Loss: 1.3358781962921868\n",
      "Epoch: 11 Step: 271 Loss: 1.4745233289800996\n",
      "Epoch: 11 Step: 281 Loss: 1.367794438525657\n",
      "Epoch: 11 Step: 291 Loss: 1.4746778174016781\n",
      "Epoch: 11 Step: 301 Loss: 1.4221222249192644\n",
      "Epoch: 11 Step: 311 Loss: 1.4337679100623988\n",
      "Epoch: 11 Step: 321 Loss: 1.4476467804700426\n",
      "Epoch: 11 Step: 331 Loss: 1.3035501774018197\n",
      "Epoch: 11 Step: 341 Loss: 1.4170782758606082\n",
      "Epoch: 11 Step: 351 Loss: 1.4141550509272247\n",
      "Epoch: 11 Step: 361 Loss: 1.4634685950026098\n",
      "Epoch: 11 Step: 371 Loss: 0.9688641069626779\n",
      "Epoch: 11 Step: 381 Loss: 1.4020525593295887\n",
      "Epoch: 11 Step: 391 Loss: 1.210003961814166\n",
      "Epoch: 11 Step: 401 Loss: 1.1937602679058943\n",
      "Epoch: 11 Step: 411 Loss: 1.3982911052877496\n",
      "Epoch: 11 Step: 421 Loss: 1.4692664856007849\n",
      "Epoch: 11 Step: 431 Loss: 1.267598334429945\n",
      "Epoch: 11 Step: 441 Loss: 1.3439706734675727\n",
      "Epoch: 11 Step: 451 Loss: 1.3131637208504578\n",
      "Epoch: 11 Step: 461 Loss: 1.3720912885098961\n",
      "Epoch: 11 Step: 471 Loss: 1.3774228778450008\n",
      "Epoch: 11 Step: 481 Loss: 1.422788353345358\n",
      "Epoch: 11 Step: 491 Loss: 1.537443570884057\n",
      "Epoch: 11 Step: 501 Loss: 1.4753719179559237\n",
      "Epoch: 11 Step: 511 Loss: 1.2757736914880873\n",
      "Epoch: 11 Step: 521 Loss: 1.2660478524754846\n",
      "Epoch: 11 Step: 531 Loss: 1.2502781836736778\n",
      "Epoch: 11 Step: 541 Loss: 1.2720697396256522\n",
      "Epoch: 11 Step: 551 Loss: 1.298238731857296\n",
      "Epoch: 11 Step: 561 Loss: 1.261870405477032\n",
      "Epoch: 11 Step: 571 Loss: 1.3537611503417517\n",
      "Epoch: 11 Step: 581 Loss: 1.3590844394317456\n",
      "Epoch: 11 Step: 591 Loss: 1.4921695008965457\n",
      "Epoch: 11 Step: 601 Loss: 1.3910689380314578\n",
      "Epoch: 11 Step: 611 Loss: 1.1654894387762442\n",
      "Epoch: 11 Step: 621 Loss: 1.204920316248412\n",
      "Epoch: 11 Step: 631 Loss: 1.4556638104660187\n",
      "Epoch: 11 Step: 641 Loss: 1.365241972522204\n",
      "Epoch: 11 Step: 651 Loss: 1.303364801549255\n",
      "Epoch: 11 Step: 661 Loss: 1.3015201388863051\n",
      "Epoch: 11 Step: 671 Loss: 1.466659431094615\n",
      "Epoch: 11 Step: 681 Loss: 1.3855338783172133\n",
      "Epoch: 11 Step: 691 Loss: 1.3524588383825633\n",
      "Epoch: 11 Step: 701 Loss: 1.3928637968987128\n",
      "Epoch: 11 Step: 711 Loss: 1.36387530828255\n",
      "Epoch: 11 Step: 721 Loss: 1.2455490992747316\n",
      "Epoch: 11 Step: 731 Loss: 1.2028155984112452\n",
      "Epoch: 11 Step: 741 Loss: 1.5504487060139218\n",
      "Epoch: 11 Step: 751 Loss: 1.4521210645118359\n",
      "Epoch: 11 Step: 761 Loss: 1.1781988067187368\n",
      "Epoch: 11 Step: 771 Loss: 1.6909659765783684\n",
      "Epoch: 11 Step: 781 Loss: 1.4085568019763879\n",
      "Epoch: 12 Step: 1 Loss: 1.548024176089039\n",
      "Epoch: 12 Step: 11 Loss: 1.3741503446490515\n",
      "Epoch: 12 Step: 21 Loss: 1.2021657881387904\n",
      "Epoch: 12 Step: 31 Loss: 1.4635339267593463\n",
      "Epoch: 12 Step: 41 Loss: 1.352604708868491\n",
      "Epoch: 12 Step: 51 Loss: 1.2334845217347843\n",
      "Epoch: 12 Step: 61 Loss: 1.2539686142999362\n",
      "Epoch: 12 Step: 71 Loss: 1.3484790389033567\n",
      "Epoch: 12 Step: 81 Loss: 1.45180098618304\n",
      "Epoch: 12 Step: 91 Loss: 1.3768192781958346\n",
      "Epoch: 12 Step: 101 Loss: 1.463900130744812\n",
      "Epoch: 12 Step: 111 Loss: 1.2787651822773445\n",
      "Epoch: 12 Step: 121 Loss: 1.5082235003286084\n",
      "Epoch: 12 Step: 131 Loss: 1.338310309046865\n",
      "Epoch: 12 Step: 141 Loss: 1.5689531672383135\n",
      "Epoch: 12 Step: 151 Loss: 1.1077911268239213\n",
      "Epoch: 12 Step: 161 Loss: 1.40544221288006\n",
      "Epoch: 12 Step: 171 Loss: 1.3089462722470533\n",
      "Epoch: 12 Step: 181 Loss: 1.2756872727858748\n",
      "Epoch: 12 Step: 191 Loss: 1.2631522745210666\n",
      "Epoch: 12 Step: 201 Loss: 0.9888466482150283\n",
      "Epoch: 12 Step: 211 Loss: 1.118950754017104\n",
      "Epoch: 12 Step: 221 Loss: 1.302819640383364\n",
      "Epoch: 12 Step: 231 Loss: 1.3238894023114396\n",
      "Epoch: 12 Step: 241 Loss: 1.4410386781521844\n",
      "Epoch: 12 Step: 251 Loss: 1.3526381854821208\n",
      "Epoch: 12 Step: 261 Loss: 1.298582208420226\n",
      "Epoch: 12 Step: 271 Loss: 1.4850532071613718\n",
      "Epoch: 12 Step: 281 Loss: 1.3792227088538536\n",
      "Epoch: 12 Step: 291 Loss: 1.4264928245002335\n",
      "Epoch: 12 Step: 301 Loss: 1.539534834035801\n",
      "Epoch: 12 Step: 311 Loss: 1.3311887064109071\n",
      "Epoch: 12 Step: 321 Loss: 1.4340078900352335\n",
      "Epoch: 12 Step: 331 Loss: 1.4200299096163231\n",
      "Epoch: 12 Step: 341 Loss: 1.4731732426594228\n",
      "Epoch: 12 Step: 351 Loss: 1.4707459727847083\n",
      "Epoch: 12 Step: 361 Loss: 1.2641185477979446\n",
      "Epoch: 12 Step: 371 Loss: 1.09329215518432\n",
      "Epoch: 12 Step: 381 Loss: 1.4131006966455166\n",
      "Epoch: 12 Step: 391 Loss: 1.2284040098617222\n",
      "Epoch: 12 Step: 401 Loss: 1.4788873061757843\n",
      "Epoch: 12 Step: 411 Loss: 1.361785687132278\n",
      "Epoch: 12 Step: 421 Loss: 1.4683600527610503\n",
      "Epoch: 12 Step: 431 Loss: 1.3161668861375095\n",
      "Epoch: 12 Step: 441 Loss: 1.4835074867212492\n",
      "Epoch: 12 Step: 451 Loss: 1.3126876564332448\n",
      "Epoch: 12 Step: 461 Loss: 1.3241500426035144\n",
      "Epoch: 12 Step: 471 Loss: 1.416866080694258\n",
      "Epoch: 12 Step: 481 Loss: 1.4095860031638858\n",
      "Epoch: 12 Step: 491 Loss: 1.5439762943277047\n",
      "Epoch: 12 Step: 501 Loss: 1.3691706170888607\n",
      "Epoch: 12 Step: 511 Loss: 1.271600051667165\n",
      "Epoch: 12 Step: 521 Loss: 1.3882961170137516\n",
      "Epoch: 12 Step: 531 Loss: 1.3093954611521412\n",
      "Epoch: 12 Step: 541 Loss: 1.187021462189823\n",
      "Epoch: 12 Step: 551 Loss: 1.2882227101379178\n",
      "Epoch: 12 Step: 561 Loss: 1.1996586902934283\n",
      "Epoch: 12 Step: 571 Loss: 1.2332826212058194\n",
      "Epoch: 12 Step: 581 Loss: 1.3499853702897209\n",
      "Epoch: 12 Step: 591 Loss: 1.2668649304532236\n",
      "Epoch: 12 Step: 601 Loss: 1.3215831201751622\n",
      "Epoch: 12 Step: 611 Loss: 1.1420574959619425\n",
      "Epoch: 12 Step: 621 Loss: 1.2249317664013577\n",
      "Epoch: 12 Step: 631 Loss: 1.3445266785805847\n",
      "Epoch: 12 Step: 641 Loss: 1.2741773683376052\n",
      "Epoch: 12 Step: 651 Loss: 1.3938388655222314\n",
      "Epoch: 12 Step: 661 Loss: 1.2014349758313925\n",
      "Epoch: 12 Step: 671 Loss: 1.4030115609786238\n",
      "Epoch: 12 Step: 681 Loss: 1.423829507081765\n",
      "Epoch: 12 Step: 691 Loss: 1.3947739829057266\n",
      "Epoch: 12 Step: 701 Loss: 1.2723038061651424\n",
      "Epoch: 12 Step: 711 Loss: 1.3198300920453605\n",
      "Epoch: 12 Step: 721 Loss: 1.1420751854494555\n",
      "Epoch: 12 Step: 731 Loss: 1.176566395162193\n",
      "Epoch: 12 Step: 741 Loss: 1.4224213890563888\n",
      "Epoch: 12 Step: 751 Loss: 1.6234796142081782\n",
      "Epoch: 12 Step: 761 Loss: 1.293262004485657\n",
      "Epoch: 12 Step: 771 Loss: 1.4598639838385585\n",
      "Epoch: 12 Step: 781 Loss: 1.3560760982003766\n",
      "Epoch: 13 Step: 1 Loss: 1.3201501337659225\n",
      "Epoch: 13 Step: 11 Loss: 1.4945211091675135\n",
      "Epoch: 13 Step: 21 Loss: 1.4863273321461852\n",
      "Epoch: 13 Step: 31 Loss: 1.5674054485983007\n",
      "Epoch: 13 Step: 41 Loss: 1.4298304811272105\n",
      "Epoch: 13 Step: 51 Loss: 1.2530002919568184\n",
      "Epoch: 13 Step: 61 Loss: 1.3625073747847947\n",
      "Epoch: 13 Step: 71 Loss: 1.3891133149838186\n",
      "Epoch: 13 Step: 81 Loss: 1.584971825834016\n",
      "Epoch: 13 Step: 91 Loss: 1.409354241760739\n",
      "Epoch: 13 Step: 101 Loss: 1.4220340796852595\n",
      "Epoch: 13 Step: 111 Loss: 1.3361306222028053\n",
      "Epoch: 13 Step: 121 Loss: 1.4401308105565311\n",
      "Epoch: 13 Step: 131 Loss: 1.2395076096411821\n",
      "Epoch: 13 Step: 141 Loss: 1.6245446389836635\n",
      "Epoch: 13 Step: 151 Loss: 1.137409283499129\n",
      "Epoch: 13 Step: 161 Loss: 1.3039174407540173\n",
      "Epoch: 13 Step: 171 Loss: 1.368936994990014\n",
      "Epoch: 13 Step: 181 Loss: 1.2830835919414343\n",
      "Epoch: 13 Step: 191 Loss: 1.1781971388822798\n",
      "Epoch: 13 Step: 201 Loss: 0.9526706475099886\n",
      "Epoch: 13 Step: 211 Loss: 1.0807399073951656\n",
      "Epoch: 13 Step: 221 Loss: 1.4508363883682844\n",
      "Epoch: 13 Step: 231 Loss: 1.1406576832857933\n",
      "Epoch: 13 Step: 241 Loss: 1.2968036332554684\n",
      "Epoch: 13 Step: 251 Loss: 1.1049013269870487\n",
      "Epoch: 13 Step: 261 Loss: 1.271327255424298\n",
      "Epoch: 13 Step: 271 Loss: 1.385380129267089\n",
      "Epoch: 13 Step: 281 Loss: 1.358689075888201\n",
      "Epoch: 13 Step: 291 Loss: 1.320969087129007\n",
      "Epoch: 13 Step: 301 Loss: 1.3781371545524626\n",
      "Epoch: 13 Step: 311 Loss: 1.3394186155251235\n",
      "Epoch: 13 Step: 321 Loss: 1.3997929525031232\n",
      "Epoch: 13 Step: 331 Loss: 1.3060462531942771\n",
      "Epoch: 13 Step: 341 Loss: 1.5054095835591226\n",
      "Epoch: 13 Step: 351 Loss: 1.414960375799036\n",
      "Epoch: 13 Step: 361 Loss: 1.3319130329192082\n",
      "Epoch: 13 Step: 371 Loss: 0.9866404398057852\n",
      "Epoch: 13 Step: 381 Loss: 1.3227554268607384\n",
      "Epoch: 13 Step: 391 Loss: 1.1330453546251573\n",
      "Epoch: 13 Step: 401 Loss: 1.2415906931004135\n",
      "Epoch: 13 Step: 411 Loss: 1.4545029500740778\n",
      "Epoch: 13 Step: 421 Loss: 1.4481919663183072\n",
      "Epoch: 13 Step: 431 Loss: 1.3485630637404649\n",
      "Epoch: 13 Step: 441 Loss: 1.4476676694435304\n",
      "Epoch: 13 Step: 451 Loss: 1.1767509949371957\n",
      "Epoch: 13 Step: 461 Loss: 1.4884822162883693\n",
      "Epoch: 13 Step: 471 Loss: 1.3329438469127455\n",
      "Epoch: 13 Step: 481 Loss: 1.497108491792574\n",
      "Epoch: 13 Step: 491 Loss: 1.6074783786732492\n",
      "Epoch: 13 Step: 501 Loss: 1.3916656562895695\n",
      "Epoch: 13 Step: 511 Loss: 1.4320426719303234\n",
      "Epoch: 13 Step: 521 Loss: 1.3177615965475953\n",
      "Epoch: 13 Step: 531 Loss: 1.3174943281433356\n",
      "Epoch: 13 Step: 541 Loss: 1.2833340199031995\n",
      "Epoch: 13 Step: 551 Loss: 1.267948696628955\n",
      "Epoch: 13 Step: 561 Loss: 1.1841214014806627\n",
      "Epoch: 13 Step: 571 Loss: 1.1871568938294328\n",
      "Epoch: 13 Step: 581 Loss: 1.515556153464058\n",
      "Epoch: 13 Step: 591 Loss: 1.3881068171911501\n",
      "Epoch: 13 Step: 601 Loss: 1.4660069677879082\n",
      "Epoch: 13 Step: 611 Loss: 1.3153128101737324\n",
      "Epoch: 13 Step: 621 Loss: 1.2091410827032942\n",
      "Epoch: 13 Step: 631 Loss: 1.4976299471784842\n",
      "Epoch: 13 Step: 641 Loss: 1.4823756583848375\n",
      "Epoch: 13 Step: 651 Loss: 1.4736017494584104\n",
      "Epoch: 13 Step: 661 Loss: 1.2598221279384114\n",
      "Epoch: 13 Step: 671 Loss: 1.311097147721117\n",
      "Epoch: 13 Step: 681 Loss: 1.4410451629845835\n",
      "Epoch: 13 Step: 691 Loss: 1.271855268359359\n",
      "Epoch: 13 Step: 701 Loss: 1.1898585513590232\n",
      "Epoch: 13 Step: 711 Loss: 1.1757457125726063\n",
      "Epoch: 13 Step: 721 Loss: 1.1407887661026272\n",
      "Epoch: 13 Step: 731 Loss: 1.1259318297513716\n",
      "Epoch: 13 Step: 741 Loss: 1.3006078195927078\n",
      "Epoch: 13 Step: 751 Loss: 1.55331523524301\n",
      "Epoch: 13 Step: 761 Loss: 1.1670979033795823\n",
      "Epoch: 13 Step: 771 Loss: 1.4125938688166393\n",
      "Epoch: 13 Step: 781 Loss: 1.2171526113224511\n",
      "Epoch: 14 Step: 1 Loss: 1.1942168070924348\n",
      "Epoch: 14 Step: 11 Loss: 1.369204812443503\n",
      "Epoch: 14 Step: 21 Loss: 1.4414840272616465\n",
      "Epoch: 14 Step: 31 Loss: 1.5311864370798292\n",
      "Epoch: 14 Step: 41 Loss: 1.2782681573300048\n",
      "Epoch: 14 Step: 51 Loss: 1.2764938765954477\n",
      "Epoch: 14 Step: 61 Loss: 1.3335234861658285\n",
      "Epoch: 14 Step: 71 Loss: 1.465199818321461\n",
      "Epoch: 14 Step: 81 Loss: 1.5421550571713674\n",
      "Epoch: 14 Step: 91 Loss: 1.4671338178727629\n",
      "Epoch: 14 Step: 101 Loss: 1.4211970708134594\n",
      "Epoch: 14 Step: 111 Loss: 1.2703998613746421\n",
      "Epoch: 14 Step: 121 Loss: 1.3901076053473984\n",
      "Epoch: 14 Step: 131 Loss: 1.4093387047328618\n",
      "Epoch: 14 Step: 141 Loss: 1.829626434177841\n",
      "Epoch: 14 Step: 151 Loss: 1.140955418537117\n",
      "Epoch: 14 Step: 161 Loss: 1.261271497451427\n",
      "Epoch: 14 Step: 171 Loss: 1.396609093522362\n",
      "Epoch: 14 Step: 181 Loss: 1.130548145446968\n",
      "Epoch: 14 Step: 191 Loss: 1.4004959049344854\n",
      "Epoch: 14 Step: 201 Loss: 0.9552703869012225\n",
      "Epoch: 14 Step: 211 Loss: 1.2400249231756821\n",
      "Epoch: 14 Step: 221 Loss: 1.2318971087776107\n",
      "Epoch: 14 Step: 231 Loss: 1.177698606943438\n",
      "Epoch: 14 Step: 241 Loss: 1.216400801608736\n",
      "Epoch: 14 Step: 251 Loss: 1.1924087172271622\n",
      "Epoch: 14 Step: 261 Loss: 1.3123634199575758\n",
      "Epoch: 14 Step: 271 Loss: 1.457714487041283\n",
      "Epoch: 14 Step: 281 Loss: 1.262712872693426\n",
      "Epoch: 14 Step: 291 Loss: 1.3126406447941121\n",
      "Epoch: 14 Step: 301 Loss: 1.4174109091296967\n",
      "Epoch: 14 Step: 311 Loss: 1.346975414910547\n",
      "Epoch: 14 Step: 321 Loss: 1.253986651246564\n",
      "Epoch: 14 Step: 331 Loss: 1.261997484689434\n",
      "Epoch: 14 Step: 341 Loss: 1.5573463686316034\n",
      "Epoch: 14 Step: 351 Loss: 1.334253082438394\n",
      "Epoch: 14 Step: 361 Loss: 1.2883905825367972\n",
      "Epoch: 14 Step: 371 Loss: 1.0240388526469264\n",
      "Epoch: 14 Step: 381 Loss: 1.377012274365091\n",
      "Epoch: 14 Step: 391 Loss: 1.2140012164396836\n",
      "Epoch: 14 Step: 401 Loss: 1.2002623053072965\n",
      "Epoch: 14 Step: 411 Loss: 1.2750020938547544\n",
      "Epoch: 14 Step: 421 Loss: 1.3953134619895935\n",
      "Epoch: 14 Step: 431 Loss: 1.3265161357696096\n",
      "Epoch: 14 Step: 441 Loss: 1.2761342047542312\n",
      "Epoch: 14 Step: 451 Loss: 1.324357318929077\n",
      "Epoch: 14 Step: 461 Loss: 1.2339583219580477\n",
      "Epoch: 14 Step: 471 Loss: 1.356862883807349\n",
      "Epoch: 14 Step: 481 Loss: 1.3569281896281107\n",
      "Epoch: 14 Step: 491 Loss: 1.5942854253622738\n",
      "Epoch: 14 Step: 501 Loss: 1.3396105281775557\n",
      "Epoch: 14 Step: 511 Loss: 1.1909732515936975\n",
      "Epoch: 14 Step: 521 Loss: 1.319320624615139\n",
      "Epoch: 14 Step: 531 Loss: 1.3224821908592954\n",
      "Epoch: 14 Step: 541 Loss: 1.218393792134083\n",
      "Epoch: 14 Step: 551 Loss: 1.3005828100039327\n",
      "Epoch: 14 Step: 561 Loss: 1.199830711437977\n",
      "Epoch: 14 Step: 571 Loss: 1.317366519399271\n",
      "Epoch: 14 Step: 581 Loss: 1.3821738872679386\n",
      "Epoch: 14 Step: 591 Loss: 1.362910227707334\n",
      "Epoch: 14 Step: 601 Loss: 1.4830866646820025\n",
      "Epoch: 14 Step: 611 Loss: 1.286401056197462\n",
      "Epoch: 14 Step: 621 Loss: 1.2443633091865551\n",
      "Epoch: 14 Step: 631 Loss: 1.4482704439355452\n",
      "Epoch: 14 Step: 641 Loss: 1.3476654389792087\n",
      "Epoch: 14 Step: 651 Loss: 1.3415214794868369\n",
      "Epoch: 14 Step: 661 Loss: 1.1266132690402941\n",
      "Epoch: 14 Step: 671 Loss: 1.420126044604956\n",
      "Epoch: 14 Step: 681 Loss: 1.5096099137807995\n",
      "Epoch: 14 Step: 691 Loss: 1.3629856365767155\n",
      "Epoch: 14 Step: 701 Loss: 1.240512967663043\n",
      "Epoch: 14 Step: 711 Loss: 1.271031093980242\n",
      "Epoch: 14 Step: 721 Loss: 1.1719663003901306\n",
      "Epoch: 14 Step: 731 Loss: 1.1272391787483766\n",
      "Epoch: 14 Step: 741 Loss: 1.4730978492599276\n",
      "Epoch: 14 Step: 751 Loss: 1.6098873467574162\n",
      "Epoch: 14 Step: 761 Loss: 1.1114642861103612\n",
      "Epoch: 14 Step: 771 Loss: 1.3386718860956228\n",
      "Epoch: 14 Step: 781 Loss: 1.229245051285542\n",
      "Epoch: 15 Step: 1 Loss: 1.3617008801393486\n",
      "Epoch: 15 Step: 11 Loss: 1.27525957716712\n",
      "Epoch: 15 Step: 21 Loss: 1.409014047621017\n",
      "Epoch: 15 Step: 31 Loss: 1.5662783405171485\n",
      "Epoch: 15 Step: 41 Loss: 1.2697528439838432\n",
      "Epoch: 15 Step: 51 Loss: 1.1638971119846384\n",
      "Epoch: 15 Step: 61 Loss: 1.165593843294485\n",
      "Epoch: 15 Step: 71 Loss: 1.305274815907155\n",
      "Epoch: 15 Step: 81 Loss: 1.4010357169288439\n",
      "Epoch: 15 Step: 91 Loss: 1.3561737679670898\n",
      "Epoch: 15 Step: 101 Loss: 1.118464314759668\n",
      "Epoch: 15 Step: 111 Loss: 1.3335443016098896\n",
      "Epoch: 15 Step: 121 Loss: 1.2466002927596793\n",
      "Epoch: 15 Step: 131 Loss: 1.401205289777514\n",
      "Epoch: 15 Step: 141 Loss: 1.7211683140722323\n",
      "Epoch: 15 Step: 151 Loss: 1.043052393459135\n",
      "Epoch: 15 Step: 161 Loss: 1.2775584517623935\n",
      "Epoch: 15 Step: 171 Loss: 1.3054646529485272\n",
      "Epoch: 15 Step: 181 Loss: 1.3679206971518398\n",
      "Epoch: 15 Step: 191 Loss: 1.2085817333239797\n",
      "Epoch: 15 Step: 201 Loss: 0.9448488301057589\n",
      "Epoch: 15 Step: 211 Loss: 0.9812778898831765\n",
      "Epoch: 15 Step: 221 Loss: 1.3263514466587427\n",
      "Epoch: 15 Step: 231 Loss: 1.328778565295818\n",
      "Epoch: 15 Step: 241 Loss: 1.247425259450769\n",
      "Epoch: 15 Step: 251 Loss: 1.1389373424970697\n",
      "Epoch: 15 Step: 261 Loss: 1.4019021668633846\n",
      "Epoch: 15 Step: 271 Loss: 1.512047740584075\n",
      "Epoch: 15 Step: 281 Loss: 1.284011205305307\n",
      "Epoch: 15 Step: 291 Loss: 1.4075004721924194\n",
      "Epoch: 15 Step: 301 Loss: 1.3250333223206407\n",
      "Epoch: 15 Step: 311 Loss: 1.329274693938851\n",
      "Epoch: 15 Step: 321 Loss: 1.2321692015939538\n",
      "Epoch: 15 Step: 331 Loss: 1.3255663944095784\n",
      "Epoch: 15 Step: 341 Loss: 1.3291707521477683\n",
      "Epoch: 15 Step: 351 Loss: 1.3630599460399402\n",
      "Epoch: 15 Step: 361 Loss: 1.2845910213144909\n",
      "Epoch: 15 Step: 371 Loss: 1.0935328547738599\n",
      "Epoch: 15 Step: 381 Loss: 1.4719512591929185\n",
      "Epoch: 15 Step: 391 Loss: 1.0614421160514367\n",
      "Epoch: 15 Step: 401 Loss: 1.153337869865815\n",
      "Epoch: 15 Step: 411 Loss: 1.2843132487683504\n",
      "Epoch: 15 Step: 421 Loss: 1.4321717302272052\n",
      "Epoch: 15 Step: 431 Loss: 1.2668560278221428\n",
      "Epoch: 15 Step: 441 Loss: 1.3364028988844192\n",
      "Epoch: 15 Step: 451 Loss: 1.1228881374667892\n",
      "Epoch: 15 Step: 461 Loss: 1.2297616817370856\n",
      "Epoch: 15 Step: 471 Loss: 1.2689798403951114\n",
      "Epoch: 15 Step: 481 Loss: 1.4080225987310504\n",
      "Epoch: 15 Step: 491 Loss: 1.5486212517188713\n",
      "Epoch: 15 Step: 501 Loss: 1.3054280752168785\n",
      "Epoch: 15 Step: 511 Loss: 1.147126312924168\n",
      "Epoch: 15 Step: 521 Loss: 1.2858238549943937\n",
      "Epoch: 15 Step: 531 Loss: 1.3073764666596892\n",
      "Epoch: 15 Step: 541 Loss: 1.1910940322874302\n",
      "Epoch: 15 Step: 551 Loss: 1.1902435197505123\n",
      "Epoch: 15 Step: 561 Loss: 1.1796170440198266\n",
      "Epoch: 15 Step: 571 Loss: 1.193343369170874\n",
      "Epoch: 15 Step: 581 Loss: 1.341414813581425\n",
      "Epoch: 15 Step: 591 Loss: 1.337210159496688\n",
      "Epoch: 15 Step: 601 Loss: 1.3098547264658444\n",
      "Epoch: 15 Step: 611 Loss: 1.0898211327510814\n",
      "Epoch: 15 Step: 621 Loss: 1.1371800837468473\n",
      "Epoch: 15 Step: 631 Loss: 1.3776218640932372\n",
      "Epoch: 15 Step: 641 Loss: 1.2331306913371272\n",
      "Epoch: 15 Step: 651 Loss: 1.2581311841276275\n",
      "Epoch: 15 Step: 661 Loss: 1.213901303186421\n",
      "Epoch: 15 Step: 671 Loss: 1.3381136558108686\n",
      "Epoch: 15 Step: 681 Loss: 1.5250172546387462\n",
      "Epoch: 15 Step: 691 Loss: 1.272019716646466\n",
      "Epoch: 15 Step: 701 Loss: 1.3324947303287118\n",
      "Epoch: 15 Step: 711 Loss: 1.2902188231412244\n",
      "Epoch: 15 Step: 721 Loss: 1.2396778582178856\n",
      "Epoch: 15 Step: 731 Loss: 1.1392206661047508\n",
      "Epoch: 15 Step: 741 Loss: 1.5736980164327141\n",
      "Epoch: 15 Step: 751 Loss: 1.5681238031478948\n",
      "Epoch: 15 Step: 761 Loss: 1.1815950685128802\n",
      "Epoch: 15 Step: 771 Loss: 1.3857616319698747\n",
      "Epoch: 15 Step: 781 Loss: 1.2937194602496414\n",
      "Epoch: 16 Step: 1 Loss: 1.4002738745691756\n",
      "Epoch: 16 Step: 11 Loss: 1.4409149247803903\n",
      "Epoch: 16 Step: 21 Loss: 1.4487540951672044\n",
      "Epoch: 16 Step: 31 Loss: 1.5296957390208923\n",
      "Epoch: 16 Step: 41 Loss: 1.187332612035974\n",
      "Epoch: 16 Step: 51 Loss: 1.1111252099965208\n",
      "Epoch: 16 Step: 61 Loss: 1.2832227606027362\n",
      "Epoch: 16 Step: 71 Loss: 1.3767273040520827\n",
      "Epoch: 16 Step: 81 Loss: 1.4020135166576422\n",
      "Epoch: 16 Step: 91 Loss: 1.3228778983448195\n",
      "Epoch: 16 Step: 101 Loss: 1.3434617579019172\n",
      "Epoch: 16 Step: 111 Loss: 1.3148225642577864\n",
      "Epoch: 16 Step: 121 Loss: 1.4243571591186934\n",
      "Epoch: 16 Step: 131 Loss: 1.346507283420138\n",
      "Epoch: 16 Step: 141 Loss: 1.3747304668659739\n",
      "Epoch: 16 Step: 151 Loss: 1.1075370811244687\n",
      "Epoch: 16 Step: 161 Loss: 1.2140626612721837\n",
      "Epoch: 16 Step: 171 Loss: 1.255452057962379\n",
      "Epoch: 16 Step: 181 Loss: 1.2113699282882606\n",
      "Epoch: 16 Step: 191 Loss: 1.2405619698707804\n",
      "Epoch: 16 Step: 201 Loss: 0.9367225324656077\n",
      "Epoch: 16 Step: 211 Loss: 1.0059673805558411\n",
      "Epoch: 16 Step: 221 Loss: 1.2847977447444765\n",
      "Epoch: 16 Step: 231 Loss: 1.1811170914388156\n",
      "Epoch: 16 Step: 241 Loss: 1.2189748864570973\n",
      "Epoch: 16 Step: 251 Loss: 1.0659838866594398\n",
      "Epoch: 16 Step: 261 Loss: 1.2212719516444295\n",
      "Epoch: 16 Step: 271 Loss: 1.3450303598197784\n",
      "Epoch: 16 Step: 281 Loss: 1.202947329247296\n",
      "Epoch: 16 Step: 291 Loss: 1.535658334828224\n",
      "Epoch: 16 Step: 301 Loss: 1.332508344715992\n",
      "Epoch: 16 Step: 311 Loss: 1.340259109424001\n",
      "Epoch: 16 Step: 321 Loss: 1.3523878709005683\n",
      "Epoch: 16 Step: 331 Loss: 1.2620593848274733\n",
      "Epoch: 16 Step: 341 Loss: 1.4531493138264722\n",
      "Epoch: 16 Step: 351 Loss: 1.3381954907839408\n",
      "Epoch: 16 Step: 361 Loss: 1.1784495943537237\n",
      "Epoch: 16 Step: 371 Loss: 0.859805156500545\n",
      "Epoch: 16 Step: 381 Loss: 1.4528509646101149\n",
      "Epoch: 16 Step: 391 Loss: 1.0393902918940947\n",
      "Epoch: 16 Step: 401 Loss: 1.3075548168030342\n",
      "Epoch: 16 Step: 411 Loss: 1.373332485944768\n",
      "Epoch: 16 Step: 421 Loss: 1.4206085911620534\n",
      "Epoch: 16 Step: 431 Loss: 1.3093870688431322\n",
      "Epoch: 16 Step: 441 Loss: 1.271596960627476\n",
      "Epoch: 16 Step: 451 Loss: 1.1932310973320193\n",
      "Epoch: 16 Step: 461 Loss: 1.404044413912119\n",
      "Epoch: 16 Step: 471 Loss: 1.2762107423758788\n",
      "Epoch: 16 Step: 481 Loss: 1.4478203290060616\n",
      "Epoch: 16 Step: 491 Loss: 1.464808034925642\n",
      "Epoch: 16 Step: 501 Loss: 1.4447737111246306\n",
      "Epoch: 16 Step: 511 Loss: 1.2163800959620317\n",
      "Epoch: 16 Step: 521 Loss: 1.401729475318775\n",
      "Epoch: 16 Step: 531 Loss: 1.2244893109690302\n",
      "Epoch: 16 Step: 541 Loss: 1.1391561976414506\n",
      "Epoch: 16 Step: 551 Loss: 1.3664366597247108\n",
      "Epoch: 16 Step: 561 Loss: 1.1671543241514966\n",
      "Epoch: 16 Step: 571 Loss: 1.2699772914477534\n",
      "Epoch: 16 Step: 581 Loss: 1.2722980495889278\n",
      "Epoch: 16 Step: 591 Loss: 1.2851949666430857\n",
      "Epoch: 16 Step: 601 Loss: 1.3359970996657033\n",
      "Epoch: 16 Step: 611 Loss: 1.1452149610638132\n",
      "Epoch: 16 Step: 621 Loss: 1.2112265316759978\n",
      "Epoch: 16 Step: 631 Loss: 1.4398434356029557\n",
      "Epoch: 16 Step: 641 Loss: 1.3623486922496193\n",
      "Epoch: 16 Step: 651 Loss: 1.2469972032812302\n",
      "Epoch: 16 Step: 661 Loss: 1.0787139904329526\n",
      "Epoch: 16 Step: 671 Loss: 1.3590469258775348\n",
      "Epoch: 16 Step: 681 Loss: 1.2862903973348372\n",
      "Epoch: 16 Step: 691 Loss: 1.2536706456114373\n",
      "Epoch: 16 Step: 701 Loss: 1.2112949659472287\n",
      "Epoch: 16 Step: 711 Loss: 1.1045761637297682\n",
      "Epoch: 16 Step: 721 Loss: 0.9790133475549161\n",
      "Epoch: 16 Step: 731 Loss: 0.9768063607221673\n",
      "Epoch: 16 Step: 741 Loss: 1.328880689790622\n",
      "Epoch: 16 Step: 751 Loss: 1.6257015958634393\n",
      "Epoch: 16 Step: 761 Loss: 1.1739842867891903\n",
      "Epoch: 16 Step: 771 Loss: 1.3219698692926578\n",
      "Epoch: 16 Step: 781 Loss: 1.2885671276037205\n",
      "Epoch: 17 Step: 1 Loss: 1.2371353536261638\n",
      "Epoch: 17 Step: 11 Loss: 1.3564336917455524\n",
      "Epoch: 17 Step: 21 Loss: 1.2487227876741778\n",
      "Epoch: 17 Step: 31 Loss: 1.6193979484104148\n",
      "Epoch: 17 Step: 41 Loss: 1.2699695627245573\n",
      "Epoch: 17 Step: 51 Loss: 1.2167057065716862\n",
      "Epoch: 17 Step: 61 Loss: 1.2191885770362823\n",
      "Epoch: 17 Step: 71 Loss: 1.4390561670101762\n",
      "Epoch: 17 Step: 81 Loss: 1.4675690669265522\n",
      "Epoch: 17 Step: 91 Loss: 1.2956155217175673\n",
      "Epoch: 17 Step: 101 Loss: 1.3535333673334977\n",
      "Epoch: 17 Step: 111 Loss: 1.323891229329821\n",
      "Epoch: 17 Step: 121 Loss: 1.4265554936217397\n",
      "Epoch: 17 Step: 131 Loss: 1.3728193064402334\n",
      "Epoch: 17 Step: 141 Loss: 1.7279859273668454\n",
      "Epoch: 17 Step: 151 Loss: 1.0335985070469276\n",
      "Epoch: 17 Step: 161 Loss: 1.3941750633490746\n",
      "Epoch: 17 Step: 171 Loss: 1.24437318121863\n",
      "Epoch: 17 Step: 181 Loss: 1.1933881105125095\n",
      "Epoch: 17 Step: 191 Loss: 1.2413975083766076\n",
      "Epoch: 17 Step: 201 Loss: 1.0044096829448887\n",
      "Epoch: 17 Step: 211 Loss: 1.0263671677583934\n",
      "Epoch: 17 Step: 221 Loss: 1.2127699608446352\n",
      "Epoch: 17 Step: 231 Loss: 1.1668148350815226\n",
      "Epoch: 17 Step: 241 Loss: 1.2206934881293336\n",
      "Epoch: 17 Step: 251 Loss: 1.054405479438524\n",
      "Epoch: 17 Step: 261 Loss: 1.1852024993464183\n",
      "Epoch: 17 Step: 271 Loss: 1.374749571764807\n",
      "Epoch: 17 Step: 281 Loss: 1.325664986627037\n",
      "Epoch: 17 Step: 291 Loss: 1.315760088302513\n",
      "Epoch: 17 Step: 301 Loss: 1.3275388358939049\n",
      "Epoch: 17 Step: 311 Loss: 1.2558844380307082\n",
      "Epoch: 17 Step: 321 Loss: 1.2156831276974156\n",
      "Epoch: 17 Step: 331 Loss: 1.1329625562626904\n",
      "Epoch: 17 Step: 341 Loss: 1.3605973538572242\n",
      "Epoch: 17 Step: 351 Loss: 1.209445888362211\n",
      "Epoch: 17 Step: 361 Loss: 1.0868023617791491\n",
      "Epoch: 17 Step: 371 Loss: 0.923458875806828\n",
      "Epoch: 17 Step: 381 Loss: 1.3699039617501234\n",
      "Epoch: 17 Step: 391 Loss: 0.8936113157534086\n",
      "Epoch: 17 Step: 401 Loss: 1.1820453156552464\n",
      "Epoch: 17 Step: 411 Loss: 1.3020601592825751\n",
      "Epoch: 17 Step: 421 Loss: 1.4462676941102353\n",
      "Epoch: 17 Step: 431 Loss: 1.1459582572101226\n",
      "Epoch: 17 Step: 441 Loss: 1.3019307475719941\n",
      "Epoch: 17 Step: 451 Loss: 1.1231393731998318\n",
      "Epoch: 17 Step: 461 Loss: 1.397026590675974\n",
      "Epoch: 17 Step: 471 Loss: 1.4387316151842264\n",
      "Epoch: 17 Step: 481 Loss: 1.3886003168976724\n",
      "Epoch: 17 Step: 491 Loss: 1.556787061442496\n",
      "Epoch: 17 Step: 501 Loss: 1.526192729526306\n",
      "Epoch: 17 Step: 511 Loss: 1.260033445758697\n",
      "Epoch: 17 Step: 521 Loss: 1.4170317520239606\n",
      "Epoch: 17 Step: 531 Loss: 1.3890754771498182\n",
      "Epoch: 17 Step: 541 Loss: 1.3599426663079646\n",
      "Epoch: 17 Step: 551 Loss: 1.2878136852955948\n",
      "Epoch: 17 Step: 561 Loss: 1.177882200313128\n",
      "Epoch: 17 Step: 571 Loss: 1.2050976807460247\n",
      "Epoch: 17 Step: 581 Loss: 1.3134987430570566\n",
      "Epoch: 17 Step: 591 Loss: 1.3289435230346398\n",
      "Epoch: 17 Step: 601 Loss: 1.4010021609109602\n",
      "Epoch: 17 Step: 611 Loss: 1.1311745711014307\n",
      "Epoch: 17 Step: 621 Loss: 1.1773750197443131\n",
      "Epoch: 17 Step: 631 Loss: 1.3641982920566593\n",
      "Epoch: 17 Step: 641 Loss: 1.3162067155293244\n",
      "Epoch: 17 Step: 651 Loss: 1.1960538253417414\n",
      "Epoch: 17 Step: 661 Loss: 1.1815858039631766\n",
      "Epoch: 17 Step: 671 Loss: 1.3398592706092587\n",
      "Epoch: 17 Step: 681 Loss: 1.4657126915679168\n",
      "Epoch: 17 Step: 691 Loss: 1.160685034838477\n",
      "Epoch: 17 Step: 701 Loss: 1.1716776954360677\n",
      "Epoch: 17 Step: 711 Loss: 1.2666437662230325\n",
      "Epoch: 17 Step: 721 Loss: 1.1266054032680342\n",
      "Epoch: 17 Step: 731 Loss: 0.9900810588252139\n",
      "Epoch: 17 Step: 741 Loss: 1.3748499591415353\n",
      "Epoch: 17 Step: 751 Loss: 1.4420606083306575\n",
      "Epoch: 17 Step: 761 Loss: 1.1171482088313869\n",
      "Epoch: 17 Step: 771 Loss: 1.2995721561995752\n",
      "Epoch: 17 Step: 781 Loss: 1.0674950387187458\n",
      "Epoch: 18 Step: 1 Loss: 1.2905967533064822\n",
      "Epoch: 18 Step: 11 Loss: 1.2056399718975184\n",
      "Epoch: 18 Step: 21 Loss: 1.2302929552704998\n",
      "Epoch: 18 Step: 31 Loss: 1.448394162568178\n",
      "Epoch: 18 Step: 41 Loss: 1.1581817376170171\n",
      "Epoch: 18 Step: 51 Loss: 1.1559067295025887\n",
      "Epoch: 18 Step: 61 Loss: 1.3026432968890944\n",
      "Epoch: 18 Step: 71 Loss: 1.2857356327680507\n",
      "Epoch: 18 Step: 81 Loss: 1.3842516902059052\n",
      "Epoch: 18 Step: 91 Loss: 1.356934302419621\n",
      "Epoch: 18 Step: 101 Loss: 1.4198641443042161\n",
      "Epoch: 18 Step: 111 Loss: 1.321069083684323\n",
      "Epoch: 18 Step: 121 Loss: 1.4466214687628602\n",
      "Epoch: 18 Step: 131 Loss: 1.2539075540579092\n",
      "Epoch: 18 Step: 141 Loss: 1.6812632221679071\n",
      "Epoch: 18 Step: 151 Loss: 0.9555429565360779\n",
      "Epoch: 18 Step: 161 Loss: 1.4452237424844694\n",
      "Epoch: 18 Step: 171 Loss: 1.2476730340558517\n",
      "Epoch: 18 Step: 181 Loss: 1.2518232018179907\n",
      "Epoch: 18 Step: 191 Loss: 1.1800667028867444\n",
      "Epoch: 18 Step: 201 Loss: 0.9161488007835423\n",
      "Epoch: 18 Step: 211 Loss: 1.1552863054846332\n",
      "Epoch: 18 Step: 221 Loss: 1.3005542289212253\n",
      "Epoch: 18 Step: 231 Loss: 1.165258175762037\n",
      "Epoch: 18 Step: 241 Loss: 1.1352001935381715\n",
      "Epoch: 18 Step: 251 Loss: 1.051526753571694\n",
      "Epoch: 18 Step: 261 Loss: 1.364203411704569\n",
      "Epoch: 18 Step: 271 Loss: 1.3555115321935114\n",
      "Epoch: 18 Step: 281 Loss: 1.2584939242082176\n",
      "Epoch: 18 Step: 291 Loss: 1.3099567107112522\n",
      "Epoch: 18 Step: 301 Loss: 1.4991861464856584\n",
      "Epoch: 18 Step: 311 Loss: 1.389980661215203\n",
      "Epoch: 18 Step: 321 Loss: 1.33734992257035\n",
      "Epoch: 18 Step: 331 Loss: 1.2739829588340097\n",
      "Epoch: 18 Step: 341 Loss: 1.374556341246885\n",
      "Epoch: 18 Step: 351 Loss: 1.3477992760979718\n",
      "Epoch: 18 Step: 361 Loss: 1.116467001625813\n",
      "Epoch: 18 Step: 371 Loss: 1.010934619962811\n",
      "Epoch: 18 Step: 381 Loss: 1.3719270944049131\n",
      "Epoch: 18 Step: 391 Loss: 0.939264701162229\n",
      "Epoch: 18 Step: 401 Loss: 1.0916116635973538\n",
      "Epoch: 18 Step: 411 Loss: 1.2188096825008432\n",
      "Epoch: 18 Step: 421 Loss: 1.3292271827683564\n",
      "Epoch: 18 Step: 431 Loss: 1.184792424265737\n",
      "Epoch: 18 Step: 441 Loss: 1.293263233541915\n",
      "Epoch: 18 Step: 451 Loss: 1.1625387656712889\n",
      "Epoch: 18 Step: 461 Loss: 1.2267189513592698\n",
      "Epoch: 18 Step: 471 Loss: 1.2861705159652557\n",
      "Epoch: 18 Step: 481 Loss: 1.263609793118318\n",
      "Epoch: 18 Step: 491 Loss: 1.5575764010289537\n",
      "Epoch: 18 Step: 501 Loss: 1.2246602643882558\n",
      "Epoch: 18 Step: 511 Loss: 1.1393534591956929\n",
      "Epoch: 18 Step: 521 Loss: 1.0418479701736945\n",
      "Epoch: 18 Step: 531 Loss: 1.3465521184474585\n",
      "Epoch: 18 Step: 541 Loss: 1.250044724299511\n",
      "Epoch: 18 Step: 551 Loss: 1.2114919596070628\n",
      "Epoch: 18 Step: 561 Loss: 1.1536660489095718\n",
      "Epoch: 18 Step: 571 Loss: 1.1978521802223887\n",
      "Epoch: 18 Step: 581 Loss: 1.26707839891601\n",
      "Epoch: 18 Step: 591 Loss: 1.2799567580914806\n",
      "Epoch: 18 Step: 601 Loss: 1.313140462213127\n",
      "Epoch: 18 Step: 611 Loss: 1.15690185283768\n",
      "Epoch: 18 Step: 621 Loss: 1.1270335046582671\n",
      "Epoch: 18 Step: 631 Loss: 1.346867700950087\n",
      "Epoch: 18 Step: 641 Loss: 1.3389108695722678\n",
      "Epoch: 18 Step: 651 Loss: 1.276123402853479\n",
      "Epoch: 18 Step: 661 Loss: 1.1028339647901806\n",
      "Epoch: 18 Step: 671 Loss: 1.2444030389550367\n",
      "Epoch: 18 Step: 681 Loss: 1.4359180988721474\n",
      "Epoch: 18 Step: 691 Loss: 1.2436777075698213\n",
      "Epoch: 18 Step: 701 Loss: 1.1667182502523594\n",
      "Epoch: 18 Step: 711 Loss: 1.312668440830881\n",
      "Epoch: 18 Step: 721 Loss: 0.9688574542057552\n",
      "Epoch: 18 Step: 731 Loss: 1.1408575182746898\n",
      "Epoch: 18 Step: 741 Loss: 1.4235765710191852\n",
      "Epoch: 18 Step: 751 Loss: 1.529831258070607\n",
      "Epoch: 18 Step: 761 Loss: 1.1794855322463609\n",
      "Epoch: 18 Step: 771 Loss: 1.2827458696518788\n",
      "Epoch: 18 Step: 781 Loss: 1.1208887659741635\n",
      "Epoch: 19 Step: 1 Loss: 1.3421905686082154\n",
      "Epoch: 19 Step: 11 Loss: 1.3420619336011825\n",
      "Epoch: 19 Step: 21 Loss: 1.3355092864828022\n",
      "Epoch: 19 Step: 31 Loss: 1.567280209309173\n",
      "Epoch: 19 Step: 41 Loss: 1.199506591915446\n",
      "Epoch: 19 Step: 51 Loss: 1.1308558799707287\n",
      "Epoch: 19 Step: 61 Loss: 1.17867199218388\n",
      "Epoch: 19 Step: 71 Loss: 1.2728065488889113\n",
      "Epoch: 19 Step: 81 Loss: 1.3299636338105407\n",
      "Epoch: 19 Step: 91 Loss: 1.1981828206546823\n",
      "Epoch: 19 Step: 101 Loss: 1.2756326994337768\n",
      "Epoch: 19 Step: 111 Loss: 1.3525756899318564\n",
      "Epoch: 19 Step: 121 Loss: 1.3325972366097565\n",
      "Epoch: 19 Step: 131 Loss: 1.2929428499593925\n",
      "Epoch: 19 Step: 141 Loss: 1.4595126259915134\n",
      "Epoch: 19 Step: 151 Loss: 0.9783792872926067\n",
      "Epoch: 19 Step: 161 Loss: 1.1236640760527263\n",
      "Epoch: 19 Step: 171 Loss: 1.1400974108952082\n",
      "Epoch: 19 Step: 181 Loss: 1.0650036141908417\n",
      "Epoch: 19 Step: 191 Loss: 1.1474626313901295\n",
      "Epoch: 19 Step: 201 Loss: 0.8394059696257319\n",
      "Epoch: 19 Step: 211 Loss: 1.0527219596352215\n",
      "Epoch: 19 Step: 221 Loss: 1.2613382551021735\n",
      "Epoch: 19 Step: 231 Loss: 1.2719292246042273\n",
      "Epoch: 19 Step: 241 Loss: 1.2608858226564426\n",
      "Epoch: 19 Step: 251 Loss: 1.0889074170036481\n",
      "Epoch: 19 Step: 261 Loss: 1.2357020324889438\n",
      "Epoch: 19 Step: 271 Loss: 1.354814794212221\n",
      "Epoch: 19 Step: 281 Loss: 1.3532653111391253\n",
      "Epoch: 19 Step: 291 Loss: 1.3001872845135025\n",
      "Epoch: 19 Step: 301 Loss: 1.4518271137617162\n",
      "Epoch: 19 Step: 311 Loss: 1.3523004479924015\n",
      "Epoch: 19 Step: 321 Loss: 1.304956186583931\n",
      "Epoch: 19 Step: 331 Loss: 1.3068833852266573\n",
      "Epoch: 19 Step: 341 Loss: 1.182583330772848\n",
      "Epoch: 19 Step: 351 Loss: 1.4365821312742226\n",
      "Epoch: 19 Step: 361 Loss: 1.2769285666642505\n",
      "Epoch: 19 Step: 371 Loss: 1.0132131826202533\n",
      "Epoch: 19 Step: 381 Loss: 1.5153938121919661\n",
      "Epoch: 19 Step: 391 Loss: 1.063795506593868\n",
      "Epoch: 19 Step: 401 Loss: 1.2860617268530457\n",
      "Epoch: 19 Step: 411 Loss: 1.2878567970025978\n",
      "Epoch: 19 Step: 421 Loss: 1.3394128237384486\n",
      "Epoch: 19 Step: 431 Loss: 1.0995524151307348\n",
      "Epoch: 19 Step: 441 Loss: 1.2031295343108064\n",
      "Epoch: 19 Step: 451 Loss: 1.1911035025193586\n",
      "Epoch: 19 Step: 461 Loss: 1.2839404734352469\n",
      "Epoch: 19 Step: 471 Loss: 1.397225545715319\n",
      "Epoch: 19 Step: 481 Loss: 1.3776239263010566\n",
      "Epoch: 19 Step: 491 Loss: 1.4207688007065378\n",
      "Epoch: 19 Step: 501 Loss: 1.3033656688227626\n",
      "Epoch: 19 Step: 511 Loss: 1.1626978068407299\n",
      "Epoch: 19 Step: 521 Loss: 1.3181778983520047\n",
      "Epoch: 19 Step: 531 Loss: 1.2188652158262823\n",
      "Epoch: 19 Step: 541 Loss: 1.226925117550168\n",
      "Epoch: 19 Step: 551 Loss: 1.1435861111404786\n",
      "Epoch: 19 Step: 561 Loss: 1.1373583307784618\n",
      "Epoch: 19 Step: 571 Loss: 1.2041288795312328\n",
      "Epoch: 19 Step: 581 Loss: 1.136779921059381\n",
      "Epoch: 19 Step: 591 Loss: 1.2318118090386823\n",
      "Epoch: 19 Step: 601 Loss: 1.258630275972406\n",
      "Epoch: 19 Step: 611 Loss: 1.0885942639042772\n",
      "Epoch: 19 Step: 621 Loss: 1.100934526303945\n",
      "Epoch: 19 Step: 631 Loss: 1.201726436388431\n",
      "Epoch: 19 Step: 641 Loss: 1.2369101332456842\n",
      "Epoch: 19 Step: 651 Loss: 1.2202965407603257\n",
      "Epoch: 19 Step: 661 Loss: 1.1477670669605624\n",
      "Epoch: 19 Step: 671 Loss: 1.1649927302028633\n",
      "Epoch: 19 Step: 681 Loss: 1.4637622864376916\n",
      "Epoch: 19 Step: 691 Loss: 1.2277084378790384\n",
      "Epoch: 19 Step: 701 Loss: 1.1289557436133375\n",
      "Epoch: 19 Step: 711 Loss: 1.2037214891437715\n",
      "Epoch: 19 Step: 721 Loss: 1.0221338282626773\n",
      "Epoch: 19 Step: 731 Loss: 1.1642787365206215\n",
      "Epoch: 19 Step: 741 Loss: 1.6119249408563063\n",
      "Epoch: 19 Step: 751 Loss: 1.391888576416211\n",
      "Epoch: 19 Step: 761 Loss: 1.1322225118341918\n",
      "Epoch: 19 Step: 771 Loss: 1.3541434744934953\n",
      "Epoch: 19 Step: 781 Loss: 1.2253330645367788\n",
      "Epoch: 20 Step: 1 Loss: 1.3121056656911814\n",
      "Epoch: 20 Step: 11 Loss: 1.3752280724093813\n",
      "Epoch: 20 Step: 21 Loss: 1.2543701338501163\n",
      "Epoch: 20 Step: 31 Loss: 1.6451957600343596\n",
      "Epoch: 20 Step: 41 Loss: 1.13118777286579\n",
      "Epoch: 20 Step: 51 Loss: 1.1333954585286115\n",
      "Epoch: 20 Step: 61 Loss: 1.3580381962367722\n",
      "Epoch: 20 Step: 71 Loss: 1.3625857964381274\n",
      "Epoch: 20 Step: 81 Loss: 1.4422642218924162\n",
      "Epoch: 20 Step: 91 Loss: 1.3493889971851896\n",
      "Epoch: 20 Step: 101 Loss: 1.2299025133834443\n",
      "Epoch: 20 Step: 111 Loss: 1.3343180378547461\n",
      "Epoch: 20 Step: 121 Loss: 1.4729831640904858\n",
      "Epoch: 20 Step: 131 Loss: 1.1577569728857846\n",
      "Epoch: 20 Step: 141 Loss: 1.440637191862699\n",
      "Epoch: 20 Step: 151 Loss: 1.1521277589884127\n",
      "Epoch: 20 Step: 161 Loss: 1.1625082698043636\n",
      "Epoch: 20 Step: 171 Loss: 1.2554528865789347\n",
      "Epoch: 20 Step: 181 Loss: 1.1880882888797797\n",
      "Epoch: 20 Step: 191 Loss: 1.2040303959613896\n",
      "Epoch: 20 Step: 201 Loss: 0.9271176445909205\n",
      "Epoch: 20 Step: 211 Loss: 1.0320779445570012\n",
      "Epoch: 20 Step: 221 Loss: 1.258769050503119\n",
      "Epoch: 20 Step: 231 Loss: 1.1781285089371871\n",
      "Epoch: 20 Step: 241 Loss: 1.0751083953784515\n",
      "Epoch: 20 Step: 251 Loss: 1.0216804660543388\n",
      "Epoch: 20 Step: 261 Loss: 1.2796730471191884\n",
      "Epoch: 20 Step: 271 Loss: 1.3907456740099615\n",
      "Epoch: 20 Step: 281 Loss: 1.3385234654329663\n",
      "Epoch: 20 Step: 291 Loss: 1.2424444941071242\n",
      "Epoch: 20 Step: 301 Loss: 1.320149471502391\n",
      "Epoch: 20 Step: 311 Loss: 1.319727122102761\n",
      "Epoch: 20 Step: 321 Loss: 1.2911101067162094\n",
      "Epoch: 20 Step: 331 Loss: 1.184746675677138\n",
      "Epoch: 20 Step: 341 Loss: 1.3896437269931579\n",
      "Epoch: 20 Step: 351 Loss: 1.4064168906328112\n",
      "Epoch: 20 Step: 361 Loss: 1.073137922727466\n",
      "Epoch: 20 Step: 371 Loss: 0.969250412976867\n",
      "Epoch: 20 Step: 381 Loss: 1.4215410264063428\n",
      "Epoch: 20 Step: 391 Loss: 0.9466690458107996\n",
      "Epoch: 20 Step: 401 Loss: 1.1087812937568828\n",
      "Epoch: 20 Step: 411 Loss: 1.2890458297593939\n",
      "Epoch: 20 Step: 421 Loss: 1.4330933621901474\n",
      "Epoch: 20 Step: 431 Loss: 1.2343383520990119\n",
      "Epoch: 20 Step: 441 Loss: 1.1991842099559997\n",
      "Epoch: 20 Step: 451 Loss: 1.0389126677427714\n",
      "Epoch: 20 Step: 461 Loss: 1.3588867388896237\n",
      "Epoch: 20 Step: 471 Loss: 1.1270870771204307\n",
      "Epoch: 20 Step: 481 Loss: 1.4736170767192627\n",
      "Epoch: 20 Step: 491 Loss: 1.6343738361141267\n",
      "Epoch: 20 Step: 501 Loss: 1.329534294589086\n",
      "Epoch: 20 Step: 511 Loss: 1.2556859827801286\n",
      "Epoch: 20 Step: 521 Loss: 1.22110507045092\n",
      "Epoch: 20 Step: 531 Loss: 1.214732529723486\n",
      "Epoch: 20 Step: 541 Loss: 1.1094790542178765\n",
      "Epoch: 20 Step: 551 Loss: 1.1981724354977281\n",
      "Epoch: 20 Step: 561 Loss: 1.1245126206263647\n",
      "Epoch: 20 Step: 571 Loss: 1.2426272887815273\n",
      "Epoch: 20 Step: 581 Loss: 1.2482762411627912\n",
      "Epoch: 20 Step: 591 Loss: 1.421365190870609\n",
      "Epoch: 20 Step: 601 Loss: 1.3262656314877388\n",
      "Epoch: 20 Step: 611 Loss: 1.1300574004146662\n",
      "Epoch: 20 Step: 621 Loss: 1.187808865634557\n",
      "Epoch: 20 Step: 631 Loss: 1.4648450355313551\n",
      "Epoch: 20 Step: 641 Loss: 1.3024644483679588\n",
      "Epoch: 20 Step: 651 Loss: 1.2792244442218923\n",
      "Epoch: 20 Step: 661 Loss: 1.084332176744101\n",
      "Epoch: 20 Step: 671 Loss: 1.2171898870371314\n",
      "Epoch: 20 Step: 681 Loss: 1.403000074211092\n",
      "Epoch: 20 Step: 691 Loss: 1.1534575683110848\n",
      "Epoch: 20 Step: 701 Loss: 1.1712316737592843\n",
      "Epoch: 20 Step: 711 Loss: 1.231274440895636\n",
      "Epoch: 20 Step: 721 Loss: 1.0045021481491418\n",
      "Epoch: 20 Step: 731 Loss: 0.9128141533897123\n",
      "Epoch: 20 Step: 741 Loss: 1.290069989237931\n",
      "Epoch: 20 Step: 751 Loss: 1.4599834397571323\n",
      "Epoch: 20 Step: 761 Loss: 1.1159224874887448\n",
      "Epoch: 20 Step: 771 Loss: 1.2497800650856021\n",
      "Epoch: 20 Step: 781 Loss: 1.1754575783417267\n",
      "Epoch: 21 Step: 1 Loss: 1.2421130687883741\n",
      "Epoch: 21 Step: 11 Loss: 1.2622479694022817\n",
      "Epoch: 21 Step: 21 Loss: 1.2146827742195434\n",
      "Epoch: 21 Step: 31 Loss: 1.4233222062825561\n",
      "Epoch: 21 Step: 41 Loss: 1.246746265916019\n",
      "Epoch: 21 Step: 51 Loss: 1.046947979644623\n",
      "Epoch: 21 Step: 61 Loss: 1.2975428864825103\n",
      "Epoch: 21 Step: 71 Loss: 1.4025639269700994\n",
      "Epoch: 21 Step: 81 Loss: 1.531638060088851\n",
      "Epoch: 21 Step: 91 Loss: 1.205349244281895\n",
      "Epoch: 21 Step: 101 Loss: 1.1577667141644563\n",
      "Epoch: 21 Step: 111 Loss: 1.3676259060564528\n",
      "Epoch: 21 Step: 121 Loss: 1.4484322484516385\n",
      "Epoch: 21 Step: 131 Loss: 1.3403019865064938\n",
      "Epoch: 21 Step: 141 Loss: 1.5097986428202828\n",
      "Epoch: 21 Step: 151 Loss: 0.9456629513520598\n",
      "Epoch: 21 Step: 161 Loss: 1.2414052148322088\n",
      "Epoch: 21 Step: 171 Loss: 1.2775420738191792\n",
      "Epoch: 21 Step: 181 Loss: 1.297188104729603\n",
      "Epoch: 21 Step: 191 Loss: 1.1502512753370082\n",
      "Epoch: 21 Step: 201 Loss: 0.9541196330460058\n",
      "Epoch: 21 Step: 211 Loss: 1.0820308663222737\n",
      "Epoch: 21 Step: 221 Loss: 1.235159471945087\n",
      "Epoch: 21 Step: 231 Loss: 1.1902003848502873\n",
      "Epoch: 21 Step: 241 Loss: 1.2923328341966145\n",
      "Epoch: 21 Step: 251 Loss: 1.201490128080811\n",
      "Epoch: 21 Step: 261 Loss: 1.1850350732478376\n",
      "Epoch: 21 Step: 271 Loss: 1.3964702697851439\n",
      "Epoch: 21 Step: 281 Loss: 1.2141330747229149\n",
      "Epoch: 21 Step: 291 Loss: 1.2101923454019325\n",
      "Epoch: 21 Step: 301 Loss: 1.3511671515906456\n",
      "Epoch: 21 Step: 311 Loss: 1.1941645179612284\n",
      "Epoch: 21 Step: 321 Loss: 1.213159929751546\n",
      "Epoch: 21 Step: 331 Loss: 1.1122903793128407\n",
      "Epoch: 21 Step: 341 Loss: 1.1925748145479642\n",
      "Epoch: 21 Step: 351 Loss: 1.241154321719304\n",
      "Epoch: 21 Step: 361 Loss: 1.227740453894026\n",
      "Epoch: 21 Step: 371 Loss: 1.003208777919411\n",
      "Epoch: 21 Step: 381 Loss: 1.3366775173599188\n",
      "Epoch: 21 Step: 391 Loss: 0.9157559140045678\n",
      "Epoch: 21 Step: 401 Loss: 1.070956316520179\n",
      "Epoch: 21 Step: 411 Loss: 1.2034903155794079\n",
      "Epoch: 21 Step: 421 Loss: 1.2712680705629513\n",
      "Epoch: 21 Step: 431 Loss: 1.2353353108977108\n",
      "Epoch: 21 Step: 441 Loss: 1.1296558586511454\n",
      "Epoch: 21 Step: 451 Loss: 1.1898456807414797\n",
      "Epoch: 21 Step: 461 Loss: 1.322085773123093\n",
      "Epoch: 21 Step: 471 Loss: 1.201322365203931\n",
      "Epoch: 21 Step: 481 Loss: 1.401925328838246\n",
      "Epoch: 21 Step: 491 Loss: 1.4539411524763826\n",
      "Epoch: 21 Step: 501 Loss: 1.3393284660502673\n",
      "Epoch: 21 Step: 511 Loss: 1.102829438475026\n",
      "Epoch: 21 Step: 521 Loss: 1.2724023941094569\n",
      "Epoch: 21 Step: 531 Loss: 1.2136045672768792\n",
      "Epoch: 21 Step: 541 Loss: 1.0934125926911458\n",
      "Epoch: 21 Step: 551 Loss: 1.3320379556147257\n",
      "Epoch: 21 Step: 561 Loss: 1.1202239037369235\n",
      "Epoch: 21 Step: 571 Loss: 1.0226246767008267\n",
      "Epoch: 21 Step: 581 Loss: 1.2298634424931154\n",
      "Epoch: 21 Step: 591 Loss: 1.3776562379171193\n",
      "Epoch: 21 Step: 601 Loss: 1.163355241825989\n",
      "Epoch: 21 Step: 611 Loss: 1.1219452551011355\n",
      "Epoch: 21 Step: 621 Loss: 1.1344254938783722\n",
      "Epoch: 21 Step: 631 Loss: 1.282058075680936\n",
      "Epoch: 21 Step: 641 Loss: 1.19902840012209\n",
      "Epoch: 21 Step: 651 Loss: 1.334498939438036\n",
      "Epoch: 21 Step: 661 Loss: 1.0366375189494372\n",
      "Epoch: 21 Step: 671 Loss: 1.185314596855613\n",
      "Epoch: 21 Step: 681 Loss: 1.336403564035241\n",
      "Epoch: 21 Step: 691 Loss: 1.318368068014599\n",
      "Epoch: 21 Step: 701 Loss: 1.1953724462617168\n",
      "Epoch: 21 Step: 711 Loss: 1.2217172651851333\n",
      "Epoch: 21 Step: 721 Loss: 1.0258457882261824\n",
      "Epoch: 21 Step: 731 Loss: 1.0057305256593072\n",
      "Epoch: 21 Step: 741 Loss: 1.33019976620294\n",
      "Epoch: 21 Step: 751 Loss: 1.2599101203152459\n",
      "Epoch: 21 Step: 761 Loss: 1.1122842275108331\n",
      "Epoch: 21 Step: 771 Loss: 1.2958309100267442\n",
      "Epoch: 21 Step: 781 Loss: 1.0455108827069854\n",
      "Epoch: 22 Step: 1 Loss: 1.312169200788941\n",
      "Epoch: 22 Step: 11 Loss: 1.2719683320708872\n",
      "Epoch: 22 Step: 21 Loss: 1.1229161209143368\n",
      "Epoch: 22 Step: 31 Loss: 1.298477427525913\n",
      "Epoch: 22 Step: 41 Loss: 0.9947653750630152\n",
      "Epoch: 22 Step: 51 Loss: 0.9562104468762354\n",
      "Epoch: 22 Step: 61 Loss: 1.271986378888622\n",
      "Epoch: 22 Step: 71 Loss: 1.3005360453355066\n",
      "Epoch: 22 Step: 81 Loss: 1.3086050811566736\n",
      "Epoch: 22 Step: 91 Loss: 1.2043212028936563\n",
      "Epoch: 22 Step: 101 Loss: 1.166999210254072\n",
      "Epoch: 22 Step: 111 Loss: 1.1109571490691132\n",
      "Epoch: 22 Step: 121 Loss: 1.422067072734953\n",
      "Epoch: 22 Step: 131 Loss: 1.2919724772068775\n",
      "Epoch: 22 Step: 141 Loss: 1.51887544235891\n",
      "Epoch: 22 Step: 151 Loss: 1.0825296330783707\n",
      "Epoch: 22 Step: 161 Loss: 1.230017201892518\n",
      "Epoch: 22 Step: 171 Loss: 1.1112990139418955\n",
      "Epoch: 22 Step: 181 Loss: 1.2349236851536192\n",
      "Epoch: 22 Step: 191 Loss: 1.2316113359360306\n",
      "Epoch: 22 Step: 201 Loss: 0.9793384045185849\n",
      "Epoch: 22 Step: 211 Loss: 1.1251701256584072\n",
      "Epoch: 22 Step: 221 Loss: 1.2822243854229547\n",
      "Epoch: 22 Step: 231 Loss: 1.1893960047738512\n",
      "Epoch: 22 Step: 241 Loss: 1.2003473134468843\n",
      "Epoch: 22 Step: 251 Loss: 1.020739140852723\n",
      "Epoch: 22 Step: 261 Loss: 1.233194754162898\n",
      "Epoch: 22 Step: 271 Loss: 1.3535126457801352\n",
      "Epoch: 22 Step: 281 Loss: 1.3114200244079375\n",
      "Epoch: 22 Step: 291 Loss: 1.127918145208085\n",
      "Epoch: 22 Step: 301 Loss: 1.3791934983189287\n",
      "Epoch: 22 Step: 311 Loss: 1.2862893019607213\n",
      "Epoch: 22 Step: 321 Loss: 1.3007725075775944\n",
      "Epoch: 22 Step: 331 Loss: 1.1506057628376143\n",
      "Epoch: 22 Step: 341 Loss: 1.3231455407862809\n",
      "Epoch: 22 Step: 351 Loss: 1.3220176159818557\n",
      "Epoch: 22 Step: 361 Loss: 1.0994204104004415\n",
      "Epoch: 22 Step: 371 Loss: 0.9105099486220171\n",
      "Epoch: 22 Step: 381 Loss: 1.3352321097823008\n",
      "Epoch: 22 Step: 391 Loss: 0.93113808220626\n",
      "Epoch: 22 Step: 401 Loss: 1.1861859587853234\n",
      "Epoch: 22 Step: 411 Loss: 1.332062007884812\n",
      "Epoch: 22 Step: 421 Loss: 1.2322460565788407\n",
      "Epoch: 22 Step: 431 Loss: 1.3337535481808112\n",
      "Epoch: 22 Step: 441 Loss: 1.264316862136437\n",
      "Epoch: 22 Step: 451 Loss: 1.1991744684040175\n",
      "Epoch: 22 Step: 461 Loss: 1.1903398137242585\n",
      "Epoch: 22 Step: 471 Loss: 1.2501878776307986\n",
      "Epoch: 22 Step: 481 Loss: 1.2265298729909615\n",
      "Epoch: 22 Step: 491 Loss: 1.3961798653895436\n",
      "Epoch: 22 Step: 501 Loss: 1.2186106823998277\n",
      "Epoch: 22 Step: 511 Loss: 1.1724998664866297\n",
      "Epoch: 22 Step: 521 Loss: 1.209470729249685\n",
      "Epoch: 22 Step: 531 Loss: 1.2011246599920045\n",
      "Epoch: 22 Step: 541 Loss: 0.9942725434779331\n",
      "Epoch: 22 Step: 551 Loss: 1.0947845450207367\n",
      "Epoch: 22 Step: 561 Loss: 1.1821983371503408\n",
      "Epoch: 22 Step: 571 Loss: 1.1416129762821887\n",
      "Epoch: 22 Step: 581 Loss: 1.1373428594666979\n",
      "Epoch: 22 Step: 591 Loss: 1.2768109629387556\n",
      "Epoch: 22 Step: 601 Loss: 1.0634081700238802\n",
      "Epoch: 22 Step: 611 Loss: 1.1119063540027403\n",
      "Epoch: 22 Step: 621 Loss: 1.036711244342623\n",
      "Epoch: 22 Step: 631 Loss: 1.3517318136164667\n",
      "Epoch: 22 Step: 641 Loss: 1.1922521426472044\n",
      "Epoch: 22 Step: 651 Loss: 1.2294767284220698\n",
      "Epoch: 22 Step: 661 Loss: 1.1069962675390148\n",
      "Epoch: 22 Step: 671 Loss: 1.2352077991619153\n",
      "Epoch: 22 Step: 681 Loss: 1.3759188103173314\n",
      "Epoch: 22 Step: 691 Loss: 1.3194764957179994\n",
      "Epoch: 22 Step: 701 Loss: 1.1309598869220312\n",
      "Epoch: 22 Step: 711 Loss: 1.1677419180426232\n",
      "Epoch: 22 Step: 721 Loss: 1.0273336976990262\n",
      "Epoch: 22 Step: 731 Loss: 1.0866061109021077\n",
      "Epoch: 22 Step: 741 Loss: 1.416930599261559\n",
      "Epoch: 22 Step: 751 Loss: 1.4405051961882314\n",
      "Epoch: 22 Step: 761 Loss: 1.090658813068121\n",
      "Epoch: 22 Step: 771 Loss: 1.1803685524709184\n",
      "Epoch: 22 Step: 781 Loss: 1.3330714747338837\n",
      "Epoch: 23 Step: 1 Loss: 1.177708777938737\n",
      "Epoch: 23 Step: 11 Loss: 1.326927889985499\n",
      "Epoch: 23 Step: 21 Loss: 1.1445340419064631\n",
      "Epoch: 23 Step: 31 Loss: 1.4478112433536223\n",
      "Epoch: 23 Step: 41 Loss: 1.0941913463872721\n",
      "Epoch: 23 Step: 51 Loss: 1.1032659124975999\n",
      "Epoch: 23 Step: 61 Loss: 1.1620561617014897\n",
      "Epoch: 23 Step: 71 Loss: 1.5275424046196384\n",
      "Epoch: 23 Step: 81 Loss: 1.3679233700346314\n",
      "Epoch: 23 Step: 91 Loss: 1.2346004475701124\n",
      "Epoch: 23 Step: 101 Loss: 1.2727976158274432\n",
      "Epoch: 23 Step: 111 Loss: 1.1702730765992422\n",
      "Epoch: 23 Step: 121 Loss: 1.3274064373439143\n",
      "Epoch: 23 Step: 131 Loss: 1.327941529946452\n",
      "Epoch: 23 Step: 141 Loss: 1.2914931454041354\n",
      "Epoch: 23 Step: 151 Loss: 0.9590164584697217\n",
      "Epoch: 23 Step: 161 Loss: 1.1358745177908975\n",
      "Epoch: 23 Step: 171 Loss: 1.134879180650207\n",
      "Epoch: 23 Step: 181 Loss: 1.0617613125043588\n",
      "Epoch: 23 Step: 191 Loss: 1.0803024156055292\n",
      "Epoch: 23 Step: 201 Loss: 0.9248203060991581\n",
      "Epoch: 23 Step: 211 Loss: 1.069179045855697\n",
      "Epoch: 23 Step: 221 Loss: 1.1376472734659628\n",
      "Epoch: 23 Step: 231 Loss: 1.0372573683503792\n",
      "Epoch: 23 Step: 241 Loss: 1.1170178932582295\n",
      "Epoch: 23 Step: 251 Loss: 1.0286974984093233\n",
      "Epoch: 23 Step: 261 Loss: 1.2565232557235437\n",
      "Epoch: 23 Step: 271 Loss: 1.2560111027318897\n",
      "Epoch: 23 Step: 281 Loss: 1.2124695257834663\n",
      "Epoch: 23 Step: 291 Loss: 1.3040263862097135\n",
      "Epoch: 23 Step: 301 Loss: 1.40165495619864\n",
      "Epoch: 23 Step: 311 Loss: 1.1655132987618\n",
      "Epoch: 23 Step: 321 Loss: 1.2724976262917673\n",
      "Epoch: 23 Step: 331 Loss: 1.1653918635273728\n",
      "Epoch: 23 Step: 341 Loss: 1.2846435724825793\n",
      "Epoch: 23 Step: 351 Loss: 1.2831022169295743\n",
      "Epoch: 23 Step: 361 Loss: 1.11509917715204\n",
      "Epoch: 23 Step: 371 Loss: 0.9177281658618932\n",
      "Epoch: 23 Step: 381 Loss: 1.2897908201962724\n",
      "Epoch: 23 Step: 391 Loss: 0.9729706575586425\n",
      "Epoch: 23 Step: 401 Loss: 1.1001283575573475\n",
      "Epoch: 23 Step: 411 Loss: 1.3216609137126392\n",
      "Epoch: 23 Step: 421 Loss: 1.3662345152485362\n",
      "Epoch: 23 Step: 431 Loss: 1.365339938448193\n",
      "Epoch: 23 Step: 441 Loss: 1.2438516375970865\n",
      "Epoch: 23 Step: 451 Loss: 1.2447841563233897\n",
      "Epoch: 23 Step: 461 Loss: 1.0813303546775392\n",
      "Epoch: 23 Step: 471 Loss: 1.3418293820034806\n",
      "Epoch: 23 Step: 481 Loss: 1.2954339905757841\n",
      "Epoch: 23 Step: 491 Loss: 1.4787393938618818\n",
      "Epoch: 23 Step: 501 Loss: 1.3062095237766864\n",
      "Epoch: 23 Step: 511 Loss: 1.2017017765860172\n",
      "Epoch: 23 Step: 521 Loss: 1.3428557998281525\n",
      "Epoch: 23 Step: 531 Loss: 1.2977907475364865\n",
      "Epoch: 23 Step: 541 Loss: 1.1857371364948275\n",
      "Epoch: 23 Step: 551 Loss: 1.0748771267608555\n",
      "Epoch: 23 Step: 561 Loss: 1.1746882984527072\n",
      "Epoch: 23 Step: 571 Loss: 1.276688501711448\n",
      "Epoch: 23 Step: 581 Loss: 1.1870104650231363\n",
      "Epoch: 23 Step: 591 Loss: 1.1914059593345012\n",
      "Epoch: 23 Step: 601 Loss: 1.2169689366569902\n",
      "Epoch: 23 Step: 611 Loss: 1.125478950793342\n",
      "Epoch: 23 Step: 621 Loss: 1.1120440329619572\n",
      "Epoch: 23 Step: 631 Loss: 1.2447240526767454\n",
      "Epoch: 23 Step: 641 Loss: 1.234513607989774\n",
      "Epoch: 23 Step: 651 Loss: 1.1609177163066482\n",
      "Epoch: 23 Step: 661 Loss: 1.1670449085710835\n",
      "Epoch: 23 Step: 671 Loss: 1.204757839184686\n",
      "Epoch: 23 Step: 681 Loss: 1.3447139622815525\n",
      "Epoch: 23 Step: 691 Loss: 1.2398426343801754\n",
      "Epoch: 23 Step: 701 Loss: 1.1532800068734461\n",
      "Epoch: 23 Step: 711 Loss: 0.9761709674265726\n",
      "Epoch: 23 Step: 721 Loss: 1.0037389756723467\n",
      "Epoch: 23 Step: 731 Loss: 1.0516872260301362\n",
      "Epoch: 23 Step: 741 Loss: 1.3359482357000032\n",
      "Epoch: 23 Step: 751 Loss: 1.447201119656102\n",
      "Epoch: 23 Step: 761 Loss: 1.1475795744681587\n",
      "Epoch: 23 Step: 771 Loss: 1.435011059616319\n",
      "Epoch: 23 Step: 781 Loss: 1.0422137226477528\n",
      "Epoch: 24 Step: 1 Loss: 1.1394559959717854\n",
      "Epoch: 24 Step: 11 Loss: 1.2442905836154041\n",
      "Epoch: 24 Step: 21 Loss: 1.283401850545338\n",
      "Epoch: 24 Step: 31 Loss: 1.4517507905168139\n",
      "Epoch: 24 Step: 41 Loss: 1.2475625024123822\n",
      "Epoch: 24 Step: 51 Loss: 1.0358986225969924\n",
      "Epoch: 24 Step: 61 Loss: 1.1035073474969175\n",
      "Epoch: 24 Step: 71 Loss: 1.4399021777850003\n",
      "Epoch: 24 Step: 81 Loss: 1.3491868070273476\n",
      "Epoch: 24 Step: 91 Loss: 1.3211750158689752\n",
      "Epoch: 24 Step: 101 Loss: 1.2824181236003587\n",
      "Epoch: 24 Step: 111 Loss: 1.3074008440310965\n",
      "Epoch: 24 Step: 121 Loss: 1.3117096015922858\n",
      "Epoch: 24 Step: 131 Loss: 1.2149238583390303\n",
      "Epoch: 24 Step: 141 Loss: 1.6441291793470816\n",
      "Epoch: 24 Step: 151 Loss: 0.9408900932940698\n",
      "Epoch: 24 Step: 161 Loss: 1.14493382067149\n",
      "Epoch: 24 Step: 171 Loss: 1.288890755239752\n",
      "Epoch: 24 Step: 181 Loss: 1.1453667136754087\n",
      "Epoch: 24 Step: 191 Loss: 1.090480279063481\n",
      "Epoch: 24 Step: 201 Loss: 1.0418276995426776\n",
      "Epoch: 24 Step: 211 Loss: 1.0687280118397524\n",
      "Epoch: 24 Step: 221 Loss: 1.2585248009477783\n",
      "Epoch: 24 Step: 231 Loss: 1.1708768687534994\n",
      "Epoch: 24 Step: 241 Loss: 1.120716374886079\n",
      "Epoch: 24 Step: 251 Loss: 0.9775787355000416\n",
      "Epoch: 24 Step: 261 Loss: 1.232545889273605\n",
      "Epoch: 24 Step: 271 Loss: 1.2073826318271614\n",
      "Epoch: 24 Step: 281 Loss: 1.041447711030353\n",
      "Epoch: 24 Step: 291 Loss: 1.19093097794075\n",
      "Epoch: 24 Step: 301 Loss: 1.385541757986009\n",
      "Epoch: 24 Step: 311 Loss: 1.2828568991089566\n",
      "Epoch: 24 Step: 321 Loss: 1.1449635912699057\n",
      "Epoch: 24 Step: 331 Loss: 1.1031356645962893\n",
      "Epoch: 24 Step: 341 Loss: 1.2537249209064136\n",
      "Epoch: 24 Step: 351 Loss: 1.112311610923078\n",
      "Epoch: 24 Step: 361 Loss: 1.0796926434666956\n",
      "Epoch: 24 Step: 371 Loss: 0.8880284468117199\n",
      "Epoch: 24 Step: 381 Loss: 1.339489582676162\n",
      "Epoch: 24 Step: 391 Loss: 0.9142609096771597\n",
      "Epoch: 24 Step: 401 Loss: 1.0190041192101438\n",
      "Epoch: 24 Step: 411 Loss: 1.1847452467615485\n",
      "Epoch: 24 Step: 421 Loss: 1.3374798925138243\n",
      "Epoch: 24 Step: 431 Loss: 1.156732949621552\n",
      "Epoch: 24 Step: 441 Loss: 1.099653493747883\n",
      "Epoch: 24 Step: 451 Loss: 1.103365664706838\n",
      "Epoch: 24 Step: 461 Loss: 1.0591040456857441\n",
      "Epoch: 24 Step: 471 Loss: 1.3227615188800668\n",
      "Epoch: 24 Step: 481 Loss: 1.2850064985940246\n",
      "Epoch: 24 Step: 491 Loss: 1.4046550161247993\n",
      "Epoch: 24 Step: 501 Loss: 1.3025085491040205\n",
      "Epoch: 24 Step: 511 Loss: 1.3158741088955246\n",
      "Epoch: 24 Step: 521 Loss: 1.229992621349149\n",
      "Epoch: 24 Step: 531 Loss: 1.2207942899727855\n",
      "Epoch: 24 Step: 541 Loss: 1.1994968831119994\n",
      "Epoch: 24 Step: 551 Loss: 1.1911615283587047\n",
      "Epoch: 24 Step: 561 Loss: 1.138704341726409\n",
      "Epoch: 24 Step: 571 Loss: 1.0681993679556983\n",
      "Epoch: 24 Step: 581 Loss: 1.1852749401764044\n",
      "Epoch: 24 Step: 591 Loss: 1.1746501557972002\n",
      "Epoch: 24 Step: 601 Loss: 1.322414462737755\n",
      "Epoch: 24 Step: 611 Loss: 1.1155386195405474\n",
      "Epoch: 24 Step: 621 Loss: 1.1053031006818068\n",
      "Epoch: 24 Step: 631 Loss: 1.2357635186910438\n",
      "Epoch: 24 Step: 641 Loss: 1.301034508484034\n",
      "Epoch: 24 Step: 651 Loss: 1.217826339588533\n",
      "Epoch: 24 Step: 661 Loss: 1.081914636232825\n",
      "Epoch: 24 Step: 671 Loss: 1.256322415952316\n",
      "Epoch: 24 Step: 681 Loss: 1.3576133416651763\n",
      "Epoch: 24 Step: 691 Loss: 1.267307611809727\n",
      "Epoch: 24 Step: 701 Loss: 1.086184624551593\n",
      "Epoch: 24 Step: 711 Loss: 1.2199410366240462\n",
      "Epoch: 24 Step: 721 Loss: 1.0326758401243308\n",
      "Epoch: 24 Step: 731 Loss: 0.9621525687764687\n",
      "Epoch: 24 Step: 741 Loss: 1.2247496685209636\n",
      "Epoch: 24 Step: 751 Loss: 1.412878406365106\n",
      "Epoch: 24 Step: 761 Loss: 1.042061381155928\n",
      "Epoch: 24 Step: 771 Loss: 1.3217841384546545\n",
      "Epoch: 24 Step: 781 Loss: 1.0842186210141516\n",
      "Epoch: 25 Step: 1 Loss: 1.1024518796921043\n",
      "Epoch: 25 Step: 11 Loss: 1.2244007669697339\n",
      "Epoch: 25 Step: 21 Loss: 1.1162017033781104\n",
      "Epoch: 25 Step: 31 Loss: 1.266418085394726\n",
      "Epoch: 25 Step: 41 Loss: 1.0805634301907021\n",
      "Epoch: 25 Step: 51 Loss: 0.9730481745382955\n",
      "Epoch: 25 Step: 61 Loss: 1.2817223591286226\n",
      "Epoch: 25 Step: 71 Loss: 1.2760710688264367\n",
      "Epoch: 25 Step: 81 Loss: 1.3227610603254312\n",
      "Epoch: 25 Step: 91 Loss: 1.3525281515339171\n",
      "Epoch: 25 Step: 101 Loss: 1.1912640589130103\n",
      "Epoch: 25 Step: 111 Loss: 1.2212449118157873\n",
      "Epoch: 25 Step: 121 Loss: 1.4489922270088194\n",
      "Epoch: 25 Step: 131 Loss: 1.2322082274743518\n",
      "Epoch: 25 Step: 141 Loss: 1.518215691951494\n",
      "Epoch: 25 Step: 151 Loss: 0.8628318169780794\n",
      "Epoch: 25 Step: 161 Loss: 1.1807841831154962\n",
      "Epoch: 25 Step: 171 Loss: 1.169921873826169\n",
      "Epoch: 25 Step: 181 Loss: 1.0471000439386327\n",
      "Epoch: 25 Step: 191 Loss: 1.1178340323808729\n",
      "Epoch: 25 Step: 201 Loss: 0.9196386049537525\n",
      "Epoch: 25 Step: 211 Loss: 1.0578276433026075\n",
      "Epoch: 25 Step: 221 Loss: 1.0991486366172547\n",
      "Epoch: 25 Step: 231 Loss: 1.1641706796004119\n",
      "Epoch: 25 Step: 241 Loss: 1.0271800560097537\n",
      "Epoch: 25 Step: 251 Loss: 1.0931941729427748\n",
      "Epoch: 25 Step: 261 Loss: 1.1819643618908824\n",
      "Epoch: 25 Step: 271 Loss: 1.2568497258866786\n",
      "Epoch: 25 Step: 281 Loss: 1.1876675414399487\n",
      "Epoch: 25 Step: 291 Loss: 1.146502643484371\n",
      "Epoch: 25 Step: 301 Loss: 1.24739802086022\n",
      "Epoch: 25 Step: 311 Loss: 1.220330801919874\n",
      "Epoch: 25 Step: 321 Loss: 1.3069945214580687\n",
      "Epoch: 25 Step: 331 Loss: 1.0657252304292308\n",
      "Epoch: 25 Step: 341 Loss: 1.3234556049214614\n",
      "Epoch: 25 Step: 351 Loss: 1.2540440242348434\n",
      "Epoch: 25 Step: 361 Loss: 1.0262895192572756\n",
      "Epoch: 25 Step: 371 Loss: 1.008340140799767\n",
      "Epoch: 25 Step: 381 Loss: 1.3360047827305772\n",
      "Epoch: 25 Step: 391 Loss: 0.9028331212544197\n",
      "Epoch: 25 Step: 401 Loss: 1.2234125864045375\n",
      "Epoch: 25 Step: 411 Loss: 1.2234374867509419\n",
      "Epoch: 25 Step: 421 Loss: 1.3168019420386248\n",
      "Epoch: 25 Step: 431 Loss: 1.112519045984795\n",
      "Epoch: 25 Step: 441 Loss: 1.1020102363471487\n",
      "Epoch: 25 Step: 451 Loss: 0.966647264917025\n",
      "Epoch: 25 Step: 461 Loss: 1.2778243155035132\n",
      "Epoch: 25 Step: 471 Loss: 1.168293985318643\n",
      "Epoch: 25 Step: 481 Loss: 1.2923926193853426\n",
      "Epoch: 25 Step: 491 Loss: 1.3261532659967257\n",
      "Epoch: 25 Step: 501 Loss: 1.2290815020250057\n",
      "Epoch: 25 Step: 511 Loss: 0.9438332717984904\n",
      "Epoch: 25 Step: 521 Loss: 1.1303235724893193\n",
      "Epoch: 25 Step: 531 Loss: 1.163927111344207\n",
      "Epoch: 25 Step: 541 Loss: 0.9911739877600274\n",
      "Epoch: 25 Step: 551 Loss: 1.194145843732735\n",
      "Epoch: 25 Step: 561 Loss: 1.0903846155971229\n",
      "Epoch: 25 Step: 571 Loss: 1.2276307970171774\n",
      "Epoch: 25 Step: 581 Loss: 1.0793806755809734\n",
      "Epoch: 25 Step: 591 Loss: 1.2917115143505358\n",
      "Epoch: 25 Step: 601 Loss: 1.3920761438581701\n",
      "Epoch: 25 Step: 611 Loss: 1.1035639693828956\n",
      "Epoch: 25 Step: 621 Loss: 1.2562966346896953\n",
      "Epoch: 25 Step: 631 Loss: 1.1873169339832486\n",
      "Epoch: 25 Step: 641 Loss: 1.2205417458513494\n",
      "Epoch: 25 Step: 651 Loss: 1.0773897060297362\n",
      "Epoch: 25 Step: 661 Loss: 0.9672145428929073\n",
      "Epoch: 25 Step: 671 Loss: 1.1630073224831752\n",
      "Epoch: 25 Step: 681 Loss: 1.4366306473626944\n",
      "Epoch: 25 Step: 691 Loss: 1.363092825115649\n",
      "Epoch: 25 Step: 701 Loss: 1.1496137328278802\n",
      "Epoch: 25 Step: 711 Loss: 1.2457558144117078\n",
      "Epoch: 25 Step: 721 Loss: 0.9718893056938901\n",
      "Epoch: 25 Step: 731 Loss: 0.8850615028080535\n",
      "Epoch: 25 Step: 741 Loss: 1.222272500138585\n",
      "Epoch: 25 Step: 751 Loss: 1.5066184611464777\n",
      "Epoch: 25 Step: 761 Loss: 0.9919141822804229\n",
      "Epoch: 25 Step: 771 Loss: 1.2552089557830053\n",
      "Epoch: 25 Step: 781 Loss: 1.0837003542837185\n",
      "Epoch: 26 Step: 1 Loss: 1.2258952711716067\n",
      "Epoch: 26 Step: 11 Loss: 1.1013626286180571\n",
      "Epoch: 26 Step: 21 Loss: 1.3542892369421389\n",
      "Epoch: 26 Step: 31 Loss: 1.4594380206344262\n",
      "Epoch: 26 Step: 41 Loss: 1.109642576913627\n",
      "Epoch: 26 Step: 51 Loss: 1.0881920044686788\n",
      "Epoch: 26 Step: 61 Loss: 1.247891914864029\n",
      "Epoch: 26 Step: 71 Loss: 1.154506998537928\n",
      "Epoch: 26 Step: 81 Loss: 1.1718230015998556\n",
      "Epoch: 26 Step: 91 Loss: 1.1585137980940803\n",
      "Epoch: 26 Step: 101 Loss: 1.18001622656986\n",
      "Epoch: 26 Step: 111 Loss: 1.1502650456004373\n",
      "Epoch: 26 Step: 121 Loss: 1.2330332787499005\n",
      "Epoch: 26 Step: 131 Loss: 1.1106875399759684\n",
      "Epoch: 26 Step: 141 Loss: 1.4315394576212277\n",
      "Epoch: 26 Step: 151 Loss: 0.8657671569600188\n",
      "Epoch: 26 Step: 161 Loss: 1.1159365785578221\n",
      "Epoch: 26 Step: 171 Loss: 1.164277229283588\n",
      "Epoch: 26 Step: 181 Loss: 1.0136810320240652\n",
      "Epoch: 26 Step: 191 Loss: 0.9288213148253943\n",
      "Epoch: 26 Step: 201 Loss: 0.7982619888154346\n",
      "Epoch: 26 Step: 211 Loss: 0.9358698130021499\n",
      "Epoch: 26 Step: 221 Loss: 1.2343644271913639\n",
      "Epoch: 26 Step: 231 Loss: 0.9850526322822797\n",
      "Epoch: 26 Step: 241 Loss: 0.9936222129853132\n",
      "Epoch: 26 Step: 251 Loss: 1.1399990449329251\n",
      "Epoch: 26 Step: 261 Loss: 1.1484223111824932\n",
      "Epoch: 26 Step: 271 Loss: 1.3295767278848643\n",
      "Epoch: 26 Step: 281 Loss: 1.1703060909066703\n",
      "Epoch: 26 Step: 291 Loss: 1.3483648111081523\n",
      "Epoch: 26 Step: 301 Loss: 1.3341198340765024\n",
      "Epoch: 26 Step: 311 Loss: 1.2264263937791422\n",
      "Epoch: 26 Step: 321 Loss: 1.2722178620509623\n",
      "Epoch: 26 Step: 331 Loss: 1.296931675459993\n",
      "Epoch: 26 Step: 341 Loss: 1.3227828113420526\n",
      "Epoch: 26 Step: 351 Loss: 1.1042097850628876\n",
      "Epoch: 26 Step: 361 Loss: 0.9986476998324464\n",
      "Epoch: 26 Step: 371 Loss: 0.9878054017932203\n",
      "Epoch: 26 Step: 381 Loss: 1.3780604432030334\n",
      "Epoch: 26 Step: 391 Loss: 1.0614224117926643\n",
      "Epoch: 26 Step: 401 Loss: 0.9928912805950452\n",
      "Epoch: 26 Step: 411 Loss: 1.3154927841021689\n",
      "Epoch: 26 Step: 421 Loss: 1.3646774951047735\n",
      "Epoch: 26 Step: 431 Loss: 1.1445927934052191\n",
      "Epoch: 26 Step: 441 Loss: 1.28285872614614\n",
      "Epoch: 26 Step: 451 Loss: 0.9845893261905885\n",
      "Epoch: 26 Step: 461 Loss: 1.1537481906982787\n",
      "Epoch: 26 Step: 471 Loss: 1.159165017369945\n",
      "Epoch: 26 Step: 481 Loss: 1.3351178619041477\n",
      "Epoch: 26 Step: 491 Loss: 1.4366375849068402\n",
      "Epoch: 26 Step: 501 Loss: 1.146189123768136\n",
      "Epoch: 26 Step: 511 Loss: 1.0799135028910738\n",
      "Epoch: 26 Step: 521 Loss: 1.2144925359340266\n",
      "Epoch: 26 Step: 531 Loss: 1.2097643387937331\n",
      "Epoch: 26 Step: 541 Loss: 0.9570827239334233\n",
      "Epoch: 26 Step: 551 Loss: 1.1692715122439494\n",
      "Epoch: 26 Step: 561 Loss: 1.0176076551655777\n",
      "Epoch: 26 Step: 571 Loss: 1.050756957642955\n",
      "Epoch: 26 Step: 581 Loss: 1.0991472664295039\n",
      "Epoch: 26 Step: 591 Loss: 1.2583935413459675\n",
      "Epoch: 26 Step: 601 Loss: 1.210231211643146\n",
      "Epoch: 26 Step: 611 Loss: 1.0433636866250593\n",
      "Epoch: 26 Step: 621 Loss: 1.0058134501294176\n",
      "Epoch: 26 Step: 631 Loss: 1.0892636213954767\n",
      "Epoch: 26 Step: 641 Loss: 1.141732561136587\n",
      "Epoch: 26 Step: 651 Loss: 1.0747853440694815\n",
      "Epoch: 26 Step: 661 Loss: 1.0069285067362213\n",
      "Epoch: 26 Step: 671 Loss: 1.2513380573876351\n",
      "Epoch: 26 Step: 681 Loss: 1.247338645273025\n",
      "Epoch: 26 Step: 691 Loss: 1.1829858632425063\n",
      "Epoch: 26 Step: 701 Loss: 1.1480257331949224\n",
      "Epoch: 26 Step: 711 Loss: 1.086102220302774\n",
      "Epoch: 26 Step: 721 Loss: 0.9921546042454162\n",
      "Epoch: 26 Step: 731 Loss: 0.9388069276272393\n",
      "Epoch: 26 Step: 741 Loss: 1.4426459111659304\n",
      "Epoch: 26 Step: 751 Loss: 1.402467068058478\n",
      "Epoch: 26 Step: 761 Loss: 1.0130734559149193\n",
      "Epoch: 26 Step: 771 Loss: 1.3242140293469662\n",
      "Epoch: 26 Step: 781 Loss: 1.129975301401145\n",
      "Epoch: 27 Step: 1 Loss: 1.3661029864604424\n",
      "Epoch: 27 Step: 11 Loss: 1.2441042492589967\n",
      "Epoch: 27 Step: 21 Loss: 1.2103619388399967\n",
      "Epoch: 27 Step: 31 Loss: 1.5497138241298405\n",
      "Epoch: 27 Step: 41 Loss: 1.0740703300594179\n",
      "Epoch: 27 Step: 51 Loss: 0.9870812306804289\n",
      "Epoch: 27 Step: 61 Loss: 1.2039803389424164\n",
      "Epoch: 27 Step: 71 Loss: 1.34349035146458\n",
      "Epoch: 27 Step: 81 Loss: 1.347932417288153\n",
      "Epoch: 27 Step: 91 Loss: 1.1723449998682267\n",
      "Epoch: 27 Step: 101 Loss: 1.25809362297328\n",
      "Epoch: 27 Step: 111 Loss: 1.1733130118767272\n",
      "Epoch: 27 Step: 121 Loss: 1.341636455521444\n",
      "Epoch: 27 Step: 131 Loss: 1.150954533028758\n",
      "Epoch: 27 Step: 141 Loss: 1.5157692096100606\n",
      "Epoch: 27 Step: 151 Loss: 0.9811697390328717\n",
      "Epoch: 27 Step: 161 Loss: 1.178677837031179\n",
      "Epoch: 27 Step: 171 Loss: 1.3477254149615754\n",
      "Epoch: 27 Step: 181 Loss: 1.105817115061212\n",
      "Epoch: 27 Step: 191 Loss: 1.1299370780176465\n",
      "Epoch: 27 Step: 201 Loss: 0.8381036577392803\n",
      "Epoch: 27 Step: 211 Loss: 1.0415768166905472\n",
      "Epoch: 27 Step: 221 Loss: 1.2195937749634722\n",
      "Epoch: 27 Step: 231 Loss: 1.0333626272942391\n",
      "Epoch: 27 Step: 241 Loss: 1.0004601101771522\n",
      "Epoch: 27 Step: 251 Loss: 0.9268095062736932\n",
      "Epoch: 27 Step: 261 Loss: 1.1410620079055416\n",
      "Epoch: 27 Step: 271 Loss: 1.073555800399902\n",
      "Epoch: 27 Step: 281 Loss: 1.0159924887329694\n",
      "Epoch: 27 Step: 291 Loss: 1.0788664783826787\n",
      "Epoch: 27 Step: 301 Loss: 1.321880658931501\n",
      "Epoch: 27 Step: 311 Loss: 1.132762312291325\n",
      "Epoch: 27 Step: 321 Loss: 1.2430079954154212\n",
      "Epoch: 27 Step: 331 Loss: 1.0076158437360612\n",
      "Epoch: 27 Step: 341 Loss: 1.1927804236010204\n",
      "Epoch: 27 Step: 351 Loss: 1.1980801698071781\n",
      "Epoch: 27 Step: 361 Loss: 1.0157535017425414\n",
      "Epoch: 27 Step: 371 Loss: 0.9077893604364586\n",
      "Epoch: 27 Step: 381 Loss: 1.322682444538966\n",
      "Epoch: 27 Step: 391 Loss: 0.9422018560518199\n",
      "Epoch: 27 Step: 401 Loss: 1.0670386382293175\n",
      "Epoch: 27 Step: 411 Loss: 1.1675125785311473\n",
      "Epoch: 27 Step: 421 Loss: 1.4155339275563086\n",
      "Epoch: 27 Step: 431 Loss: 1.1877716215322685\n",
      "Epoch: 27 Step: 441 Loss: 1.135254722789562\n",
      "Epoch: 27 Step: 451 Loss: 1.1271110941755338\n",
      "Epoch: 27 Step: 461 Loss: 1.2704342473306376\n",
      "Epoch: 27 Step: 471 Loss: 1.2520418553428123\n",
      "Epoch: 27 Step: 481 Loss: 1.2301236199958294\n",
      "Epoch: 27 Step: 491 Loss: 1.539426435942946\n",
      "Epoch: 27 Step: 501 Loss: 1.393956862425809\n",
      "Epoch: 27 Step: 511 Loss: 1.199437529790469\n",
      "Epoch: 27 Step: 521 Loss: 1.424356531351056\n",
      "Epoch: 27 Step: 531 Loss: 1.1608684228949036\n",
      "Epoch: 27 Step: 541 Loss: 1.0960603970617138\n",
      "Epoch: 27 Step: 551 Loss: 1.2246654757238908\n",
      "Epoch: 27 Step: 561 Loss: 1.2093188888403938\n",
      "Epoch: 27 Step: 571 Loss: 1.2138516358944882\n",
      "Epoch: 27 Step: 581 Loss: 1.125077637729461\n",
      "Epoch: 27 Step: 591 Loss: 1.325937743063454\n",
      "Epoch: 27 Step: 601 Loss: 1.1922741288877288\n",
      "Epoch: 27 Step: 611 Loss: 1.0491974008096216\n",
      "Epoch: 27 Step: 621 Loss: 1.085701344092354\n",
      "Epoch: 27 Step: 631 Loss: 1.1379010314657134\n",
      "Epoch: 27 Step: 641 Loss: 1.2634294323014503\n",
      "Epoch: 27 Step: 651 Loss: 1.098633344170982\n",
      "Epoch: 27 Step: 661 Loss: 0.8852535363147143\n",
      "Epoch: 27 Step: 671 Loss: 1.104691953006881\n",
      "Epoch: 27 Step: 681 Loss: 1.348092224316456\n",
      "Epoch: 27 Step: 691 Loss: 1.1593333252786686\n",
      "Epoch: 27 Step: 701 Loss: 1.009606138130871\n",
      "Epoch: 27 Step: 711 Loss: 1.1725790671173537\n",
      "Epoch: 27 Step: 721 Loss: 0.8469023189228687\n",
      "Epoch: 27 Step: 731 Loss: 0.8643548824212224\n",
      "Epoch: 27 Step: 741 Loss: 1.2486461854564688\n",
      "Epoch: 27 Step: 751 Loss: 1.3653126691582305\n",
      "Epoch: 27 Step: 761 Loss: 0.9957342214417935\n",
      "Epoch: 27 Step: 771 Loss: 1.1957466480404668\n",
      "Epoch: 27 Step: 781 Loss: 1.1056165047459492\n",
      "Epoch: 28 Step: 1 Loss: 1.1934034789538843\n",
      "Epoch: 28 Step: 11 Loss: 1.1373450424696863\n",
      "Epoch: 28 Step: 21 Loss: 1.2541740310290517\n",
      "Epoch: 28 Step: 31 Loss: 1.3961247986874379\n",
      "Epoch: 28 Step: 41 Loss: 1.0762947674359533\n",
      "Epoch: 28 Step: 51 Loss: 0.9050134409445343\n",
      "Epoch: 28 Step: 61 Loss: 1.2126046854703758\n",
      "Epoch: 28 Step: 71 Loss: 1.3024074157541112\n",
      "Epoch: 28 Step: 81 Loss: 1.243000773524213\n",
      "Epoch: 28 Step: 91 Loss: 1.1904247903401468\n",
      "Epoch: 28 Step: 101 Loss: 1.1584069809777673\n",
      "Epoch: 28 Step: 111 Loss: 1.2386680551775404\n",
      "Epoch: 28 Step: 121 Loss: 1.1798408049490452\n",
      "Epoch: 28 Step: 131 Loss: 1.1060935313964302\n",
      "Epoch: 28 Step: 141 Loss: 1.4283559211565506\n",
      "Epoch: 28 Step: 151 Loss: 1.0184111603062538\n",
      "Epoch: 28 Step: 161 Loss: 1.1219216391521136\n",
      "Epoch: 28 Step: 171 Loss: 1.223058679104026\n",
      "Epoch: 28 Step: 181 Loss: 1.0675107060641542\n",
      "Epoch: 28 Step: 191 Loss: 1.1486637645237403\n",
      "Epoch: 28 Step: 201 Loss: 0.8883790439822139\n",
      "Epoch: 28 Step: 211 Loss: 1.0580474710435355\n",
      "Epoch: 28 Step: 221 Loss: 1.0903933554792111\n",
      "Epoch: 28 Step: 231 Loss: 1.1407852046842204\n",
      "Epoch: 28 Step: 241 Loss: 1.2525087941388187\n",
      "Epoch: 28 Step: 251 Loss: 0.9950741923040634\n",
      "Epoch: 28 Step: 261 Loss: 1.1444935557886997\n",
      "Epoch: 28 Step: 271 Loss: 1.243222303348435\n",
      "Epoch: 28 Step: 281 Loss: 1.1718058430892007\n",
      "Epoch: 28 Step: 291 Loss: 1.1548434458887888\n",
      "Epoch: 28 Step: 301 Loss: 1.249645428957288\n",
      "Epoch: 28 Step: 311 Loss: 1.2514544600574746\n",
      "Epoch: 28 Step: 321 Loss: 1.1723209971897712\n",
      "Epoch: 28 Step: 331 Loss: 1.0845217511638559\n",
      "Epoch: 28 Step: 341 Loss: 1.3464067631204837\n",
      "Epoch: 28 Step: 351 Loss: 1.2585054722271032\n",
      "Epoch: 28 Step: 361 Loss: 0.99780549357113\n",
      "Epoch: 28 Step: 371 Loss: 0.8071835624860199\n",
      "Epoch: 28 Step: 381 Loss: 1.326603801802594\n",
      "Epoch: 28 Step: 391 Loss: 0.8943899673700393\n",
      "Epoch: 28 Step: 401 Loss: 1.0429432799803278\n",
      "Epoch: 28 Step: 411 Loss: 1.2466485374573009\n",
      "Epoch: 28 Step: 421 Loss: 1.2711212951319535\n",
      "Epoch: 28 Step: 431 Loss: 1.075319206512029\n",
      "Epoch: 28 Step: 441 Loss: 0.9969436288090328\n",
      "Epoch: 28 Step: 451 Loss: 0.9974565454180981\n",
      "Epoch: 28 Step: 461 Loss: 1.1813423201229618\n",
      "Epoch: 28 Step: 471 Loss: 1.268734057463948\n",
      "Epoch: 28 Step: 481 Loss: 1.3203189918188922\n",
      "Epoch: 28 Step: 491 Loss: 1.5903266332460124\n",
      "Epoch: 28 Step: 501 Loss: 1.2969797135287298\n",
      "Epoch: 28 Step: 511 Loss: 1.0131945535450066\n",
      "Epoch: 28 Step: 521 Loss: 1.2176676527030161\n",
      "Epoch: 28 Step: 531 Loss: 1.0872746211408684\n",
      "Epoch: 28 Step: 541 Loss: 1.1049195844629633\n",
      "Epoch: 28 Step: 551 Loss: 0.9853786957904924\n",
      "Epoch: 28 Step: 561 Loss: 1.015046649629595\n",
      "Epoch: 28 Step: 571 Loss: 1.0917717640938955\n",
      "Epoch: 28 Step: 581 Loss: 1.17171290564386\n",
      "Epoch: 28 Step: 591 Loss: 1.111460174505281\n",
      "Epoch: 28 Step: 601 Loss: 1.2548324634640962\n",
      "Epoch: 28 Step: 611 Loss: 1.0538158914165607\n",
      "Epoch: 28 Step: 621 Loss: 0.9496219599144087\n",
      "Epoch: 28 Step: 631 Loss: 1.2371865603109362\n",
      "Epoch: 28 Step: 641 Loss: 1.3447011747164348\n",
      "Epoch: 28 Step: 651 Loss: 1.116089712462088\n",
      "Epoch: 28 Step: 661 Loss: 1.0277556252344677\n",
      "Epoch: 28 Step: 671 Loss: 1.0613062430151208\n",
      "Epoch: 28 Step: 681 Loss: 1.2242175010287828\n",
      "Epoch: 28 Step: 691 Loss: 1.2165145435603149\n",
      "Epoch: 28 Step: 701 Loss: 1.1761370178303332\n",
      "Epoch: 28 Step: 711 Loss: 1.0927191262143996\n",
      "Epoch: 28 Step: 721 Loss: 1.0202075716876355\n",
      "Epoch: 28 Step: 731 Loss: 0.8185093295086141\n",
      "Epoch: 28 Step: 741 Loss: 1.2844660191363118\n",
      "Epoch: 28 Step: 751 Loss: 1.3189580837020256\n",
      "Epoch: 28 Step: 761 Loss: 0.921954838933275\n",
      "Epoch: 28 Step: 771 Loss: 1.0525992587432933\n",
      "Epoch: 28 Step: 781 Loss: 1.1542009294514946\n",
      "Epoch: 29 Step: 1 Loss: 1.0455833799298646\n",
      "Epoch: 29 Step: 11 Loss: 1.1207622564579287\n",
      "Epoch: 29 Step: 21 Loss: 1.1888569311532353\n",
      "Epoch: 29 Step: 31 Loss: 1.3521754682875504\n",
      "Epoch: 29 Step: 41 Loss: 0.8989818145587372\n",
      "Epoch: 29 Step: 51 Loss: 1.0449127327209828\n",
      "Epoch: 29 Step: 61 Loss: 1.07669291946367\n",
      "Epoch: 29 Step: 71 Loss: 1.1799016432912057\n",
      "Epoch: 29 Step: 81 Loss: 1.288622654633179\n",
      "Epoch: 29 Step: 91 Loss: 1.196628684807631\n",
      "Epoch: 29 Step: 101 Loss: 1.0475604861883725\n",
      "Epoch: 29 Step: 111 Loss: 1.1403723679126783\n",
      "Epoch: 29 Step: 121 Loss: 1.3887705673449453\n",
      "Epoch: 29 Step: 131 Loss: 1.0753930817763928\n",
      "Epoch: 29 Step: 141 Loss: 1.4153939328529603\n",
      "Epoch: 29 Step: 151 Loss: 0.8820413531883287\n",
      "Epoch: 29 Step: 161 Loss: 1.2261863364216592\n",
      "Epoch: 29 Step: 171 Loss: 0.9930966350675876\n",
      "Epoch: 29 Step: 181 Loss: 1.0167772075248844\n",
      "Epoch: 29 Step: 191 Loss: 1.2289614874273294\n",
      "Epoch: 29 Step: 201 Loss: 0.9194438557756752\n",
      "Epoch: 29 Step: 211 Loss: 1.066760959234463\n",
      "Epoch: 29 Step: 221 Loss: 1.1980172187482512\n",
      "Epoch: 29 Step: 231 Loss: 1.1829716874182454\n",
      "Epoch: 29 Step: 241 Loss: 0.9697154081682544\n",
      "Epoch: 29 Step: 251 Loss: 1.0948561460041115\n",
      "Epoch: 29 Step: 261 Loss: 1.2034239792553914\n",
      "Epoch: 29 Step: 271 Loss: 1.154923770045325\n",
      "Epoch: 29 Step: 281 Loss: 1.1504821725160712\n",
      "Epoch: 29 Step: 291 Loss: 1.221510862719738\n",
      "Epoch: 29 Step: 301 Loss: 1.2516505182871973\n",
      "Epoch: 29 Step: 311 Loss: 1.3739022925014477\n",
      "Epoch: 29 Step: 321 Loss: 1.3388454675565487\n",
      "Epoch: 29 Step: 331 Loss: 1.2581374835260364\n",
      "Epoch: 29 Step: 341 Loss: 1.2405734831405533\n",
      "Epoch: 29 Step: 351 Loss: 1.207940881843827\n",
      "Epoch: 29 Step: 361 Loss: 1.0512176669580704\n",
      "Epoch: 29 Step: 371 Loss: 0.855465008287199\n",
      "Epoch: 29 Step: 381 Loss: 1.319645790089101\n",
      "Epoch: 29 Step: 391 Loss: 0.9665837424086496\n",
      "Epoch: 29 Step: 401 Loss: 1.1783231451231087\n",
      "Epoch: 29 Step: 411 Loss: 1.1664550941344014\n",
      "Epoch: 29 Step: 421 Loss: 1.3916990918448775\n",
      "Epoch: 29 Step: 431 Loss: 1.0882681210421015\n",
      "Epoch: 29 Step: 441 Loss: 1.3621421446179167\n",
      "Epoch: 29 Step: 451 Loss: 1.213003701278462\n",
      "Epoch: 29 Step: 461 Loss: 1.1455492498116153\n",
      "Epoch: 29 Step: 471 Loss: 1.1405451678937855\n",
      "Epoch: 29 Step: 481 Loss: 1.3039487766355844\n",
      "Epoch: 29 Step: 491 Loss: 1.42609019556148\n",
      "Epoch: 29 Step: 501 Loss: 1.1055788010191756\n",
      "Epoch: 29 Step: 511 Loss: 0.9460932073953154\n",
      "Epoch: 29 Step: 521 Loss: 1.272571218854896\n",
      "Epoch: 29 Step: 531 Loss: 1.0843872847816118\n",
      "Epoch: 29 Step: 541 Loss: 1.0295353401110885\n",
      "Epoch: 29 Step: 551 Loss: 0.9958327555291993\n",
      "Epoch: 29 Step: 561 Loss: 1.136147192945262\n",
      "Epoch: 29 Step: 571 Loss: 1.2267051239422018\n",
      "Epoch: 29 Step: 581 Loss: 1.0525907953075666\n",
      "Epoch: 29 Step: 591 Loss: 1.1468823754927544\n",
      "Epoch: 29 Step: 601 Loss: 1.201187146059373\n",
      "Epoch: 29 Step: 611 Loss: 1.0945948587459353\n",
      "Epoch: 29 Step: 621 Loss: 1.1956207034612734\n",
      "Epoch: 29 Step: 631 Loss: 1.1877884808901373\n",
      "Epoch: 29 Step: 641 Loss: 1.2630533923494096\n",
      "Epoch: 29 Step: 651 Loss: 1.0417466679952412\n",
      "Epoch: 29 Step: 661 Loss: 0.9707126196247953\n",
      "Epoch: 29 Step: 671 Loss: 1.190028556655186\n",
      "Epoch: 29 Step: 681 Loss: 1.3914015985032833\n",
      "Epoch: 29 Step: 691 Loss: 1.1979093930301539\n",
      "Epoch: 29 Step: 701 Loss: 1.1652093509236907\n",
      "Epoch: 29 Step: 711 Loss: 1.0776325986149882\n",
      "Epoch: 29 Step: 721 Loss: 0.9873245133582705\n",
      "Epoch: 29 Step: 731 Loss: 0.893256123805362\n",
      "Epoch: 29 Step: 741 Loss: 1.3873634767306986\n",
      "Epoch: 29 Step: 751 Loss: 1.518087260778807\n",
      "Epoch: 29 Step: 761 Loss: 0.9783298143218639\n",
      "Epoch: 29 Step: 771 Loss: 1.379794051448613\n",
      "Epoch: 29 Step: 781 Loss: 1.1901534647455947\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/oneran/机01器学习课设/cifar-10/Photon/sgd_cifar_DenseNet.pkl'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2135/2325190066.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/oneran/Downloads/sgd_cifar_DenseNet_history.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/oneran/机01器学习课设/cifar-10/Photon/sgd_cifar_DenseNet.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/机器学习课设/cifar-10/Photon/DenseNet.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(self, save_path)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mjson_formated_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_formated_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/oneran/机01器学习课设/cifar-10/Photon/sgd_cifar_DenseNet.pkl'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "np.savetxt('/home/oneran/Downloads/sgd_cifar_DenseNet_history.txt', model.history)\n",
    "model.save_model('/home/oneran/机器学习课设/cifar-10/Photon/sgd_cifar_DenseNet.pkl')\n",
    "score, pred = model.score(X_train, Y_train)\n",
    "score, pred = model.score(X_test, Y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score is 0.5875680217669654\n",
      "Score is 0.488681891025641\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 用RMSprop跑跑看"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "model = ResNet(datasets='cifar_10', opt='rmsprop')\n",
    "model.datas = [data, label]\n",
    "model.train(30)\n",
    "plt.plot(np.arange(len(model.history)), model.history)\n",
    "plt.show()\n",
    "np.savetxt('/home/oneran/Downloads/rmsprop_cifar_ResNet_history.txt', model.history)\n",
    "model.save_model('/home/oneran/机器学习课设/cifar-10/Photon/rmsprop_cifar_ResNet.pkl')\n",
    "score, pred = model.score(X_train, Y_train)\n",
    "score, pred = model.score(X_test, Y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 0 Step: 1 Loss: 2.3020723067279136\n",
      "Epoch: 0 Step: 11 Loss: 2.3326882140497016\n",
      "Epoch: 0 Step: 21 Loss: 2.349317606022593\n",
      "Epoch: 0 Step: 31 Loss: 2.2980925004265984\n",
      "Epoch: 0 Step: 41 Loss: 2.1110592762084135\n",
      "Epoch: 0 Step: 51 Loss: 2.1740229780339124\n",
      "Epoch: 0 Step: 61 Loss: 2.1480222713858064\n",
      "Epoch: 0 Step: 71 Loss: 2.054963279548372\n",
      "Epoch: 0 Step: 81 Loss: 2.1134797488185915\n",
      "Epoch: 0 Step: 91 Loss: 1.99990673924755\n",
      "Epoch: 0 Step: 101 Loss: 1.975162010230237\n",
      "Epoch: 0 Step: 111 Loss: 1.8456292330555466\n",
      "Epoch: 0 Step: 121 Loss: 1.8277156216371915\n",
      "Epoch: 0 Step: 131 Loss: 2.177903304028172\n",
      "Epoch: 0 Step: 141 Loss: 2.398981965178815\n",
      "Epoch: 0 Step: 151 Loss: 1.782457342375361\n",
      "Epoch: 0 Step: 161 Loss: 1.966299188996214\n",
      "Epoch: 0 Step: 171 Loss: 1.9809524528171274\n",
      "Epoch: 0 Step: 181 Loss: 1.803694062595353\n",
      "Epoch: 0 Step: 191 Loss: 1.8369279972234875\n",
      "Epoch: 0 Step: 201 Loss: 1.910824635861491\n",
      "Epoch: 0 Step: 211 Loss: 2.020558754679972\n",
      "Epoch: 0 Step: 221 Loss: 1.9974675870998637\n",
      "Epoch: 0 Step: 231 Loss: 1.9091996371469486\n",
      "Epoch: 0 Step: 241 Loss: 2.0700883929053573\n",
      "Epoch: 0 Step: 251 Loss: 1.8300954391884068\n",
      "Epoch: 0 Step: 261 Loss: 1.949587425144165\n",
      "Epoch: 0 Step: 271 Loss: 1.823682896129504\n",
      "Epoch: 0 Step: 281 Loss: 1.903766453275926\n",
      "Epoch: 0 Step: 291 Loss: 1.8592841811302812\n",
      "Epoch: 0 Step: 301 Loss: 1.7411393501467003\n",
      "Epoch: 0 Step: 311 Loss: 1.830917185090816\n",
      "Epoch: 0 Step: 321 Loss: 1.8231664646043395\n",
      "Epoch: 0 Step: 331 Loss: 1.5876016755077198\n",
      "Epoch: 0 Step: 341 Loss: 1.8048237870307386\n",
      "Epoch: 0 Step: 351 Loss: 1.6835035713028956\n",
      "Epoch: 0 Step: 361 Loss: 1.715634002349494\n",
      "Epoch: 0 Step: 371 Loss: 1.6237734292337187\n",
      "Epoch: 0 Step: 381 Loss: 1.8350891619828824\n",
      "Epoch: 0 Step: 391 Loss: 1.877452976283854\n",
      "Epoch: 0 Step: 401 Loss: 1.890188456411178\n",
      "Epoch: 0 Step: 411 Loss: 2.0099106047813966\n",
      "Epoch: 0 Step: 421 Loss: 1.8817460833915425\n",
      "Epoch: 0 Step: 431 Loss: 1.778287257552639\n",
      "Epoch: 0 Step: 441 Loss: 1.8166039696473666\n",
      "Epoch: 0 Step: 451 Loss: 1.499961772127547\n",
      "Epoch: 0 Step: 461 Loss: 1.7074524749282092\n",
      "Epoch: 0 Step: 471 Loss: 1.6405751551027152\n",
      "Epoch: 0 Step: 481 Loss: 1.7164685162993807\n",
      "Epoch: 0 Step: 491 Loss: 1.9379781074244504\n",
      "Epoch: 0 Step: 501 Loss: 1.6754043759559887\n",
      "Epoch: 0 Step: 511 Loss: 1.7801893445947334\n",
      "Epoch: 0 Step: 521 Loss: 1.6529951625131374\n",
      "Epoch: 0 Step: 531 Loss: 1.662924580779587\n",
      "Epoch: 0 Step: 541 Loss: 1.5873149753055977\n",
      "Epoch: 0 Step: 551 Loss: 1.5451042173270282\n",
      "Epoch: 0 Step: 561 Loss: 1.6956291649867463\n",
      "Epoch: 0 Step: 571 Loss: 1.6182903132453044\n",
      "Epoch: 0 Step: 581 Loss: 1.7926834096154278\n",
      "Epoch: 0 Step: 591 Loss: 1.7744184342815195\n",
      "Epoch: 0 Step: 601 Loss: 1.6902271360599912\n",
      "Epoch: 0 Step: 611 Loss: 1.660507769189433\n",
      "Epoch: 0 Step: 621 Loss: 1.6313371113840698\n",
      "Epoch: 0 Step: 631 Loss: 1.7439455906043282\n",
      "Epoch: 0 Step: 641 Loss: 1.7619425244821858\n",
      "Epoch: 0 Step: 651 Loss: 1.6384866736870316\n",
      "Epoch: 0 Step: 661 Loss: 1.5414622194894747\n",
      "Epoch: 0 Step: 671 Loss: 1.6398644612098165\n",
      "Epoch: 0 Step: 681 Loss: 1.8720535867119195\n",
      "Epoch: 0 Step: 691 Loss: 1.6646550731535097\n",
      "Epoch: 0 Step: 701 Loss: 1.526328900189843\n",
      "Epoch: 0 Step: 711 Loss: 1.5389650637781211\n",
      "Epoch: 0 Step: 721 Loss: 1.412306789583916\n",
      "Epoch: 0 Step: 731 Loss: 1.1791546001620292\n",
      "Epoch: 0 Step: 741 Loss: 1.813539843027579\n",
      "Epoch: 0 Step: 751 Loss: 1.9569735492403915\n",
      "Epoch: 0 Step: 761 Loss: 1.489357219772642\n",
      "Epoch: 0 Step: 771 Loss: 1.7241520947855173\n",
      "Epoch: 0 Step: 781 Loss: 1.4705871396534533\n",
      "Epoch: 1 Step: 1 Loss: 1.7347924964704753\n",
      "Epoch: 1 Step: 11 Loss: 1.9148884625304872\n",
      "Epoch: 1 Step: 21 Loss: 1.8903550875918298\n",
      "Epoch: 1 Step: 31 Loss: 1.80222150483816\n",
      "Epoch: 1 Step: 41 Loss: 1.5216910530681176\n",
      "Epoch: 1 Step: 51 Loss: 1.4418107753149658\n",
      "Epoch: 1 Step: 61 Loss: 1.564285217854978\n",
      "Epoch: 1 Step: 71 Loss: 1.7568046734108713\n",
      "Epoch: 1 Step: 81 Loss: 1.6541592293285077\n",
      "Epoch: 1 Step: 91 Loss: 1.5574426214531174\n",
      "Epoch: 1 Step: 101 Loss: 1.5298885884232283\n",
      "Epoch: 1 Step: 111 Loss: 1.5023882925217475\n",
      "Epoch: 1 Step: 121 Loss: 1.652527915939701\n",
      "Epoch: 1 Step: 131 Loss: 1.6290852531001057\n",
      "Epoch: 1 Step: 141 Loss: 1.8801114123802263\n",
      "Epoch: 1 Step: 151 Loss: 1.6479503367720865\n",
      "Epoch: 1 Step: 161 Loss: 1.690921982450961\n",
      "Epoch: 1 Step: 171 Loss: 1.757551182503376\n",
      "Epoch: 1 Step: 181 Loss: 1.7210589719197749\n",
      "Epoch: 1 Step: 191 Loss: 1.4533423616328527\n",
      "Epoch: 1 Step: 201 Loss: 1.362101680493228\n",
      "Epoch: 1 Step: 211 Loss: 1.460748226762807\n",
      "Epoch: 1 Step: 221 Loss: 1.7026896112702916\n",
      "Epoch: 1 Step: 231 Loss: 1.4902386811409545\n",
      "Epoch: 1 Step: 241 Loss: 1.7238215867855549\n",
      "Epoch: 1 Step: 251 Loss: 1.5496734713155704\n",
      "Epoch: 1 Step: 261 Loss: 1.3960280301007923\n",
      "Epoch: 1 Step: 271 Loss: 1.5593153707294123\n",
      "Epoch: 1 Step: 281 Loss: 1.7030905450813747\n",
      "Epoch: 1 Step: 291 Loss: 1.4379966278858172\n",
      "Epoch: 1 Step: 301 Loss: 1.644068268932159\n",
      "Epoch: 1 Step: 311 Loss: 1.3958001374545022\n",
      "Epoch: 1 Step: 321 Loss: 1.7811071146958652\n",
      "Epoch: 1 Step: 331 Loss: 1.5158607223991394\n",
      "Epoch: 1 Step: 341 Loss: 1.6495951535795266\n",
      "Epoch: 1 Step: 351 Loss: 1.656896920996862\n",
      "Epoch: 1 Step: 361 Loss: 1.4529691630004926\n",
      "Epoch: 1 Step: 371 Loss: 1.282976958162865\n",
      "Epoch: 1 Step: 381 Loss: 1.476174691015867\n",
      "Epoch: 1 Step: 391 Loss: 1.4549307273844372\n",
      "Epoch: 1 Step: 401 Loss: 1.574888114520311\n",
      "Epoch: 1 Step: 411 Loss: 1.7401375321332644\n",
      "Epoch: 1 Step: 421 Loss: 1.58113970837662\n",
      "Epoch: 1 Step: 431 Loss: 1.5920736803451367\n",
      "Epoch: 1 Step: 441 Loss: 1.6134498447116878\n",
      "Epoch: 1 Step: 451 Loss: 1.259100265923178\n",
      "Epoch: 1 Step: 461 Loss: 1.4708127925289376\n",
      "Epoch: 1 Step: 471 Loss: 1.4795602269628376\n",
      "Epoch: 1 Step: 481 Loss: 1.4373151259647612\n",
      "Epoch: 1 Step: 491 Loss: 1.6363414985120162\n",
      "Epoch: 1 Step: 501 Loss: 1.4899467345406103\n",
      "Epoch: 1 Step: 511 Loss: 1.7043163300092097\n",
      "Epoch: 1 Step: 521 Loss: 1.5488065892500709\n",
      "Epoch: 1 Step: 531 Loss: 1.4688605275179536\n",
      "Epoch: 1 Step: 541 Loss: 1.5493162746750913\n",
      "Epoch: 1 Step: 551 Loss: 1.4237670547329913\n",
      "Epoch: 1 Step: 561 Loss: 1.482087259569492\n",
      "Epoch: 1 Step: 571 Loss: 1.329828031323755\n",
      "Epoch: 1 Step: 581 Loss: 1.568106134556241\n",
      "Epoch: 1 Step: 591 Loss: 1.679732248765025\n",
      "Epoch: 1 Step: 601 Loss: 1.4557851968913418\n",
      "Epoch: 1 Step: 611 Loss: 1.5526182276137777\n",
      "Epoch: 1 Step: 621 Loss: 1.412407401093873\n",
      "Epoch: 1 Step: 631 Loss: 1.4653688404386425\n",
      "Epoch: 1 Step: 641 Loss: 1.5851186320422608\n",
      "Epoch: 1 Step: 651 Loss: 1.3643236828279899\n",
      "Epoch: 1 Step: 661 Loss: 1.1779221237249304\n",
      "Epoch: 1 Step: 671 Loss: 1.4694470827780868\n",
      "Epoch: 1 Step: 681 Loss: 1.5606049461312053\n",
      "Epoch: 1 Step: 691 Loss: 1.6882600670900239\n",
      "Epoch: 1 Step: 701 Loss: 1.4518854023390118\n",
      "Epoch: 1 Step: 711 Loss: 1.5748949200471365\n",
      "Epoch: 1 Step: 721 Loss: 1.3959013255806534\n",
      "Epoch: 1 Step: 731 Loss: 1.1738936795672161\n",
      "Epoch: 1 Step: 741 Loss: 1.540161121352721\n",
      "Epoch: 1 Step: 751 Loss: 1.786616853300667\n",
      "Epoch: 1 Step: 761 Loss: 1.3500544794298546\n",
      "Epoch: 1 Step: 771 Loss: 1.7333327767064381\n",
      "Epoch: 1 Step: 781 Loss: 1.344994355062223\n",
      "Epoch: 2 Step: 1 Loss: 1.4838730468128738\n",
      "Epoch: 2 Step: 11 Loss: 1.7201822828418198\n",
      "Epoch: 2 Step: 21 Loss: 1.6860917135853861\n",
      "Epoch: 2 Step: 31 Loss: 1.6115598190939258\n",
      "Epoch: 2 Step: 41 Loss: 1.3339998710985839\n",
      "Epoch: 2 Step: 51 Loss: 1.2538149157457061\n",
      "Epoch: 2 Step: 61 Loss: 1.2938883926306324\n",
      "Epoch: 2 Step: 71 Loss: 1.664157202810107\n",
      "Epoch: 2 Step: 81 Loss: 1.470498035581061\n",
      "Epoch: 2 Step: 91 Loss: 1.4355415063266015\n",
      "Epoch: 2 Step: 101 Loss: 1.397729507692228\n",
      "Epoch: 2 Step: 111 Loss: 1.5632120537278542\n",
      "Epoch: 2 Step: 121 Loss: 1.544560172986058\n",
      "Epoch: 2 Step: 131 Loss: 1.4560148261127777\n",
      "Epoch: 2 Step: 141 Loss: 1.8905803126742002\n",
      "Epoch: 2 Step: 151 Loss: 1.4278865777063459\n",
      "Epoch: 2 Step: 161 Loss: 1.6515962785859846\n",
      "Epoch: 2 Step: 171 Loss: 1.6150412631624866\n",
      "Epoch: 2 Step: 181 Loss: 1.4872351554783414\n",
      "Epoch: 2 Step: 191 Loss: 1.3410667980687179\n",
      "Epoch: 2 Step: 201 Loss: 1.1640728696148614\n",
      "Epoch: 2 Step: 211 Loss: 1.1124684627392276\n",
      "Epoch: 2 Step: 221 Loss: 1.4311086063700564\n",
      "Epoch: 2 Step: 231 Loss: 1.3519692604047018\n",
      "Epoch: 2 Step: 241 Loss: 1.531151020957434\n",
      "Epoch: 2 Step: 251 Loss: 1.3310277383188964\n",
      "Epoch: 2 Step: 261 Loss: 1.2840535750268598\n",
      "Epoch: 2 Step: 271 Loss: 1.5963467719043418\n",
      "Epoch: 2 Step: 281 Loss: 1.707611623285938\n",
      "Epoch: 2 Step: 291 Loss: 1.6087849175917048\n",
      "Epoch: 2 Step: 301 Loss: 1.584502357143076\n",
      "Epoch: 2 Step: 311 Loss: 1.4345983293149684\n",
      "Epoch: 2 Step: 321 Loss: 1.4130826348132253\n",
      "Epoch: 2 Step: 331 Loss: 1.344316760740722\n",
      "Epoch: 2 Step: 341 Loss: 1.3784268803597541\n",
      "Epoch: 2 Step: 351 Loss: 1.3980312840677493\n",
      "Epoch: 2 Step: 361 Loss: 1.4216109233398533\n",
      "Epoch: 2 Step: 371 Loss: 1.0451516535031757\n",
      "Epoch: 2 Step: 381 Loss: 1.2811254501652813\n",
      "Epoch: 2 Step: 391 Loss: 1.1824330467132125\n",
      "Epoch: 2 Step: 401 Loss: 1.333527406071819\n",
      "Epoch: 2 Step: 411 Loss: 1.5131892499864774\n",
      "Epoch: 2 Step: 421 Loss: 1.4280379414889877\n",
      "Epoch: 2 Step: 431 Loss: 1.314217575095162\n",
      "Epoch: 2 Step: 441 Loss: 1.4525504605866817\n",
      "Epoch: 2 Step: 451 Loss: 1.2484044413353783\n",
      "Epoch: 2 Step: 461 Loss: 1.631813247682219\n",
      "Epoch: 2 Step: 471 Loss: 1.5554151213848773\n",
      "Epoch: 2 Step: 481 Loss: 1.4807705739815675\n",
      "Epoch: 2 Step: 491 Loss: 1.7513907729777176\n",
      "Epoch: 2 Step: 501 Loss: 1.4389131394166996\n",
      "Epoch: 2 Step: 511 Loss: 1.404810301159777\n",
      "Epoch: 2 Step: 521 Loss: 1.3796470299064911\n",
      "Epoch: 2 Step: 531 Loss: 1.4144653300311802\n",
      "Epoch: 2 Step: 541 Loss: 1.272056000520179\n",
      "Epoch: 2 Step: 551 Loss: 1.1898586228646\n",
      "Epoch: 2 Step: 561 Loss: 1.2026900480018263\n",
      "Epoch: 2 Step: 571 Loss: 1.202982675028216\n",
      "Epoch: 2 Step: 581 Loss: 1.3832469617733851\n",
      "Epoch: 2 Step: 591 Loss: 1.5276662024998076\n",
      "Epoch: 2 Step: 601 Loss: 1.2722320399688942\n",
      "Epoch: 2 Step: 611 Loss: 1.325011511265061\n",
      "Epoch: 2 Step: 621 Loss: 1.3383725730296663\n",
      "Epoch: 2 Step: 631 Loss: 1.3820313072410577\n",
      "Epoch: 2 Step: 641 Loss: 1.670291004329197\n",
      "Epoch: 2 Step: 651 Loss: 1.197722566302683\n",
      "Epoch: 2 Step: 661 Loss: 1.1386963563677732\n",
      "Epoch: 2 Step: 671 Loss: 1.5920480265033168\n",
      "Epoch: 2 Step: 681 Loss: 1.539524283190787\n",
      "Epoch: 2 Step: 691 Loss: 1.5171450839114131\n",
      "Epoch: 2 Step: 701 Loss: 1.3541800721675652\n",
      "Epoch: 2 Step: 711 Loss: 1.4401628440316665\n",
      "Epoch: 2 Step: 721 Loss: 1.1991269914375786\n",
      "Epoch: 2 Step: 731 Loss: 1.1110400733947883\n",
      "Epoch: 2 Step: 741 Loss: 1.2871286537179922\n",
      "Epoch: 2 Step: 751 Loss: 1.5039405593553647\n",
      "Epoch: 2 Step: 761 Loss: 1.2145209306538816\n",
      "Epoch: 2 Step: 771 Loss: 1.4862577277598028\n",
      "Epoch: 2 Step: 781 Loss: 1.3326722630106405\n",
      "Epoch: 3 Step: 1 Loss: 1.3572484602528634\n",
      "Epoch: 3 Step: 11 Loss: 1.551435739293444\n",
      "Epoch: 3 Step: 21 Loss: 1.5965754242943242\n",
      "Epoch: 3 Step: 31 Loss: 1.5851160397190345\n",
      "Epoch: 3 Step: 41 Loss: 1.3281526948907296\n",
      "Epoch: 3 Step: 51 Loss: 1.091796916016968\n",
      "Epoch: 3 Step: 61 Loss: 1.3630999855834764\n",
      "Epoch: 3 Step: 71 Loss: 1.763856138932537\n",
      "Epoch: 3 Step: 81 Loss: 1.3807450851738523\n",
      "Epoch: 3 Step: 91 Loss: 1.4544870195367117\n",
      "Epoch: 3 Step: 101 Loss: 1.2798623170307775\n",
      "Epoch: 3 Step: 111 Loss: 1.5148150080702885\n",
      "Epoch: 3 Step: 121 Loss: 1.5014198728913157\n",
      "Epoch: 3 Step: 131 Loss: 1.317752583176209\n",
      "Epoch: 3 Step: 141 Loss: 1.6062822017715488\n",
      "Epoch: 3 Step: 151 Loss: 1.280586505998753\n",
      "Epoch: 3 Step: 161 Loss: 1.3777898732853298\n",
      "Epoch: 3 Step: 171 Loss: 1.543723884676313\n",
      "Epoch: 3 Step: 181 Loss: 1.1421722848328053\n",
      "Epoch: 3 Step: 191 Loss: 1.2791867966241837\n",
      "Epoch: 3 Step: 201 Loss: 0.9685323889900848\n",
      "Epoch: 3 Step: 211 Loss: 1.0041521166266403\n",
      "Epoch: 3 Step: 221 Loss: 1.3182002914403799\n",
      "Epoch: 3 Step: 231 Loss: 1.2766849864835996\n",
      "Epoch: 3 Step: 241 Loss: 1.4327176368529981\n",
      "Epoch: 3 Step: 251 Loss: 1.285560206110758\n",
      "Epoch: 3 Step: 261 Loss: 1.366277186351982\n",
      "Epoch: 3 Step: 271 Loss: 1.4291667257120269\n",
      "Epoch: 3 Step: 281 Loss: 1.4372985695808849\n",
      "Epoch: 3 Step: 291 Loss: 1.361382401753012\n",
      "Epoch: 3 Step: 301 Loss: 1.4062990155632926\n",
      "Epoch: 3 Step: 311 Loss: 1.283055637520255\n",
      "Epoch: 3 Step: 321 Loss: 1.2976224907390346\n",
      "Epoch: 3 Step: 331 Loss: 1.2994169591823614\n",
      "Epoch: 3 Step: 341 Loss: 1.282799221748848\n",
      "Epoch: 3 Step: 351 Loss: 1.3457955463651066\n",
      "Epoch: 3 Step: 361 Loss: 1.3044878454151942\n",
      "Epoch: 3 Step: 371 Loss: 0.9750747999740655\n",
      "Epoch: 3 Step: 381 Loss: 1.2698551304985173\n",
      "Epoch: 3 Step: 391 Loss: 1.0253292332748793\n",
      "Epoch: 3 Step: 401 Loss: 1.259658632219789\n",
      "Epoch: 3 Step: 411 Loss: 1.4994268034727791\n",
      "Epoch: 3 Step: 421 Loss: 1.4716052852602677\n",
      "Epoch: 3 Step: 431 Loss: 1.3331797581662297\n",
      "Epoch: 3 Step: 441 Loss: 1.4605139465681987\n",
      "Epoch: 3 Step: 451 Loss: 1.2495567363179854\n",
      "Epoch: 3 Step: 461 Loss: 1.377786241405763\n",
      "Epoch: 3 Step: 471 Loss: 1.3747176541663182\n",
      "Epoch: 3 Step: 481 Loss: 1.3091593382158313\n",
      "Epoch: 3 Step: 491 Loss: 1.3659036197437855\n",
      "Epoch: 3 Step: 501 Loss: 1.2821813911164401\n",
      "Epoch: 3 Step: 511 Loss: 1.2747947040608172\n",
      "Epoch: 3 Step: 521 Loss: 1.2358146629811635\n",
      "Epoch: 3 Step: 531 Loss: 1.2022967747415867\n",
      "Epoch: 3 Step: 541 Loss: 1.1600275330072205\n",
      "Epoch: 3 Step: 551 Loss: 1.0394031688900291\n",
      "Epoch: 3 Step: 561 Loss: 1.0337264277190186\n",
      "Epoch: 3 Step: 571 Loss: 1.0639880295435098\n",
      "Epoch: 3 Step: 581 Loss: 1.4340751051965277\n",
      "Epoch: 3 Step: 591 Loss: 1.4908245592085618\n",
      "Epoch: 3 Step: 601 Loss: 1.3708652907470738\n",
      "Epoch: 3 Step: 611 Loss: 1.285251673728498\n",
      "Epoch: 3 Step: 621 Loss: 1.24650655928691\n",
      "Epoch: 3 Step: 631 Loss: 1.4783608976476517\n",
      "Epoch: 3 Step: 641 Loss: 1.5572317081037341\n",
      "Epoch: 3 Step: 651 Loss: 1.1003136435812406\n",
      "Epoch: 3 Step: 661 Loss: 1.0401742861051195\n",
      "Epoch: 3 Step: 671 Loss: 1.4823435714162234\n",
      "Epoch: 3 Step: 681 Loss: 1.3981684276517194\n",
      "Epoch: 3 Step: 691 Loss: 1.423983260189872\n",
      "Epoch: 3 Step: 701 Loss: 1.2792896076917224\n",
      "Epoch: 3 Step: 711 Loss: 1.3478477242408167\n",
      "Epoch: 3 Step: 721 Loss: 1.096432977235825\n",
      "Epoch: 3 Step: 731 Loss: 1.0158673031194674\n",
      "Epoch: 3 Step: 741 Loss: 1.3126496029452484\n",
      "Epoch: 3 Step: 751 Loss: 1.4165578343026626\n",
      "Epoch: 3 Step: 761 Loss: 1.080071634369345\n",
      "Epoch: 3 Step: 771 Loss: 1.5485616618458429\n",
      "Epoch: 3 Step: 781 Loss: 1.285235123275952\n",
      "Epoch: 4 Step: 1 Loss: 1.432552355753168\n",
      "Epoch: 4 Step: 11 Loss: 1.4873487789151696\n",
      "Epoch: 4 Step: 21 Loss: 1.5650857214812715\n",
      "Epoch: 4 Step: 31 Loss: 1.588981647708901\n",
      "Epoch: 4 Step: 41 Loss: 1.0952320877462505\n",
      "Epoch: 4 Step: 51 Loss: 1.0297159047869247\n",
      "Epoch: 4 Step: 61 Loss: 1.1750238573154808\n",
      "Epoch: 4 Step: 71 Loss: 1.7550050027673936\n",
      "Epoch: 4 Step: 81 Loss: 1.2686525174307515\n",
      "Epoch: 4 Step: 91 Loss: 1.3399135220904816\n",
      "Epoch: 4 Step: 101 Loss: 1.1377416562691829\n",
      "Epoch: 4 Step: 111 Loss: 1.33178697948782\n",
      "Epoch: 4 Step: 121 Loss: 1.350671551755536\n",
      "Epoch: 4 Step: 131 Loss: 1.219876986348086\n",
      "Epoch: 4 Step: 141 Loss: 1.512464004681434\n",
      "Epoch: 4 Step: 151 Loss: 1.1161981060639827\n",
      "Epoch: 4 Step: 161 Loss: 1.1142825798480889\n",
      "Epoch: 4 Step: 171 Loss: 1.7104160528381598\n",
      "Epoch: 4 Step: 181 Loss: 1.2638705015068956\n",
      "Epoch: 4 Step: 191 Loss: 1.2808101859823184\n",
      "Epoch: 4 Step: 201 Loss: 1.1074851186446302\n",
      "Epoch: 4 Step: 211 Loss: 1.0499450317038623\n",
      "Epoch: 4 Step: 221 Loss: 1.1764435408787937\n",
      "Epoch: 4 Step: 231 Loss: 1.2128473335950944\n",
      "Epoch: 4 Step: 241 Loss: 1.33409802029222\n",
      "Epoch: 4 Step: 251 Loss: 1.2260502642589939\n",
      "Epoch: 4 Step: 261 Loss: 1.1631698305871447\n",
      "Epoch: 4 Step: 271 Loss: 1.190273944661229\n",
      "Epoch: 4 Step: 281 Loss: 1.1854973231309398\n",
      "Epoch: 4 Step: 291 Loss: 1.225573642605492\n",
      "Epoch: 4 Step: 301 Loss: 1.255407614993901\n",
      "Epoch: 4 Step: 311 Loss: 1.1373352840444675\n",
      "Epoch: 4 Step: 321 Loss: 1.285908061049165\n",
      "Epoch: 4 Step: 331 Loss: 1.1089954729040394\n",
      "Epoch: 4 Step: 341 Loss: 1.2467646293864805\n",
      "Epoch: 4 Step: 351 Loss: 1.4033211073772096\n",
      "Epoch: 4 Step: 361 Loss: 1.274391249768267\n",
      "Epoch: 4 Step: 371 Loss: 0.8392737918040744\n",
      "Epoch: 4 Step: 381 Loss: 1.1909267261150929\n",
      "Epoch: 4 Step: 391 Loss: 1.1459711312564669\n",
      "Epoch: 4 Step: 401 Loss: 1.1518512240083634\n",
      "Epoch: 4 Step: 411 Loss: 1.2902273289658734\n",
      "Epoch: 4 Step: 421 Loss: 1.3886293918865888\n",
      "Epoch: 4 Step: 431 Loss: 1.1577317963376283\n",
      "Epoch: 4 Step: 441 Loss: 1.2891241144715062\n",
      "Epoch: 4 Step: 451 Loss: 1.076597400347092\n",
      "Epoch: 4 Step: 461 Loss: 1.2508020353875564\n",
      "Epoch: 4 Step: 471 Loss: 1.3049431654400037\n",
      "Epoch: 4 Step: 481 Loss: 1.348427119447751\n",
      "Epoch: 4 Step: 491 Loss: 1.2967159193889866\n",
      "Epoch: 4 Step: 501 Loss: 1.2554591478033181\n",
      "Epoch: 4 Step: 511 Loss: 1.0236801494458687\n",
      "Epoch: 4 Step: 521 Loss: 1.3442493513972225\n",
      "Epoch: 4 Step: 531 Loss: 1.1290539843457692\n",
      "Epoch: 4 Step: 541 Loss: 1.1288607367182153\n",
      "Epoch: 4 Step: 551 Loss: 1.1252970565429188\n",
      "Epoch: 4 Step: 561 Loss: 1.2508817083418442\n",
      "Epoch: 4 Step: 571 Loss: 1.0409064077231898\n",
      "Epoch: 4 Step: 581 Loss: 1.2723507670025613\n",
      "Epoch: 4 Step: 591 Loss: 1.3800460448555465\n",
      "Epoch: 4 Step: 601 Loss: 1.2769514396194168\n",
      "Epoch: 4 Step: 611 Loss: 1.0774604050081926\n",
      "Epoch: 4 Step: 621 Loss: 1.2065502724841264\n",
      "Epoch: 4 Step: 631 Loss: 1.0690412979440755\n",
      "Epoch: 4 Step: 641 Loss: 1.3369754783912446\n",
      "Epoch: 4 Step: 651 Loss: 0.989162133932561\n",
      "Epoch: 4 Step: 661 Loss: 1.011675313589584\n",
      "Epoch: 4 Step: 671 Loss: 1.371755966298098\n",
      "Epoch: 4 Step: 681 Loss: 1.5405680754753404\n",
      "Epoch: 4 Step: 691 Loss: 1.2739352925451943\n",
      "Epoch: 4 Step: 701 Loss: 1.1977837843657273\n",
      "Epoch: 4 Step: 711 Loss: 1.4080819977391108\n",
      "Epoch: 4 Step: 721 Loss: 1.1597036521595225\n",
      "Epoch: 4 Step: 731 Loss: 1.009010271715919\n",
      "Epoch: 4 Step: 741 Loss: 1.2145308654937368\n",
      "Epoch: 4 Step: 751 Loss: 1.5358308396117788\n",
      "Epoch: 4 Step: 761 Loss: 1.024964954379565\n",
      "Epoch: 4 Step: 771 Loss: 1.3033069728947217\n",
      "Epoch: 4 Step: 781 Loss: 1.2627769590905464\n",
      "Epoch: 5 Step: 1 Loss: 1.280852754720546\n",
      "Epoch: 5 Step: 11 Loss: 1.5179000734247512\n",
      "Epoch: 5 Step: 21 Loss: 1.5182881941038944\n",
      "Epoch: 5 Step: 31 Loss: 1.4115001422251066\n",
      "Epoch: 5 Step: 41 Loss: 1.0295292647986278\n",
      "Epoch: 5 Step: 51 Loss: 1.018829646152609\n",
      "Epoch: 5 Step: 61 Loss: 1.0530308883757988\n",
      "Epoch: 5 Step: 71 Loss: 1.4956109957443844\n",
      "Epoch: 5 Step: 81 Loss: 1.2122683706607493\n",
      "Epoch: 5 Step: 91 Loss: 1.0898235330098969\n",
      "Epoch: 5 Step: 101 Loss: 1.128983816767812\n",
      "Epoch: 5 Step: 111 Loss: 1.3857929943495855\n",
      "Epoch: 5 Step: 121 Loss: 1.3987012879767344\n",
      "Epoch: 5 Step: 131 Loss: 1.1211441921379106\n",
      "Epoch: 5 Step: 141 Loss: 1.5862599373077009\n",
      "Epoch: 5 Step: 151 Loss: 1.1234374979021733\n",
      "Epoch: 5 Step: 161 Loss: 1.1797497175541078\n",
      "Epoch: 5 Step: 171 Loss: 1.3894230361830113\n",
      "Epoch: 5 Step: 181 Loss: 1.1633882833158027\n",
      "Epoch: 5 Step: 191 Loss: 1.1485659613847599\n",
      "Epoch: 5 Step: 201 Loss: 0.9799118640635381\n",
      "Epoch: 5 Step: 211 Loss: 0.8219226893640994\n",
      "Epoch: 5 Step: 221 Loss: 1.1217732531365179\n",
      "Epoch: 5 Step: 231 Loss: 0.9942978988277488\n",
      "Epoch: 5 Step: 241 Loss: 1.1098008847146346\n",
      "Epoch: 5 Step: 251 Loss: 1.0159173212895372\n",
      "Epoch: 5 Step: 261 Loss: 1.1333102898188123\n",
      "Epoch: 5 Step: 271 Loss: 1.1157119158364914\n",
      "Epoch: 5 Step: 281 Loss: 1.0774299527919853\n",
      "Epoch: 5 Step: 291 Loss: 1.1903831032387073\n",
      "Epoch: 5 Step: 301 Loss: 1.307119071507137\n",
      "Epoch: 5 Step: 311 Loss: 1.08148121873489\n",
      "Epoch: 5 Step: 321 Loss: 1.0628572995130505\n",
      "Epoch: 5 Step: 331 Loss: 1.2558552207820657\n",
      "Epoch: 5 Step: 341 Loss: 1.221282213306392\n",
      "Epoch: 5 Step: 351 Loss: 1.2582866517752134\n",
      "Epoch: 5 Step: 361 Loss: 1.2836865730686986\n",
      "Epoch: 5 Step: 371 Loss: 0.8458697942521312\n",
      "Epoch: 5 Step: 381 Loss: 1.028210965967678\n",
      "Epoch: 5 Step: 391 Loss: 1.110318743209897\n",
      "Epoch: 5 Step: 401 Loss: 1.1257396309376686\n",
      "Epoch: 5 Step: 411 Loss: 1.3223837112592038\n",
      "Epoch: 5 Step: 421 Loss: 1.1606335537531742\n",
      "Epoch: 5 Step: 431 Loss: 0.9872815809598809\n",
      "Epoch: 5 Step: 441 Loss: 1.152444959295003\n",
      "Epoch: 5 Step: 451 Loss: 1.0952963201526102\n",
      "Epoch: 5 Step: 461 Loss: 1.1183123556111823\n",
      "Epoch: 5 Step: 471 Loss: 1.3057065739286589\n",
      "Epoch: 5 Step: 481 Loss: 1.2864880696226777\n",
      "Epoch: 5 Step: 491 Loss: 1.3405228891514884\n",
      "Epoch: 5 Step: 501 Loss: 1.2965147677022295\n",
      "Epoch: 5 Step: 511 Loss: 1.0007858174970519\n",
      "Epoch: 5 Step: 521 Loss: 1.1434232609889978\n",
      "Epoch: 5 Step: 531 Loss: 1.0420412654218825\n",
      "Epoch: 5 Step: 541 Loss: 1.0288423079798261\n",
      "Epoch: 5 Step: 551 Loss: 1.0433462009900858\n",
      "Epoch: 5 Step: 561 Loss: 1.0690505209690164\n",
      "Epoch: 5 Step: 571 Loss: 0.8988588173559878\n",
      "Epoch: 5 Step: 581 Loss: 1.216096606248532\n",
      "Epoch: 5 Step: 591 Loss: 1.1211375798477419\n",
      "Epoch: 5 Step: 601 Loss: 1.1040675386846595\n",
      "Epoch: 5 Step: 611 Loss: 1.188457463943172\n",
      "Epoch: 5 Step: 621 Loss: 1.1628843802407596\n",
      "Epoch: 5 Step: 631 Loss: 0.952232209721904\n",
      "Epoch: 5 Step: 641 Loss: 1.2312560568268434\n",
      "Epoch: 5 Step: 651 Loss: 0.9105165490761472\n",
      "Epoch: 5 Step: 661 Loss: 0.8950367388001579\n",
      "Epoch: 5 Step: 671 Loss: 1.4153803157063245\n",
      "Epoch: 5 Step: 681 Loss: 1.308824688788256\n",
      "Epoch: 5 Step: 691 Loss: 1.4001563861260031\n",
      "Epoch: 5 Step: 701 Loss: 1.2635260721434332\n",
      "Epoch: 5 Step: 711 Loss: 1.0366771746784735\n",
      "Epoch: 5 Step: 721 Loss: 0.9759719465954899\n",
      "Epoch: 5 Step: 731 Loss: 1.0330932675222377\n",
      "Epoch: 5 Step: 741 Loss: 1.0713468649527547\n",
      "Epoch: 5 Step: 751 Loss: 1.3008855106847177\n",
      "Epoch: 5 Step: 761 Loss: 1.066646774417565\n",
      "Epoch: 5 Step: 771 Loss: 1.2162791501350696\n",
      "Epoch: 5 Step: 781 Loss: 1.2013105754096962\n",
      "Epoch: 6 Step: 1 Loss: 1.0482956123044314\n",
      "Epoch: 6 Step: 11 Loss: 1.444752878235997\n",
      "Epoch: 6 Step: 21 Loss: 1.2026551242334256\n",
      "Epoch: 6 Step: 31 Loss: 1.3306727317153093\n",
      "Epoch: 6 Step: 41 Loss: 0.9398879223308372\n",
      "Epoch: 6 Step: 51 Loss: 0.9667436182887171\n",
      "Epoch: 6 Step: 61 Loss: 1.0642159520501893\n",
      "Epoch: 6 Step: 71 Loss: 1.3449446428901968\n",
      "Epoch: 6 Step: 81 Loss: 1.156812729724988\n",
      "Epoch: 6 Step: 91 Loss: 1.1148300145712455\n",
      "Epoch: 6 Step: 101 Loss: 1.1437641044309144\n",
      "Epoch: 6 Step: 111 Loss: 1.3026347938448004\n",
      "Epoch: 6 Step: 121 Loss: 1.2379987683680223\n",
      "Epoch: 6 Step: 131 Loss: 0.9983374033394292\n",
      "Epoch: 6 Step: 141 Loss: 1.3307280180298882\n",
      "Epoch: 6 Step: 151 Loss: 0.9703893041805504\n",
      "Epoch: 6 Step: 161 Loss: 1.0303796041435693\n",
      "Epoch: 6 Step: 171 Loss: 1.1818432107174175\n",
      "Epoch: 6 Step: 181 Loss: 1.0187449196433584\n",
      "Epoch: 6 Step: 191 Loss: 0.9802163301973714\n",
      "Epoch: 6 Step: 201 Loss: 0.8182337086316495\n",
      "Epoch: 6 Step: 211 Loss: 0.7682661098357713\n",
      "Epoch: 6 Step: 221 Loss: 0.9404603682397548\n",
      "Epoch: 6 Step: 231 Loss: 0.905802027745794\n",
      "Epoch: 6 Step: 241 Loss: 0.9253613340402763\n",
      "Epoch: 6 Step: 251 Loss: 1.1857479023291588\n",
      "Epoch: 6 Step: 261 Loss: 1.1228755902212664\n",
      "Epoch: 6 Step: 271 Loss: 1.0983580291245563\n",
      "Epoch: 6 Step: 281 Loss: 1.1144715762975874\n",
      "Epoch: 6 Step: 291 Loss: 1.1748247001226633\n",
      "Epoch: 6 Step: 301 Loss: 1.2249075038199466\n",
      "Epoch: 6 Step: 311 Loss: 1.1293990157253213\n",
      "Epoch: 6 Step: 321 Loss: 1.1857943638639965\n",
      "Epoch: 6 Step: 331 Loss: 1.1585646597777526\n",
      "Epoch: 6 Step: 341 Loss: 1.0431279008133885\n",
      "Epoch: 6 Step: 351 Loss: 1.1659399522459561\n",
      "Epoch: 6 Step: 361 Loss: 0.9889344390531949\n",
      "Epoch: 6 Step: 371 Loss: 0.7315931267965776\n",
      "Epoch: 6 Step: 381 Loss: 0.925859296207042\n",
      "Epoch: 6 Step: 391 Loss: 0.8455285076200362\n",
      "Epoch: 6 Step: 401 Loss: 0.9508969888948127\n",
      "Epoch: 6 Step: 411 Loss: 1.151612224893918\n",
      "Epoch: 6 Step: 421 Loss: 1.1180571019526655\n",
      "Epoch: 6 Step: 431 Loss: 1.0852248958103416\n",
      "Epoch: 6 Step: 441 Loss: 0.9784027001676325\n",
      "Epoch: 6 Step: 451 Loss: 0.985882626376597\n",
      "Epoch: 6 Step: 461 Loss: 1.2996722716174087\n",
      "Epoch: 6 Step: 471 Loss: 1.280782417714788\n",
      "Epoch: 6 Step: 481 Loss: 1.271602336806938\n",
      "Epoch: 6 Step: 491 Loss: 1.0149601140134088\n",
      "Epoch: 6 Step: 501 Loss: 1.2559071793491277\n",
      "Epoch: 6 Step: 511 Loss: 1.0527803669707865\n",
      "Epoch: 6 Step: 521 Loss: 1.0746690523924771\n",
      "Epoch: 6 Step: 531 Loss: 1.0137989990047347\n",
      "Epoch: 6 Step: 541 Loss: 1.0713274193602915\n",
      "Epoch: 6 Step: 551 Loss: 0.976665286826832\n",
      "Epoch: 6 Step: 561 Loss: 0.9664353718122687\n",
      "Epoch: 6 Step: 571 Loss: 0.8016564466987053\n",
      "Epoch: 6 Step: 581 Loss: 1.1763673975714997\n",
      "Epoch: 6 Step: 591 Loss: 1.106346453482971\n",
      "Epoch: 6 Step: 601 Loss: 0.9969901359393365\n",
      "Epoch: 6 Step: 611 Loss: 1.0515271282167444\n",
      "Epoch: 6 Step: 621 Loss: 1.1915352489341333\n",
      "Epoch: 6 Step: 631 Loss: 1.0324643808942446\n",
      "Epoch: 6 Step: 641 Loss: 1.3937789369609286\n",
      "Epoch: 6 Step: 651 Loss: 0.9355787969797867\n",
      "Epoch: 6 Step: 661 Loss: 0.7862591414835568\n",
      "Epoch: 6 Step: 671 Loss: 1.2909165224232444\n",
      "Epoch: 6 Step: 681 Loss: 1.261963002701708\n",
      "Epoch: 6 Step: 691 Loss: 1.2155083357937178\n",
      "Epoch: 6 Step: 701 Loss: 1.141104538287843\n",
      "Epoch: 6 Step: 711 Loss: 1.0774491369451582\n",
      "Epoch: 6 Step: 721 Loss: 0.9087584772051458\n",
      "Epoch: 6 Step: 731 Loss: 0.8429377322872924\n",
      "Epoch: 6 Step: 741 Loss: 0.9724922723116957\n",
      "Epoch: 6 Step: 751 Loss: 1.0741736746414756\n",
      "Epoch: 6 Step: 761 Loss: 0.815732251080127\n",
      "Epoch: 6 Step: 771 Loss: 1.1910222903314813\n",
      "Epoch: 6 Step: 781 Loss: 1.0477720703129096\n",
      "Epoch: 7 Step: 1 Loss: 0.9427511303879814\n",
      "Epoch: 7 Step: 11 Loss: 1.3041285968323755\n",
      "Epoch: 7 Step: 21 Loss: 1.324664866270247\n",
      "Epoch: 7 Step: 31 Loss: 1.7661754806090086\n",
      "Epoch: 7 Step: 41 Loss: 0.9286420015641028\n",
      "Epoch: 7 Step: 51 Loss: 1.0035414283685198\n",
      "Epoch: 7 Step: 61 Loss: 0.9564016835021655\n",
      "Epoch: 7 Step: 71 Loss: 1.2786221275906893\n",
      "Epoch: 7 Step: 81 Loss: 1.0756444149682605\n",
      "Epoch: 7 Step: 91 Loss: 0.9991591420321972\n",
      "Epoch: 7 Step: 101 Loss: 1.0828651303229178\n",
      "Epoch: 7 Step: 111 Loss: 1.1377257016283326\n",
      "Epoch: 7 Step: 121 Loss: 0.9803092671027421\n",
      "Epoch: 7 Step: 131 Loss: 0.9173583505653667\n",
      "Epoch: 7 Step: 141 Loss: 1.2197313255088267\n",
      "Epoch: 7 Step: 151 Loss: 0.7361386839189368\n",
      "Epoch: 7 Step: 161 Loss: 0.988065359770335\n",
      "Epoch: 7 Step: 171 Loss: 1.105776628824941\n",
      "Epoch: 7 Step: 181 Loss: 0.8245750669804927\n",
      "Epoch: 7 Step: 191 Loss: 1.1058218214737858\n",
      "Epoch: 7 Step: 201 Loss: 0.8877579554835655\n",
      "Epoch: 7 Step: 211 Loss: 0.8353234534995595\n",
      "Epoch: 7 Step: 221 Loss: 1.07679739360228\n",
      "Epoch: 7 Step: 231 Loss: 1.0509434767702026\n",
      "Epoch: 7 Step: 241 Loss: 0.9785263295594184\n",
      "Epoch: 7 Step: 251 Loss: 1.0247793652954047\n",
      "Epoch: 7 Step: 261 Loss: 1.1271460226955263\n",
      "Epoch: 7 Step: 271 Loss: 0.9596680615803546\n",
      "Epoch: 7 Step: 281 Loss: 0.9522677325842329\n",
      "Epoch: 7 Step: 291 Loss: 1.0449105327223895\n",
      "Epoch: 7 Step: 301 Loss: 1.0904811956995486\n",
      "Epoch: 7 Step: 311 Loss: 1.0047946841916793\n",
      "Epoch: 7 Step: 321 Loss: 1.0614111022474155\n",
      "Epoch: 7 Step: 331 Loss: 1.015737355790888\n",
      "Epoch: 7 Step: 341 Loss: 1.0138052624051581\n",
      "Epoch: 7 Step: 351 Loss: 1.0827510074281328\n",
      "Epoch: 7 Step: 361 Loss: 0.9998910287901953\n",
      "Epoch: 7 Step: 371 Loss: 0.6003124862381598\n",
      "Epoch: 7 Step: 381 Loss: 0.8994903263767019\n",
      "Epoch: 7 Step: 391 Loss: 0.9572731493228149\n",
      "Epoch: 7 Step: 401 Loss: 1.0915664823813016\n",
      "Epoch: 7 Step: 411 Loss: 1.2510329952210866\n",
      "Epoch: 7 Step: 421 Loss: 1.1145333152674144\n",
      "Epoch: 7 Step: 431 Loss: 0.9878115118179085\n",
      "Epoch: 7 Step: 441 Loss: 1.0332496007689895\n",
      "Epoch: 7 Step: 451 Loss: 1.1146427799899825\n",
      "Epoch: 7 Step: 461 Loss: 1.0761273908489772\n",
      "Epoch: 7 Step: 471 Loss: 1.117179238437482\n",
      "Epoch: 7 Step: 481 Loss: 1.314549971004647\n",
      "Epoch: 7 Step: 491 Loss: 0.9066680832992695\n",
      "Epoch: 7 Step: 501 Loss: 1.119606857468275\n",
      "Epoch: 7 Step: 511 Loss: 0.8514248733720794\n",
      "Epoch: 7 Step: 521 Loss: 1.0151208667246372\n",
      "Epoch: 7 Step: 531 Loss: 0.9020111947638866\n",
      "Epoch: 7 Step: 541 Loss: 0.8526530541633909\n",
      "Epoch: 7 Step: 551 Loss: 0.9233779703137847\n",
      "Epoch: 7 Step: 561 Loss: 0.9702091665888968\n",
      "Epoch: 7 Step: 571 Loss: 0.7761106693736392\n",
      "Epoch: 7 Step: 581 Loss: 1.2564022349811177\n",
      "Epoch: 7 Step: 591 Loss: 1.0400102777237343\n",
      "Epoch: 7 Step: 601 Loss: 1.027491447823399\n",
      "Epoch: 7 Step: 611 Loss: 0.8600684320741505\n",
      "Epoch: 7 Step: 621 Loss: 1.0500789276869886\n",
      "Epoch: 7 Step: 631 Loss: 0.9218376402176579\n",
      "Epoch: 7 Step: 641 Loss: 1.121752712778582\n",
      "Epoch: 7 Step: 651 Loss: 0.748436251746116\n",
      "Epoch: 7 Step: 661 Loss: 0.8053085501266444\n",
      "Epoch: 7 Step: 671 Loss: 1.0479206896830875\n",
      "Epoch: 7 Step: 681 Loss: 1.3368927622098603\n",
      "Epoch: 7 Step: 691 Loss: 1.0822866103007893\n",
      "Epoch: 7 Step: 701 Loss: 1.1506795944895458\n",
      "Epoch: 7 Step: 711 Loss: 0.9165034885894594\n",
      "Epoch: 7 Step: 721 Loss: 0.7775053246437935\n",
      "Epoch: 7 Step: 731 Loss: 0.7000898240637471\n",
      "Epoch: 7 Step: 741 Loss: 1.1000003497183652\n",
      "Epoch: 7 Step: 751 Loss: 1.4131553692693373\n",
      "Epoch: 7 Step: 761 Loss: 0.8922579774631222\n",
      "Epoch: 7 Step: 771 Loss: 1.148534822024632\n",
      "Epoch: 7 Step: 781 Loss: 1.0898471258975326\n",
      "Epoch: 8 Step: 1 Loss: 0.8671351507137863\n",
      "Epoch: 8 Step: 11 Loss: 1.1785002043868267\n",
      "Epoch: 8 Step: 21 Loss: 1.115317870422357\n",
      "Epoch: 8 Step: 31 Loss: 1.1645322798862145\n",
      "Epoch: 8 Step: 41 Loss: 0.8139660513172008\n",
      "Epoch: 8 Step: 51 Loss: 0.9879066241007411\n",
      "Epoch: 8 Step: 61 Loss: 0.8659463596477218\n",
      "Epoch: 8 Step: 71 Loss: 1.2741074169530822\n",
      "Epoch: 8 Step: 81 Loss: 1.042310777909799\n",
      "Epoch: 8 Step: 91 Loss: 0.9857776205708969\n",
      "Epoch: 8 Step: 101 Loss: 0.9064079681704158\n",
      "Epoch: 8 Step: 111 Loss: 1.000630260978765\n",
      "Epoch: 8 Step: 121 Loss: 1.0630878252126172\n",
      "Epoch: 8 Step: 131 Loss: 0.8825670738466427\n",
      "Epoch: 8 Step: 141 Loss: 1.3130374730214267\n",
      "Epoch: 8 Step: 151 Loss: 0.7952726332740598\n",
      "Epoch: 8 Step: 161 Loss: 1.2102754621863976\n",
      "Epoch: 8 Step: 171 Loss: 1.2349402575989925\n",
      "Epoch: 8 Step: 181 Loss: 1.1077317374211963\n",
      "Epoch: 8 Step: 191 Loss: 0.8572753111605116\n",
      "Epoch: 8 Step: 201 Loss: 0.881124889361117\n",
      "Epoch: 8 Step: 211 Loss: 0.69190426420362\n",
      "Epoch: 8 Step: 221 Loss: 0.8450009223045043\n",
      "Epoch: 8 Step: 231 Loss: 0.7668142000344389\n",
      "Epoch: 8 Step: 241 Loss: 0.892643758654926\n",
      "Epoch: 8 Step: 251 Loss: 0.8616262156527508\n",
      "Epoch: 8 Step: 261 Loss: 0.9165807076444763\n",
      "Epoch: 8 Step: 271 Loss: 0.8172618381132903\n",
      "Epoch: 8 Step: 281 Loss: 0.8210598443540499\n",
      "Epoch: 8 Step: 291 Loss: 0.9899140370047721\n",
      "Epoch: 8 Step: 301 Loss: 1.0633499262036232\n",
      "Epoch: 8 Step: 311 Loss: 1.0533542453910556\n",
      "Epoch: 8 Step: 321 Loss: 0.9885042401082486\n",
      "Epoch: 8 Step: 331 Loss: 0.9720482279152991\n",
      "Epoch: 8 Step: 341 Loss: 1.1246613061354007\n",
      "Epoch: 8 Step: 351 Loss: 1.3135987650271708\n",
      "Epoch: 8 Step: 361 Loss: 1.0304184811031674\n",
      "Epoch: 8 Step: 371 Loss: 0.6957934389324494\n",
      "Epoch: 8 Step: 381 Loss: 0.7956447129853547\n",
      "Epoch: 8 Step: 391 Loss: 0.7827538795475009\n",
      "Epoch: 8 Step: 401 Loss: 0.963090700597924\n",
      "Epoch: 8 Step: 411 Loss: 1.0201660626000648\n",
      "Epoch: 8 Step: 421 Loss: 1.0958040264787974\n",
      "Epoch: 8 Step: 431 Loss: 0.8646052562834565\n",
      "Epoch: 8 Step: 441 Loss: 0.9884212291640037\n",
      "Epoch: 8 Step: 451 Loss: 0.858845612773942\n",
      "Epoch: 8 Step: 461 Loss: 1.0615990635452253\n",
      "Epoch: 8 Step: 471 Loss: 1.0604153857999001\n",
      "Epoch: 8 Step: 481 Loss: 1.1579180257707553\n",
      "Epoch: 8 Step: 491 Loss: 1.0601862421158286\n",
      "Epoch: 8 Step: 501 Loss: 1.2857088549677753\n",
      "Epoch: 8 Step: 511 Loss: 0.8246871375441465\n",
      "Epoch: 8 Step: 521 Loss: 1.0381199702246469\n",
      "Epoch: 8 Step: 531 Loss: 0.9405085365175219\n",
      "Epoch: 8 Step: 541 Loss: 1.056663743604208\n",
      "Epoch: 8 Step: 551 Loss: 0.7870798216670143\n",
      "Epoch: 8 Step: 561 Loss: 0.8296483701041282\n",
      "Epoch: 8 Step: 571 Loss: 0.7220897296208665\n",
      "Epoch: 8 Step: 581 Loss: 1.1873242627550278\n",
      "Epoch: 8 Step: 591 Loss: 1.1047332994543844\n",
      "Epoch: 8 Step: 601 Loss: 0.8606772433997731\n",
      "Epoch: 8 Step: 611 Loss: 0.801402723600641\n",
      "Epoch: 8 Step: 621 Loss: 0.9380678208433156\n",
      "Epoch: 8 Step: 631 Loss: 0.742516715249327\n",
      "Epoch: 8 Step: 641 Loss: 0.925547933191917\n",
      "Epoch: 8 Step: 651 Loss: 0.7909767539417256\n",
      "Epoch: 8 Step: 661 Loss: 0.724112919334243\n",
      "Epoch: 8 Step: 671 Loss: 1.2162137116780494\n",
      "Epoch: 8 Step: 681 Loss: 1.1347752245779468\n",
      "Epoch: 8 Step: 691 Loss: 1.14818624845645\n",
      "Epoch: 8 Step: 701 Loss: 1.0695831360430692\n",
      "Epoch: 8 Step: 711 Loss: 1.0936429995787744\n",
      "Epoch: 8 Step: 721 Loss: 0.9956674852819279\n",
      "Epoch: 8 Step: 731 Loss: 0.697064752091007\n",
      "Epoch: 8 Step: 741 Loss: 0.9347340701860052\n",
      "Epoch: 8 Step: 751 Loss: 1.1872081665943126\n",
      "Epoch: 8 Step: 761 Loss: 0.8150078043475372\n",
      "Epoch: 8 Step: 771 Loss: 1.114692766197485\n",
      "Epoch: 8 Step: 781 Loss: 0.9707500633226388\n",
      "Epoch: 9 Step: 1 Loss: 0.882692941445339\n",
      "Epoch: 9 Step: 11 Loss: 1.2422974547514745\n",
      "Epoch: 9 Step: 21 Loss: 1.0703996313552753\n",
      "Epoch: 9 Step: 31 Loss: 1.1516455783028787\n",
      "Epoch: 9 Step: 41 Loss: 0.7079135022272172\n",
      "Epoch: 9 Step: 51 Loss: 0.710251272804422\n",
      "Epoch: 9 Step: 61 Loss: 0.9071124392695726\n",
      "Epoch: 9 Step: 71 Loss: 1.1220862327479557\n",
      "Epoch: 9 Step: 81 Loss: 0.9242305215285507\n",
      "Epoch: 9 Step: 91 Loss: 0.9307911009392509\n",
      "Epoch: 9 Step: 101 Loss: 0.9762648214806051\n",
      "Epoch: 9 Step: 111 Loss: 1.2580266913352762\n",
      "Epoch: 9 Step: 121 Loss: 1.0908966233855997\n",
      "Epoch: 9 Step: 131 Loss: 0.81107152295453\n",
      "Epoch: 9 Step: 141 Loss: 1.0613239482223338\n",
      "Epoch: 9 Step: 151 Loss: 0.7452793530937074\n",
      "Epoch: 9 Step: 161 Loss: 0.9389953020858397\n",
      "Epoch: 9 Step: 171 Loss: 0.8866701497112186\n",
      "Epoch: 9 Step: 181 Loss: 0.9926807784229635\n",
      "Epoch: 9 Step: 191 Loss: 0.737215935377342\n",
      "Epoch: 9 Step: 201 Loss: 0.6284630452215096\n",
      "Epoch: 9 Step: 211 Loss: 0.5613957383182937\n",
      "Epoch: 9 Step: 221 Loss: 0.8186548735446094\n",
      "Epoch: 9 Step: 231 Loss: 0.7878682119968168\n",
      "Epoch: 9 Step: 241 Loss: 0.7731802046835718\n",
      "Epoch: 9 Step: 251 Loss: 0.7598104193324824\n",
      "Epoch: 9 Step: 261 Loss: 0.9497222576283513\n",
      "Epoch: 9 Step: 271 Loss: 0.8917443345484584\n",
      "Epoch: 9 Step: 281 Loss: 0.9743149867095305\n",
      "Epoch: 9 Step: 291 Loss: 1.044844648921944\n",
      "Epoch: 9 Step: 301 Loss: 0.9619240075665347\n",
      "Epoch: 9 Step: 311 Loss: 0.9733687505617754\n",
      "Epoch: 9 Step: 321 Loss: 1.0447009506130738\n",
      "Epoch: 9 Step: 331 Loss: 0.8892374699324243\n",
      "Epoch: 9 Step: 341 Loss: 1.0235934028000226\n",
      "Epoch: 9 Step: 351 Loss: 1.0332577298633054\n",
      "Epoch: 9 Step: 361 Loss: 0.9102029015849353\n",
      "Epoch: 9 Step: 371 Loss: 0.6327864146324556\n",
      "Epoch: 9 Step: 381 Loss: 0.7084967540595442\n",
      "Epoch: 9 Step: 391 Loss: 0.7642015972738653\n",
      "Epoch: 9 Step: 401 Loss: 0.9252185580493731\n",
      "Epoch: 9 Step: 411 Loss: 0.9404154708703378\n",
      "Epoch: 9 Step: 421 Loss: 0.9541592742377398\n",
      "Epoch: 9 Step: 431 Loss: 0.8450272067145895\n",
      "Epoch: 9 Step: 441 Loss: 0.7407369018690158\n",
      "Epoch: 9 Step: 451 Loss: 0.7627666286750987\n",
      "Epoch: 9 Step: 461 Loss: 1.1697981187422664\n",
      "Epoch: 9 Step: 471 Loss: 1.3172012745962969\n",
      "Epoch: 9 Step: 481 Loss: 1.1941312347466075\n",
      "Epoch: 9 Step: 491 Loss: 1.036710798827885\n",
      "Epoch: 9 Step: 501 Loss: 1.0150521539999828\n",
      "Epoch: 9 Step: 511 Loss: 0.7022196618153771\n",
      "Epoch: 9 Step: 521 Loss: 1.0569437822088403\n",
      "Epoch: 9 Step: 531 Loss: 0.8062147941338069\n",
      "Epoch: 9 Step: 541 Loss: 0.7282277749460491\n",
      "Epoch: 9 Step: 551 Loss: 0.7962265275922698\n",
      "Epoch: 9 Step: 561 Loss: 0.7673515928527301\n",
      "Epoch: 9 Step: 571 Loss: 0.5019904638185573\n",
      "Epoch: 9 Step: 581 Loss: 0.9586572942769456\n",
      "Epoch: 9 Step: 591 Loss: 0.9100254006563895\n",
      "Epoch: 9 Step: 601 Loss: 0.7725609178727064\n",
      "Epoch: 9 Step: 611 Loss: 0.9423681675370628\n",
      "Epoch: 9 Step: 621 Loss: 0.9326596805806918\n",
      "Epoch: 9 Step: 631 Loss: 0.9217446241743966\n",
      "Epoch: 9 Step: 641 Loss: 1.1037237348667681\n",
      "Epoch: 9 Step: 651 Loss: 0.8221752147948242\n",
      "Epoch: 9 Step: 661 Loss: 0.6952390483471664\n",
      "Epoch: 9 Step: 671 Loss: 1.1987898623916164\n",
      "Epoch: 9 Step: 681 Loss: 0.9924512837401125\n",
      "Epoch: 9 Step: 691 Loss: 1.092666948729767\n",
      "Epoch: 9 Step: 701 Loss: 1.0859591511520261\n",
      "Epoch: 9 Step: 711 Loss: 1.0215575119713107\n",
      "Epoch: 9 Step: 721 Loss: 0.7142920593438228\n",
      "Epoch: 9 Step: 731 Loss: 0.6046625707125578\n",
      "Epoch: 9 Step: 741 Loss: 0.9103664020085029\n",
      "Epoch: 9 Step: 751 Loss: 0.867552362449981\n",
      "Epoch: 9 Step: 761 Loss: 0.7947286070477235\n",
      "Epoch: 9 Step: 771 Loss: 1.0051976762178803\n",
      "Epoch: 9 Step: 781 Loss: 0.8851059869796356\n",
      "Epoch: 10 Step: 1 Loss: 0.6721009133953006\n",
      "Epoch: 10 Step: 11 Loss: 1.0748735499774649\n",
      "Epoch: 10 Step: 21 Loss: 1.0656376936501335\n",
      "Epoch: 10 Step: 31 Loss: 1.0467914528102265\n",
      "Epoch: 10 Step: 41 Loss: 0.883061752358632\n",
      "Epoch: 10 Step: 51 Loss: 0.9542520838618438\n",
      "Epoch: 10 Step: 61 Loss: 1.0584994563203387\n",
      "Epoch: 10 Step: 71 Loss: 1.1872919996131137\n",
      "Epoch: 10 Step: 81 Loss: 1.0356496198591496\n",
      "Epoch: 10 Step: 91 Loss: 0.9391985784530397\n",
      "Epoch: 10 Step: 101 Loss: 0.9423195354930051\n",
      "Epoch: 10 Step: 111 Loss: 0.9528860527551317\n",
      "Epoch: 10 Step: 121 Loss: 0.9240606579927337\n",
      "Epoch: 10 Step: 131 Loss: 0.6558437086850522\n",
      "Epoch: 10 Step: 141 Loss: 1.277173600806453\n",
      "Epoch: 10 Step: 151 Loss: 0.6443607847173726\n",
      "Epoch: 10 Step: 161 Loss: 0.6710874626740733\n",
      "Epoch: 10 Step: 171 Loss: 0.8376575879135348\n",
      "Epoch: 10 Step: 181 Loss: 0.7809769897316392\n",
      "Epoch: 10 Step: 191 Loss: 0.7704284826452382\n",
      "Epoch: 10 Step: 201 Loss: 0.590584229279872\n",
      "Epoch: 10 Step: 211 Loss: 0.572358508876165\n",
      "Epoch: 10 Step: 221 Loss: 0.8850359563168471\n",
      "Epoch: 10 Step: 231 Loss: 0.7498028362394566\n",
      "Epoch: 10 Step: 241 Loss: 0.8675701077394287\n",
      "Epoch: 10 Step: 251 Loss: 0.8577677800164519\n",
      "Epoch: 10 Step: 261 Loss: 1.043699565518372\n",
      "Epoch: 10 Step: 271 Loss: 0.7190796378829143\n",
      "Epoch: 10 Step: 281 Loss: 0.8314917254198069\n",
      "Epoch: 10 Step: 291 Loss: 0.8770976696980632\n",
      "Epoch: 10 Step: 301 Loss: 0.9551654245770886\n",
      "Epoch: 10 Step: 311 Loss: 0.8164870559237907\n",
      "Epoch: 10 Step: 321 Loss: 0.8633790721490469\n",
      "Epoch: 10 Step: 331 Loss: 0.9792385300976878\n",
      "Epoch: 10 Step: 341 Loss: 0.9005837355148936\n",
      "Epoch: 10 Step: 351 Loss: 0.7849942093364212\n",
      "Epoch: 10 Step: 361 Loss: 0.8456416740638284\n",
      "Epoch: 10 Step: 371 Loss: 0.5636458237617172\n",
      "Epoch: 10 Step: 381 Loss: 0.8920533463380803\n",
      "Epoch: 10 Step: 391 Loss: 0.6896266612217998\n",
      "Epoch: 10 Step: 401 Loss: 0.9307216530441281\n",
      "Epoch: 10 Step: 411 Loss: 0.9905374403580599\n",
      "Epoch: 10 Step: 421 Loss: 1.0610821532167467\n",
      "Epoch: 10 Step: 431 Loss: 0.991787165150589\n",
      "Epoch: 10 Step: 441 Loss: 0.7733517069895128\n",
      "Epoch: 10 Step: 451 Loss: 0.7676277061045036\n",
      "Epoch: 10 Step: 461 Loss: 0.7990530687607247\n",
      "Epoch: 10 Step: 471 Loss: 0.9172341039664307\n",
      "Epoch: 10 Step: 481 Loss: 1.1221194058945745\n",
      "Epoch: 10 Step: 491 Loss: 0.9703234832863534\n",
      "Epoch: 10 Step: 501 Loss: 0.970794117815091\n",
      "Epoch: 10 Step: 511 Loss: 0.5295982602033501\n",
      "Epoch: 10 Step: 521 Loss: 0.950825473911882\n",
      "Epoch: 10 Step: 531 Loss: 0.8302378541030899\n",
      "Epoch: 10 Step: 541 Loss: 0.7695709948820028\n",
      "Epoch: 10 Step: 551 Loss: 0.654908352582626\n",
      "Epoch: 10 Step: 561 Loss: 0.6407125253112791\n",
      "Epoch: 10 Step: 571 Loss: 0.5777713385669865\n",
      "Epoch: 10 Step: 581 Loss: 1.0612512938839846\n",
      "Epoch: 10 Step: 591 Loss: 1.278467202152887\n",
      "Epoch: 10 Step: 601 Loss: 0.9007269286735031\n",
      "Epoch: 10 Step: 611 Loss: 0.7894201164694319\n",
      "Epoch: 10 Step: 621 Loss: 1.051281395013706\n",
      "Epoch: 10 Step: 631 Loss: 0.8644773185605718\n",
      "Epoch: 10 Step: 641 Loss: 0.7756529714776335\n",
      "Epoch: 10 Step: 651 Loss: 0.6300053534720951\n",
      "Epoch: 10 Step: 661 Loss: 0.6895837622364169\n",
      "Epoch: 10 Step: 671 Loss: 0.992328299887743\n",
      "Epoch: 10 Step: 681 Loss: 1.2269997369231829\n",
      "Epoch: 10 Step: 691 Loss: 1.0400525493901673\n",
      "Epoch: 10 Step: 701 Loss: 0.8693169339234561\n",
      "Epoch: 10 Step: 711 Loss: 0.7520890941720701\n",
      "Epoch: 10 Step: 721 Loss: 0.6786143629443735\n",
      "Epoch: 10 Step: 731 Loss: 0.5669040339006168\n",
      "Epoch: 10 Step: 741 Loss: 0.9123827156969779\n",
      "Epoch: 10 Step: 751 Loss: 0.9366753567618593\n",
      "Epoch: 10 Step: 761 Loss: 0.6355123169379606\n",
      "Epoch: 10 Step: 771 Loss: 1.083130857535353\n",
      "Epoch: 10 Step: 781 Loss: 0.7963778299466548\n",
      "Epoch: 11 Step: 1 Loss: 0.6875476665285117\n",
      "Epoch: 11 Step: 11 Loss: 0.9319464139015146\n",
      "Epoch: 11 Step: 21 Loss: 1.2210390394986574\n",
      "Epoch: 11 Step: 31 Loss: 1.0323049343339883\n",
      "Epoch: 11 Step: 41 Loss: 0.688561214247341\n",
      "Epoch: 11 Step: 51 Loss: 0.6874593631616512\n",
      "Epoch: 11 Step: 61 Loss: 0.9188722925451159\n",
      "Epoch: 11 Step: 71 Loss: 1.1447003812717995\n",
      "Epoch: 11 Step: 81 Loss: 0.6565457027405313\n",
      "Epoch: 11 Step: 91 Loss: 0.8282231533181661\n",
      "Epoch: 11 Step: 101 Loss: 0.7376218765107082\n",
      "Epoch: 11 Step: 111 Loss: 1.037591944530647\n",
      "Epoch: 11 Step: 121 Loss: 0.8504052088988345\n",
      "Epoch: 11 Step: 131 Loss: 0.7314502069234319\n",
      "Epoch: 11 Step: 141 Loss: 1.257540111371153\n",
      "Epoch: 11 Step: 151 Loss: 0.6416809159362182\n",
      "Epoch: 11 Step: 161 Loss: 0.7115680568869247\n",
      "Epoch: 11 Step: 171 Loss: 0.9209009895385598\n",
      "Epoch: 11 Step: 181 Loss: 0.9679604659526371\n",
      "Epoch: 11 Step: 191 Loss: 0.7300088918937802\n",
      "Epoch: 11 Step: 201 Loss: 0.6759073131593463\n",
      "Epoch: 11 Step: 211 Loss: 0.6343898562206829\n",
      "Epoch: 11 Step: 221 Loss: 0.7040105922766798\n",
      "Epoch: 11 Step: 231 Loss: 0.61676205739404\n",
      "Epoch: 11 Step: 241 Loss: 0.606558588311678\n",
      "Epoch: 11 Step: 251 Loss: 0.5995518629989992\n",
      "Epoch: 11 Step: 261 Loss: 0.8557051780859491\n",
      "Epoch: 11 Step: 271 Loss: 0.6627846374408788\n",
      "Epoch: 11 Step: 281 Loss: 0.6883950606005398\n",
      "Epoch: 11 Step: 291 Loss: 0.9128953955310285\n",
      "Epoch: 11 Step: 301 Loss: 0.840883017047339\n",
      "Epoch: 11 Step: 311 Loss: 0.6588458688740577\n",
      "Epoch: 11 Step: 321 Loss: 0.7677975842976756\n",
      "Epoch: 11 Step: 331 Loss: 0.8503903081834281\n",
      "Epoch: 11 Step: 341 Loss: 0.875897940800362\n",
      "Epoch: 11 Step: 351 Loss: 0.8285153453561505\n",
      "Epoch: 11 Step: 361 Loss: 0.9700023566042452\n",
      "Epoch: 11 Step: 371 Loss: 0.6948960760576113\n",
      "Epoch: 11 Step: 381 Loss: 0.7149209099307401\n",
      "Epoch: 11 Step: 391 Loss: 0.5659145066353499\n",
      "Epoch: 11 Step: 401 Loss: 0.8740916096781554\n",
      "Epoch: 11 Step: 411 Loss: 0.7962470761003912\n",
      "Epoch: 11 Step: 421 Loss: 0.8392387818852941\n",
      "Epoch: 11 Step: 431 Loss: 0.6239600463367958\n",
      "Epoch: 11 Step: 441 Loss: 0.72226042155791\n",
      "Epoch: 11 Step: 451 Loss: 0.6559094702912199\n",
      "Epoch: 11 Step: 461 Loss: 0.8372917197811446\n",
      "Epoch: 11 Step: 471 Loss: 0.891471138753885\n",
      "Epoch: 11 Step: 481 Loss: 1.041072019067573\n",
      "Epoch: 11 Step: 491 Loss: 0.8367231859783875\n",
      "Epoch: 11 Step: 501 Loss: 1.0063867649971463\n",
      "Epoch: 11 Step: 511 Loss: 0.6208478552811367\n",
      "Epoch: 11 Step: 521 Loss: 0.8265858454927495\n",
      "Epoch: 11 Step: 531 Loss: 0.859011816381228\n",
      "Epoch: 11 Step: 541 Loss: 0.9451761608208\n",
      "Epoch: 11 Step: 551 Loss: 0.8398710791359312\n",
      "Epoch: 11 Step: 561 Loss: 0.696062893817398\n",
      "Epoch: 11 Step: 571 Loss: 0.7955656426633124\n",
      "Epoch: 11 Step: 581 Loss: 0.8398649940341723\n",
      "Epoch: 11 Step: 591 Loss: 0.9156349747975747\n",
      "Epoch: 11 Step: 601 Loss: 0.9172785303238756\n",
      "Epoch: 11 Step: 611 Loss: 0.8050541259164696\n",
      "Epoch: 11 Step: 621 Loss: 0.8344783702694845\n",
      "Epoch: 11 Step: 631 Loss: 0.7336412077848516\n",
      "Epoch: 11 Step: 641 Loss: 0.786655904060926\n",
      "Epoch: 11 Step: 651 Loss: 0.6367356943315254\n",
      "Epoch: 11 Step: 661 Loss: 0.5169531918466019\n",
      "Epoch: 11 Step: 671 Loss: 0.8624224359640713\n",
      "Epoch: 11 Step: 681 Loss: 0.9794889379285606\n",
      "Epoch: 11 Step: 691 Loss: 0.9288093318706513\n",
      "Epoch: 11 Step: 701 Loss: 0.8466188678094245\n",
      "Epoch: 11 Step: 711 Loss: 0.9117792559855807\n",
      "Epoch: 11 Step: 721 Loss: 0.7074397627543372\n",
      "Epoch: 11 Step: 731 Loss: 0.46605989895525585\n",
      "Epoch: 11 Step: 741 Loss: 0.8314131835308418\n",
      "Epoch: 11 Step: 751 Loss: 1.0049979238888491\n",
      "Epoch: 11 Step: 761 Loss: 0.6765073910328898\n",
      "Epoch: 11 Step: 771 Loss: 1.0997512791216602\n",
      "Epoch: 11 Step: 781 Loss: 0.664485571209865\n",
      "Epoch: 12 Step: 1 Loss: 0.6215741833941597\n",
      "Epoch: 12 Step: 11 Loss: 0.9769392266851167\n",
      "Epoch: 12 Step: 21 Loss: 1.0833697780060532\n",
      "Epoch: 12 Step: 31 Loss: 0.8295177290652613\n",
      "Epoch: 12 Step: 41 Loss: 0.5380853385110004\n",
      "Epoch: 12 Step: 51 Loss: 0.6560187632769159\n",
      "Epoch: 12 Step: 61 Loss: 0.7889370480984159\n",
      "Epoch: 12 Step: 71 Loss: 0.8983693821895553\n",
      "Epoch: 12 Step: 81 Loss: 0.7256409705550991\n",
      "Epoch: 12 Step: 91 Loss: 0.6484382589546314\n",
      "Epoch: 12 Step: 101 Loss: 0.6282233798667198\n",
      "Epoch: 12 Step: 111 Loss: 0.9500314740142568\n",
      "Epoch: 12 Step: 121 Loss: 0.7272505038478846\n",
      "Epoch: 12 Step: 131 Loss: 0.71076377927254\n",
      "Epoch: 12 Step: 141 Loss: 1.140158693869941\n",
      "Epoch: 12 Step: 151 Loss: 0.8658230884797018\n",
      "Epoch: 12 Step: 161 Loss: 0.7713646753504777\n",
      "Epoch: 12 Step: 171 Loss: 0.877153307152934\n",
      "Epoch: 12 Step: 181 Loss: 0.7780269979414027\n",
      "Epoch: 12 Step: 191 Loss: 0.8025040525894016\n",
      "Epoch: 12 Step: 201 Loss: 0.5064973064508624\n",
      "Epoch: 12 Step: 211 Loss: 0.47172519721996475\n",
      "Epoch: 12 Step: 221 Loss: 0.5924195700151584\n",
      "Epoch: 12 Step: 231 Loss: 0.5732197747626304\n",
      "Epoch: 12 Step: 241 Loss: 0.6044848310937152\n",
      "Epoch: 12 Step: 251 Loss: 0.5119458141294528\n",
      "Epoch: 12 Step: 261 Loss: 0.7278078373186337\n",
      "Epoch: 12 Step: 271 Loss: 0.6640195096835207\n",
      "Epoch: 12 Step: 281 Loss: 0.7569262187595627\n",
      "Epoch: 12 Step: 291 Loss: 0.8200325592626176\n",
      "Epoch: 12 Step: 301 Loss: 0.7372972798612518\n",
      "Epoch: 12 Step: 311 Loss: 0.6867743381804016\n",
      "Epoch: 12 Step: 321 Loss: 0.8729604051292768\n",
      "Epoch: 12 Step: 331 Loss: 0.9869588037321575\n",
      "Epoch: 12 Step: 341 Loss: 0.7460530004663019\n",
      "Epoch: 12 Step: 351 Loss: 0.8555082752476986\n",
      "Epoch: 12 Step: 361 Loss: 0.8234683173273761\n",
      "Epoch: 12 Step: 371 Loss: 0.537235711567541\n",
      "Epoch: 12 Step: 381 Loss: 0.710471686420656\n",
      "Epoch: 12 Step: 391 Loss: 0.5916819423694294\n",
      "Epoch: 12 Step: 401 Loss: 0.5510351431242067\n",
      "Epoch: 12 Step: 411 Loss: 0.6736180574809172\n",
      "Epoch: 12 Step: 421 Loss: 0.7759204722639907\n",
      "Epoch: 12 Step: 431 Loss: 0.6196614215602363\n",
      "Epoch: 12 Step: 441 Loss: 0.6270351105097858\n",
      "Epoch: 12 Step: 451 Loss: 0.5215316373895229\n",
      "Epoch: 12 Step: 461 Loss: 0.7245024207578371\n",
      "Epoch: 12 Step: 471 Loss: 0.8428381537912495\n",
      "Epoch: 12 Step: 481 Loss: 1.1041300279196151\n",
      "Epoch: 12 Step: 491 Loss: 1.0653188906353952\n",
      "Epoch: 12 Step: 501 Loss: 1.0433948225333425\n",
      "Epoch: 12 Step: 511 Loss: 0.612173120430952\n",
      "Epoch: 12 Step: 521 Loss: 0.8385961909942874\n",
      "Epoch: 12 Step: 531 Loss: 0.8910832024989362\n",
      "Epoch: 12 Step: 541 Loss: 0.6483263763646122\n",
      "Epoch: 12 Step: 551 Loss: 0.6674194910681421\n",
      "Epoch: 12 Step: 561 Loss: 0.7649336176199966\n",
      "Epoch: 12 Step: 571 Loss: 0.5632988401771545\n",
      "Epoch: 12 Step: 581 Loss: 0.885824422982755\n",
      "Epoch: 12 Step: 591 Loss: 0.882087777641978\n",
      "Epoch: 12 Step: 601 Loss: 0.558298336058942\n",
      "Epoch: 12 Step: 611 Loss: 0.7528634028524637\n",
      "Epoch: 12 Step: 621 Loss: 0.8532873933652307\n",
      "Epoch: 12 Step: 631 Loss: 0.5986726029024362\n",
      "Epoch: 12 Step: 641 Loss: 0.8194246882076209\n",
      "Epoch: 12 Step: 651 Loss: 0.7368158963366449\n",
      "Epoch: 12 Step: 661 Loss: 0.5510939978432029\n",
      "Epoch: 12 Step: 671 Loss: 0.896010603497801\n",
      "Epoch: 12 Step: 681 Loss: 1.1881237497496515\n",
      "Epoch: 12 Step: 691 Loss: 0.9084207380851135\n",
      "Epoch: 12 Step: 701 Loss: 0.9898903653688592\n",
      "Epoch: 12 Step: 711 Loss: 0.8946031607453087\n",
      "Epoch: 12 Step: 721 Loss: 0.4966863389922318\n",
      "Epoch: 12 Step: 731 Loss: 0.5919482441565892\n",
      "Epoch: 12 Step: 741 Loss: 0.838116362106337\n",
      "Epoch: 12 Step: 751 Loss: 0.7894946201317882\n",
      "Epoch: 12 Step: 761 Loss: 0.5901437052196665\n",
      "Epoch: 12 Step: 771 Loss: 0.9228065662475234\n",
      "Epoch: 12 Step: 781 Loss: 0.7728668061099884\n",
      "Epoch: 13 Step: 1 Loss: 0.705276954287485\n",
      "Epoch: 13 Step: 11 Loss: 0.7822326610449302\n",
      "Epoch: 13 Step: 21 Loss: 1.0815302483047882\n",
      "Epoch: 13 Step: 31 Loss: 0.7633896082660641\n",
      "Epoch: 13 Step: 41 Loss: 0.4904003583613431\n",
      "Epoch: 13 Step: 51 Loss: 0.7958107815108513\n",
      "Epoch: 13 Step: 61 Loss: 0.9121104591187497\n",
      "Epoch: 13 Step: 71 Loss: 1.1085965282406178\n",
      "Epoch: 13 Step: 81 Loss: 0.7143432805280594\n",
      "Epoch: 13 Step: 91 Loss: 0.8544190624801935\n",
      "Epoch: 13 Step: 101 Loss: 0.8463989934127736\n",
      "Epoch: 13 Step: 111 Loss: 0.8352420861673959\n",
      "Epoch: 13 Step: 121 Loss: 0.5598600190611052\n",
      "Epoch: 13 Step: 131 Loss: 0.7024882527500342\n",
      "Epoch: 13 Step: 141 Loss: 1.0634504971404513\n",
      "Epoch: 13 Step: 151 Loss: 0.8557314811160688\n",
      "Epoch: 13 Step: 161 Loss: 0.724888631106124\n",
      "Epoch: 13 Step: 171 Loss: 0.7792808088696008\n",
      "Epoch: 13 Step: 181 Loss: 0.5651243268368669\n",
      "Epoch: 13 Step: 191 Loss: 0.6399779219165171\n",
      "Epoch: 13 Step: 201 Loss: 0.3864481330404185\n",
      "Epoch: 13 Step: 211 Loss: 0.44490510340451495\n",
      "Epoch: 13 Step: 221 Loss: 0.5949165562701626\n",
      "Epoch: 13 Step: 231 Loss: 0.4482286952225357\n",
      "Epoch: 13 Step: 241 Loss: 0.5773612485464659\n",
      "Epoch: 13 Step: 251 Loss: 0.5800857390661904\n",
      "Epoch: 13 Step: 261 Loss: 0.8142754136098617\n",
      "Epoch: 13 Step: 271 Loss: 0.7426252853750621\n",
      "Epoch: 13 Step: 281 Loss: 0.6753988560805009\n",
      "Epoch: 13 Step: 291 Loss: 0.722491809039239\n",
      "Epoch: 13 Step: 301 Loss: 0.7676335636824481\n",
      "Epoch: 13 Step: 311 Loss: 0.6650344612434546\n",
      "Epoch: 13 Step: 321 Loss: 0.7966642750618459\n",
      "Epoch: 13 Step: 331 Loss: 0.6890701923461469\n",
      "Epoch: 13 Step: 341 Loss: 0.6548405535074866\n",
      "Epoch: 13 Step: 351 Loss: 0.6832959368695168\n",
      "Epoch: 13 Step: 361 Loss: 0.631769962839003\n",
      "Epoch: 13 Step: 371 Loss: 0.4959465822152165\n",
      "Epoch: 13 Step: 381 Loss: 0.6094305028910353\n",
      "Epoch: 13 Step: 391 Loss: 0.47784945901719394\n",
      "Epoch: 13 Step: 401 Loss: 0.6547880838254325\n",
      "Epoch: 13 Step: 411 Loss: 0.6297693037401645\n",
      "Epoch: 13 Step: 421 Loss: 0.832506681800054\n",
      "Epoch: 13 Step: 431 Loss: 0.8769932497148467\n",
      "Epoch: 13 Step: 441 Loss: 0.8624183265836872\n",
      "Epoch: 13 Step: 451 Loss: 0.6538817663965018\n",
      "Epoch: 13 Step: 461 Loss: 0.7412894232656135\n",
      "Epoch: 13 Step: 471 Loss: 0.9222389146938312\n",
      "Epoch: 13 Step: 481 Loss: 0.9119456752670019\n",
      "Epoch: 13 Step: 491 Loss: 0.6923202126138386\n",
      "Epoch: 13 Step: 501 Loss: 1.063095044852605\n",
      "Epoch: 13 Step: 511 Loss: 0.5766429680655862\n",
      "Epoch: 13 Step: 521 Loss: 0.732459278828699\n",
      "Epoch: 13 Step: 531 Loss: 0.7558018518298122\n",
      "Epoch: 13 Step: 541 Loss: 0.7051496240825887\n",
      "Epoch: 13 Step: 551 Loss: 0.535792917694474\n",
      "Epoch: 13 Step: 561 Loss: 0.6016427704296492\n",
      "Epoch: 13 Step: 571 Loss: 0.5315583718883776\n",
      "Epoch: 13 Step: 581 Loss: 0.6527087814853806\n",
      "Epoch: 13 Step: 591 Loss: 0.7603454457608632\n",
      "Epoch: 13 Step: 601 Loss: 0.499708307342674\n",
      "Epoch: 13 Step: 611 Loss: 0.7817437825529804\n",
      "Epoch: 13 Step: 621 Loss: 0.6632020843004537\n",
      "Epoch: 13 Step: 631 Loss: 0.7888012139515761\n",
      "Epoch: 13 Step: 641 Loss: 0.9904913732079897\n",
      "Epoch: 13 Step: 651 Loss: 0.7130161463289483\n",
      "Epoch: 13 Step: 661 Loss: 0.44813838703579256\n",
      "Epoch: 13 Step: 671 Loss: 0.9720741440722366\n",
      "Epoch: 13 Step: 681 Loss: 0.842768052505671\n",
      "Epoch: 13 Step: 691 Loss: 0.7954496882328841\n",
      "Epoch: 13 Step: 701 Loss: 0.7777238274712456\n",
      "Epoch: 13 Step: 711 Loss: 0.596174758616501\n",
      "Epoch: 13 Step: 721 Loss: 0.6123633310003902\n",
      "Epoch: 13 Step: 731 Loss: 0.4152710484742375\n",
      "Epoch: 13 Step: 741 Loss: 0.869595431848096\n",
      "Epoch: 13 Step: 751 Loss: 0.6789953960989621\n",
      "Epoch: 13 Step: 761 Loss: 0.6654278616934756\n",
      "Epoch: 13 Step: 771 Loss: 0.7658876335994158\n",
      "Epoch: 13 Step: 781 Loss: 0.756269810105895\n",
      "Epoch: 14 Step: 1 Loss: 0.5669111048096731\n",
      "Epoch: 14 Step: 11 Loss: 0.8934254543632483\n",
      "Epoch: 14 Step: 21 Loss: 1.032449860734015\n",
      "Epoch: 14 Step: 31 Loss: 0.9584506539305542\n",
      "Epoch: 14 Step: 41 Loss: 0.53810619815352\n",
      "Epoch: 14 Step: 51 Loss: 0.931392933322786\n",
      "Epoch: 14 Step: 61 Loss: 0.8287008472748698\n",
      "Epoch: 14 Step: 71 Loss: 0.8989373532490155\n",
      "Epoch: 14 Step: 81 Loss: 0.7087279657432766\n",
      "Epoch: 14 Step: 91 Loss: 0.6782674143509626\n",
      "Epoch: 14 Step: 101 Loss: 0.5818523301392359\n",
      "Epoch: 14 Step: 111 Loss: 0.7829989409951335\n",
      "Epoch: 14 Step: 121 Loss: 0.6709719849531571\n",
      "Epoch: 14 Step: 131 Loss: 0.5776691118192069\n",
      "Epoch: 14 Step: 141 Loss: 0.8325896934003987\n",
      "Epoch: 14 Step: 151 Loss: 0.5806562521327663\n",
      "Epoch: 14 Step: 161 Loss: 0.533446293354531\n",
      "Epoch: 14 Step: 171 Loss: 0.6926011720173713\n",
      "Epoch: 14 Step: 181 Loss: 0.6372224701947113\n",
      "Epoch: 14 Step: 191 Loss: 0.5676221007948233\n",
      "Epoch: 14 Step: 201 Loss: 0.4509636462346164\n",
      "Epoch: 14 Step: 211 Loss: 0.5871600311155398\n",
      "Epoch: 14 Step: 221 Loss: 0.5899525834454842\n",
      "Epoch: 14 Step: 231 Loss: 0.7184754465844925\n",
      "Epoch: 14 Step: 241 Loss: 0.7493351666144201\n",
      "Epoch: 14 Step: 251 Loss: 0.5288644948039023\n",
      "Epoch: 14 Step: 261 Loss: 0.6641712673949358\n",
      "Epoch: 14 Step: 271 Loss: 0.5346804097516692\n",
      "Epoch: 14 Step: 281 Loss: 0.714211620860767\n",
      "Epoch: 14 Step: 291 Loss: 0.5685978514377219\n",
      "Epoch: 14 Step: 301 Loss: 0.6454826828795966\n",
      "Epoch: 14 Step: 311 Loss: 0.5499053877539807\n",
      "Epoch: 14 Step: 321 Loss: 0.7791319162854282\n",
      "Epoch: 14 Step: 331 Loss: 0.6484087125639671\n",
      "Epoch: 14 Step: 341 Loss: 0.7314981398696376\n",
      "Epoch: 14 Step: 351 Loss: 0.5629718816061203\n",
      "Epoch: 14 Step: 361 Loss: 0.7093031380856194\n",
      "Epoch: 14 Step: 371 Loss: 0.40387941632198754\n",
      "Epoch: 14 Step: 381 Loss: 0.5815188617737204\n",
      "Epoch: 14 Step: 391 Loss: 0.6766184074049186\n",
      "Epoch: 14 Step: 401 Loss: 0.8189563649095237\n",
      "Epoch: 14 Step: 411 Loss: 0.7307301262992376\n",
      "Epoch: 14 Step: 421 Loss: 0.7039278156431045\n",
      "Epoch: 14 Step: 431 Loss: 0.7684455257621379\n",
      "Epoch: 14 Step: 441 Loss: 0.49353213071851443\n",
      "Epoch: 14 Step: 451 Loss: 0.6552453434801149\n",
      "Epoch: 14 Step: 461 Loss: 0.5113309193733537\n",
      "Epoch: 14 Step: 471 Loss: 0.7094318273148145\n",
      "Epoch: 14 Step: 481 Loss: 0.730759439456642\n",
      "Epoch: 14 Step: 491 Loss: 0.7661721721936796\n",
      "Epoch: 14 Step: 501 Loss: 0.8235067162318832\n",
      "Epoch: 14 Step: 511 Loss: 0.4824400575619229\n",
      "Epoch: 14 Step: 521 Loss: 0.7157402524488499\n",
      "Epoch: 14 Step: 531 Loss: 0.5646036762946757\n",
      "Epoch: 14 Step: 541 Loss: 0.8111136938492055\n",
      "Epoch: 14 Step: 551 Loss: 0.6606732692864709\n",
      "Epoch: 14 Step: 561 Loss: 0.547978155341468\n",
      "Epoch: 14 Step: 571 Loss: 0.4365319948117341\n",
      "Epoch: 14 Step: 581 Loss: 0.6910338357795696\n",
      "Epoch: 14 Step: 591 Loss: 0.9014582034463267\n",
      "Epoch: 14 Step: 601 Loss: 0.6363809986934924\n",
      "Epoch: 14 Step: 611 Loss: 0.6476470611345975\n",
      "Epoch: 14 Step: 621 Loss: 0.611033195474079\n",
      "Epoch: 14 Step: 631 Loss: 0.699967723257795\n",
      "Epoch: 14 Step: 641 Loss: 0.6475615988762382\n",
      "Epoch: 14 Step: 651 Loss: 0.5637184594337812\n",
      "Epoch: 14 Step: 661 Loss: 0.418467190874033\n",
      "Epoch: 14 Step: 671 Loss: 0.7135039188370871\n",
      "Epoch: 14 Step: 681 Loss: 0.9120321699414075\n",
      "Epoch: 14 Step: 691 Loss: 0.7887328688714865\n",
      "Epoch: 14 Step: 701 Loss: 0.6523886608023255\n",
      "Epoch: 14 Step: 711 Loss: 0.6482693290396532\n",
      "Epoch: 14 Step: 721 Loss: 0.3902188863490734\n",
      "Epoch: 14 Step: 731 Loss: 0.4445783972158224\n",
      "Epoch: 14 Step: 741 Loss: 0.735580454682536\n",
      "Epoch: 14 Step: 751 Loss: 1.0236002649172722\n",
      "Epoch: 14 Step: 761 Loss: 0.5574122024045678\n",
      "Epoch: 14 Step: 771 Loss: 0.7634028961425703\n",
      "Epoch: 14 Step: 781 Loss: 0.8033651847480572\n",
      "Epoch: 15 Step: 1 Loss: 0.6156003310199154\n",
      "Epoch: 15 Step: 11 Loss: 0.7128600548885361\n",
      "Epoch: 15 Step: 21 Loss: 0.8645408023135075\n",
      "Epoch: 15 Step: 31 Loss: 0.8331094780725692\n",
      "Epoch: 15 Step: 41 Loss: 0.5520501606141786\n",
      "Epoch: 15 Step: 51 Loss: 0.7034927873123896\n",
      "Epoch: 15 Step: 61 Loss: 0.6349555427634185\n",
      "Epoch: 15 Step: 71 Loss: 0.6364360537897458\n",
      "Epoch: 15 Step: 81 Loss: 0.6034614867138259\n",
      "Epoch: 15 Step: 91 Loss: 0.7396940641097818\n",
      "Epoch: 15 Step: 101 Loss: 0.6538565088816868\n",
      "Epoch: 15 Step: 111 Loss: 0.6983777923308958\n",
      "Epoch: 15 Step: 121 Loss: 0.6322000160916641\n",
      "Epoch: 15 Step: 131 Loss: 0.5250719300382798\n",
      "Epoch: 15 Step: 141 Loss: 0.9527832262873471\n",
      "Epoch: 15 Step: 151 Loss: 0.6012258616789219\n",
      "Epoch: 15 Step: 161 Loss: 0.7019905006194709\n",
      "Epoch: 15 Step: 171 Loss: 0.9817856090248159\n",
      "Epoch: 15 Step: 181 Loss: 0.7485095008415243\n",
      "Epoch: 15 Step: 191 Loss: 0.6261735590189388\n",
      "Epoch: 15 Step: 201 Loss: 0.41910060898075474\n",
      "Epoch: 15 Step: 211 Loss: 0.4717813280970414\n",
      "Epoch: 15 Step: 221 Loss: 0.502459383078231\n",
      "Epoch: 15 Step: 231 Loss: 0.4698495770624351\n",
      "Epoch: 15 Step: 241 Loss: 0.5420787659415574\n",
      "Epoch: 15 Step: 251 Loss: 0.3425749397484584\n",
      "Epoch: 15 Step: 261 Loss: 0.5874227377301768\n",
      "Epoch: 15 Step: 271 Loss: 0.42807486504386105\n",
      "Epoch: 15 Step: 281 Loss: 0.5080407025716103\n",
      "Epoch: 15 Step: 291 Loss: 0.8156830995429128\n",
      "Epoch: 15 Step: 301 Loss: 0.44443711849896017\n",
      "Epoch: 15 Step: 311 Loss: 0.5509935926241534\n",
      "Epoch: 15 Step: 321 Loss: 0.7080781981215654\n",
      "Epoch: 15 Step: 331 Loss: 0.7680657834990602\n",
      "Epoch: 15 Step: 341 Loss: 0.6704011783827664\n",
      "Epoch: 15 Step: 351 Loss: 0.6061934446008398\n",
      "Epoch: 15 Step: 361 Loss: 0.7606364056061168\n",
      "Epoch: 15 Step: 371 Loss: 0.44901427840096103\n",
      "Epoch: 15 Step: 381 Loss: 0.5852892205672242\n",
      "Epoch: 15 Step: 391 Loss: 0.5532994881277924\n",
      "Epoch: 15 Step: 401 Loss: 0.5301121509397811\n",
      "Epoch: 15 Step: 411 Loss: 0.5799419599574256\n",
      "Epoch: 15 Step: 421 Loss: 0.8762325646192443\n",
      "Epoch: 15 Step: 431 Loss: 0.541053792069862\n",
      "Epoch: 15 Step: 441 Loss: 0.5919674481336072\n",
      "Epoch: 15 Step: 451 Loss: 0.5029499351809705\n",
      "Epoch: 15 Step: 461 Loss: 0.5274856189368575\n",
      "Epoch: 15 Step: 471 Loss: 0.6285359350719568\n",
      "Epoch: 15 Step: 481 Loss: 0.8316584213436707\n",
      "Epoch: 15 Step: 491 Loss: 0.8332286705987816\n",
      "Epoch: 15 Step: 501 Loss: 0.894949832848564\n",
      "Epoch: 15 Step: 511 Loss: 0.5173235392041038\n",
      "Epoch: 15 Step: 521 Loss: 0.7278851024554527\n",
      "Epoch: 15 Step: 531 Loss: 0.7389621372086712\n",
      "Epoch: 15 Step: 541 Loss: 0.534341846188248\n",
      "Epoch: 15 Step: 551 Loss: 0.6088460150799087\n",
      "Epoch: 15 Step: 561 Loss: 0.4977867804149279\n",
      "Epoch: 15 Step: 571 Loss: 0.43025339129445317\n",
      "Epoch: 15 Step: 581 Loss: 0.7726649414295632\n",
      "Epoch: 15 Step: 591 Loss: 0.544872391456817\n",
      "Epoch: 15 Step: 601 Loss: 0.6529112600247139\n",
      "Epoch: 15 Step: 611 Loss: 0.5904060278945917\n",
      "Epoch: 15 Step: 621 Loss: 0.5596339193283837\n",
      "Epoch: 15 Step: 631 Loss: 0.4745297469304659\n",
      "Epoch: 15 Step: 641 Loss: 0.6218893363481575\n",
      "Epoch: 15 Step: 651 Loss: 0.6154599439804913\n",
      "Epoch: 15 Step: 661 Loss: 0.38610177602228185\n",
      "Epoch: 15 Step: 671 Loss: 0.7269103168866551\n",
      "Epoch: 15 Step: 681 Loss: 0.8288753400360164\n",
      "Epoch: 15 Step: 691 Loss: 0.8612442174133538\n",
      "Epoch: 15 Step: 701 Loss: 0.8452786342160212\n",
      "Epoch: 15 Step: 711 Loss: 0.7763906060593073\n",
      "Epoch: 15 Step: 721 Loss: 0.4933525459598909\n",
      "Epoch: 15 Step: 731 Loss: 0.5745244142918117\n",
      "Epoch: 15 Step: 741 Loss: 0.569102798492847\n",
      "Epoch: 15 Step: 751 Loss: 0.6591673548555839\n",
      "Epoch: 15 Step: 761 Loss: 0.5776010948261366\n",
      "Epoch: 15 Step: 771 Loss: 1.007260260490152\n",
      "Epoch: 15 Step: 781 Loss: 0.5700886751224998\n",
      "Epoch: 16 Step: 1 Loss: 0.46540985569612076\n",
      "Epoch: 16 Step: 11 Loss: 0.6705428791628272\n",
      "Epoch: 16 Step: 21 Loss: 0.6505883301190571\n",
      "Epoch: 16 Step: 31 Loss: 0.5424080100075346\n",
      "Epoch: 16 Step: 41 Loss: 0.4246581951012304\n",
      "Epoch: 16 Step: 51 Loss: 0.49392120214047663\n",
      "Epoch: 16 Step: 61 Loss: 0.6260728211673341\n",
      "Epoch: 16 Step: 71 Loss: 0.5345440523260037\n",
      "Epoch: 16 Step: 81 Loss: 0.6243082338867327\n",
      "Epoch: 16 Step: 91 Loss: 0.8416358045341472\n",
      "Epoch: 16 Step: 101 Loss: 0.5766212474189645\n",
      "Epoch: 16 Step: 111 Loss: 0.890128021189829\n",
      "Epoch: 16 Step: 121 Loss: 0.8300037028254632\n",
      "Epoch: 16 Step: 131 Loss: 0.5820688631777304\n",
      "Epoch: 16 Step: 141 Loss: 0.9448251587615903\n",
      "Epoch: 16 Step: 151 Loss: 0.5668738196134245\n",
      "Epoch: 16 Step: 161 Loss: 0.5851912156071744\n",
      "Epoch: 16 Step: 171 Loss: 0.673638134506429\n",
      "Epoch: 16 Step: 181 Loss: 0.5565955279009643\n",
      "Epoch: 16 Step: 191 Loss: 0.46955830959118\n",
      "Epoch: 16 Step: 201 Loss: 0.34651348581622643\n",
      "Epoch: 16 Step: 211 Loss: 0.38572311996684705\n",
      "Epoch: 16 Step: 221 Loss: 0.3992203160571778\n",
      "Epoch: 16 Step: 231 Loss: 0.5457369091584008\n",
      "Epoch: 16 Step: 241 Loss: 0.47124011780962854\n",
      "Epoch: 16 Step: 251 Loss: 0.35983366334310163\n",
      "Epoch: 16 Step: 261 Loss: 0.7541138375096612\n",
      "Epoch: 16 Step: 271 Loss: 0.5087389409510413\n",
      "Epoch: 16 Step: 281 Loss: 0.6370964390255576\n",
      "Epoch: 16 Step: 291 Loss: 0.7859190001551131\n",
      "Epoch: 16 Step: 301 Loss: 0.7021446665992122\n",
      "Epoch: 16 Step: 311 Loss: 0.6963744471638711\n",
      "Epoch: 16 Step: 321 Loss: 0.9958879342353888\n",
      "Epoch: 16 Step: 331 Loss: 0.6945824929527601\n",
      "Epoch: 16 Step: 341 Loss: 0.6242299893683567\n",
      "Epoch: 16 Step: 351 Loss: 0.573499833183826\n",
      "Epoch: 16 Step: 361 Loss: 0.6362266449145458\n",
      "Epoch: 16 Step: 371 Loss: 0.5647313500665639\n",
      "Epoch: 16 Step: 381 Loss: 0.5100483673266438\n",
      "Epoch: 16 Step: 391 Loss: 0.33061144701587475\n",
      "Epoch: 16 Step: 401 Loss: 0.5491793052161638\n",
      "Epoch: 16 Step: 411 Loss: 0.3766796076180492\n",
      "Epoch: 16 Step: 421 Loss: 0.7487043637522092\n",
      "Epoch: 16 Step: 431 Loss: 0.538770452511546\n",
      "Epoch: 16 Step: 441 Loss: 0.32152036322827765\n",
      "Epoch: 16 Step: 451 Loss: 0.5993860011940673\n",
      "Epoch: 16 Step: 461 Loss: 0.6357425494643837\n",
      "Epoch: 16 Step: 471 Loss: 0.876327519260647\n",
      "Epoch: 16 Step: 481 Loss: 0.9578191601543766\n",
      "Epoch: 16 Step: 491 Loss: 0.8734713685936824\n",
      "Epoch: 16 Step: 501 Loss: 0.748316221575024\n",
      "Epoch: 16 Step: 511 Loss: 0.3182514076078595\n",
      "Epoch: 16 Step: 521 Loss: 0.7994184338423338\n",
      "Epoch: 16 Step: 531 Loss: 0.6183771088960028\n",
      "Epoch: 16 Step: 541 Loss: 0.6361191986302612\n",
      "Epoch: 16 Step: 551 Loss: 0.5816691290327658\n",
      "Epoch: 16 Step: 561 Loss: 0.32925136212564454\n",
      "Epoch: 16 Step: 571 Loss: 0.3942273208565289\n",
      "Epoch: 16 Step: 581 Loss: 0.7371497682410308\n",
      "Epoch: 16 Step: 591 Loss: 0.5863445772956245\n",
      "Epoch: 16 Step: 601 Loss: 0.4202333405639724\n",
      "Epoch: 16 Step: 611 Loss: 0.6151877970806867\n",
      "Epoch: 16 Step: 621 Loss: 0.6076022247416718\n",
      "Epoch: 16 Step: 631 Loss: 0.5073173938721309\n",
      "Epoch: 16 Step: 641 Loss: 0.657265570703345\n",
      "Epoch: 16 Step: 651 Loss: 0.5614525787471171\n",
      "Epoch: 16 Step: 661 Loss: 0.5204474882650225\n",
      "Epoch: 16 Step: 671 Loss: 0.7806985049440349\n",
      "Epoch: 16 Step: 681 Loss: 0.7351877225794329\n",
      "Epoch: 16 Step: 691 Loss: 0.7884745595852238\n",
      "Epoch: 16 Step: 701 Loss: 0.7034899031724282\n",
      "Epoch: 16 Step: 711 Loss: 0.5754387972210268\n",
      "Epoch: 16 Step: 721 Loss: 0.37823306065703843\n",
      "Epoch: 16 Step: 731 Loss: 0.35291089343750415\n",
      "Epoch: 16 Step: 741 Loss: 0.45050861182320917\n",
      "Epoch: 16 Step: 751 Loss: 0.6048558667548886\n",
      "Epoch: 16 Step: 761 Loss: 0.4975040815344989\n",
      "Epoch: 16 Step: 771 Loss: 0.6225365488685\n",
      "Epoch: 16 Step: 781 Loss: 0.5528448840573327\n",
      "Epoch: 17 Step: 1 Loss: 0.4139225323358713\n",
      "Epoch: 17 Step: 11 Loss: 0.6118565013396853\n",
      "Epoch: 17 Step: 21 Loss: 0.6106082270240594\n",
      "Epoch: 17 Step: 31 Loss: 0.8496780012776795\n",
      "Epoch: 17 Step: 41 Loss: 0.521399832588041\n",
      "Epoch: 17 Step: 51 Loss: 0.6536463252749035\n",
      "Epoch: 17 Step: 61 Loss: 0.8678348477629292\n",
      "Epoch: 17 Step: 71 Loss: 0.7675620409856256\n",
      "Epoch: 17 Step: 81 Loss: 0.6436234319440128\n",
      "Epoch: 17 Step: 91 Loss: 0.5556482943799357\n",
      "Epoch: 17 Step: 101 Loss: 0.5855155159942527\n",
      "Epoch: 17 Step: 111 Loss: 0.5945765490460331\n",
      "Epoch: 17 Step: 121 Loss: 0.45353105576800545\n",
      "Epoch: 17 Step: 131 Loss: 0.4302848334416012\n",
      "Epoch: 17 Step: 141 Loss: 0.7469435420076982\n",
      "Epoch: 17 Step: 151 Loss: 0.43965434134433345\n",
      "Epoch: 17 Step: 161 Loss: 0.5206530779510739\n",
      "Epoch: 17 Step: 171 Loss: 0.4884047908454909\n",
      "Epoch: 17 Step: 181 Loss: 0.460657835214669\n",
      "Epoch: 17 Step: 191 Loss: 0.6346309027164694\n",
      "Epoch: 17 Step: 201 Loss: 0.2999062526139413\n",
      "Epoch: 17 Step: 211 Loss: 0.4518776853496162\n",
      "Epoch: 17 Step: 221 Loss: 0.4436051015083755\n",
      "Epoch: 17 Step: 231 Loss: 0.6332763754014733\n",
      "Epoch: 17 Step: 241 Loss: 0.6220352955812876\n",
      "Epoch: 17 Step: 251 Loss: 0.5574121718352167\n",
      "Epoch: 17 Step: 261 Loss: 0.7592630628189403\n",
      "Epoch: 17 Step: 271 Loss: 0.43246339916657234\n",
      "Epoch: 17 Step: 281 Loss: 0.47175492773314714\n",
      "Epoch: 17 Step: 291 Loss: 0.5792933213564369\n",
      "Epoch: 17 Step: 301 Loss: 0.7314040667685271\n",
      "Epoch: 17 Step: 311 Loss: 0.565167077779098\n",
      "Epoch: 17 Step: 321 Loss: 0.6820286943725644\n",
      "Epoch: 17 Step: 331 Loss: 0.5144059208559575\n",
      "Epoch: 17 Step: 341 Loss: 0.5840971942946024\n",
      "Epoch: 17 Step: 351 Loss: 0.4668249713726472\n",
      "Epoch: 17 Step: 361 Loss: 0.3902206343126261\n",
      "Epoch: 17 Step: 371 Loss: 0.33115920807473964\n",
      "Epoch: 17 Step: 381 Loss: 0.44936090555058816\n",
      "Epoch: 17 Step: 391 Loss: 0.42347493896339783\n",
      "Epoch: 17 Step: 401 Loss: 0.46126166125938706\n",
      "Epoch: 17 Step: 411 Loss: 0.3938317436556389\n",
      "Epoch: 17 Step: 421 Loss: 0.7401659298076897\n",
      "Epoch: 17 Step: 431 Loss: 0.598720335461775\n",
      "Epoch: 17 Step: 441 Loss: 0.5688257612807087\n",
      "Epoch: 17 Step: 451 Loss: 0.4412692083741554\n",
      "Epoch: 17 Step: 461 Loss: 0.539582089699445\n",
      "Epoch: 17 Step: 471 Loss: 0.7351698372475479\n",
      "Epoch: 17 Step: 481 Loss: 0.7873008505157437\n",
      "Epoch: 17 Step: 491 Loss: 0.7744850080473467\n",
      "Epoch: 17 Step: 501 Loss: 0.6194096747738878\n",
      "Epoch: 17 Step: 511 Loss: 0.35068304160057984\n",
      "Epoch: 17 Step: 521 Loss: 0.5788525704828286\n",
      "Epoch: 17 Step: 531 Loss: 0.5105519728980011\n",
      "Epoch: 17 Step: 541 Loss: 0.6585313620017954\n",
      "Epoch: 17 Step: 551 Loss: 0.48797937710837735\n",
      "Epoch: 17 Step: 561 Loss: 0.460493087287536\n",
      "Epoch: 17 Step: 571 Loss: 0.4107242888815498\n",
      "Epoch: 17 Step: 581 Loss: 0.5861042684337279\n",
      "Epoch: 17 Step: 591 Loss: 0.5966139326677298\n",
      "Epoch: 17 Step: 601 Loss: 0.5812867118003417\n",
      "Epoch: 17 Step: 611 Loss: 0.730664366339432\n",
      "Epoch: 17 Step: 621 Loss: 0.571669813766266\n",
      "Epoch: 17 Step: 631 Loss: 0.5474232073910592\n",
      "Epoch: 17 Step: 641 Loss: 0.676197348524544\n",
      "Epoch: 17 Step: 651 Loss: 0.4524228446695173\n",
      "Epoch: 17 Step: 661 Loss: 0.44340827708364194\n",
      "Epoch: 17 Step: 671 Loss: 0.7674906955232983\n",
      "Epoch: 17 Step: 681 Loss: 0.6184970005099235\n",
      "Epoch: 17 Step: 691 Loss: 0.5457485930071833\n",
      "Epoch: 17 Step: 701 Loss: 0.5582395635969424\n",
      "Epoch: 17 Step: 711 Loss: 0.49821187729279953\n",
      "Epoch: 17 Step: 721 Loss: 0.3658481303854869\n",
      "Epoch: 17 Step: 731 Loss: 0.34442605968421397\n",
      "Epoch: 17 Step: 741 Loss: 0.5064346609399851\n",
      "Epoch: 17 Step: 751 Loss: 0.4405799354744717\n",
      "Epoch: 17 Step: 761 Loss: 0.5299359842261491\n",
      "Epoch: 17 Step: 771 Loss: 1.0255341250793264\n",
      "Epoch: 17 Step: 781 Loss: 0.5730159780460267\n",
      "Epoch: 18 Step: 1 Loss: 0.4725888524879346\n",
      "Epoch: 18 Step: 11 Loss: 0.6784157658156915\n",
      "Epoch: 18 Step: 21 Loss: 0.7591323679723493\n",
      "Epoch: 18 Step: 31 Loss: 0.7708104412137532\n",
      "Epoch: 18 Step: 41 Loss: 0.5745369404490245\n",
      "Epoch: 18 Step: 51 Loss: 0.5343771882502837\n",
      "Epoch: 18 Step: 61 Loss: 0.6861299615069416\n",
      "Epoch: 18 Step: 71 Loss: 0.6220898254032444\n",
      "Epoch: 18 Step: 81 Loss: 0.507477199798769\n",
      "Epoch: 18 Step: 91 Loss: 0.6436290557696492\n",
      "Epoch: 18 Step: 101 Loss: 0.3975138185384616\n",
      "Epoch: 18 Step: 111 Loss: 0.7067128276760593\n",
      "Epoch: 18 Step: 121 Loss: 0.472318205621846\n",
      "Epoch: 18 Step: 131 Loss: 0.5399189415548453\n",
      "Epoch: 18 Step: 141 Loss: 0.8214930677661887\n",
      "Epoch: 18 Step: 151 Loss: 0.482536571302904\n",
      "Epoch: 18 Step: 161 Loss: 0.6537948676527778\n",
      "Epoch: 18 Step: 171 Loss: 0.809925734123776\n",
      "Epoch: 18 Step: 181 Loss: 0.4249126633472805\n",
      "Epoch: 18 Step: 191 Loss: 0.7626519803164536\n",
      "Epoch: 18 Step: 201 Loss: 0.36584169404959127\n",
      "Epoch: 18 Step: 211 Loss: 0.5255699050005739\n",
      "Epoch: 18 Step: 221 Loss: 0.6354825893781062\n",
      "Epoch: 18 Step: 231 Loss: 0.47601250496448877\n",
      "Epoch: 18 Step: 241 Loss: 0.5906551593636696\n",
      "Epoch: 18 Step: 251 Loss: 0.34144022074727964\n",
      "Epoch: 18 Step: 261 Loss: 0.6796249648803618\n",
      "Epoch: 18 Step: 271 Loss: 0.4196847669963459\n",
      "Epoch: 18 Step: 281 Loss: 0.4849663990216845\n",
      "Epoch: 18 Step: 291 Loss: 0.5930170400634867\n",
      "Epoch: 18 Step: 301 Loss: 0.531224932820771\n",
      "Epoch: 18 Step: 311 Loss: 0.6351904169125374\n",
      "Epoch: 18 Step: 321 Loss: 0.7138348697465627\n",
      "Epoch: 18 Step: 331 Loss: 0.45417480160275076\n",
      "Epoch: 18 Step: 341 Loss: 0.44001066662012167\n",
      "Epoch: 18 Step: 351 Loss: 0.5432997431251714\n",
      "Epoch: 18 Step: 361 Loss: 0.48444586519407407\n",
      "Epoch: 18 Step: 371 Loss: 0.5451013488733245\n",
      "Epoch: 18 Step: 381 Loss: 0.6684941691078774\n",
      "Epoch: 18 Step: 391 Loss: 0.49281582668010826\n",
      "Epoch: 18 Step: 401 Loss: 0.5301142038973183\n",
      "Epoch: 18 Step: 411 Loss: 0.5277003906367395\n",
      "Epoch: 18 Step: 421 Loss: 0.7757229909910763\n",
      "Epoch: 18 Step: 431 Loss: 0.57314952094052\n",
      "Epoch: 18 Step: 441 Loss: 0.329190015430604\n",
      "Epoch: 18 Step: 451 Loss: 0.40048333401473823\n",
      "Epoch: 18 Step: 461 Loss: 0.5130715484923847\n",
      "Epoch: 18 Step: 471 Loss: 0.5305622051463976\n",
      "Epoch: 18 Step: 481 Loss: 0.6798639341286798\n",
      "Epoch: 18 Step: 491 Loss: 0.6051305414272088\n",
      "Epoch: 18 Step: 501 Loss: 0.7039748301214594\n",
      "Epoch: 18 Step: 511 Loss: 0.3529852397142307\n",
      "Epoch: 18 Step: 521 Loss: 0.49153621206833914\n",
      "Epoch: 18 Step: 531 Loss: 0.47064065372643504\n",
      "Epoch: 18 Step: 541 Loss: 0.40736608606321234\n",
      "Epoch: 18 Step: 551 Loss: 0.6297535172715953\n",
      "Epoch: 18 Step: 561 Loss: 0.5589792812273942\n",
      "Epoch: 18 Step: 571 Loss: 0.5868913437321328\n",
      "Epoch: 18 Step: 581 Loss: 0.47597658691332123\n",
      "Epoch: 18 Step: 591 Loss: 0.5365763509870813\n",
      "Epoch: 18 Step: 601 Loss: 0.3845970609480417\n",
      "Epoch: 18 Step: 611 Loss: 0.5476251859315353\n",
      "Epoch: 18 Step: 621 Loss: 0.5199622538926183\n",
      "Epoch: 18 Step: 631 Loss: 0.4471988034953066\n",
      "Epoch: 18 Step: 641 Loss: 0.3678538105137011\n",
      "Epoch: 18 Step: 651 Loss: 0.44368153085781736\n",
      "Epoch: 18 Step: 661 Loss: 0.30903990904849143\n",
      "Epoch: 18 Step: 671 Loss: 0.6333209083296238\n",
      "Epoch: 18 Step: 681 Loss: 0.7122723566489779\n",
      "Epoch: 18 Step: 691 Loss: 0.5171617664172931\n",
      "Epoch: 18 Step: 701 Loss: 0.5095948863196708\n",
      "Epoch: 18 Step: 711 Loss: 0.5159661359536586\n",
      "Epoch: 18 Step: 721 Loss: 0.44937054737589166\n",
      "Epoch: 18 Step: 731 Loss: 0.4599830595170966\n",
      "Epoch: 18 Step: 741 Loss: 0.6469193883738739\n",
      "Epoch: 18 Step: 751 Loss: 0.5500457019201606\n",
      "Epoch: 18 Step: 761 Loss: 0.5403099793811073\n",
      "Epoch: 18 Step: 771 Loss: 0.7460687452106165\n",
      "Epoch: 18 Step: 781 Loss: 0.5287620811692155\n",
      "Epoch: 19 Step: 1 Loss: 0.35692078391264603\n",
      "Epoch: 19 Step: 11 Loss: 0.4475016998404052\n",
      "Epoch: 19 Step: 21 Loss: 0.3550882905084989\n",
      "Epoch: 19 Step: 31 Loss: 0.6347130603456936\n",
      "Epoch: 19 Step: 41 Loss: 0.48549150080283465\n",
      "Epoch: 19 Step: 51 Loss: 0.3566756787414961\n",
      "Epoch: 19 Step: 61 Loss: 0.4451235734062595\n",
      "Epoch: 19 Step: 71 Loss: 0.4442039047979839\n",
      "Epoch: 19 Step: 81 Loss: 0.4159840722273137\n",
      "Epoch: 19 Step: 91 Loss: 0.4314744486333404\n",
      "Epoch: 19 Step: 101 Loss: 0.5399047506724021\n",
      "Epoch: 19 Step: 111 Loss: 0.5459096589310396\n",
      "Epoch: 19 Step: 121 Loss: 0.5093098602106331\n",
      "Epoch: 19 Step: 131 Loss: 0.5547950899060097\n",
      "Epoch: 19 Step: 141 Loss: 0.7906766241171062\n",
      "Epoch: 19 Step: 151 Loss: 0.5618993634896371\n",
      "Epoch: 19 Step: 161 Loss: 0.5288479357217428\n",
      "Epoch: 19 Step: 171 Loss: 0.5727816311646898\n",
      "Epoch: 19 Step: 181 Loss: 0.43811884898086445\n",
      "Epoch: 19 Step: 191 Loss: 0.4583698106293287\n",
      "Epoch: 19 Step: 201 Loss: 0.2890207673511587\n",
      "Epoch: 19 Step: 211 Loss: 0.553827537722688\n",
      "Epoch: 19 Step: 221 Loss: 0.34264006949909476\n",
      "Epoch: 19 Step: 231 Loss: 0.376762356588331\n",
      "Epoch: 19 Step: 241 Loss: 0.532367008277001\n",
      "Epoch: 19 Step: 251 Loss: 0.34032471954495647\n",
      "Epoch: 19 Step: 261 Loss: 0.6535259450944556\n",
      "Epoch: 19 Step: 271 Loss: 0.38843181706440316\n",
      "Epoch: 19 Step: 281 Loss: 0.3220418331842785\n",
      "Epoch: 19 Step: 291 Loss: 0.7557699017937191\n",
      "Epoch: 19 Step: 301 Loss: 0.5444638295366412\n",
      "Epoch: 19 Step: 311 Loss: 0.511641255168561\n",
      "Epoch: 19 Step: 321 Loss: 0.47433577108886377\n",
      "Epoch: 19 Step: 331 Loss: 0.6261209608409559\n",
      "Epoch: 19 Step: 341 Loss: 0.6326057012529389\n",
      "Epoch: 19 Step: 351 Loss: 0.5231816613697626\n",
      "Epoch: 19 Step: 361 Loss: 0.47056392300462635\n",
      "Epoch: 19 Step: 371 Loss: 0.3633523759655678\n",
      "Epoch: 19 Step: 381 Loss: 0.5337148261812608\n",
      "Epoch: 19 Step: 391 Loss: 0.3374048509481069\n",
      "Epoch: 19 Step: 401 Loss: 0.45546073269191045\n",
      "Epoch: 19 Step: 411 Loss: 0.2171759366715565\n",
      "Epoch: 19 Step: 421 Loss: 0.4894487589814956\n",
      "Epoch: 19 Step: 431 Loss: 0.4652417481109158\n",
      "Epoch: 19 Step: 441 Loss: 0.3985235927748738\n",
      "Epoch: 19 Step: 451 Loss: 0.25630372828057046\n",
      "Epoch: 19 Step: 461 Loss: 0.5202994314927021\n",
      "Epoch: 19 Step: 471 Loss: 0.6062710994456899\n",
      "Epoch: 19 Step: 481 Loss: 1.0075926204672365\n",
      "Epoch: 19 Step: 491 Loss: 0.8112923015909064\n",
      "Epoch: 19 Step: 501 Loss: 0.7188784938002618\n",
      "Epoch: 19 Step: 511 Loss: 0.3910711316373865\n",
      "Epoch: 19 Step: 521 Loss: 0.7002337516721082\n",
      "Epoch: 19 Step: 531 Loss: 0.39775897323671217\n",
      "Epoch: 19 Step: 541 Loss: 0.48630637557532863\n",
      "Epoch: 19 Step: 551 Loss: 0.5378569197920334\n",
      "Epoch: 19 Step: 561 Loss: 0.33711761495919257\n",
      "Epoch: 19 Step: 571 Loss: 0.3589571902933841\n",
      "Epoch: 19 Step: 581 Loss: 0.5146246206953085\n",
      "Epoch: 19 Step: 591 Loss: 0.29877745402448797\n",
      "Epoch: 19 Step: 601 Loss: 0.5711754732966492\n",
      "Epoch: 19 Step: 611 Loss: 0.4689680937150803\n",
      "Epoch: 19 Step: 621 Loss: 0.3759817315233105\n",
      "Epoch: 19 Step: 631 Loss: 0.3673006415869306\n",
      "Epoch: 19 Step: 641 Loss: 0.3502325727866782\n",
      "Epoch: 19 Step: 651 Loss: 0.4181856904762585\n",
      "Epoch: 19 Step: 661 Loss: 0.35681618623597905\n",
      "Epoch: 19 Step: 671 Loss: 0.7467334214952781\n",
      "Epoch: 19 Step: 681 Loss: 0.6361000306941289\n",
      "Epoch: 19 Step: 691 Loss: 0.7415621529329216\n",
      "Epoch: 19 Step: 701 Loss: 0.625135778671372\n",
      "Epoch: 19 Step: 711 Loss: 0.5845656067707075\n",
      "Epoch: 19 Step: 721 Loss: 0.3530543870256375\n",
      "Epoch: 19 Step: 731 Loss: 0.26672105815828806\n",
      "Epoch: 19 Step: 741 Loss: 0.44458909755983517\n",
      "Epoch: 19 Step: 751 Loss: 0.6507779518926687\n",
      "Epoch: 19 Step: 761 Loss: 0.36943965485911356\n",
      "Epoch: 19 Step: 771 Loss: 0.5700506828324892\n",
      "Epoch: 19 Step: 781 Loss: 0.4659512981754889\n",
      "Epoch: 20 Step: 1 Loss: 0.5952863858748126\n",
      "Epoch: 20 Step: 11 Loss: 0.48203174721980246\n",
      "Epoch: 20 Step: 21 Loss: 0.45440805528332706\n",
      "Epoch: 20 Step: 31 Loss: 0.4559166221922377\n",
      "Epoch: 20 Step: 41 Loss: 0.24631288909101504\n",
      "Epoch: 20 Step: 51 Loss: 0.4885816388078998\n",
      "Epoch: 20 Step: 61 Loss: 0.5212223199237215\n",
      "Epoch: 20 Step: 71 Loss: 0.8445146665844372\n",
      "Epoch: 20 Step: 81 Loss: 0.7323217269210398\n",
      "Epoch: 20 Step: 91 Loss: 0.4958250583263951\n",
      "Epoch: 20 Step: 101 Loss: 0.4449065888877617\n",
      "Epoch: 20 Step: 111 Loss: 0.6339601534970184\n",
      "Epoch: 20 Step: 121 Loss: 0.4461324933728984\n",
      "Epoch: 20 Step: 131 Loss: 0.34408026786311374\n",
      "Epoch: 20 Step: 141 Loss: 0.6518336944365333\n",
      "Epoch: 20 Step: 151 Loss: 0.39846269433030607\n",
      "Epoch: 20 Step: 161 Loss: 0.41681968152395843\n",
      "Epoch: 20 Step: 171 Loss: 0.3828499530994596\n",
      "Epoch: 20 Step: 181 Loss: 0.3288555994230742\n",
      "Epoch: 20 Step: 191 Loss: 0.4914337010080407\n",
      "Epoch: 20 Step: 201 Loss: 0.3285336003001672\n",
      "Epoch: 20 Step: 211 Loss: 0.3058336481111505\n",
      "Epoch: 20 Step: 221 Loss: 0.3359602064174533\n",
      "Epoch: 20 Step: 231 Loss: 0.27050808218026123\n",
      "Epoch: 20 Step: 241 Loss: 0.49723796496102224\n",
      "Epoch: 20 Step: 251 Loss: 0.4400447089311673\n",
      "Epoch: 20 Step: 261 Loss: 0.787605919412186\n",
      "Epoch: 20 Step: 271 Loss: 0.3938765943476881\n",
      "Epoch: 20 Step: 281 Loss: 0.3374981947699224\n",
      "Epoch: 20 Step: 291 Loss: 0.4615825244872166\n",
      "Epoch: 20 Step: 301 Loss: 0.586534682790256\n",
      "Epoch: 20 Step: 311 Loss: 0.47905060285989276\n",
      "Epoch: 20 Step: 321 Loss: 0.5643340416432794\n",
      "Epoch: 20 Step: 331 Loss: 0.6637897810400237\n",
      "Epoch: 20 Step: 341 Loss: 0.3782513277206334\n",
      "Epoch: 20 Step: 351 Loss: 0.2738958529292986\n",
      "Epoch: 20 Step: 361 Loss: 0.3609903798318588\n",
      "Epoch: 20 Step: 371 Loss: 0.4093820110836798\n",
      "Epoch: 20 Step: 381 Loss: 0.4225121151474654\n",
      "Epoch: 20 Step: 391 Loss: 0.2706522540833644\n",
      "Epoch: 20 Step: 401 Loss: 0.33880731241784545\n",
      "Epoch: 20 Step: 411 Loss: 0.276748100017452\n",
      "Epoch: 20 Step: 421 Loss: 0.5287870025731216\n",
      "Epoch: 20 Step: 431 Loss: 0.6112159522549159\n",
      "Epoch: 20 Step: 441 Loss: 0.38842742574403055\n",
      "Epoch: 20 Step: 451 Loss: 0.5590227459232129\n",
      "Epoch: 20 Step: 461 Loss: 0.49497702239146085\n",
      "Epoch: 20 Step: 471 Loss: 0.41034546225776586\n",
      "Epoch: 20 Step: 481 Loss: 0.7868873441556354\n",
      "Epoch: 20 Step: 491 Loss: 0.6462102475050602\n",
      "Epoch: 20 Step: 501 Loss: 0.5514970948405681\n",
      "Epoch: 20 Step: 511 Loss: 0.4392691598237848\n",
      "Epoch: 20 Step: 521 Loss: 0.6078997003995498\n",
      "Epoch: 20 Step: 531 Loss: 0.46726724514814466\n",
      "Epoch: 20 Step: 541 Loss: 0.4474565872608454\n",
      "Epoch: 20 Step: 551 Loss: 0.43051435215786515\n",
      "Epoch: 20 Step: 561 Loss: 0.38535214643133364\n",
      "Epoch: 20 Step: 571 Loss: 0.3850009834954421\n",
      "Epoch: 20 Step: 581 Loss: 0.3654013154252575\n",
      "Epoch: 20 Step: 591 Loss: 0.4205464023390407\n",
      "Epoch: 20 Step: 601 Loss: 0.46493579068058\n",
      "Epoch: 20 Step: 611 Loss: 0.4742419071425533\n",
      "Epoch: 20 Step: 621 Loss: 0.3914809439203736\n",
      "Epoch: 20 Step: 631 Loss: 0.34723271245235504\n",
      "Epoch: 20 Step: 641 Loss: 0.41330338346425355\n",
      "Epoch: 20 Step: 651 Loss: 0.5989170598866499\n",
      "Epoch: 20 Step: 661 Loss: 0.28200467800018747\n",
      "Epoch: 20 Step: 671 Loss: 0.49490312333607706\n",
      "Epoch: 20 Step: 681 Loss: 0.5253464008429318\n",
      "Epoch: 20 Step: 691 Loss: 0.5760433031329677\n",
      "Epoch: 20 Step: 701 Loss: 0.5039108091907363\n",
      "Epoch: 20 Step: 711 Loss: 0.4566236382878919\n",
      "Epoch: 20 Step: 721 Loss: 0.4871114642283635\n",
      "Epoch: 20 Step: 731 Loss: 0.21188381407831003\n",
      "Epoch: 20 Step: 741 Loss: 0.38809371099022466\n",
      "Epoch: 20 Step: 751 Loss: 0.36200654843782026\n",
      "Epoch: 20 Step: 761 Loss: 0.5993903868291609\n",
      "Epoch: 20 Step: 771 Loss: 0.5482611200715692\n",
      "Epoch: 20 Step: 781 Loss: 0.4864872129906312\n",
      "Epoch: 21 Step: 1 Loss: 0.6624288013585006\n",
      "Epoch: 21 Step: 11 Loss: 0.3463943198094942\n",
      "Epoch: 21 Step: 21 Loss: 0.7775905422552775\n",
      "Epoch: 21 Step: 31 Loss: 0.5053564071685852\n",
      "Epoch: 21 Step: 41 Loss: 0.41883197791848303\n",
      "Epoch: 21 Step: 51 Loss: 0.5431079727845707\n",
      "Epoch: 21 Step: 61 Loss: 0.5377549456845894\n",
      "Epoch: 21 Step: 71 Loss: 0.5178796355291029\n",
      "Epoch: 21 Step: 81 Loss: 0.3137552370913337\n",
      "Epoch: 21 Step: 91 Loss: 0.48125753449942504\n",
      "Epoch: 21 Step: 101 Loss: 0.4640350272522591\n",
      "Epoch: 21 Step: 111 Loss: 0.5669608908680761\n",
      "Epoch: 21 Step: 121 Loss: 0.2824429369448357\n",
      "Epoch: 21 Step: 131 Loss: 0.34974755151201986\n",
      "Epoch: 21 Step: 141 Loss: 0.605678399694158\n",
      "Epoch: 21 Step: 151 Loss: 0.4167944914614019\n",
      "Epoch: 21 Step: 161 Loss: 0.359970347575964\n",
      "Epoch: 21 Step: 171 Loss: 0.3806558192394187\n",
      "Epoch: 21 Step: 181 Loss: 0.368101073262201\n",
      "Epoch: 21 Step: 191 Loss: 0.4084300138868509\n",
      "Epoch: 21 Step: 201 Loss: 0.43061320041161677\n",
      "Epoch: 21 Step: 211 Loss: 0.48396120561255684\n",
      "Epoch: 21 Step: 221 Loss: 0.4368729300462093\n",
      "Epoch: 21 Step: 231 Loss: 0.26459866820678335\n",
      "Epoch: 21 Step: 241 Loss: 0.4314236871348599\n",
      "Epoch: 21 Step: 251 Loss: 0.2731976686164681\n",
      "Epoch: 21 Step: 261 Loss: 0.36188522834051157\n",
      "Epoch: 21 Step: 271 Loss: 0.4796160928941947\n",
      "Epoch: 21 Step: 281 Loss: 0.44397703606680106\n",
      "Epoch: 21 Step: 291 Loss: 0.497286031202139\n",
      "Epoch: 21 Step: 301 Loss: 0.4792274478097933\n",
      "Epoch: 21 Step: 311 Loss: 0.43774780684669146\n",
      "Epoch: 21 Step: 321 Loss: 0.5239939820215072\n",
      "Epoch: 21 Step: 331 Loss: 0.6887899830354225\n",
      "Epoch: 21 Step: 341 Loss: 0.476676274451933\n",
      "Epoch: 21 Step: 351 Loss: 0.30276585937422124\n",
      "Epoch: 21 Step: 361 Loss: 0.4038607224777935\n",
      "Epoch: 21 Step: 371 Loss: 0.4203621692306833\n",
      "Epoch: 21 Step: 381 Loss: 0.37813213638381793\n",
      "Epoch: 21 Step: 391 Loss: 0.5035551319079601\n",
      "Epoch: 21 Step: 401 Loss: 0.6323845550999811\n",
      "Epoch: 21 Step: 411 Loss: 0.3114390163094516\n",
      "Epoch: 21 Step: 421 Loss: 0.8366576182967812\n",
      "Epoch: 21 Step: 431 Loss: 0.6280559981018365\n",
      "Epoch: 21 Step: 441 Loss: 0.4263622029110593\n",
      "Epoch: 21 Step: 451 Loss: 0.41669722902873274\n",
      "Epoch: 21 Step: 461 Loss: 0.3770441097773761\n",
      "Epoch: 21 Step: 471 Loss: 0.4723296441353041\n",
      "Epoch: 21 Step: 481 Loss: 0.5486239018899975\n",
      "Epoch: 21 Step: 491 Loss: 0.4249348368966456\n",
      "Epoch: 21 Step: 501 Loss: 0.5577079866795456\n",
      "Epoch: 21 Step: 511 Loss: 0.24855785143547798\n",
      "Epoch: 21 Step: 521 Loss: 0.6305160851594084\n",
      "Epoch: 21 Step: 531 Loss: 0.38186306879373694\n",
      "Epoch: 21 Step: 541 Loss: 0.36830242314176653\n",
      "Epoch: 21 Step: 551 Loss: 0.5094667440622422\n",
      "Epoch: 21 Step: 561 Loss: 0.40765093037980316\n",
      "Epoch: 21 Step: 571 Loss: 0.526798651305064\n",
      "Epoch: 21 Step: 581 Loss: 0.555581259228162\n",
      "Epoch: 21 Step: 591 Loss: 0.5302403879458109\n",
      "Epoch: 21 Step: 601 Loss: 0.5024836333768291\n",
      "Epoch: 21 Step: 611 Loss: 0.356496579860246\n",
      "Epoch: 21 Step: 621 Loss: 0.3911080241430628\n",
      "Epoch: 21 Step: 631 Loss: 0.39275830714253024\n",
      "Epoch: 21 Step: 641 Loss: 0.5627619998723878\n",
      "Epoch: 21 Step: 651 Loss: 0.41386915665522406\n",
      "Epoch: 21 Step: 661 Loss: 0.27170480788536144\n",
      "Epoch: 21 Step: 671 Loss: 0.5570445166932158\n",
      "Epoch: 21 Step: 681 Loss: 0.7935584399153568\n",
      "Epoch: 21 Step: 691 Loss: 0.4948734992372288\n",
      "Epoch: 21 Step: 701 Loss: 0.4620306670041662\n",
      "Epoch: 21 Step: 711 Loss: 0.4106825171401863\n",
      "Epoch: 21 Step: 721 Loss: 0.4523660315068573\n",
      "Epoch: 21 Step: 731 Loss: 0.27123684358897127\n",
      "Epoch: 21 Step: 741 Loss: 0.4449843912636234\n",
      "Epoch: 21 Step: 751 Loss: 0.621812650455769\n",
      "Epoch: 21 Step: 761 Loss: 0.6528870462230334\n",
      "Epoch: 21 Step: 771 Loss: 0.6126446234138736\n",
      "Epoch: 21 Step: 781 Loss: 0.5438717449773259\n",
      "Epoch: 22 Step: 1 Loss: 0.3165865927391146\n",
      "Epoch: 22 Step: 11 Loss: 0.38932079576337275\n",
      "Epoch: 22 Step: 21 Loss: 0.34774279329891855\n",
      "Epoch: 22 Step: 31 Loss: 0.4401009356280193\n",
      "Epoch: 22 Step: 41 Loss: 0.2727251908812097\n",
      "Epoch: 22 Step: 51 Loss: 0.35061516873095944\n",
      "Epoch: 22 Step: 61 Loss: 0.38410552591784336\n",
      "Epoch: 22 Step: 71 Loss: 0.38782105052502525\n",
      "Epoch: 22 Step: 81 Loss: 0.4138492658156159\n",
      "Epoch: 22 Step: 91 Loss: 0.445203744345734\n",
      "Epoch: 22 Step: 101 Loss: 0.31536653770807094\n",
      "Epoch: 22 Step: 111 Loss: 0.621568410384135\n",
      "Epoch: 22 Step: 121 Loss: 0.42624786492293554\n",
      "Epoch: 22 Step: 131 Loss: 0.25100131841947954\n",
      "Epoch: 22 Step: 141 Loss: 0.6834239738109132\n",
      "Epoch: 22 Step: 151 Loss: 0.5250034924654559\n",
      "Epoch: 22 Step: 161 Loss: 0.4918468220523131\n",
      "Epoch: 22 Step: 171 Loss: 0.6295829011417933\n",
      "Epoch: 22 Step: 181 Loss: 0.5142378773027976\n",
      "Epoch: 22 Step: 191 Loss: 0.5696823981680983\n",
      "Epoch: 22 Step: 201 Loss: 0.1870657269872074\n",
      "Epoch: 22 Step: 211 Loss: 0.3273531276860614\n",
      "Epoch: 22 Step: 221 Loss: 0.33824584011919523\n",
      "Epoch: 22 Step: 231 Loss: 0.2919820577107581\n",
      "Epoch: 22 Step: 241 Loss: 0.41547729286983504\n",
      "Epoch: 22 Step: 251 Loss: 0.2764998410563472\n",
      "Epoch: 22 Step: 261 Loss: 0.28848895811960273\n",
      "Epoch: 22 Step: 271 Loss: 0.3896225017807625\n",
      "Epoch: 22 Step: 281 Loss: 0.19496223956628042\n",
      "Epoch: 22 Step: 291 Loss: 0.40418093433334823\n",
      "Epoch: 22 Step: 301 Loss: 0.38960222018351576\n",
      "Epoch: 22 Step: 311 Loss: 0.4427762677710811\n",
      "Epoch: 22 Step: 321 Loss: 0.5788207303127835\n",
      "Epoch: 22 Step: 331 Loss: 0.40375026330495656\n",
      "Epoch: 22 Step: 341 Loss: 0.503714512802525\n",
      "Epoch: 22 Step: 351 Loss: 0.38398619222647473\n",
      "Epoch: 22 Step: 361 Loss: 0.5069389013418721\n",
      "Epoch: 22 Step: 371 Loss: 0.51560836918864\n",
      "Epoch: 22 Step: 381 Loss: 0.32626236380774404\n",
      "Epoch: 22 Step: 391 Loss: 0.28351034610476095\n",
      "Epoch: 22 Step: 401 Loss: 0.35567391949624183\n",
      "Epoch: 22 Step: 411 Loss: 0.5513190839043433\n",
      "Epoch: 22 Step: 421 Loss: 0.5328613411069958\n",
      "Epoch: 22 Step: 431 Loss: 0.3986722968481282\n",
      "Epoch: 22 Step: 441 Loss: 0.3655905008219237\n",
      "Epoch: 22 Step: 451 Loss: 0.3868432059945367\n",
      "Epoch: 22 Step: 461 Loss: 0.3975610447804814\n",
      "Epoch: 22 Step: 471 Loss: 0.4456463731746575\n",
      "Epoch: 22 Step: 481 Loss: 0.7211071064227935\n",
      "Epoch: 22 Step: 491 Loss: 0.7598012897680472\n",
      "Epoch: 22 Step: 501 Loss: 1.1429147121075582\n",
      "Epoch: 22 Step: 511 Loss: 0.2556979622211114\n",
      "Epoch: 22 Step: 521 Loss: 0.5375510601367623\n",
      "Epoch: 22 Step: 531 Loss: 0.4086192337546276\n",
      "Epoch: 22 Step: 541 Loss: 0.4284560882236463\n",
      "Epoch: 22 Step: 551 Loss: 0.34245808041600156\n",
      "Epoch: 22 Step: 561 Loss: 0.44379205474616934\n",
      "Epoch: 22 Step: 571 Loss: 0.42336405067367633\n",
      "Epoch: 22 Step: 581 Loss: 0.4133064327907773\n",
      "Epoch: 22 Step: 591 Loss: 0.33377441295862326\n",
      "Epoch: 22 Step: 601 Loss: 0.4179981210179209\n",
      "Epoch: 22 Step: 611 Loss: 0.4021161946956321\n",
      "Epoch: 22 Step: 621 Loss: 0.2717034280381823\n",
      "Epoch: 22 Step: 631 Loss: 0.24171701709786286\n",
      "Epoch: 22 Step: 641 Loss: 0.3914146947050166\n",
      "Epoch: 22 Step: 651 Loss: 0.4136289829270976\n",
      "Epoch: 22 Step: 661 Loss: 0.19803187135995248\n",
      "Epoch: 22 Step: 671 Loss: 0.3917088906105699\n",
      "Epoch: 22 Step: 681 Loss: 0.7560240807953672\n",
      "Epoch: 22 Step: 691 Loss: 0.6255876419053463\n",
      "Epoch: 22 Step: 701 Loss: 0.4618848049755028\n",
      "Epoch: 22 Step: 711 Loss: 0.8140003434000409\n",
      "Epoch: 22 Step: 721 Loss: 0.5415959884387553\n",
      "Epoch: 22 Step: 731 Loss: 0.3724584208480899\n",
      "Epoch: 22 Step: 741 Loss: 0.20447540126636843\n",
      "Epoch: 22 Step: 751 Loss: 0.5637185293498169\n",
      "Epoch: 22 Step: 761 Loss: 0.2315036132254297\n",
      "Epoch: 22 Step: 771 Loss: 0.3673706234952383\n",
      "Epoch: 22 Step: 781 Loss: 0.3838710802919811\n",
      "Epoch: 23 Step: 1 Loss: 0.4721604024918917\n",
      "Epoch: 23 Step: 11 Loss: 0.3584313345087127\n",
      "Epoch: 23 Step: 21 Loss: 0.29374849304142164\n",
      "Epoch: 23 Step: 31 Loss: 0.6436066396476225\n",
      "Epoch: 23 Step: 41 Loss: 0.27255821141034275\n",
      "Epoch: 23 Step: 51 Loss: 0.5290588625016699\n",
      "Epoch: 23 Step: 61 Loss: 0.5907591168713608\n",
      "Epoch: 23 Step: 71 Loss: 0.2813118063963278\n",
      "Epoch: 23 Step: 81 Loss: 0.29957835317014914\n",
      "Epoch: 23 Step: 91 Loss: 0.39274208904106983\n",
      "Epoch: 23 Step: 101 Loss: 0.553776499598033\n",
      "Epoch: 23 Step: 111 Loss: 0.5746870695766824\n",
      "Epoch: 23 Step: 121 Loss: 0.37840966002952614\n",
      "Epoch: 23 Step: 131 Loss: 0.30117069304548655\n",
      "Epoch: 23 Step: 141 Loss: 0.4856020999725828\n",
      "Epoch: 23 Step: 151 Loss: 0.27917782661723445\n",
      "Epoch: 23 Step: 161 Loss: 0.48880452584127276\n",
      "Epoch: 23 Step: 171 Loss: 0.41144518117819656\n",
      "Epoch: 23 Step: 181 Loss: 0.3788580424393305\n",
      "Epoch: 23 Step: 191 Loss: 0.44437652684313755\n",
      "Epoch: 23 Step: 201 Loss: 0.3185465529799805\n",
      "Epoch: 23 Step: 211 Loss: 0.28457003521083646\n",
      "Epoch: 23 Step: 221 Loss: 0.4421160382540373\n",
      "Epoch: 23 Step: 231 Loss: 0.3327827258134661\n",
      "Epoch: 23 Step: 241 Loss: 0.3120788451971531\n",
      "Epoch: 23 Step: 251 Loss: 0.28034191781650725\n",
      "Epoch: 23 Step: 261 Loss: 0.5468062913976521\n",
      "Epoch: 23 Step: 271 Loss: 0.3067146044742463\n",
      "Epoch: 23 Step: 281 Loss: 0.4342491248755008\n",
      "Epoch: 23 Step: 291 Loss: 0.5961115863793695\n",
      "Epoch: 23 Step: 301 Loss: 0.6326223739456647\n",
      "Epoch: 23 Step: 311 Loss: 0.747294108180206\n",
      "Epoch: 23 Step: 321 Loss: 0.47840048307343863\n",
      "Epoch: 23 Step: 331 Loss: 0.3832843321100847\n",
      "Epoch: 23 Step: 341 Loss: 0.3927719631632625\n",
      "Epoch: 23 Step: 351 Loss: 0.3999288197440823\n",
      "Epoch: 23 Step: 361 Loss: 0.36601767090768167\n",
      "Epoch: 23 Step: 371 Loss: 0.41491547128398476\n",
      "Epoch: 23 Step: 381 Loss: 0.189491465903567\n",
      "Epoch: 23 Step: 391 Loss: 0.19354511976844377\n",
      "Epoch: 23 Step: 401 Loss: 0.27783542194307453\n",
      "Epoch: 23 Step: 411 Loss: 0.2501804556100888\n",
      "Epoch: 23 Step: 421 Loss: 0.4815927124548889\n",
      "Epoch: 23 Step: 431 Loss: 0.3351110158855377\n",
      "Epoch: 23 Step: 441 Loss: 0.19396722671255956\n",
      "Epoch: 23 Step: 451 Loss: 0.3582105109595892\n",
      "Epoch: 23 Step: 461 Loss: 0.6990283351280591\n",
      "Epoch: 23 Step: 471 Loss: 0.7068630851493622\n",
      "Epoch: 23 Step: 481 Loss: 0.7440187625443877\n",
      "Epoch: 23 Step: 491 Loss: 0.6721943201896501\n",
      "Epoch: 23 Step: 501 Loss: 0.6206778349805444\n",
      "Epoch: 23 Step: 511 Loss: 0.30866337042600683\n",
      "Epoch: 23 Step: 521 Loss: 0.3648236340878154\n",
      "Epoch: 23 Step: 531 Loss: 0.41179563338018926\n",
      "Epoch: 23 Step: 541 Loss: 0.355269270866875\n",
      "Epoch: 23 Step: 551 Loss: 0.3613283964724143\n",
      "Epoch: 23 Step: 561 Loss: 0.3325788184951757\n",
      "Epoch: 23 Step: 571 Loss: 0.3795443512183976\n",
      "Epoch: 23 Step: 581 Loss: 0.46970607805480635\n",
      "Epoch: 23 Step: 591 Loss: 0.3331009780045754\n",
      "Epoch: 23 Step: 601 Loss: 0.34203490655705526\n",
      "Epoch: 23 Step: 611 Loss: 0.23077767116160924\n",
      "Epoch: 23 Step: 621 Loss: 0.4654515881538498\n",
      "Epoch: 23 Step: 631 Loss: 0.3240949588714851\n",
      "Epoch: 23 Step: 641 Loss: 0.4646883152440321\n",
      "Epoch: 23 Step: 651 Loss: 0.6409153270574088\n",
      "Epoch: 23 Step: 661 Loss: 0.3568449888355849\n",
      "Epoch: 23 Step: 671 Loss: 0.6799090896705605\n",
      "Epoch: 23 Step: 681 Loss: 0.5530046125120409\n",
      "Epoch: 23 Step: 691 Loss: 0.44924259794129623\n",
      "Epoch: 23 Step: 701 Loss: 0.42393519774148253\n",
      "Epoch: 23 Step: 711 Loss: 0.4175747684448071\n",
      "Epoch: 23 Step: 721 Loss: 0.46277577293805594\n",
      "Epoch: 23 Step: 731 Loss: 0.3070309425788529\n",
      "Epoch: 23 Step: 741 Loss: 0.358545426458439\n",
      "Epoch: 23 Step: 751 Loss: 0.40313974751756065\n",
      "Epoch: 23 Step: 761 Loss: 0.4010108792203211\n",
      "Epoch: 23 Step: 771 Loss: 0.5824750632553297\n",
      "Epoch: 23 Step: 781 Loss: 0.49007029941902125\n",
      "Epoch: 24 Step: 1 Loss: 0.19038969370978837\n",
      "Epoch: 24 Step: 11 Loss: 0.384485895606366\n",
      "Epoch: 24 Step: 21 Loss: 0.38913050449612735\n",
      "Epoch: 24 Step: 31 Loss: 0.5354412108212241\n",
      "Epoch: 24 Step: 41 Loss: 0.46199671325608527\n",
      "Epoch: 24 Step: 51 Loss: 0.6428973290109661\n",
      "Epoch: 24 Step: 61 Loss: 0.40215014847934705\n",
      "Epoch: 24 Step: 71 Loss: 0.514709943328768\n",
      "Epoch: 24 Step: 81 Loss: 0.35604282205086674\n",
      "Epoch: 24 Step: 91 Loss: 0.5460506106129981\n",
      "Epoch: 24 Step: 101 Loss: 0.3670803842695929\n",
      "Epoch: 24 Step: 111 Loss: 0.4754206881836342\n",
      "Epoch: 24 Step: 121 Loss: 0.3224713963260917\n",
      "Epoch: 24 Step: 131 Loss: 0.3461688930434948\n",
      "Epoch: 24 Step: 141 Loss: 0.549257925988435\n",
      "Epoch: 24 Step: 151 Loss: 0.2336158078685981\n",
      "Epoch: 24 Step: 161 Loss: 0.5614022461167583\n",
      "Epoch: 24 Step: 171 Loss: 0.26780105213619465\n",
      "Epoch: 24 Step: 181 Loss: 0.1973326138371648\n",
      "Epoch: 24 Step: 191 Loss: 0.38629747093587397\n",
      "Epoch: 24 Step: 201 Loss: 0.2827595746616186\n",
      "Epoch: 24 Step: 211 Loss: 0.42154947705469087\n",
      "Epoch: 24 Step: 221 Loss: 0.3847315484878334\n",
      "Epoch: 24 Step: 231 Loss: 0.28354751461665995\n",
      "Epoch: 24 Step: 241 Loss: 0.5304955823957395\n",
      "Epoch: 24 Step: 251 Loss: 0.3231112851513295\n",
      "Epoch: 24 Step: 261 Loss: 0.360495672663706\n",
      "Epoch: 24 Step: 271 Loss: 0.2882553765965591\n",
      "Epoch: 24 Step: 281 Loss: 0.36992603110753963\n",
      "Epoch: 24 Step: 291 Loss: 0.4007232335937241\n",
      "Epoch: 24 Step: 301 Loss: 0.3434510199489187\n",
      "Epoch: 24 Step: 311 Loss: 0.3173740277948246\n",
      "Epoch: 24 Step: 321 Loss: 0.3887079013738869\n",
      "Epoch: 24 Step: 331 Loss: 0.43546030327314034\n",
      "Epoch: 24 Step: 341 Loss: 0.20049429320659623\n",
      "Epoch: 24 Step: 351 Loss: 0.3866601482959551\n",
      "Epoch: 24 Step: 361 Loss: 0.32681090536046664\n",
      "Epoch: 24 Step: 371 Loss: 0.24558108691002678\n",
      "Epoch: 24 Step: 381 Loss: 0.22695547554066905\n",
      "Epoch: 24 Step: 391 Loss: 0.1650422844850808\n",
      "Epoch: 24 Step: 401 Loss: 0.24905502684129766\n",
      "Epoch: 24 Step: 411 Loss: 0.37290836699403884\n",
      "Epoch: 24 Step: 421 Loss: 0.6228066796156517\n",
      "Epoch: 24 Step: 431 Loss: 0.662864077623825\n",
      "Epoch: 24 Step: 441 Loss: 0.559313095095818\n",
      "Epoch: 24 Step: 451 Loss: 0.297192069816372\n",
      "Epoch: 24 Step: 461 Loss: 0.4085092438092015\n",
      "Epoch: 24 Step: 471 Loss: 0.40128096345742587\n",
      "Epoch: 24 Step: 481 Loss: 0.5348729677067021\n",
      "Epoch: 24 Step: 491 Loss: 0.6384357937225493\n",
      "Epoch: 24 Step: 501 Loss: 0.5025865680014778\n",
      "Epoch: 24 Step: 511 Loss: 0.18712917000903906\n",
      "Epoch: 24 Step: 521 Loss: 0.448461334832035\n",
      "Epoch: 24 Step: 531 Loss: 0.49036371974607473\n",
      "Epoch: 24 Step: 541 Loss: 0.4211786627514154\n",
      "Epoch: 24 Step: 551 Loss: 0.2122167274672939\n",
      "Epoch: 24 Step: 561 Loss: 0.29975439924028646\n",
      "Epoch: 24 Step: 571 Loss: 0.42143271604073645\n",
      "Epoch: 24 Step: 581 Loss: 0.6338245765379694\n",
      "Epoch: 24 Step: 591 Loss: 0.46933377919141617\n",
      "Epoch: 24 Step: 601 Loss: 0.5277533591417203\n",
      "Epoch: 24 Step: 611 Loss: 0.32046325144863547\n",
      "Epoch: 24 Step: 621 Loss: 0.3702668895105214\n",
      "Epoch: 24 Step: 631 Loss: 0.24503900403429252\n",
      "Epoch: 24 Step: 641 Loss: 0.5567528283194606\n",
      "Epoch: 24 Step: 651 Loss: 0.34196809665351\n",
      "Epoch: 24 Step: 661 Loss: 0.2753830740263465\n",
      "Epoch: 24 Step: 671 Loss: 0.5277009845329961\n",
      "Epoch: 24 Step: 681 Loss: 0.4562967493743589\n",
      "Epoch: 24 Step: 691 Loss: 0.36158082870444863\n",
      "Epoch: 24 Step: 701 Loss: 0.33324769404361737\n",
      "Epoch: 24 Step: 711 Loss: 0.2818359899324254\n",
      "Epoch: 24 Step: 721 Loss: 0.2379069218571413\n",
      "Epoch: 24 Step: 731 Loss: 0.1681418255011245\n",
      "Epoch: 24 Step: 741 Loss: 0.3391216259671057\n",
      "Epoch: 24 Step: 751 Loss: 0.4912881560055625\n",
      "Epoch: 24 Step: 761 Loss: 0.34955251809098176\n",
      "Epoch: 24 Step: 771 Loss: 0.6975240449079123\n",
      "Epoch: 24 Step: 781 Loss: 0.29530034931622057\n",
      "Epoch: 25 Step: 1 Loss: 0.3142224777289723\n",
      "Epoch: 25 Step: 11 Loss: 0.3909428295640761\n",
      "Epoch: 25 Step: 21 Loss: 0.32852920699644994\n",
      "Epoch: 25 Step: 31 Loss: 0.4171975116154171\n",
      "Epoch: 25 Step: 41 Loss: 0.35144981694858857\n",
      "Epoch: 25 Step: 51 Loss: 0.5855153030777975\n",
      "Epoch: 25 Step: 61 Loss: 0.545103854781454\n",
      "Epoch: 25 Step: 71 Loss: 0.42777360036552703\n",
      "Epoch: 25 Step: 81 Loss: 0.4302336609898654\n",
      "Epoch: 25 Step: 91 Loss: 0.4107781729977935\n",
      "Epoch: 25 Step: 101 Loss: 0.3974303699151976\n",
      "Epoch: 25 Step: 111 Loss: 0.4601551002512625\n",
      "Epoch: 25 Step: 121 Loss: 0.43865086447156393\n",
      "Epoch: 25 Step: 131 Loss: 0.47731575740612564\n",
      "Epoch: 25 Step: 141 Loss: 0.5973233850144433\n",
      "Epoch: 25 Step: 151 Loss: 0.1925402185903271\n",
      "Epoch: 25 Step: 161 Loss: 0.5109675409771486\n",
      "Epoch: 25 Step: 171 Loss: 0.4876421488416867\n",
      "Epoch: 25 Step: 181 Loss: 0.574336673886841\n",
      "Epoch: 25 Step: 191 Loss: 0.40685857844053713\n",
      "Epoch: 25 Step: 201 Loss: 0.2409635166201359\n",
      "Epoch: 25 Step: 211 Loss: 0.41473813072160287\n",
      "Epoch: 25 Step: 221 Loss: 0.3735495579559166\n",
      "Epoch: 25 Step: 231 Loss: 0.2506622157678278\n",
      "Epoch: 25 Step: 241 Loss: 0.3135084589229818\n",
      "Epoch: 25 Step: 251 Loss: 0.26770812220017925\n",
      "Epoch: 25 Step: 261 Loss: 0.1758483420389836\n",
      "Epoch: 25 Step: 271 Loss: 0.3222494255808736\n",
      "Epoch: 25 Step: 281 Loss: 0.3744298788533513\n",
      "Epoch: 25 Step: 291 Loss: 0.49780582874545953\n",
      "Epoch: 25 Step: 301 Loss: 0.5159049315957116\n",
      "Epoch: 25 Step: 311 Loss: 0.38541059140135214\n",
      "Epoch: 25 Step: 321 Loss: 0.448854818057239\n",
      "Epoch: 25 Step: 331 Loss: 0.34528798768660174\n",
      "Epoch: 25 Step: 341 Loss: 0.4649117857582368\n",
      "Epoch: 25 Step: 351 Loss: 0.30298908051195295\n",
      "Epoch: 25 Step: 361 Loss: 0.30956882693581467\n",
      "Epoch: 25 Step: 371 Loss: 0.27868912996137146\n",
      "Epoch: 25 Step: 381 Loss: 0.41510430882347665\n",
      "Epoch: 25 Step: 391 Loss: 0.24952705547877121\n",
      "Epoch: 25 Step: 401 Loss: 0.295281702053967\n",
      "Epoch: 25 Step: 411 Loss: 0.30919828458162935\n",
      "Epoch: 25 Step: 421 Loss: 0.22273674932334706\n",
      "Epoch: 25 Step: 431 Loss: 0.23125648855420186\n",
      "Epoch: 25 Step: 441 Loss: 0.35169384982336793\n",
      "Epoch: 25 Step: 451 Loss: 0.3579993314976814\n",
      "Epoch: 25 Step: 461 Loss: 0.45049479174662865\n",
      "Epoch: 25 Step: 471 Loss: 0.4818596939390777\n",
      "Epoch: 25 Step: 481 Loss: 0.4155950667621116\n",
      "Epoch: 25 Step: 491 Loss: 0.5679031632720568\n",
      "Epoch: 25 Step: 501 Loss: 0.5921630269996229\n",
      "Epoch: 25 Step: 511 Loss: 0.13962592331666646\n",
      "Epoch: 25 Step: 521 Loss: 0.38194267225194967\n",
      "Epoch: 25 Step: 531 Loss: 0.34865604288229735\n",
      "Epoch: 25 Step: 541 Loss: 0.6101739680034994\n",
      "Epoch: 25 Step: 551 Loss: 0.3259181817095246\n",
      "Epoch: 25 Step: 561 Loss: 0.5418215567694685\n",
      "Epoch: 25 Step: 571 Loss: 0.37879085533938583\n",
      "Epoch: 25 Step: 581 Loss: 0.45470974428653144\n",
      "Epoch: 25 Step: 591 Loss: 0.25545573865031823\n",
      "Epoch: 25 Step: 601 Loss: 0.40009411401589623\n",
      "Epoch: 25 Step: 611 Loss: 0.38676514588748145\n",
      "Epoch: 25 Step: 621 Loss: 0.43324859520061476\n",
      "Epoch: 25 Step: 631 Loss: 0.22259752807349115\n",
      "Epoch: 25 Step: 641 Loss: 0.41321358840872857\n",
      "Epoch: 25 Step: 651 Loss: 0.24184676489072138\n",
      "Epoch: 25 Step: 661 Loss: 0.25645268308928637\n",
      "Epoch: 25 Step: 671 Loss: 0.3214082067605817\n",
      "Epoch: 25 Step: 681 Loss: 0.4708907769206882\n",
      "Epoch: 25 Step: 691 Loss: 0.3721908752256439\n",
      "Epoch: 25 Step: 701 Loss: 0.43874083090195515\n",
      "Epoch: 25 Step: 711 Loss: 0.6576362201542514\n",
      "Epoch: 25 Step: 721 Loss: 0.3624828689272207\n",
      "Epoch: 25 Step: 731 Loss: 0.18636903342092329\n",
      "Epoch: 25 Step: 741 Loss: 0.5249441033883646\n",
      "Epoch: 25 Step: 751 Loss: 0.7960661485303684\n",
      "Epoch: 25 Step: 761 Loss: 0.2216338168282351\n",
      "Epoch: 25 Step: 771 Loss: 0.7721189657464221\n",
      "Epoch: 25 Step: 781 Loss: 0.30175270775934315\n",
      "Epoch: 26 Step: 1 Loss: 0.3331327295502665\n",
      "Epoch: 26 Step: 11 Loss: 0.6164735298133847\n",
      "Epoch: 26 Step: 21 Loss: 0.3779607254949935\n",
      "Epoch: 26 Step: 31 Loss: 0.6819112347708861\n",
      "Epoch: 26 Step: 41 Loss: 0.3433608067148592\n",
      "Epoch: 26 Step: 51 Loss: 0.3918988149131174\n",
      "Epoch: 26 Step: 61 Loss: 0.26589033818245555\n",
      "Epoch: 26 Step: 71 Loss: 0.42942669226353825\n",
      "Epoch: 26 Step: 81 Loss: 0.4816091694166613\n",
      "Epoch: 26 Step: 91 Loss: 0.36070145285663424\n",
      "Epoch: 26 Step: 101 Loss: 0.25986361980764217\n",
      "Epoch: 26 Step: 111 Loss: 0.582342323110124\n",
      "Epoch: 26 Step: 121 Loss: 0.39774470064360634\n",
      "Epoch: 26 Step: 131 Loss: 0.540442281211869\n",
      "Epoch: 26 Step: 141 Loss: 0.6200247814493252\n",
      "Epoch: 26 Step: 151 Loss: 0.26676504888677854\n",
      "Epoch: 26 Step: 161 Loss: 0.43893215807423935\n",
      "Epoch: 26 Step: 171 Loss: 0.5186282148394747\n",
      "Epoch: 26 Step: 181 Loss: 0.48811478890628707\n",
      "Epoch: 26 Step: 191 Loss: 0.47668024717812796\n",
      "Epoch: 26 Step: 201 Loss: 0.4439337079438085\n",
      "Epoch: 26 Step: 211 Loss: 0.2590093297098496\n",
      "Epoch: 26 Step: 221 Loss: 0.23453280895059883\n",
      "Epoch: 26 Step: 231 Loss: 0.31818050922489116\n",
      "Epoch: 26 Step: 241 Loss: 0.3824728338172441\n",
      "Epoch: 26 Step: 251 Loss: 0.2711065288926053\n",
      "Epoch: 26 Step: 261 Loss: 0.20716240953259604\n",
      "Epoch: 26 Step: 271 Loss: 0.2733204481885325\n",
      "Epoch: 26 Step: 281 Loss: 0.22554489672266495\n",
      "Epoch: 26 Step: 291 Loss: 0.4366119008113477\n",
      "Epoch: 26 Step: 301 Loss: 0.41512690419742426\n",
      "Epoch: 26 Step: 311 Loss: 0.42757687910606323\n",
      "Epoch: 26 Step: 321 Loss: 0.41321362235916187\n",
      "Epoch: 26 Step: 331 Loss: 0.4253096712132829\n",
      "Epoch: 26 Step: 341 Loss: 0.19919873179232342\n",
      "Epoch: 26 Step: 351 Loss: 0.2196166780439806\n",
      "Epoch: 26 Step: 361 Loss: 0.30852714298054795\n",
      "Epoch: 26 Step: 371 Loss: 0.2733589533546388\n",
      "Epoch: 26 Step: 381 Loss: 0.4573569763940046\n",
      "Epoch: 26 Step: 391 Loss: 0.19049253791171117\n",
      "Epoch: 26 Step: 401 Loss: 0.33240947765993256\n",
      "Epoch: 26 Step: 411 Loss: 0.5694466409830423\n",
      "Epoch: 26 Step: 421 Loss: 0.33712995903045706\n",
      "Epoch: 26 Step: 431 Loss: 0.2808635600936741\n",
      "Epoch: 26 Step: 441 Loss: 0.27473134346899003\n",
      "Epoch: 26 Step: 451 Loss: 0.30807179137540175\n",
      "Epoch: 26 Step: 461 Loss: 0.34584607747628404\n",
      "Epoch: 26 Step: 471 Loss: 0.4318151451946599\n",
      "Epoch: 26 Step: 481 Loss: 0.5679959771832374\n",
      "Epoch: 26 Step: 491 Loss: 0.4522540762476887\n",
      "Epoch: 26 Step: 501 Loss: 0.5756299595557788\n",
      "Epoch: 26 Step: 511 Loss: 0.21802247769766742\n",
      "Epoch: 26 Step: 521 Loss: 0.4214684561645159\n",
      "Epoch: 26 Step: 531 Loss: 0.48758352548176215\n",
      "Epoch: 26 Step: 541 Loss: 0.27342311912145917\n",
      "Epoch: 26 Step: 551 Loss: 0.29758577326938745\n",
      "Epoch: 26 Step: 561 Loss: 0.3645853575496304\n",
      "Epoch: 26 Step: 571 Loss: 0.3537173935776592\n",
      "Epoch: 26 Step: 581 Loss: 0.25675858053758754\n",
      "Epoch: 26 Step: 591 Loss: 0.4684427693264726\n",
      "Epoch: 26 Step: 601 Loss: 0.2755038866236795\n",
      "Epoch: 26 Step: 611 Loss: 0.23762427535869196\n",
      "Epoch: 26 Step: 621 Loss: 0.32123731075595313\n",
      "Epoch: 26 Step: 631 Loss: 0.3266096064336544\n",
      "Epoch: 26 Step: 641 Loss: 0.37889463671376417\n",
      "Epoch: 26 Step: 651 Loss: 0.3294903379539711\n",
      "Epoch: 26 Step: 661 Loss: 0.37573640781079387\n",
      "Epoch: 26 Step: 671 Loss: 0.38892016521697603\n",
      "Epoch: 26 Step: 681 Loss: 0.8641402615953073\n",
      "Epoch: 26 Step: 691 Loss: 0.3967749048333973\n",
      "Epoch: 26 Step: 701 Loss: 0.5936233124036364\n",
      "Epoch: 26 Step: 711 Loss: 0.5957699816662445\n",
      "Epoch: 26 Step: 721 Loss: 0.2719279496494949\n",
      "Epoch: 26 Step: 731 Loss: 0.49922600268440304\n",
      "Epoch: 26 Step: 741 Loss: 0.33827441585532847\n",
      "Epoch: 26 Step: 751 Loss: 0.26628344696810846\n",
      "Epoch: 26 Step: 761 Loss: 0.30801753833966394\n",
      "Epoch: 26 Step: 771 Loss: 0.47042618030395844\n",
      "Epoch: 26 Step: 781 Loss: 0.4412784920024742\n",
      "Epoch: 27 Step: 1 Loss: 0.3925303008126642\n",
      "Epoch: 27 Step: 11 Loss: 0.35456758194286186\n",
      "Epoch: 27 Step: 21 Loss: 0.3145035105270295\n",
      "Epoch: 27 Step: 31 Loss: 0.3028845042442267\n",
      "Epoch: 27 Step: 41 Loss: 0.21821359005398394\n",
      "Epoch: 27 Step: 51 Loss: 0.30179764091774963\n",
      "Epoch: 27 Step: 61 Loss: 0.5113463385297675\n",
      "Epoch: 27 Step: 71 Loss: 0.4918382069574583\n",
      "Epoch: 27 Step: 81 Loss: 0.6589581470334942\n",
      "Epoch: 27 Step: 91 Loss: 0.29914043528703677\n",
      "Epoch: 27 Step: 101 Loss: 0.42544831965696905\n",
      "Epoch: 27 Step: 111 Loss: 0.45364692148977387\n",
      "Epoch: 27 Step: 121 Loss: 0.3062751271781297\n",
      "Epoch: 27 Step: 131 Loss: 0.2661739203171089\n",
      "Epoch: 27 Step: 141 Loss: 0.49452837271141453\n",
      "Epoch: 27 Step: 151 Loss: 0.31026723760195335\n",
      "Epoch: 27 Step: 161 Loss: 0.4695089245076753\n",
      "Epoch: 27 Step: 171 Loss: 0.40020386703766997\n",
      "Epoch: 27 Step: 181 Loss: 0.19439094852513916\n",
      "Epoch: 27 Step: 191 Loss: 0.5341538968674532\n",
      "Epoch: 27 Step: 201 Loss: 0.19663216558226007\n",
      "Epoch: 27 Step: 211 Loss: 0.2554286776173659\n",
      "Epoch: 27 Step: 221 Loss: 0.23407548692919936\n",
      "Epoch: 27 Step: 231 Loss: 0.2547446352582401\n",
      "Epoch: 27 Step: 241 Loss: 0.23467277841228357\n",
      "Epoch: 27 Step: 251 Loss: 0.1914311373925045\n",
      "Epoch: 27 Step: 261 Loss: 0.38813801008500415\n",
      "Epoch: 27 Step: 271 Loss: 0.31185786294984075\n",
      "Epoch: 27 Step: 281 Loss: 0.2779959074483144\n",
      "Epoch: 27 Step: 291 Loss: 0.2625271170715884\n",
      "Epoch: 27 Step: 301 Loss: 0.44499103726183503\n",
      "Epoch: 27 Step: 311 Loss: 0.39548797734649666\n",
      "Epoch: 27 Step: 321 Loss: 0.3390079294760053\n",
      "Epoch: 27 Step: 331 Loss: 0.6728119491601798\n",
      "Epoch: 27 Step: 341 Loss: 0.2840950242763283\n",
      "Epoch: 27 Step: 351 Loss: 0.29515864159746\n",
      "Epoch: 27 Step: 361 Loss: 0.14792791442215003\n",
      "Epoch: 27 Step: 371 Loss: 0.16540448665613108\n",
      "Epoch: 27 Step: 381 Loss: 0.15440235490949944\n",
      "Epoch: 27 Step: 391 Loss: 0.21026626987805383\n",
      "Epoch: 27 Step: 401 Loss: 0.19168294405556652\n",
      "Epoch: 27 Step: 411 Loss: 0.16745037388549314\n",
      "Epoch: 27 Step: 421 Loss: 0.544399897405477\n",
      "Epoch: 27 Step: 431 Loss: 0.3028865626117511\n",
      "Epoch: 27 Step: 441 Loss: 0.2701381457103368\n",
      "Epoch: 27 Step: 451 Loss: 0.49018079449797247\n",
      "Epoch: 27 Step: 461 Loss: 0.2602828640748521\n",
      "Epoch: 27 Step: 471 Loss: 0.3612415550699416\n",
      "Epoch: 27 Step: 481 Loss: 0.38172987248583384\n",
      "Epoch: 27 Step: 491 Loss: 0.4073625892249305\n",
      "Epoch: 27 Step: 501 Loss: 0.6315029261707258\n",
      "Epoch: 27 Step: 511 Loss: 0.23983761786825608\n",
      "Epoch: 27 Step: 521 Loss: 0.4232413050310423\n",
      "Epoch: 27 Step: 531 Loss: 0.2747165873680897\n",
      "Epoch: 27 Step: 541 Loss: 0.3097172667551903\n",
      "Epoch: 27 Step: 551 Loss: 0.21201056666271892\n",
      "Epoch: 27 Step: 561 Loss: 0.31679414744653545\n",
      "Epoch: 27 Step: 571 Loss: 0.21256372817294622\n",
      "Epoch: 27 Step: 581 Loss: 0.1759999604992396\n",
      "Epoch: 27 Step: 591 Loss: 0.3078310499618734\n",
      "Epoch: 27 Step: 601 Loss: 0.38679738034199734\n",
      "Epoch: 27 Step: 611 Loss: 0.43804944702581716\n",
      "Epoch: 27 Step: 621 Loss: 0.3767958482330576\n",
      "Epoch: 27 Step: 631 Loss: 0.3771021668719634\n",
      "Epoch: 27 Step: 641 Loss: 0.3361442506708092\n",
      "Epoch: 27 Step: 651 Loss: 0.2991110160184632\n",
      "Epoch: 27 Step: 661 Loss: 0.2755924373681468\n",
      "Epoch: 27 Step: 671 Loss: 0.3760515049937626\n",
      "Epoch: 27 Step: 681 Loss: 0.3696225603291056\n",
      "Epoch: 27 Step: 691 Loss: 0.3949511813953642\n",
      "Epoch: 27 Step: 701 Loss: 0.4194438149742015\n",
      "Epoch: 27 Step: 711 Loss: 0.32355027176983314\n",
      "Epoch: 27 Step: 721 Loss: 0.2811080906156614\n",
      "Epoch: 27 Step: 731 Loss: 0.11921034079505757\n",
      "Epoch: 27 Step: 741 Loss: 0.20170601539781735\n",
      "Epoch: 27 Step: 751 Loss: 0.4727411114866183\n",
      "Epoch: 27 Step: 761 Loss: 0.40444146558496263\n",
      "Epoch: 27 Step: 771 Loss: 0.3967283701063298\n",
      "Epoch: 27 Step: 781 Loss: 0.37005516804196015\n",
      "Epoch: 28 Step: 1 Loss: 0.21489654670043817\n",
      "Epoch: 28 Step: 11 Loss: 0.2592088116648843\n",
      "Epoch: 28 Step: 21 Loss: 0.5298906227479584\n",
      "Epoch: 28 Step: 31 Loss: 0.3898145701585537\n",
      "Epoch: 28 Step: 41 Loss: 0.17983105867226504\n",
      "Epoch: 28 Step: 51 Loss: 0.6329153481555387\n",
      "Epoch: 28 Step: 61 Loss: 0.2230901358508066\n",
      "Epoch: 28 Step: 71 Loss: 0.3484763882336035\n",
      "Epoch: 28 Step: 81 Loss: 0.501559297866608\n",
      "Epoch: 28 Step: 91 Loss: 0.418063393123395\n",
      "Epoch: 28 Step: 101 Loss: 0.26029341708784476\n",
      "Epoch: 28 Step: 111 Loss: 0.3125604231813313\n",
      "Epoch: 28 Step: 121 Loss: 0.24294793428709116\n",
      "Epoch: 28 Step: 131 Loss: 0.2297384625806671\n",
      "Epoch: 28 Step: 141 Loss: 0.3366241191232524\n",
      "Epoch: 28 Step: 151 Loss: 0.3370583693763418\n",
      "Epoch: 28 Step: 161 Loss: 0.2737799649375423\n",
      "Epoch: 28 Step: 171 Loss: 0.39273563726785765\n",
      "Epoch: 28 Step: 181 Loss: 0.25964211887823485\n",
      "Epoch: 28 Step: 191 Loss: 0.4907331549160431\n",
      "Epoch: 28 Step: 201 Loss: 0.21687965924909658\n",
      "Epoch: 28 Step: 211 Loss: 0.32648873798209804\n",
      "Epoch: 28 Step: 221 Loss: 0.3492299806016949\n",
      "Epoch: 28 Step: 231 Loss: 0.5326134336040056\n",
      "Epoch: 28 Step: 241 Loss: 0.5230554506250957\n",
      "Epoch: 28 Step: 251 Loss: 0.32695221304106253\n",
      "Epoch: 28 Step: 261 Loss: 0.41059347644882604\n",
      "Epoch: 28 Step: 271 Loss: 0.3378318513704879\n",
      "Epoch: 28 Step: 281 Loss: 0.33598147852888666\n",
      "Epoch: 28 Step: 291 Loss: 0.21164842295031563\n",
      "Epoch: 28 Step: 301 Loss: 0.33175445043212975\n",
      "Epoch: 28 Step: 311 Loss: 0.3687796306733151\n",
      "Epoch: 28 Step: 321 Loss: 0.27402339318470736\n",
      "Epoch: 28 Step: 331 Loss: 0.46573557415686895\n",
      "Epoch: 28 Step: 341 Loss: 0.31771436755404653\n",
      "Epoch: 28 Step: 351 Loss: 0.28709797855525765\n",
      "Epoch: 28 Step: 361 Loss: 0.24803970614269352\n",
      "Epoch: 28 Step: 371 Loss: 0.2998695223743859\n",
      "Epoch: 28 Step: 381 Loss: 0.3239800981864994\n",
      "Epoch: 28 Step: 391 Loss: 0.2680205640018625\n",
      "Epoch: 28 Step: 401 Loss: 0.46333116889228565\n",
      "Epoch: 28 Step: 411 Loss: 0.5088140650107453\n",
      "Epoch: 28 Step: 421 Loss: 0.3697610269572186\n",
      "Epoch: 28 Step: 431 Loss: 0.422988332318548\n",
      "Epoch: 28 Step: 441 Loss: 0.5606622431153616\n",
      "Epoch: 28 Step: 451 Loss: 0.36375857611463375\n",
      "Epoch: 28 Step: 461 Loss: 0.5075757494463904\n",
      "Epoch: 28 Step: 471 Loss: 0.4236711995477953\n",
      "Epoch: 28 Step: 481 Loss: 0.37118620394102786\n",
      "Epoch: 28 Step: 491 Loss: 0.31444516399451167\n",
      "Epoch: 28 Step: 501 Loss: 0.5210136014971005\n",
      "Epoch: 28 Step: 511 Loss: 0.2666147113531634\n",
      "Epoch: 28 Step: 521 Loss: 0.21424740432132605\n",
      "Epoch: 28 Step: 531 Loss: 0.24943911484182024\n",
      "Epoch: 28 Step: 541 Loss: 0.39443625174879826\n",
      "Epoch: 28 Step: 551 Loss: 0.43076290496838665\n",
      "Epoch: 28 Step: 561 Loss: 0.4241558208173158\n",
      "Epoch: 28 Step: 571 Loss: 0.3077310583340708\n",
      "Epoch: 28 Step: 581 Loss: 0.34924936832226006\n",
      "Epoch: 28 Step: 591 Loss: 0.5530275296832129\n",
      "Epoch: 28 Step: 601 Loss: 0.34877401279781906\n",
      "Epoch: 28 Step: 611 Loss: 0.17893142113194718\n",
      "Epoch: 28 Step: 621 Loss: 0.28808524695340315\n",
      "Epoch: 28 Step: 631 Loss: 0.24394394763768998\n",
      "Epoch: 28 Step: 641 Loss: 0.717263240071986\n",
      "Epoch: 28 Step: 651 Loss: 0.5634372628776501\n",
      "Epoch: 28 Step: 661 Loss: 0.27320610509672\n",
      "Epoch: 28 Step: 671 Loss: 0.4375928955726159\n",
      "Epoch: 28 Step: 681 Loss: 0.3978643746280788\n",
      "Epoch: 28 Step: 691 Loss: 0.3798110073235301\n",
      "Epoch: 28 Step: 701 Loss: 0.21740313822141683\n",
      "Epoch: 28 Step: 711 Loss: 0.3304842121948406\n",
      "Epoch: 28 Step: 721 Loss: 0.17258239024726735\n",
      "Epoch: 28 Step: 731 Loss: 0.14524923910247392\n",
      "Epoch: 28 Step: 741 Loss: 0.3942079191673472\n",
      "Epoch: 28 Step: 751 Loss: 0.37861190622144725\n",
      "Epoch: 28 Step: 761 Loss: 0.26352930501520994\n",
      "Epoch: 28 Step: 771 Loss: 0.38910623529860433\n",
      "Epoch: 28 Step: 781 Loss: 0.39370330583121166\n",
      "Epoch: 29 Step: 1 Loss: 0.3679237430678167\n",
      "Epoch: 29 Step: 11 Loss: 0.2912911788638034\n",
      "Epoch: 29 Step: 21 Loss: 0.2014526230562284\n",
      "Epoch: 29 Step: 31 Loss: 0.33388542411286803\n",
      "Epoch: 29 Step: 41 Loss: 0.23651895675306228\n",
      "Epoch: 29 Step: 51 Loss: 0.43116187590592087\n",
      "Epoch: 29 Step: 61 Loss: 0.2315166068439678\n",
      "Epoch: 29 Step: 71 Loss: 0.38896837133242557\n",
      "Epoch: 29 Step: 81 Loss: 0.3958517685000833\n",
      "Epoch: 29 Step: 91 Loss: 0.0983804559279317\n",
      "Epoch: 29 Step: 101 Loss: 0.24875246063140827\n",
      "Epoch: 29 Step: 111 Loss: 0.43091101845708946\n",
      "Epoch: 29 Step: 121 Loss: 0.4381236013425595\n",
      "Epoch: 29 Step: 131 Loss: 0.33588340054206556\n",
      "Epoch: 29 Step: 141 Loss: 0.34673111457478034\n",
      "Epoch: 29 Step: 151 Loss: 0.24625340635380483\n",
      "Epoch: 29 Step: 161 Loss: 0.27862639174759285\n",
      "Epoch: 29 Step: 171 Loss: 0.597730834978387\n",
      "Epoch: 29 Step: 181 Loss: 0.2317958617762529\n",
      "Epoch: 29 Step: 191 Loss: 0.25559043017686045\n",
      "Epoch: 29 Step: 201 Loss: 0.16280933446426585\n",
      "Epoch: 29 Step: 211 Loss: 0.3499339612059481\n",
      "Epoch: 29 Step: 221 Loss: 0.40120088719245384\n",
      "Epoch: 29 Step: 231 Loss: 0.4209292460068558\n",
      "Epoch: 29 Step: 241 Loss: 0.25874644553790677\n",
      "Epoch: 29 Step: 251 Loss: 0.2043398259963191\n",
      "Epoch: 29 Step: 261 Loss: 0.29662290908140604\n",
      "Epoch: 29 Step: 271 Loss: 0.32711746346988235\n",
      "Epoch: 29 Step: 281 Loss: 0.18407309183442913\n",
      "Epoch: 29 Step: 291 Loss: 0.32842001018368394\n",
      "Epoch: 29 Step: 301 Loss: 0.2110217853089419\n",
      "Epoch: 29 Step: 311 Loss: 0.286894409783439\n",
      "Epoch: 29 Step: 321 Loss: 0.2690486754046182\n",
      "Epoch: 29 Step: 331 Loss: 0.3584866038271773\n",
      "Epoch: 29 Step: 341 Loss: 0.36747666167474635\n",
      "Epoch: 29 Step: 351 Loss: 0.30123442761568686\n",
      "Epoch: 29 Step: 361 Loss: 0.3573399518655552\n",
      "Epoch: 29 Step: 371 Loss: 0.16147946565894034\n",
      "Epoch: 29 Step: 381 Loss: 0.1931532343226961\n",
      "Epoch: 29 Step: 391 Loss: 0.24582491520436095\n",
      "Epoch: 29 Step: 401 Loss: 0.3385735210374809\n",
      "Epoch: 29 Step: 411 Loss: 0.24050971257965867\n",
      "Epoch: 29 Step: 421 Loss: 0.31109794183922673\n",
      "Epoch: 29 Step: 431 Loss: 0.23920850272489774\n",
      "Epoch: 29 Step: 441 Loss: 0.12481546531795469\n",
      "Epoch: 29 Step: 451 Loss: 0.26791128630224004\n",
      "Epoch: 29 Step: 461 Loss: 0.21036028621539798\n",
      "Epoch: 29 Step: 471 Loss: 0.38851617369112357\n",
      "Epoch: 29 Step: 481 Loss: 0.33814838216707155\n",
      "Epoch: 29 Step: 491 Loss: 0.3022049981559749\n",
      "Epoch: 29 Step: 501 Loss: 0.39351205895045294\n",
      "Epoch: 29 Step: 511 Loss: 0.1778033270586621\n",
      "Epoch: 29 Step: 521 Loss: 0.5014716014459768\n",
      "Epoch: 29 Step: 531 Loss: 0.3231823726068904\n",
      "Epoch: 29 Step: 541 Loss: 0.457657968717857\n",
      "Epoch: 29 Step: 551 Loss: 0.3782171064671811\n",
      "Epoch: 29 Step: 561 Loss: 0.510444335548125\n",
      "Epoch: 29 Step: 571 Loss: 0.20669292876129883\n",
      "Epoch: 29 Step: 581 Loss: 0.1704534956230179\n",
      "Epoch: 29 Step: 591 Loss: 0.32286295268774856\n",
      "Epoch: 29 Step: 601 Loss: 0.2850241454989885\n",
      "Epoch: 29 Step: 611 Loss: 0.2787047055657595\n",
      "Epoch: 29 Step: 621 Loss: 0.31314292180861714\n",
      "Epoch: 29 Step: 631 Loss: 0.24053235163218634\n",
      "Epoch: 29 Step: 641 Loss: 0.3559068600320322\n",
      "Epoch: 29 Step: 651 Loss: 0.23844248767870302\n",
      "Epoch: 29 Step: 661 Loss: 0.14871294135713806\n",
      "Epoch: 29 Step: 671 Loss: 0.4353669166017873\n",
      "Epoch: 29 Step: 681 Loss: 0.30774741360492475\n",
      "Epoch: 29 Step: 691 Loss: 0.3054625999755048\n",
      "Epoch: 29 Step: 701 Loss: 0.4328718545096803\n",
      "Epoch: 29 Step: 711 Loss: 0.5290962201612546\n",
      "Epoch: 29 Step: 721 Loss: 0.28328943094042214\n",
      "Epoch: 29 Step: 731 Loss: 0.2085317235849647\n",
      "Epoch: 29 Step: 741 Loss: 0.3571854172218182\n",
      "Epoch: 29 Step: 751 Loss: 0.5010830624076811\n",
      "Epoch: 29 Step: 761 Loss: 0.18009657148200073\n",
      "Epoch: 29 Step: 771 Loss: 0.2690676065758345\n",
      "Epoch: 29 Step: 781 Loss: 0.4336320464154489\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score is 0.8429097311139565\n",
      "Score is 0.6481370192307693\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "model = ConvNet(datasets='cifar_10', opt='rmsprop')\n",
    "model.datas = [data, label]\n",
    "model.train(30)\n",
    "plt.plot(np.arange(len(model.history)), model.history)\n",
    "plt.show()\n",
    "np.savetxt('/home/oneran/Downloads/rmsprop_cifar_ConvNet_history.txt', model.history)\n",
    "model.save_model('/home/oneran/机器学习课设/cifar-10/Photon/rmsprop_cifar_ConvNet.pkl')\n",
    "score, pred = model.score(X_train, Y_train)\n",
    "score, pred = model.score(X_test, Y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 0 Step: 1 Loss: 2.3019728679370335\n",
      "Epoch: 0 Step: 11 Loss: 2.3614226566692067\n",
      "Epoch: 0 Step: 21 Loss: 2.425474199043677\n",
      "Epoch: 0 Step: 31 Loss: 2.3199717347934663\n",
      "Epoch: 0 Step: 41 Loss: 2.300047590474624\n",
      "Epoch: 0 Step: 51 Loss: 2.253036676581023\n",
      "Epoch: 0 Step: 61 Loss: 2.310242261736249\n",
      "Epoch: 0 Step: 71 Loss: 2.3349101047743934\n",
      "Epoch: 0 Step: 81 Loss: 2.384478650177856\n",
      "Epoch: 0 Step: 91 Loss: 2.4261706985194\n",
      "Epoch: 0 Step: 101 Loss: 2.3111997284514567\n",
      "Epoch: 0 Step: 111 Loss: 2.3487904279917893\n",
      "Epoch: 0 Step: 121 Loss: 2.319989730457805\n",
      "Epoch: 0 Step: 131 Loss: 2.2706889652315914\n",
      "Epoch: 0 Step: 141 Loss: 2.3643423186098724\n",
      "Epoch: 0 Step: 151 Loss: 2.168953777857044\n",
      "Epoch: 0 Step: 161 Loss: 2.15173586730816\n",
      "Epoch: 0 Step: 171 Loss: 2.142543011908139\n",
      "Epoch: 0 Step: 181 Loss: 2.2005444165234955\n",
      "Epoch: 0 Step: 191 Loss: 2.1320039275148064\n",
      "Epoch: 0 Step: 201 Loss: 2.2204059637837483\n",
      "Epoch: 0 Step: 211 Loss: 2.0720384670325878\n",
      "Epoch: 0 Step: 221 Loss: 2.192977526666052\n",
      "Epoch: 0 Step: 231 Loss: 2.168958282494486\n",
      "Epoch: 0 Step: 241 Loss: 2.2367270698169106\n",
      "Epoch: 0 Step: 251 Loss: 2.013298764384036\n",
      "Epoch: 0 Step: 261 Loss: 2.122817332682601\n",
      "Epoch: 0 Step: 271 Loss: 2.326201204833403\n",
      "Epoch: 0 Step: 281 Loss: 2.323610647003993\n",
      "Epoch: 0 Step: 291 Loss: 2.1854815761188937\n",
      "Epoch: 0 Step: 301 Loss: 2.2062995440244495\n",
      "Epoch: 0 Step: 311 Loss: 2.1031008278859096\n",
      "Epoch: 0 Step: 321 Loss: 2.001492687966488\n",
      "Epoch: 0 Step: 331 Loss: 2.1054647428635476\n",
      "Epoch: 0 Step: 341 Loss: 2.138363414768757\n",
      "Epoch: 0 Step: 351 Loss: 2.224787480297392\n",
      "Epoch: 0 Step: 361 Loss: 2.1547853587672163\n",
      "Epoch: 0 Step: 371 Loss: 2.0057522661448584\n",
      "Epoch: 0 Step: 381 Loss: 2.096166184576452\n",
      "Epoch: 0 Step: 391 Loss: 2.153055233452923\n",
      "Epoch: 0 Step: 401 Loss: 2.1377068470250067\n",
      "Epoch: 0 Step: 411 Loss: 2.26017229337148\n",
      "Epoch: 0 Step: 421 Loss: 2.1414958459771576\n",
      "Epoch: 0 Step: 431 Loss: 2.100937736733888\n",
      "Epoch: 0 Step: 441 Loss: 2.1667787787217474\n",
      "Epoch: 0 Step: 451 Loss: 2.071862270564141\n",
      "Epoch: 0 Step: 461 Loss: 2.086688531115008\n",
      "Epoch: 0 Step: 471 Loss: 1.9974393391903362\n",
      "Epoch: 0 Step: 481 Loss: 2.1093658935486257\n",
      "Epoch: 0 Step: 491 Loss: 2.176314103734433\n",
      "Epoch: 0 Step: 501 Loss: 2.2254183701569064\n",
      "Epoch: 0 Step: 511 Loss: 2.1758923148004907\n",
      "Epoch: 0 Step: 521 Loss: 2.247685297340589\n",
      "Epoch: 0 Step: 531 Loss: 2.1210324814376476\n",
      "Epoch: 0 Step: 541 Loss: 2.0357421687443162\n",
      "Epoch: 0 Step: 551 Loss: 2.024796204128921\n",
      "Epoch: 0 Step: 561 Loss: 1.9078845730971161\n",
      "Epoch: 0 Step: 571 Loss: 1.9779915963686854\n",
      "Epoch: 0 Step: 581 Loss: 2.103315213695968\n",
      "Epoch: 0 Step: 591 Loss: 2.1001662444361404\n",
      "Epoch: 0 Step: 601 Loss: 2.1751194965803053\n",
      "Epoch: 0 Step: 611 Loss: 1.8783402316726612\n",
      "Epoch: 0 Step: 621 Loss: 1.9865680211519392\n",
      "Epoch: 0 Step: 631 Loss: 1.9791030249114612\n",
      "Epoch: 0 Step: 641 Loss: 2.138553234863301\n",
      "Epoch: 0 Step: 651 Loss: 1.7519533492364583\n",
      "Epoch: 0 Step: 661 Loss: 1.9673198172441566\n",
      "Epoch: 0 Step: 671 Loss: 2.007861153115095\n",
      "Epoch: 0 Step: 681 Loss: 2.055061998187221\n",
      "Epoch: 0 Step: 691 Loss: 1.891000092201129\n",
      "Epoch: 0 Step: 701 Loss: 1.8049339094874108\n",
      "Epoch: 0 Step: 711 Loss: 1.8984938963037647\n",
      "Epoch: 0 Step: 721 Loss: 1.846240724141823\n",
      "Epoch: 0 Step: 731 Loss: 1.8564792668246393\n",
      "Epoch: 0 Step: 741 Loss: 1.8974787981549444\n",
      "Epoch: 0 Step: 751 Loss: 2.2585932581275783\n",
      "Epoch: 0 Step: 761 Loss: 1.8682540179987097\n",
      "Epoch: 0 Step: 771 Loss: 2.1140338551789144\n",
      "Epoch: 0 Step: 781 Loss: 1.9907028306037406\n",
      "Epoch: 1 Step: 1 Loss: 2.0288195893122984\n",
      "Epoch: 1 Step: 11 Loss: 1.8134967478010746\n",
      "Epoch: 1 Step: 21 Loss: 2.008519036092177\n",
      "Epoch: 1 Step: 31 Loss: 2.0175284047554913\n",
      "Epoch: 1 Step: 41 Loss: 1.909865333933387\n",
      "Epoch: 1 Step: 51 Loss: 1.8717681824778154\n",
      "Epoch: 1 Step: 61 Loss: 1.9214941852994014\n",
      "Epoch: 1 Step: 71 Loss: 1.939184886725473\n",
      "Epoch: 1 Step: 81 Loss: 1.9943615610043781\n",
      "Epoch: 1 Step: 91 Loss: 2.017246846743015\n",
      "Epoch: 1 Step: 101 Loss: 1.889592584785115\n",
      "Epoch: 1 Step: 111 Loss: 1.7574377047985217\n",
      "Epoch: 1 Step: 121 Loss: 1.8621408227596892\n",
      "Epoch: 1 Step: 131 Loss: 1.8506138192176056\n",
      "Epoch: 1 Step: 141 Loss: 2.1127768960638393\n",
      "Epoch: 1 Step: 151 Loss: 1.7179779330731746\n",
      "Epoch: 1 Step: 161 Loss: 1.8242059043522636\n",
      "Epoch: 1 Step: 171 Loss: 1.9120702889859058\n",
      "Epoch: 1 Step: 181 Loss: 1.6778408195039445\n",
      "Epoch: 1 Step: 191 Loss: 1.6692230716404959\n",
      "Epoch: 1 Step: 201 Loss: 1.6015083062291091\n",
      "Epoch: 1 Step: 211 Loss: 1.7157369524420791\n",
      "Epoch: 1 Step: 221 Loss: 1.9308746205616876\n",
      "Epoch: 1 Step: 231 Loss: 1.9884791249014029\n",
      "Epoch: 1 Step: 241 Loss: 1.918746454902829\n",
      "Epoch: 1 Step: 251 Loss: 1.848951861325157\n",
      "Epoch: 1 Step: 261 Loss: 1.8114524385151085\n",
      "Epoch: 1 Step: 271 Loss: 1.9325921794043333\n",
      "Epoch: 1 Step: 281 Loss: 1.8764424626133387\n",
      "Epoch: 1 Step: 291 Loss: 1.8003542145721645\n",
      "Epoch: 1 Step: 301 Loss: 1.8992147429136073\n",
      "Epoch: 1 Step: 311 Loss: 1.8456988419067502\n",
      "Epoch: 1 Step: 321 Loss: 1.798386138688282\n",
      "Epoch: 1 Step: 331 Loss: 1.7369556660601322\n",
      "Epoch: 1 Step: 341 Loss: 1.7538448309139265\n",
      "Epoch: 1 Step: 351 Loss: 1.8247605423556805\n",
      "Epoch: 1 Step: 361 Loss: 1.7770487832879522\n",
      "Epoch: 1 Step: 371 Loss: 1.5583368375637485\n",
      "Epoch: 1 Step: 381 Loss: 1.7104387973935913\n",
      "Epoch: 1 Step: 391 Loss: 1.4988063867872918\n",
      "Epoch: 1 Step: 401 Loss: 1.7337233897326285\n",
      "Epoch: 1 Step: 411 Loss: 1.8881196684456372\n",
      "Epoch: 1 Step: 421 Loss: 1.921301506346655\n",
      "Epoch: 1 Step: 431 Loss: 1.6947717899584265\n",
      "Epoch: 1 Step: 441 Loss: 1.9471334781269118\n",
      "Epoch: 1 Step: 451 Loss: 1.5240027418995639\n",
      "Epoch: 1 Step: 461 Loss: 1.6433837720245439\n",
      "Epoch: 1 Step: 471 Loss: 1.8338412925501035\n",
      "Epoch: 1 Step: 481 Loss: 1.8000684739868653\n",
      "Epoch: 1 Step: 491 Loss: 2.2771580843790247\n",
      "Epoch: 1 Step: 501 Loss: 1.849458767129034\n",
      "Epoch: 1 Step: 511 Loss: 2.0039946144015985\n",
      "Epoch: 1 Step: 521 Loss: 1.8438093911618147\n",
      "Epoch: 1 Step: 531 Loss: 1.7250606453810131\n",
      "Epoch: 1 Step: 541 Loss: 1.6880288470368412\n",
      "Epoch: 1 Step: 551 Loss: 1.7716869204772323\n",
      "Epoch: 1 Step: 561 Loss: 1.6767775802342675\n",
      "Epoch: 1 Step: 571 Loss: 1.6178817553047045\n",
      "Epoch: 1 Step: 581 Loss: 1.9906628362393313\n",
      "Epoch: 1 Step: 591 Loss: 1.8241442189960768\n",
      "Epoch: 1 Step: 601 Loss: 1.7468350340404677\n",
      "Epoch: 1 Step: 611 Loss: 1.813313623371998\n",
      "Epoch: 1 Step: 621 Loss: 1.7269592034742702\n",
      "Epoch: 1 Step: 631 Loss: 1.6391447989797283\n",
      "Epoch: 1 Step: 641 Loss: 1.8762841304763682\n",
      "Epoch: 1 Step: 651 Loss: 1.8360071292611462\n",
      "Epoch: 1 Step: 661 Loss: 1.6181352919628187\n",
      "Epoch: 1 Step: 671 Loss: 1.791746253442481\n",
      "Epoch: 1 Step: 681 Loss: 1.7275828168213803\n",
      "Epoch: 1 Step: 691 Loss: 1.739286633210459\n",
      "Epoch: 1 Step: 701 Loss: 1.5316409414902805\n",
      "Epoch: 1 Step: 711 Loss: 1.8708191041206281\n",
      "Epoch: 1 Step: 721 Loss: 1.6941045185274286\n",
      "Epoch: 1 Step: 731 Loss: 1.6047294326521717\n",
      "Epoch: 1 Step: 741 Loss: 1.719922103899683\n",
      "Epoch: 1 Step: 751 Loss: 1.946707485501769\n",
      "Epoch: 1 Step: 761 Loss: 1.751008862190678\n",
      "Epoch: 1 Step: 771 Loss: 1.945021574666952\n",
      "Epoch: 1 Step: 781 Loss: 1.7611652278454601\n",
      "Epoch: 2 Step: 1 Loss: 1.9771464303418376\n",
      "Epoch: 2 Step: 11 Loss: 1.8333175022858574\n",
      "Epoch: 2 Step: 21 Loss: 1.860669829855544\n",
      "Epoch: 2 Step: 31 Loss: 1.8459130218308495\n",
      "Epoch: 2 Step: 41 Loss: 1.7201049957923489\n",
      "Epoch: 2 Step: 51 Loss: 1.781334183385432\n",
      "Epoch: 2 Step: 61 Loss: 1.6863978126658083\n",
      "Epoch: 2 Step: 71 Loss: 1.948517719646903\n",
      "Epoch: 2 Step: 81 Loss: 1.8531631594238502\n",
      "Epoch: 2 Step: 91 Loss: 1.7575666795771334\n",
      "Epoch: 2 Step: 101 Loss: 1.5828418114768104\n",
      "Epoch: 2 Step: 111 Loss: 1.577157624233482\n",
      "Epoch: 2 Step: 121 Loss: 1.8106737703878344\n",
      "Epoch: 2 Step: 131 Loss: 1.600186462925672\n",
      "Epoch: 2 Step: 141 Loss: 1.9693601747677645\n",
      "Epoch: 2 Step: 151 Loss: 1.5454977484942238\n",
      "Epoch: 2 Step: 161 Loss: 1.5006285015114766\n",
      "Epoch: 2 Step: 171 Loss: 1.752456407172732\n",
      "Epoch: 2 Step: 181 Loss: 1.4954403067940234\n",
      "Epoch: 2 Step: 191 Loss: 1.6597931539794142\n",
      "Epoch: 2 Step: 201 Loss: 1.5586083932524861\n",
      "Epoch: 2 Step: 211 Loss: 1.7507580015982358\n",
      "Epoch: 2 Step: 221 Loss: 2.0316608513553684\n",
      "Epoch: 2 Step: 231 Loss: 1.6312290718278386\n",
      "Epoch: 2 Step: 241 Loss: 1.846721050972053\n",
      "Epoch: 2 Step: 251 Loss: 1.7208228054909243\n",
      "Epoch: 2 Step: 261 Loss: 1.6781027925848055\n",
      "Epoch: 2 Step: 271 Loss: 1.7134371078411663\n",
      "Epoch: 2 Step: 281 Loss: 1.6749515119198346\n",
      "Epoch: 2 Step: 291 Loss: 1.7041408492487904\n",
      "Epoch: 2 Step: 301 Loss: 1.7432949347002724\n",
      "Epoch: 2 Step: 311 Loss: 1.6127169158175327\n",
      "Epoch: 2 Step: 321 Loss: 1.6632758347451793\n",
      "Epoch: 2 Step: 331 Loss: 1.7332401954557466\n",
      "Epoch: 2 Step: 341 Loss: 1.6854082636021062\n",
      "Epoch: 2 Step: 351 Loss: 1.5490808930050222\n",
      "Epoch: 2 Step: 361 Loss: 1.6504958001124677\n",
      "Epoch: 2 Step: 371 Loss: 1.4139181166604706\n",
      "Epoch: 2 Step: 381 Loss: 1.5529557292269258\n",
      "Epoch: 2 Step: 391 Loss: 1.4214939710081498\n",
      "Epoch: 2 Step: 401 Loss: 1.6190102037915555\n",
      "Epoch: 2 Step: 411 Loss: 1.7013975672032546\n",
      "Epoch: 2 Step: 421 Loss: 1.6933272873194363\n",
      "Epoch: 2 Step: 431 Loss: 1.62427852966174\n",
      "Epoch: 2 Step: 441 Loss: 1.7397347954255566\n",
      "Epoch: 2 Step: 451 Loss: 1.5251364186246543\n",
      "Epoch: 2 Step: 461 Loss: 1.7502599122897866\n",
      "Epoch: 2 Step: 471 Loss: 1.688166111886917\n",
      "Epoch: 2 Step: 481 Loss: 1.728882652780551\n",
      "Epoch: 2 Step: 491 Loss: 1.8459090528744517\n",
      "Epoch: 2 Step: 501 Loss: 1.6962146948841124\n",
      "Epoch: 2 Step: 511 Loss: 1.9043636089613123\n",
      "Epoch: 2 Step: 521 Loss: 1.7132798534474798\n",
      "Epoch: 2 Step: 531 Loss: 1.6288616581100883\n",
      "Epoch: 2 Step: 541 Loss: 1.6227807734185404\n",
      "Epoch: 2 Step: 551 Loss: 1.4122530291501936\n",
      "Epoch: 2 Step: 561 Loss: 1.4383861927062445\n",
      "Epoch: 2 Step: 571 Loss: 1.5941162993609104\n",
      "Epoch: 2 Step: 581 Loss: 1.6493038854852409\n",
      "Epoch: 2 Step: 591 Loss: 1.6430013174690759\n",
      "Epoch: 2 Step: 601 Loss: 1.7103702096069828\n",
      "Epoch: 2 Step: 611 Loss: 1.8138229545828135\n",
      "Epoch: 2 Step: 621 Loss: 1.5774806026538528\n",
      "Epoch: 2 Step: 631 Loss: 1.5449558485758335\n",
      "Epoch: 2 Step: 641 Loss: 1.6884035869458933\n",
      "Epoch: 2 Step: 651 Loss: 1.4996815202987483\n",
      "Epoch: 2 Step: 661 Loss: 1.3932118321392912\n",
      "Epoch: 2 Step: 671 Loss: 1.6909531533584055\n",
      "Epoch: 2 Step: 681 Loss: 1.694467998835044\n",
      "Epoch: 2 Step: 691 Loss: 1.7870405525770112\n",
      "Epoch: 2 Step: 701 Loss: 1.5188970526936434\n",
      "Epoch: 2 Step: 711 Loss: 1.7589642568717232\n",
      "Epoch: 2 Step: 721 Loss: 1.579842125955391\n",
      "Epoch: 2 Step: 731 Loss: 1.4526501998752266\n",
      "Epoch: 2 Step: 741 Loss: 1.7092806540296053\n",
      "Epoch: 2 Step: 751 Loss: 1.9251991942754763\n",
      "Epoch: 2 Step: 761 Loss: 1.6145844496645827\n",
      "Epoch: 2 Step: 771 Loss: 1.8941873482985416\n",
      "Epoch: 2 Step: 781 Loss: 1.550254519775528\n",
      "Epoch: 3 Step: 1 Loss: 1.9640566332070288\n",
      "Epoch: 3 Step: 11 Loss: 1.9840124501519438\n",
      "Epoch: 3 Step: 21 Loss: 1.7612275040308178\n",
      "Epoch: 3 Step: 31 Loss: 1.7992269182389364\n",
      "Epoch: 3 Step: 41 Loss: 1.5758459620432907\n",
      "Epoch: 3 Step: 51 Loss: 1.4554994934696401\n",
      "Epoch: 3 Step: 61 Loss: 1.6051828316882748\n",
      "Epoch: 3 Step: 71 Loss: 1.7952789802080296\n",
      "Epoch: 3 Step: 81 Loss: 1.6523012202622185\n",
      "Epoch: 3 Step: 91 Loss: 1.631732776552372\n",
      "Epoch: 3 Step: 101 Loss: 1.4805560306554009\n",
      "Epoch: 3 Step: 111 Loss: 1.5655150546395737\n",
      "Epoch: 3 Step: 121 Loss: 1.6442882257504572\n",
      "Epoch: 3 Step: 131 Loss: 1.5459975863677493\n",
      "Epoch: 3 Step: 141 Loss: 1.8897965231552378\n",
      "Epoch: 3 Step: 151 Loss: 1.6644316694831445\n",
      "Epoch: 3 Step: 161 Loss: 1.780508841165088\n",
      "Epoch: 3 Step: 171 Loss: 1.9307512173252874\n",
      "Epoch: 3 Step: 181 Loss: 1.618581154954996\n",
      "Epoch: 3 Step: 191 Loss: 1.3403506348940957\n",
      "Epoch: 3 Step: 201 Loss: 1.5525156644437148\n",
      "Epoch: 3 Step: 211 Loss: 1.5379747161724229\n",
      "Epoch: 3 Step: 221 Loss: 1.6151579008007046\n",
      "Epoch: 3 Step: 231 Loss: 1.4093846176662002\n",
      "Epoch: 3 Step: 241 Loss: 1.7590227218450183\n",
      "Epoch: 3 Step: 251 Loss: 1.6166769191645152\n",
      "Epoch: 3 Step: 261 Loss: 1.4953462739632677\n",
      "Epoch: 3 Step: 271 Loss: 1.6884534926505135\n",
      "Epoch: 3 Step: 281 Loss: 1.629737895241867\n",
      "Epoch: 3 Step: 291 Loss: 1.5941007095800739\n",
      "Epoch: 3 Step: 301 Loss: 1.5665636185325371\n",
      "Epoch: 3 Step: 311 Loss: 1.4952635708061717\n",
      "Epoch: 3 Step: 321 Loss: 1.5084492732468666\n",
      "Epoch: 3 Step: 331 Loss: 1.5739177952517909\n",
      "Epoch: 3 Step: 341 Loss: 1.5581263432244112\n",
      "Epoch: 3 Step: 351 Loss: 1.4120098592451962\n",
      "Epoch: 3 Step: 361 Loss: 1.5356236011461535\n",
      "Epoch: 3 Step: 371 Loss: 1.303408918357881\n",
      "Epoch: 3 Step: 381 Loss: 1.7511812517457876\n",
      "Epoch: 3 Step: 391 Loss: 1.3815384483043436\n",
      "Epoch: 3 Step: 401 Loss: 1.6151610981803461\n",
      "Epoch: 3 Step: 411 Loss: 1.791992283351118\n",
      "Epoch: 3 Step: 421 Loss: 1.5457849089013893\n",
      "Epoch: 3 Step: 431 Loss: 1.4881182962235515\n",
      "Epoch: 3 Step: 441 Loss: 2.127534462522197\n",
      "Epoch: 3 Step: 451 Loss: 1.3358064312875215\n",
      "Epoch: 3 Step: 461 Loss: 1.728980387743033\n",
      "Epoch: 3 Step: 471 Loss: 1.6207889363396453\n",
      "Epoch: 3 Step: 481 Loss: 1.6346415752020542\n",
      "Epoch: 3 Step: 491 Loss: 1.8045028208854081\n",
      "Epoch: 3 Step: 501 Loss: 1.7113205942856147\n",
      "Epoch: 3 Step: 511 Loss: 1.5754199885280966\n",
      "Epoch: 3 Step: 521 Loss: 1.6313928702574132\n",
      "Epoch: 3 Step: 531 Loss: 1.3371143518204391\n",
      "Epoch: 3 Step: 541 Loss: 1.494650747660348\n",
      "Epoch: 3 Step: 551 Loss: 1.4168670767746576\n",
      "Epoch: 3 Step: 561 Loss: 1.551331512112045\n",
      "Epoch: 3 Step: 571 Loss: 1.523721825828468\n",
      "Epoch: 3 Step: 581 Loss: 1.4364522735198992\n",
      "Epoch: 3 Step: 591 Loss: 1.4777612446344048\n",
      "Epoch: 3 Step: 601 Loss: 1.5809393641795795\n",
      "Epoch: 3 Step: 611 Loss: 1.5586204799521277\n",
      "Epoch: 3 Step: 621 Loss: 1.50154188016718\n",
      "Epoch: 3 Step: 631 Loss: 1.4141251395122332\n",
      "Epoch: 3 Step: 641 Loss: 1.6997713912674506\n",
      "Epoch: 3 Step: 651 Loss: 1.4680923259091079\n",
      "Epoch: 3 Step: 661 Loss: 1.525713712983066\n",
      "Epoch: 3 Step: 671 Loss: 1.8975763220979147\n",
      "Epoch: 3 Step: 681 Loss: 1.6534857439227952\n",
      "Epoch: 3 Step: 691 Loss: 1.7141846084118706\n",
      "Epoch: 3 Step: 701 Loss: 1.5028721691121167\n",
      "Epoch: 3 Step: 711 Loss: 1.6812915427946522\n",
      "Epoch: 3 Step: 721 Loss: 1.651021326599178\n",
      "Epoch: 3 Step: 731 Loss: 1.4746000690716183\n",
      "Epoch: 3 Step: 741 Loss: 1.5669629256004056\n",
      "Epoch: 3 Step: 751 Loss: 1.7763088889761602\n",
      "Epoch: 3 Step: 761 Loss: 1.4630492851014592\n",
      "Epoch: 3 Step: 771 Loss: 1.8060318898714676\n",
      "Epoch: 3 Step: 781 Loss: 1.555270158136714\n",
      "Epoch: 4 Step: 1 Loss: 1.69088467060704\n",
      "Epoch: 4 Step: 11 Loss: 1.9146616165024133\n",
      "Epoch: 4 Step: 21 Loss: 1.8162701664190948\n",
      "Epoch: 4 Step: 31 Loss: 1.7802642107958155\n",
      "Epoch: 4 Step: 41 Loss: 1.5022639585082835\n",
      "Epoch: 4 Step: 51 Loss: 1.4121683597698582\n",
      "Epoch: 4 Step: 61 Loss: 1.4787405615565943\n",
      "Epoch: 4 Step: 71 Loss: 1.9647412071472248\n",
      "Epoch: 4 Step: 81 Loss: 1.6148632778462817\n",
      "Epoch: 4 Step: 91 Loss: 1.7198260815775497\n",
      "Epoch: 4 Step: 101 Loss: 1.414692670579326\n",
      "Epoch: 4 Step: 111 Loss: 1.5520207663258423\n",
      "Epoch: 4 Step: 121 Loss: 1.8122847856631776\n",
      "Epoch: 4 Step: 131 Loss: 1.5639438502064578\n",
      "Epoch: 4 Step: 141 Loss: 1.880154442728288\n",
      "Epoch: 4 Step: 151 Loss: 1.762745200937629\n",
      "Epoch: 4 Step: 161 Loss: 1.677603360125514\n",
      "Epoch: 4 Step: 171 Loss: 1.7460758907463387\n",
      "Epoch: 4 Step: 181 Loss: 1.490611515726505\n",
      "Epoch: 4 Step: 191 Loss: 1.484804567410083\n",
      "Epoch: 4 Step: 201 Loss: 1.556498155553577\n",
      "Epoch: 4 Step: 211 Loss: 1.429628390899591\n",
      "Epoch: 4 Step: 221 Loss: 1.514057267813337\n",
      "Epoch: 4 Step: 231 Loss: 1.666562439831131\n",
      "Epoch: 4 Step: 241 Loss: 1.601660986798135\n",
      "Epoch: 4 Step: 251 Loss: 1.5326006307444415\n",
      "Epoch: 4 Step: 261 Loss: 1.5694958102938799\n",
      "Epoch: 4 Step: 271 Loss: 1.5804959203255002\n",
      "Epoch: 4 Step: 281 Loss: 1.5353409765346773\n",
      "Epoch: 4 Step: 291 Loss: 1.4493775418892283\n",
      "Epoch: 4 Step: 301 Loss: 1.5017885311125359\n",
      "Epoch: 4 Step: 311 Loss: 1.40024335371388\n",
      "Epoch: 4 Step: 321 Loss: 1.523989945033871\n",
      "Epoch: 4 Step: 331 Loss: 1.5285951054008526\n",
      "Epoch: 4 Step: 341 Loss: 1.552412666463863\n",
      "Epoch: 4 Step: 351 Loss: 1.3803320486667199\n",
      "Epoch: 4 Step: 361 Loss: 1.5999057502348129\n",
      "Epoch: 4 Step: 371 Loss: 1.324883954770295\n",
      "Epoch: 4 Step: 381 Loss: 1.5887213163397482\n",
      "Epoch: 4 Step: 391 Loss: 1.5016483317889713\n",
      "Epoch: 4 Step: 401 Loss: 1.6231366738732427\n",
      "Epoch: 4 Step: 411 Loss: 1.784520184369544\n",
      "Epoch: 4 Step: 421 Loss: 1.6069384034048535\n",
      "Epoch: 4 Step: 431 Loss: 1.5753475893149096\n",
      "Epoch: 4 Step: 441 Loss: 1.8994674541522079\n",
      "Epoch: 4 Step: 451 Loss: 1.3702590393828262\n",
      "Epoch: 4 Step: 461 Loss: 1.6142612529834133\n",
      "Epoch: 4 Step: 471 Loss: 1.6148842634525473\n",
      "Epoch: 4 Step: 481 Loss: 1.532283780852319\n",
      "Epoch: 4 Step: 491 Loss: 1.675988818672474\n",
      "Epoch: 4 Step: 501 Loss: 1.7723304321234092\n",
      "Epoch: 4 Step: 511 Loss: 1.6344475992697052\n",
      "Epoch: 4 Step: 521 Loss: 1.5973255018872148\n",
      "Epoch: 4 Step: 531 Loss: 1.5482927423847468\n",
      "Epoch: 4 Step: 541 Loss: 1.4989914284166161\n",
      "Epoch: 4 Step: 551 Loss: 1.444433280404653\n",
      "Epoch: 4 Step: 561 Loss: 1.4939304794946446\n",
      "Epoch: 4 Step: 571 Loss: 1.4020700151823358\n",
      "Epoch: 4 Step: 581 Loss: 1.5229994405104157\n",
      "Epoch: 4 Step: 591 Loss: 1.6160763019598372\n",
      "Epoch: 4 Step: 601 Loss: 1.4373204219943596\n",
      "Epoch: 4 Step: 611 Loss: 1.5905897509233564\n",
      "Epoch: 4 Step: 621 Loss: 1.6416064729799116\n",
      "Epoch: 4 Step: 631 Loss: 1.4746105788201724\n",
      "Epoch: 4 Step: 641 Loss: 1.8731582553540287\n",
      "Epoch: 4 Step: 651 Loss: 1.4316200999291948\n",
      "Epoch: 4 Step: 661 Loss: 1.4101357034921007\n",
      "Epoch: 4 Step: 671 Loss: 1.683757212736019\n",
      "Epoch: 4 Step: 681 Loss: 1.596956626018004\n",
      "Epoch: 4 Step: 691 Loss: 1.6519214221984957\n",
      "Epoch: 4 Step: 701 Loss: 1.3957473212333644\n",
      "Epoch: 4 Step: 711 Loss: 1.626829084727539\n",
      "Epoch: 4 Step: 721 Loss: 1.3202017069661822\n",
      "Epoch: 4 Step: 731 Loss: 1.314143028903204\n",
      "Epoch: 4 Step: 741 Loss: 1.558883573532329\n",
      "Epoch: 4 Step: 751 Loss: 1.6783627593455988\n",
      "Epoch: 4 Step: 761 Loss: 1.443906028314798\n",
      "Epoch: 4 Step: 771 Loss: 1.661723997802608\n",
      "Epoch: 4 Step: 781 Loss: 1.5141155813489793\n",
      "Epoch: 5 Step: 1 Loss: 1.6324647327488209\n",
      "Epoch: 5 Step: 11 Loss: 1.7622707876572345\n",
      "Epoch: 5 Step: 21 Loss: 1.6930225147767632\n",
      "Epoch: 5 Step: 31 Loss: 1.791124296024861\n",
      "Epoch: 5 Step: 41 Loss: 1.359986522797565\n",
      "Epoch: 5 Step: 51 Loss: 1.3618185539990184\n",
      "Epoch: 5 Step: 61 Loss: 1.4612756356099919\n",
      "Epoch: 5 Step: 71 Loss: 1.7184346341142693\n",
      "Epoch: 5 Step: 81 Loss: 1.7095051661604697\n",
      "Epoch: 5 Step: 91 Loss: 1.8971550460041766\n",
      "Epoch: 5 Step: 101 Loss: 1.556695052916483\n",
      "Epoch: 5 Step: 111 Loss: 1.5203906154378535\n",
      "Epoch: 5 Step: 121 Loss: 1.7554675807257036\n",
      "Epoch: 5 Step: 131 Loss: 1.5798629727991074\n",
      "Epoch: 5 Step: 141 Loss: 1.7944305165277814\n",
      "Epoch: 5 Step: 151 Loss: 1.5603666903911857\n",
      "Epoch: 5 Step: 161 Loss: 1.7427358899015752\n",
      "Epoch: 5 Step: 171 Loss: 1.6208723170952104\n",
      "Epoch: 5 Step: 181 Loss: 1.343823499789346\n",
      "Epoch: 5 Step: 191 Loss: 1.3638571712738292\n",
      "Epoch: 5 Step: 201 Loss: 1.3520034458109116\n",
      "Epoch: 5 Step: 211 Loss: 1.3062245106760995\n",
      "Epoch: 5 Step: 221 Loss: 1.4681094922747562\n",
      "Epoch: 5 Step: 231 Loss: 1.5007493229782596\n",
      "Epoch: 5 Step: 241 Loss: 1.665457433671754\n",
      "Epoch: 5 Step: 251 Loss: 1.5068619494312805\n",
      "Epoch: 5 Step: 261 Loss: 1.42478656271431\n",
      "Epoch: 5 Step: 271 Loss: 1.544384788445925\n",
      "Epoch: 5 Step: 281 Loss: 1.429511354305864\n",
      "Epoch: 5 Step: 291 Loss: 1.3982164879387917\n",
      "Epoch: 5 Step: 301 Loss: 1.5461549849613656\n",
      "Epoch: 5 Step: 311 Loss: 1.4539929018194575\n",
      "Epoch: 5 Step: 321 Loss: 1.6457009257417836\n",
      "Epoch: 5 Step: 331 Loss: 1.4197487609862145\n",
      "Epoch: 5 Step: 341 Loss: 1.6046294160409165\n",
      "Epoch: 5 Step: 351 Loss: 1.5136486037480554\n",
      "Epoch: 5 Step: 361 Loss: 1.5170906574186778\n",
      "Epoch: 5 Step: 371 Loss: 1.2408186949719289\n",
      "Epoch: 5 Step: 381 Loss: 1.576366400524045\n",
      "Epoch: 5 Step: 391 Loss: 1.3292783171079647\n",
      "Epoch: 5 Step: 401 Loss: 1.5997830099642303\n",
      "Epoch: 5 Step: 411 Loss: 1.7368183280542366\n",
      "Epoch: 5 Step: 421 Loss: 1.6209917763628274\n",
      "Epoch: 5 Step: 431 Loss: 1.5701423316414531\n",
      "Epoch: 5 Step: 441 Loss: 1.6444169512827138\n",
      "Epoch: 5 Step: 451 Loss: 1.317695690742945\n",
      "Epoch: 5 Step: 461 Loss: 1.4705691598691275\n",
      "Epoch: 5 Step: 471 Loss: 1.4517814990027365\n",
      "Epoch: 5 Step: 481 Loss: 1.5070207605340311\n",
      "Epoch: 5 Step: 491 Loss: 1.6168609867260981\n",
      "Epoch: 5 Step: 501 Loss: 1.560604585236387\n",
      "Epoch: 5 Step: 511 Loss: 1.3956813364442884\n",
      "Epoch: 5 Step: 521 Loss: 1.5041948637776588\n",
      "Epoch: 5 Step: 531 Loss: 1.5050318666370746\n",
      "Epoch: 5 Step: 541 Loss: 1.4279230502055515\n",
      "Epoch: 5 Step: 551 Loss: 1.358622663266571\n",
      "Epoch: 5 Step: 561 Loss: 1.4042549846380592\n",
      "Epoch: 5 Step: 571 Loss: 1.4296534474746665\n",
      "Epoch: 5 Step: 581 Loss: 1.5559200859950322\n",
      "Epoch: 5 Step: 591 Loss: 1.5127589138034692\n",
      "Epoch: 5 Step: 601 Loss: 1.5186720124663928\n",
      "Epoch: 5 Step: 611 Loss: 1.3880959592444553\n",
      "Epoch: 5 Step: 621 Loss: 1.4769132048311777\n",
      "Epoch: 5 Step: 631 Loss: 1.4936162871047332\n",
      "Epoch: 5 Step: 641 Loss: 1.6411010081740363\n",
      "Epoch: 5 Step: 651 Loss: 1.42167094789624\n",
      "Epoch: 5 Step: 661 Loss: 1.4350018395119786\n",
      "Epoch: 5 Step: 671 Loss: 1.607747485425824\n",
      "Epoch: 5 Step: 681 Loss: 1.608091913048018\n",
      "Epoch: 5 Step: 691 Loss: 1.5586484861723031\n",
      "Epoch: 5 Step: 701 Loss: 1.3794035583117101\n",
      "Epoch: 5 Step: 711 Loss: 1.4357406455445698\n",
      "Epoch: 5 Step: 721 Loss: 1.239259223621274\n",
      "Epoch: 5 Step: 731 Loss: 1.2564276084413937\n",
      "Epoch: 5 Step: 741 Loss: 1.2445523068846616\n",
      "Epoch: 5 Step: 751 Loss: 1.7507089671279195\n",
      "Epoch: 5 Step: 761 Loss: 1.1570516701153708\n",
      "Epoch: 5 Step: 771 Loss: 1.508664066450041\n",
      "Epoch: 5 Step: 781 Loss: 1.279644870479181\n",
      "Epoch: 6 Step: 1 Loss: 1.5866194191891188\n",
      "Epoch: 6 Step: 11 Loss: 1.7253924967649263\n",
      "Epoch: 6 Step: 21 Loss: 1.6599126039116419\n",
      "Epoch: 6 Step: 31 Loss: 1.689240085189862\n",
      "Epoch: 6 Step: 41 Loss: 1.3876378601387396\n",
      "Epoch: 6 Step: 51 Loss: 1.3557429948361468\n",
      "Epoch: 6 Step: 61 Loss: 1.543073723089581\n",
      "Epoch: 6 Step: 71 Loss: 1.8997045992855401\n",
      "Epoch: 6 Step: 81 Loss: 1.6160697528378738\n",
      "Epoch: 6 Step: 91 Loss: 1.6393794453313855\n",
      "Epoch: 6 Step: 101 Loss: 1.4267270528581828\n",
      "Epoch: 6 Step: 111 Loss: 1.516959541668268\n",
      "Epoch: 6 Step: 121 Loss: 1.6576432689590863\n",
      "Epoch: 6 Step: 131 Loss: 1.4386724455622373\n",
      "Epoch: 6 Step: 141 Loss: 1.650561315037106\n",
      "Epoch: 6 Step: 151 Loss: 1.5521371075142922\n",
      "Epoch: 6 Step: 161 Loss: 1.5765544427367395\n",
      "Epoch: 6 Step: 171 Loss: 1.4014204466873994\n",
      "Epoch: 6 Step: 181 Loss: 1.3083737689951283\n",
      "Epoch: 6 Step: 191 Loss: 1.1842490255406362\n",
      "Epoch: 6 Step: 201 Loss: 1.1560944704111056\n",
      "Epoch: 6 Step: 211 Loss: 1.0901603281344219\n",
      "Epoch: 6 Step: 221 Loss: 1.4230492890948763\n",
      "Epoch: 6 Step: 231 Loss: 1.4152054981980235\n",
      "Epoch: 6 Step: 241 Loss: 1.623595351969962\n",
      "Epoch: 6 Step: 251 Loss: 1.281532818853956\n",
      "Epoch: 6 Step: 261 Loss: 1.33071539776635\n",
      "Epoch: 6 Step: 271 Loss: 1.5489337824616083\n",
      "Epoch: 6 Step: 281 Loss: 1.4012678444747522\n",
      "Epoch: 6 Step: 291 Loss: 1.4651704635962997\n",
      "Epoch: 6 Step: 301 Loss: 1.5318882500851312\n",
      "Epoch: 6 Step: 311 Loss: 1.3424615373958244\n",
      "Epoch: 6 Step: 321 Loss: 1.447869072263419\n",
      "Epoch: 6 Step: 331 Loss: 1.3635650625451925\n",
      "Epoch: 6 Step: 341 Loss: 1.575033846654165\n",
      "Epoch: 6 Step: 351 Loss: 1.4056270107723894\n",
      "Epoch: 6 Step: 361 Loss: 1.5569594395879065\n",
      "Epoch: 6 Step: 371 Loss: 1.1447191637206475\n",
      "Epoch: 6 Step: 381 Loss: 1.3607454400955201\n",
      "Epoch: 6 Step: 391 Loss: 1.1614385489136734\n",
      "Epoch: 6 Step: 401 Loss: 1.4624043846775614\n",
      "Epoch: 6 Step: 411 Loss: 1.5557796352889053\n",
      "Epoch: 6 Step: 421 Loss: 1.6004881380875284\n",
      "Epoch: 6 Step: 431 Loss: 1.4151975187630779\n",
      "Epoch: 6 Step: 441 Loss: 1.3833025532988485\n",
      "Epoch: 6 Step: 451 Loss: 1.2372523035909826\n",
      "Epoch: 6 Step: 461 Loss: 1.3529252689183129\n",
      "Epoch: 6 Step: 471 Loss: 1.5432925551423748\n",
      "Epoch: 6 Step: 481 Loss: 1.4198666156989268\n",
      "Epoch: 6 Step: 491 Loss: 1.6134536805061197\n",
      "Epoch: 6 Step: 501 Loss: 1.6258725971125068\n",
      "Epoch: 6 Step: 511 Loss: 1.2189508719077473\n",
      "Epoch: 6 Step: 521 Loss: 1.3858724280523058\n",
      "Epoch: 6 Step: 531 Loss: 1.3635385644068723\n",
      "Epoch: 6 Step: 541 Loss: 1.3250691784601276\n",
      "Epoch: 6 Step: 551 Loss: 1.428454461533533\n",
      "Epoch: 6 Step: 561 Loss: 1.3584531881693398\n",
      "Epoch: 6 Step: 571 Loss: 1.3433527023876297\n",
      "Epoch: 6 Step: 581 Loss: 1.5895698439514967\n",
      "Epoch: 6 Step: 591 Loss: 1.4958006997721773\n",
      "Epoch: 6 Step: 601 Loss: 1.4390172307558196\n",
      "Epoch: 6 Step: 611 Loss: 1.3870247363873993\n",
      "Epoch: 6 Step: 621 Loss: 1.4965103323334732\n",
      "Epoch: 6 Step: 631 Loss: 1.3921023171942206\n",
      "Epoch: 6 Step: 641 Loss: 1.504877553964395\n",
      "Epoch: 6 Step: 651 Loss: 1.242403426975425\n",
      "Epoch: 6 Step: 661 Loss: 1.160044636468961\n",
      "Epoch: 6 Step: 671 Loss: 1.4881300475364003\n",
      "Epoch: 6 Step: 681 Loss: 1.6766125842821797\n",
      "Epoch: 6 Step: 691 Loss: 1.5988346539415752\n",
      "Epoch: 6 Step: 701 Loss: 1.3989356452395647\n",
      "Epoch: 6 Step: 711 Loss: 1.3918862210842247\n",
      "Epoch: 6 Step: 721 Loss: 1.2353181389483328\n",
      "Epoch: 6 Step: 731 Loss: 1.050540736263712\n",
      "Epoch: 6 Step: 741 Loss: 1.4174249089645516\n",
      "Epoch: 6 Step: 751 Loss: 1.6500219268347727\n",
      "Epoch: 6 Step: 761 Loss: 1.205754667950448\n",
      "Epoch: 6 Step: 771 Loss: 1.533986164598811\n",
      "Epoch: 6 Step: 781 Loss: 1.2415739459943866\n",
      "Epoch: 7 Step: 1 Loss: 1.553954894724276\n",
      "Epoch: 7 Step: 11 Loss: 1.6165672766197017\n",
      "Epoch: 7 Step: 21 Loss: 1.647670368398361\n",
      "Epoch: 7 Step: 31 Loss: 1.7129921035407842\n",
      "Epoch: 7 Step: 41 Loss: 1.3052473496941766\n",
      "Epoch: 7 Step: 51 Loss: 1.1015316663357004\n",
      "Epoch: 7 Step: 61 Loss: 1.4636976883298272\n",
      "Epoch: 7 Step: 71 Loss: 1.6884877948154928\n",
      "Epoch: 7 Step: 81 Loss: 1.414619441688887\n",
      "Epoch: 7 Step: 91 Loss: 1.4405557905630086\n",
      "Epoch: 7 Step: 101 Loss: 1.3893676741886662\n",
      "Epoch: 7 Step: 111 Loss: 1.4007450359337883\n",
      "Epoch: 7 Step: 121 Loss: 1.4432119828044465\n",
      "Epoch: 7 Step: 131 Loss: 1.3962690465163605\n",
      "Epoch: 7 Step: 141 Loss: 1.5990199392197448\n",
      "Epoch: 7 Step: 151 Loss: 1.3107673871659395\n",
      "Epoch: 7 Step: 161 Loss: 1.3131955208063775\n",
      "Epoch: 7 Step: 171 Loss: 1.3745691516023324\n",
      "Epoch: 7 Step: 181 Loss: 1.2075532226691017\n",
      "Epoch: 7 Step: 191 Loss: 1.1255822414100738\n",
      "Epoch: 7 Step: 201 Loss: 1.1506369566951995\n",
      "Epoch: 7 Step: 211 Loss: 0.953961287534302\n",
      "Epoch: 7 Step: 221 Loss: 1.2317063634074756\n",
      "Epoch: 7 Step: 231 Loss: 1.2310952645452626\n",
      "Epoch: 7 Step: 241 Loss: 1.5177955590269898\n",
      "Epoch: 7 Step: 251 Loss: 1.1973132542271765\n",
      "Epoch: 7 Step: 261 Loss: 1.3577486759735613\n",
      "Epoch: 7 Step: 271 Loss: 1.5758853276962335\n",
      "Epoch: 7 Step: 281 Loss: 1.5141832213267281\n",
      "Epoch: 7 Step: 291 Loss: 1.100187933677777\n",
      "Epoch: 7 Step: 301 Loss: 1.4587309349912223\n",
      "Epoch: 7 Step: 311 Loss: 1.3477696691211176\n",
      "Epoch: 7 Step: 321 Loss: 1.459659539761393\n",
      "Epoch: 7 Step: 331 Loss: 1.3001184752033703\n",
      "Epoch: 7 Step: 341 Loss: 1.4233147562573882\n",
      "Epoch: 7 Step: 351 Loss: 1.3186027955008537\n",
      "Epoch: 7 Step: 361 Loss: 1.4847580716479731\n",
      "Epoch: 7 Step: 371 Loss: 1.0822118627168427\n",
      "Epoch: 7 Step: 381 Loss: 1.3740625499672667\n",
      "Epoch: 7 Step: 391 Loss: 1.1642690454324465\n",
      "Epoch: 7 Step: 401 Loss: 1.4089195237335472\n",
      "Epoch: 7 Step: 411 Loss: 1.5363662769487898\n",
      "Epoch: 7 Step: 421 Loss: 1.31625049192593\n",
      "Epoch: 7 Step: 431 Loss: 1.3098934088667624\n",
      "Epoch: 7 Step: 441 Loss: 1.3599032452744493\n",
      "Epoch: 7 Step: 451 Loss: 1.056731393631541\n",
      "Epoch: 7 Step: 461 Loss: 1.347200089353032\n",
      "Epoch: 7 Step: 471 Loss: 1.4928137304471778\n",
      "Epoch: 7 Step: 481 Loss: 1.435890579732153\n",
      "Epoch: 7 Step: 491 Loss: 1.575422875075374\n",
      "Epoch: 7 Step: 501 Loss: 1.4292976347088722\n",
      "Epoch: 7 Step: 511 Loss: 1.284638714998031\n",
      "Epoch: 7 Step: 521 Loss: 1.3891555778831342\n",
      "Epoch: 7 Step: 531 Loss: 1.3849765907299874\n",
      "Epoch: 7 Step: 541 Loss: 1.3690166195284406\n",
      "Epoch: 7 Step: 551 Loss: 1.1376548429277515\n",
      "Epoch: 7 Step: 561 Loss: 1.327706942646854\n",
      "Epoch: 7 Step: 571 Loss: 1.244000906809346\n",
      "Epoch: 7 Step: 581 Loss: 1.3526710965984314\n",
      "Epoch: 7 Step: 591 Loss: 1.400132896550594\n",
      "Epoch: 7 Step: 601 Loss: 1.4050286357253317\n",
      "Epoch: 7 Step: 611 Loss: 1.266477730877486\n",
      "Epoch: 7 Step: 621 Loss: 1.345776171859363\n",
      "Epoch: 7 Step: 631 Loss: 1.4387530553287338\n",
      "Epoch: 7 Step: 641 Loss: 1.591288816629825\n",
      "Epoch: 7 Step: 651 Loss: 1.2900535447910582\n",
      "Epoch: 7 Step: 661 Loss: 1.145154054312786\n",
      "Epoch: 7 Step: 671 Loss: 1.3838614355732184\n",
      "Epoch: 7 Step: 681 Loss: 1.62134515867121\n",
      "Epoch: 7 Step: 691 Loss: 1.3915595262712106\n",
      "Epoch: 7 Step: 701 Loss: 1.2723961264619672\n",
      "Epoch: 7 Step: 711 Loss: 1.3223115996244659\n",
      "Epoch: 7 Step: 721 Loss: 1.0741824081346438\n",
      "Epoch: 7 Step: 731 Loss: 1.0424106576882968\n",
      "Epoch: 7 Step: 741 Loss: 1.2268933569619047\n",
      "Epoch: 7 Step: 751 Loss: 1.7080505113720061\n",
      "Epoch: 7 Step: 761 Loss: 1.054700909456372\n",
      "Epoch: 7 Step: 771 Loss: 1.722475664958398\n",
      "Epoch: 7 Step: 781 Loss: 1.3998716869736796\n",
      "Epoch: 8 Step: 1 Loss: 1.5568824274998017\n",
      "Epoch: 8 Step: 11 Loss: 1.53430490644878\n",
      "Epoch: 8 Step: 21 Loss: 1.7010479269206629\n",
      "Epoch: 8 Step: 31 Loss: 1.4805092444131387\n",
      "Epoch: 8 Step: 41 Loss: 1.2412297067674216\n",
      "Epoch: 8 Step: 51 Loss: 1.1845912891358208\n",
      "Epoch: 8 Step: 61 Loss: 1.3747230144617892\n",
      "Epoch: 8 Step: 71 Loss: 1.7453928780620895\n",
      "Epoch: 8 Step: 81 Loss: 1.3922354255400449\n",
      "Epoch: 8 Step: 91 Loss: 1.181437479176937\n",
      "Epoch: 8 Step: 101 Loss: 1.315725267519835\n",
      "Epoch: 8 Step: 111 Loss: 1.242348142606204\n",
      "Epoch: 8 Step: 121 Loss: 1.29262586956466\n",
      "Epoch: 8 Step: 131 Loss: 1.3923809203511806\n",
      "Epoch: 8 Step: 141 Loss: 1.4361250185940269\n",
      "Epoch: 8 Step: 151 Loss: 1.2682807707940333\n",
      "Epoch: 8 Step: 161 Loss: 1.199416339291215\n",
      "Epoch: 8 Step: 171 Loss: 1.2865229600407224\n",
      "Epoch: 8 Step: 181 Loss: 1.1435593365373058\n",
      "Epoch: 8 Step: 191 Loss: 1.124602319140823\n",
      "Epoch: 8 Step: 201 Loss: 1.0186544293287665\n",
      "Epoch: 8 Step: 211 Loss: 0.9622004468054897\n",
      "Epoch: 8 Step: 221 Loss: 1.212561556034207\n",
      "Epoch: 8 Step: 231 Loss: 1.407232419126518\n",
      "Epoch: 8 Step: 241 Loss: 1.4846722962687382\n",
      "Epoch: 8 Step: 251 Loss: 1.2776607916792293\n",
      "Epoch: 8 Step: 261 Loss: 1.2479708141458103\n",
      "Epoch: 8 Step: 271 Loss: 1.3183130842750221\n",
      "Epoch: 8 Step: 281 Loss: 1.434724302572562\n",
      "Epoch: 8 Step: 291 Loss: 1.272496539807611\n",
      "Epoch: 8 Step: 301 Loss: 1.3137558027519056\n",
      "Epoch: 8 Step: 311 Loss: 1.1842122993478168\n",
      "Epoch: 8 Step: 321 Loss: 1.506126892698041\n",
      "Epoch: 8 Step: 331 Loss: 1.3157455294390061\n",
      "Epoch: 8 Step: 341 Loss: 1.3359241569413123\n",
      "Epoch: 8 Step: 351 Loss: 1.3668585810876803\n",
      "Epoch: 8 Step: 361 Loss: 1.425937730143685\n",
      "Epoch: 8 Step: 371 Loss: 1.0437954623643\n",
      "Epoch: 8 Step: 381 Loss: 1.2467250959767582\n",
      "Epoch: 8 Step: 391 Loss: 0.989439942153961\n",
      "Epoch: 8 Step: 401 Loss: 1.2396265547748047\n",
      "Epoch: 8 Step: 411 Loss: 1.3433794608434066\n",
      "Epoch: 8 Step: 421 Loss: 1.4721817476565713\n",
      "Epoch: 8 Step: 431 Loss: 1.2354840761497987\n",
      "Epoch: 8 Step: 441 Loss: 1.246889470172969\n",
      "Epoch: 8 Step: 451 Loss: 1.051131783516301\n",
      "Epoch: 8 Step: 461 Loss: 1.398910649400837\n",
      "Epoch: 8 Step: 471 Loss: 1.4373090639065818\n",
      "Epoch: 8 Step: 481 Loss: 1.4002129064558697\n",
      "Epoch: 8 Step: 491 Loss: 1.6755807814655896\n",
      "Epoch: 8 Step: 501 Loss: 1.5472681985552774\n",
      "Epoch: 8 Step: 511 Loss: 1.233178712411175\n",
      "Epoch: 8 Step: 521 Loss: 1.378766716716879\n",
      "Epoch: 8 Step: 531 Loss: 1.3032973463155078\n",
      "Epoch: 8 Step: 541 Loss: 1.3364398816313487\n",
      "Epoch: 8 Step: 551 Loss: 1.0260792090761726\n",
      "Epoch: 8 Step: 561 Loss: 1.3954890468694958\n",
      "Epoch: 8 Step: 571 Loss: 1.2170011161266705\n",
      "Epoch: 8 Step: 581 Loss: 1.3907941954851115\n",
      "Epoch: 8 Step: 591 Loss: 1.4439456338736132\n",
      "Epoch: 8 Step: 601 Loss: 1.222544949862225\n",
      "Epoch: 8 Step: 611 Loss: 1.3511139237036087\n",
      "Epoch: 8 Step: 621 Loss: 1.210350958230471\n",
      "Epoch: 8 Step: 631 Loss: 1.290909874022487\n",
      "Epoch: 8 Step: 641 Loss: 1.3969045615761484\n",
      "Epoch: 8 Step: 651 Loss: 1.2933488066047385\n",
      "Epoch: 8 Step: 661 Loss: 1.1391899929367668\n",
      "Epoch: 8 Step: 671 Loss: 1.3292666974473168\n",
      "Epoch: 8 Step: 681 Loss: 1.4591041373143236\n",
      "Epoch: 8 Step: 691 Loss: 1.403217191798512\n",
      "Epoch: 8 Step: 701 Loss: 1.3648990273781934\n",
      "Epoch: 8 Step: 711 Loss: 1.36514720839868\n",
      "Epoch: 8 Step: 721 Loss: 1.1184239286798476\n",
      "Epoch: 8 Step: 731 Loss: 1.187519610199819\n",
      "Epoch: 8 Step: 741 Loss: 1.3851174986835102\n",
      "Epoch: 8 Step: 751 Loss: 1.748130032930252\n",
      "Epoch: 8 Step: 761 Loss: 1.0318978800010645\n",
      "Epoch: 8 Step: 771 Loss: 1.7101634048487593\n",
      "Epoch: 8 Step: 781 Loss: 1.2548466678764436\n",
      "Epoch: 9 Step: 1 Loss: 1.4608870881463842\n",
      "Epoch: 9 Step: 11 Loss: 1.5569321579007365\n",
      "Epoch: 9 Step: 21 Loss: 1.366410156818946\n",
      "Epoch: 9 Step: 31 Loss: 1.5016512066101262\n",
      "Epoch: 9 Step: 41 Loss: 1.070344689052659\n",
      "Epoch: 9 Step: 51 Loss: 1.0211586814327722\n",
      "Epoch: 9 Step: 61 Loss: 1.2648073407727032\n",
      "Epoch: 9 Step: 71 Loss: 1.6875272576895588\n",
      "Epoch: 9 Step: 81 Loss: 1.3426829707537948\n",
      "Epoch: 9 Step: 91 Loss: 1.170868545146193\n",
      "Epoch: 9 Step: 101 Loss: 1.2688354345374708\n",
      "Epoch: 9 Step: 111 Loss: 1.3242500990398287\n",
      "Epoch: 9 Step: 121 Loss: 1.3416886112190007\n",
      "Epoch: 9 Step: 131 Loss: 1.2587826369794075\n",
      "Epoch: 9 Step: 141 Loss: 1.504263651915198\n",
      "Epoch: 9 Step: 151 Loss: 1.2042094231214382\n",
      "Epoch: 9 Step: 161 Loss: 1.2034512498057532\n",
      "Epoch: 9 Step: 171 Loss: 1.307370095126546\n",
      "Epoch: 9 Step: 181 Loss: 1.192102737456576\n",
      "Epoch: 9 Step: 191 Loss: 1.1110134420544957\n",
      "Epoch: 9 Step: 201 Loss: 1.1601729948635524\n",
      "Epoch: 9 Step: 211 Loss: 1.0987064495712737\n",
      "Epoch: 9 Step: 221 Loss: 1.2949185842166009\n",
      "Epoch: 9 Step: 231 Loss: 1.1646928380097672\n",
      "Epoch: 9 Step: 241 Loss: 1.486523937036865\n",
      "Epoch: 9 Step: 251 Loss: 1.14925851398977\n",
      "Epoch: 9 Step: 261 Loss: 1.3635220034509312\n",
      "Epoch: 9 Step: 271 Loss: 1.299309373593509\n",
      "Epoch: 9 Step: 281 Loss: 1.3218410569241925\n",
      "Epoch: 9 Step: 291 Loss: 1.1856210123051816\n",
      "Epoch: 9 Step: 301 Loss: 1.351787120792532\n",
      "Epoch: 9 Step: 311 Loss: 1.3354369727838005\n",
      "Epoch: 9 Step: 321 Loss: 1.2635779580654796\n",
      "Epoch: 9 Step: 331 Loss: 1.3838553730813459\n",
      "Epoch: 9 Step: 341 Loss: 1.291787410754667\n",
      "Epoch: 9 Step: 351 Loss: 1.1465627159404268\n",
      "Epoch: 9 Step: 361 Loss: 1.439217840991203\n",
      "Epoch: 9 Step: 371 Loss: 1.0098868158564618\n",
      "Epoch: 9 Step: 381 Loss: 1.1552998311965066\n",
      "Epoch: 9 Step: 391 Loss: 1.0684122881517744\n",
      "Epoch: 9 Step: 401 Loss: 1.1579198633112266\n",
      "Epoch: 9 Step: 411 Loss: 1.3710702202408211\n",
      "Epoch: 9 Step: 421 Loss: 1.428427329815435\n",
      "Epoch: 9 Step: 431 Loss: 1.4142775606446962\n",
      "Epoch: 9 Step: 441 Loss: 1.3363302209441565\n",
      "Epoch: 9 Step: 451 Loss: 1.216655373717007\n",
      "Epoch: 9 Step: 461 Loss: 1.4018009627615862\n",
      "Epoch: 9 Step: 471 Loss: 1.273583336849697\n",
      "Epoch: 9 Step: 481 Loss: 1.4538349371067376\n",
      "Epoch: 9 Step: 491 Loss: 1.6505109133535778\n",
      "Epoch: 9 Step: 501 Loss: 1.444489425096413\n",
      "Epoch: 9 Step: 511 Loss: 1.152443147032249\n",
      "Epoch: 9 Step: 521 Loss: 1.34002869667721\n",
      "Epoch: 9 Step: 531 Loss: 1.1048078314093364\n",
      "Epoch: 9 Step: 541 Loss: 1.1780976636278684\n",
      "Epoch: 9 Step: 551 Loss: 1.0360029720376551\n",
      "Epoch: 9 Step: 561 Loss: 1.4042051553245378\n",
      "Epoch: 9 Step: 571 Loss: 1.1250650723416635\n",
      "Epoch: 9 Step: 581 Loss: 1.3660474652832224\n",
      "Epoch: 9 Step: 591 Loss: 1.3963090482948162\n",
      "Epoch: 9 Step: 601 Loss: 1.156246975727103\n",
      "Epoch: 9 Step: 611 Loss: 1.1013442866982774\n",
      "Epoch: 9 Step: 621 Loss: 1.126554199415849\n",
      "Epoch: 9 Step: 631 Loss: 1.1827240967626997\n",
      "Epoch: 9 Step: 641 Loss: 1.4196744507881536\n",
      "Epoch: 9 Step: 651 Loss: 1.2664034231998036\n",
      "Epoch: 9 Step: 661 Loss: 1.1127416084411301\n",
      "Epoch: 9 Step: 671 Loss: 1.382000222880429\n",
      "Epoch: 9 Step: 681 Loss: 1.3947150735702174\n",
      "Epoch: 9 Step: 691 Loss: 1.3176833825908603\n",
      "Epoch: 9 Step: 701 Loss: 1.2259596497823408\n",
      "Epoch: 9 Step: 711 Loss: 1.25496324045753\n",
      "Epoch: 9 Step: 721 Loss: 1.0096792851469099\n",
      "Epoch: 9 Step: 731 Loss: 1.1139432908881548\n",
      "Epoch: 9 Step: 741 Loss: 1.1969278846821374\n",
      "Epoch: 9 Step: 751 Loss: 1.5537234375694982\n",
      "Epoch: 9 Step: 761 Loss: 0.951417301700492\n",
      "Epoch: 9 Step: 771 Loss: 1.37072103421615\n",
      "Epoch: 9 Step: 781 Loss: 1.1264403518721025\n",
      "Epoch: 10 Step: 1 Loss: 1.43607713996971\n",
      "Epoch: 10 Step: 11 Loss: 1.5560643435665507\n",
      "Epoch: 10 Step: 21 Loss: 1.2627007086138775\n",
      "Epoch: 10 Step: 31 Loss: 1.3966203296306272\n",
      "Epoch: 10 Step: 41 Loss: 0.9911160885387367\n",
      "Epoch: 10 Step: 51 Loss: 0.9223655862121833\n",
      "Epoch: 10 Step: 61 Loss: 1.2092414866811076\n",
      "Epoch: 10 Step: 71 Loss: 1.718539235746689\n",
      "Epoch: 10 Step: 81 Loss: 1.2722543641492983\n",
      "Epoch: 10 Step: 91 Loss: 1.017494748268559\n",
      "Epoch: 10 Step: 101 Loss: 1.2850947225748124\n",
      "Epoch: 10 Step: 111 Loss: 1.3431332744250826\n",
      "Epoch: 10 Step: 121 Loss: 1.2971327880682413\n",
      "Epoch: 10 Step: 131 Loss: 1.2071351739777278\n",
      "Epoch: 10 Step: 141 Loss: 1.5619526921978135\n",
      "Epoch: 10 Step: 151 Loss: 1.2277405418890044\n",
      "Epoch: 10 Step: 161 Loss: 1.3010609387163448\n",
      "Epoch: 10 Step: 171 Loss: 1.3673261230855207\n",
      "Epoch: 10 Step: 181 Loss: 1.2196848677392187\n",
      "Epoch: 10 Step: 191 Loss: 1.0094672343238555\n",
      "Epoch: 10 Step: 201 Loss: 1.0479275162687212\n",
      "Epoch: 10 Step: 211 Loss: 1.084145316492612\n",
      "Epoch: 10 Step: 221 Loss: 1.2458619737893488\n",
      "Epoch: 10 Step: 231 Loss: 1.0043382783799477\n",
      "Epoch: 10 Step: 241 Loss: 1.2842320914270984\n",
      "Epoch: 10 Step: 251 Loss: 1.0947632625116002\n",
      "Epoch: 10 Step: 261 Loss: 1.3084093724233323\n",
      "Epoch: 10 Step: 271 Loss: 1.2291477786795966\n",
      "Epoch: 10 Step: 281 Loss: 1.1386243502649325\n",
      "Epoch: 10 Step: 291 Loss: 1.1063989960968283\n",
      "Epoch: 10 Step: 301 Loss: 1.288690708078403\n",
      "Epoch: 10 Step: 311 Loss: 1.1427783167901922\n",
      "Epoch: 10 Step: 321 Loss: 1.3294474251586137\n",
      "Epoch: 10 Step: 331 Loss: 1.2234218932155145\n",
      "Epoch: 10 Step: 341 Loss: 1.2595808573376006\n",
      "Epoch: 10 Step: 351 Loss: 1.0936420509653593\n",
      "Epoch: 10 Step: 361 Loss: 1.333337800835272\n",
      "Epoch: 10 Step: 371 Loss: 1.0678051549825895\n",
      "Epoch: 10 Step: 381 Loss: 1.2783518904055033\n",
      "Epoch: 10 Step: 391 Loss: 0.9263006054673415\n",
      "Epoch: 10 Step: 401 Loss: 1.1751070040279263\n",
      "Epoch: 10 Step: 411 Loss: 1.2998818074915346\n",
      "Epoch: 10 Step: 421 Loss: 1.382054957346417\n",
      "Epoch: 10 Step: 431 Loss: 1.452370218685476\n",
      "Epoch: 10 Step: 441 Loss: 1.3816821858536306\n",
      "Epoch: 10 Step: 451 Loss: 1.0141387079080444\n",
      "Epoch: 10 Step: 461 Loss: 1.3173249872704464\n",
      "Epoch: 10 Step: 471 Loss: 1.283567349845808\n",
      "Epoch: 10 Step: 481 Loss: 1.340370012496674\n",
      "Epoch: 10 Step: 491 Loss: 1.5490935720831853\n",
      "Epoch: 10 Step: 501 Loss: 1.4133828788796836\n",
      "Epoch: 10 Step: 511 Loss: 0.9363943155355476\n",
      "Epoch: 10 Step: 521 Loss: 1.2640095412102377\n",
      "Epoch: 10 Step: 531 Loss: 1.296168186919934\n",
      "Epoch: 10 Step: 541 Loss: 1.1950301057270076\n",
      "Epoch: 10 Step: 551 Loss: 0.9253142240209185\n",
      "Epoch: 10 Step: 561 Loss: 1.1613870856702038\n",
      "Epoch: 10 Step: 571 Loss: 1.0384703245009406\n",
      "Epoch: 10 Step: 581 Loss: 1.468191140961189\n",
      "Epoch: 10 Step: 591 Loss: 1.2626952113561978\n",
      "Epoch: 10 Step: 601 Loss: 1.173937654089773\n",
      "Epoch: 10 Step: 611 Loss: 1.0891955266276483\n",
      "Epoch: 10 Step: 621 Loss: 1.1987029350975558\n",
      "Epoch: 10 Step: 631 Loss: 1.0836020943516735\n",
      "Epoch: 10 Step: 641 Loss: 1.393028916995871\n",
      "Epoch: 10 Step: 651 Loss: 1.2031351628653002\n",
      "Epoch: 10 Step: 661 Loss: 1.1298497343916183\n",
      "Epoch: 10 Step: 671 Loss: 1.4905020323445384\n",
      "Epoch: 10 Step: 681 Loss: 1.547497953993505\n",
      "Epoch: 10 Step: 691 Loss: 1.209683716955787\n",
      "Epoch: 10 Step: 701 Loss: 1.2899434154684013\n",
      "Epoch: 10 Step: 711 Loss: 1.3702969497499864\n",
      "Epoch: 10 Step: 721 Loss: 0.9853573598843421\n",
      "Epoch: 10 Step: 731 Loss: 1.0382268821154663\n",
      "Epoch: 10 Step: 741 Loss: 1.1021612255074804\n",
      "Epoch: 10 Step: 751 Loss: 1.431521363906213\n",
      "Epoch: 10 Step: 761 Loss: 0.8894413273889299\n",
      "Epoch: 10 Step: 771 Loss: 1.2723291638748448\n",
      "Epoch: 10 Step: 781 Loss: 1.0955230294697347\n",
      "Epoch: 11 Step: 1 Loss: 1.3780513003508763\n",
      "Epoch: 11 Step: 11 Loss: 1.3715757696841153\n",
      "Epoch: 11 Step: 21 Loss: 1.2797963440620543\n",
      "Epoch: 11 Step: 31 Loss: 1.3645104078529853\n",
      "Epoch: 11 Step: 41 Loss: 0.9600204167225702\n",
      "Epoch: 11 Step: 51 Loss: 0.8949609266266328\n",
      "Epoch: 11 Step: 61 Loss: 1.0319877628099103\n",
      "Epoch: 11 Step: 71 Loss: 1.3650236191964558\n",
      "Epoch: 11 Step: 81 Loss: 1.367102745073085\n",
      "Epoch: 11 Step: 91 Loss: 1.0565584572648357\n",
      "Epoch: 11 Step: 101 Loss: 1.2602654318660111\n",
      "Epoch: 11 Step: 111 Loss: 1.1480120112389085\n",
      "Epoch: 11 Step: 121 Loss: 1.3756539378484793\n",
      "Epoch: 11 Step: 131 Loss: 1.3047752322375943\n",
      "Epoch: 11 Step: 141 Loss: 1.6660525012324192\n",
      "Epoch: 11 Step: 151 Loss: 1.2758727800772607\n",
      "Epoch: 11 Step: 161 Loss: 1.2312040102971746\n",
      "Epoch: 11 Step: 171 Loss: 1.2923879655460744\n",
      "Epoch: 11 Step: 181 Loss: 1.1269633090105204\n",
      "Epoch: 11 Step: 191 Loss: 1.0492625576529502\n",
      "Epoch: 11 Step: 201 Loss: 1.007549285577709\n",
      "Epoch: 11 Step: 211 Loss: 1.0557570115756594\n",
      "Epoch: 11 Step: 221 Loss: 1.2015052739476766\n",
      "Epoch: 11 Step: 231 Loss: 1.0929018388091256\n",
      "Epoch: 11 Step: 241 Loss: 1.3024130324492846\n",
      "Epoch: 11 Step: 251 Loss: 1.1906057759945354\n",
      "Epoch: 11 Step: 261 Loss: 1.1761407119802265\n",
      "Epoch: 11 Step: 271 Loss: 1.1889428565574425\n",
      "Epoch: 11 Step: 281 Loss: 0.9643380168272295\n",
      "Epoch: 11 Step: 291 Loss: 1.2127009362556236\n",
      "Epoch: 11 Step: 301 Loss: 1.194161470968956\n",
      "Epoch: 11 Step: 311 Loss: 1.090195755838745\n",
      "Epoch: 11 Step: 321 Loss: 1.4588727273128748\n",
      "Epoch: 11 Step: 331 Loss: 1.2702127243523664\n",
      "Epoch: 11 Step: 341 Loss: 1.2818395758076324\n",
      "Epoch: 11 Step: 351 Loss: 1.0525361365327366\n",
      "Epoch: 11 Step: 361 Loss: 1.4919920463810414\n",
      "Epoch: 11 Step: 371 Loss: 0.9465344759389456\n",
      "Epoch: 11 Step: 381 Loss: 1.2229407689509386\n",
      "Epoch: 11 Step: 391 Loss: 1.0161494841095606\n",
      "Epoch: 11 Step: 401 Loss: 1.1489646072808997\n",
      "Epoch: 11 Step: 411 Loss: 1.3020865558160588\n",
      "Epoch: 11 Step: 421 Loss: 1.2750717429861234\n",
      "Epoch: 11 Step: 431 Loss: 1.3885826797657943\n",
      "Epoch: 11 Step: 441 Loss: 1.2316257131498993\n",
      "Epoch: 11 Step: 451 Loss: 0.9670311356689987\n",
      "Epoch: 11 Step: 461 Loss: 1.2771745061632116\n",
      "Epoch: 11 Step: 471 Loss: 1.2486259481520927\n",
      "Epoch: 11 Step: 481 Loss: 1.2978302733223235\n",
      "Epoch: 11 Step: 491 Loss: 1.4395843516100157\n",
      "Epoch: 11 Step: 501 Loss: 1.2840397942458603\n",
      "Epoch: 11 Step: 511 Loss: 1.1145362352403796\n",
      "Epoch: 11 Step: 521 Loss: 1.22424323391507\n",
      "Epoch: 11 Step: 531 Loss: 1.1501145630854965\n",
      "Epoch: 11 Step: 541 Loss: 1.1990640132103878\n",
      "Epoch: 11 Step: 551 Loss: 0.9137248527477688\n",
      "Epoch: 11 Step: 561 Loss: 1.1390631259897446\n",
      "Epoch: 11 Step: 571 Loss: 1.0237094326213634\n",
      "Epoch: 11 Step: 581 Loss: 1.3643118122693763\n",
      "Epoch: 11 Step: 591 Loss: 1.1824369559647203\n",
      "Epoch: 11 Step: 601 Loss: 1.060453687176484\n",
      "Epoch: 11 Step: 611 Loss: 1.1869954082870993\n",
      "Epoch: 11 Step: 621 Loss: 1.2026489197142942\n",
      "Epoch: 11 Step: 631 Loss: 1.05891163427183\n",
      "Epoch: 11 Step: 641 Loss: 1.5106909543982066\n",
      "Epoch: 11 Step: 651 Loss: 1.1669336014903053\n",
      "Epoch: 11 Step: 661 Loss: 0.9930404825615335\n",
      "Epoch: 11 Step: 671 Loss: 1.2581904824087944\n",
      "Epoch: 11 Step: 681 Loss: 1.2447881430983159\n",
      "Epoch: 11 Step: 691 Loss: 1.2946915236021082\n",
      "Epoch: 11 Step: 701 Loss: 1.2412585759964345\n",
      "Epoch: 11 Step: 711 Loss: 1.306245279434016\n",
      "Epoch: 11 Step: 721 Loss: 1.0447333891852983\n",
      "Epoch: 11 Step: 731 Loss: 0.9110537400903689\n",
      "Epoch: 11 Step: 741 Loss: 1.1692070620337276\n",
      "Epoch: 11 Step: 751 Loss: 1.473840677295509\n",
      "Epoch: 11 Step: 761 Loss: 1.0065060946450637\n",
      "Epoch: 11 Step: 771 Loss: 1.3038725751704896\n",
      "Epoch: 11 Step: 781 Loss: 1.1543692806740022\n",
      "Epoch: 12 Step: 1 Loss: 1.4302878168341433\n",
      "Epoch: 12 Step: 11 Loss: 1.308459240760201\n",
      "Epoch: 12 Step: 21 Loss: 1.263901598749282\n",
      "Epoch: 12 Step: 31 Loss: 1.452186941428934\n",
      "Epoch: 12 Step: 41 Loss: 0.8987691507241213\n",
      "Epoch: 12 Step: 51 Loss: 0.9733220718766085\n",
      "Epoch: 12 Step: 61 Loss: 1.0805579243830974\n",
      "Epoch: 12 Step: 71 Loss: 1.3462451751211533\n",
      "Epoch: 12 Step: 81 Loss: 1.35003646203016\n",
      "Epoch: 12 Step: 91 Loss: 1.2816284920681724\n",
      "Epoch: 12 Step: 101 Loss: 1.2489035853976924\n",
      "Epoch: 12 Step: 111 Loss: 1.3023893462647802\n",
      "Epoch: 12 Step: 121 Loss: 1.3471712332372854\n",
      "Epoch: 12 Step: 131 Loss: 1.229773817261892\n",
      "Epoch: 12 Step: 141 Loss: 1.5898294661774401\n",
      "Epoch: 12 Step: 151 Loss: 1.1453778517832451\n",
      "Epoch: 12 Step: 161 Loss: 1.2752853779387023\n",
      "Epoch: 12 Step: 171 Loss: 1.3191795866525382\n",
      "Epoch: 12 Step: 181 Loss: 1.0544462445263334\n",
      "Epoch: 12 Step: 191 Loss: 0.9673989896603986\n",
      "Epoch: 12 Step: 201 Loss: 0.9910382097617639\n",
      "Epoch: 12 Step: 211 Loss: 0.9765428374792678\n",
      "Epoch: 12 Step: 221 Loss: 1.1410774589528772\n",
      "Epoch: 12 Step: 231 Loss: 0.9041794148207423\n",
      "Epoch: 12 Step: 241 Loss: 1.1476763639550613\n",
      "Epoch: 12 Step: 251 Loss: 0.9984309466846676\n",
      "Epoch: 12 Step: 261 Loss: 1.1989888448038324\n",
      "Epoch: 12 Step: 271 Loss: 1.139380376257924\n",
      "Epoch: 12 Step: 281 Loss: 1.051230270462375\n",
      "Epoch: 12 Step: 291 Loss: 1.0530299798702978\n",
      "Epoch: 12 Step: 301 Loss: 1.2325082418286448\n",
      "Epoch: 12 Step: 311 Loss: 1.1348734817577393\n",
      "Epoch: 12 Step: 321 Loss: 1.4817841015796698\n",
      "Epoch: 12 Step: 331 Loss: 1.1341421919077974\n",
      "Epoch: 12 Step: 341 Loss: 1.2139942998649063\n",
      "Epoch: 12 Step: 351 Loss: 1.456878210540848\n",
      "Epoch: 12 Step: 361 Loss: 1.3235085863133964\n",
      "Epoch: 12 Step: 371 Loss: 1.0684395694974358\n",
      "Epoch: 12 Step: 381 Loss: 1.4190448345067996\n",
      "Epoch: 12 Step: 391 Loss: 0.8307921250183485\n",
      "Epoch: 12 Step: 401 Loss: 1.1144840276877508\n",
      "Epoch: 12 Step: 411 Loss: 1.1163105823741835\n",
      "Epoch: 12 Step: 421 Loss: 1.2585304681978995\n",
      "Epoch: 12 Step: 431 Loss: 1.4936553251563254\n",
      "Epoch: 12 Step: 441 Loss: 1.2967128029803687\n",
      "Epoch: 12 Step: 451 Loss: 0.9418650476495605\n",
      "Epoch: 12 Step: 461 Loss: 1.1857244571182737\n",
      "Epoch: 12 Step: 471 Loss: 1.28787472683323\n",
      "Epoch: 12 Step: 481 Loss: 1.2161059957909082\n",
      "Epoch: 12 Step: 491 Loss: 1.332049727761997\n",
      "Epoch: 12 Step: 501 Loss: 1.3069524281101652\n",
      "Epoch: 12 Step: 511 Loss: 1.0022382656305662\n",
      "Epoch: 12 Step: 521 Loss: 1.324948514269632\n",
      "Epoch: 12 Step: 531 Loss: 1.1205887892312307\n",
      "Epoch: 12 Step: 541 Loss: 1.1150243684087764\n",
      "Epoch: 12 Step: 551 Loss: 0.9228112461316093\n",
      "Epoch: 12 Step: 561 Loss: 1.0636791125000484\n",
      "Epoch: 12 Step: 571 Loss: 0.8736032804108026\n",
      "Epoch: 12 Step: 581 Loss: 1.334716835717543\n",
      "Epoch: 12 Step: 591 Loss: 1.2513118507442174\n",
      "Epoch: 12 Step: 601 Loss: 1.268358454529333\n",
      "Epoch: 12 Step: 611 Loss: 1.1039931058876629\n",
      "Epoch: 12 Step: 621 Loss: 1.18392579805613\n",
      "Epoch: 12 Step: 631 Loss: 1.1799529419293515\n",
      "Epoch: 12 Step: 641 Loss: 1.4455575357433932\n",
      "Epoch: 12 Step: 651 Loss: 1.028281785980341\n",
      "Epoch: 12 Step: 661 Loss: 0.8556443295746062\n",
      "Epoch: 12 Step: 671 Loss: 1.2185516372747955\n",
      "Epoch: 12 Step: 681 Loss: 1.317569186702129\n",
      "Epoch: 12 Step: 691 Loss: 1.165299405790684\n",
      "Epoch: 12 Step: 701 Loss: 1.064088986883949\n",
      "Epoch: 12 Step: 711 Loss: 1.3043600404739917\n",
      "Epoch: 12 Step: 721 Loss: 0.846711840978267\n",
      "Epoch: 12 Step: 731 Loss: 0.8176323480849063\n",
      "Epoch: 12 Step: 741 Loss: 1.0228450617035258\n",
      "Epoch: 12 Step: 751 Loss: 1.3152225186676099\n",
      "Epoch: 12 Step: 761 Loss: 0.8132992243278496\n",
      "Epoch: 12 Step: 771 Loss: 1.1457988232650314\n",
      "Epoch: 12 Step: 781 Loss: 1.1695376368263442\n",
      "Epoch: 13 Step: 1 Loss: 1.179871125266171\n",
      "Epoch: 13 Step: 11 Loss: 1.3366824169591294\n",
      "Epoch: 13 Step: 21 Loss: 1.2002539314775564\n",
      "Epoch: 13 Step: 31 Loss: 1.3893211304896727\n",
      "Epoch: 13 Step: 41 Loss: 0.8998365395349008\n",
      "Epoch: 13 Step: 51 Loss: 1.0049070448388888\n",
      "Epoch: 13 Step: 61 Loss: 1.182045735902896\n",
      "Epoch: 13 Step: 71 Loss: 1.5435377983360392\n",
      "Epoch: 13 Step: 81 Loss: 1.2626920579544674\n",
      "Epoch: 13 Step: 91 Loss: 1.324216913897049\n",
      "Epoch: 13 Step: 101 Loss: 1.2188370830521946\n",
      "Epoch: 13 Step: 111 Loss: 1.2402123006425074\n",
      "Epoch: 13 Step: 121 Loss: 1.4202365052978712\n",
      "Epoch: 13 Step: 131 Loss: 1.2288693152145544\n",
      "Epoch: 13 Step: 141 Loss: 1.5150566090331166\n",
      "Epoch: 13 Step: 151 Loss: 1.214942639378205\n",
      "Epoch: 13 Step: 161 Loss: 1.213753898601588\n",
      "Epoch: 13 Step: 171 Loss: 1.1160548691167502\n",
      "Epoch: 13 Step: 181 Loss: 0.9319260143829339\n",
      "Epoch: 13 Step: 191 Loss: 1.0542202164983923\n",
      "Epoch: 13 Step: 201 Loss: 0.8261523930849478\n",
      "Epoch: 13 Step: 211 Loss: 0.8733857058437277\n",
      "Epoch: 13 Step: 221 Loss: 1.1466510300223385\n",
      "Epoch: 13 Step: 231 Loss: 0.9439093161376202\n",
      "Epoch: 13 Step: 241 Loss: 1.1374196986265632\n",
      "Epoch: 13 Step: 251 Loss: 1.045484427144659\n",
      "Epoch: 13 Step: 261 Loss: 1.2044401452910471\n",
      "Epoch: 13 Step: 271 Loss: 1.187620316515142\n",
      "Epoch: 13 Step: 281 Loss: 0.9667333964699099\n",
      "Epoch: 13 Step: 291 Loss: 1.0681792842515851\n",
      "Epoch: 13 Step: 301 Loss: 1.3120084425882816\n",
      "Epoch: 13 Step: 311 Loss: 1.2665902711856734\n",
      "Epoch: 13 Step: 321 Loss: 1.227045319572257\n",
      "Epoch: 13 Step: 331 Loss: 1.071795361881457\n",
      "Epoch: 13 Step: 341 Loss: 1.045714444978158\n",
      "Epoch: 13 Step: 351 Loss: 1.285531272584665\n",
      "Epoch: 13 Step: 361 Loss: 1.1874729674867774\n",
      "Epoch: 13 Step: 371 Loss: 0.8260820190554377\n",
      "Epoch: 13 Step: 381 Loss: 1.0953336036931607\n",
      "Epoch: 13 Step: 391 Loss: 1.0145871302503298\n",
      "Epoch: 13 Step: 401 Loss: 1.2035502466087973\n",
      "Epoch: 13 Step: 411 Loss: 1.1803292988604794\n",
      "Epoch: 13 Step: 421 Loss: 1.1379696524839726\n",
      "Epoch: 13 Step: 431 Loss: 1.4145687598544887\n",
      "Epoch: 13 Step: 441 Loss: 1.0020977896882675\n",
      "Epoch: 13 Step: 451 Loss: 0.8240798304642769\n",
      "Epoch: 13 Step: 461 Loss: 1.074408928790428\n",
      "Epoch: 13 Step: 471 Loss: 1.2196213826857085\n",
      "Epoch: 13 Step: 481 Loss: 1.0839672445985555\n",
      "Epoch: 13 Step: 491 Loss: 1.2080238471253937\n",
      "Epoch: 13 Step: 501 Loss: 1.1427659706452293\n",
      "Epoch: 13 Step: 511 Loss: 1.0243986648683725\n",
      "Epoch: 13 Step: 521 Loss: 1.1835726465168122\n",
      "Epoch: 13 Step: 531 Loss: 1.186833671647359\n",
      "Epoch: 13 Step: 541 Loss: 1.199802133173493\n",
      "Epoch: 13 Step: 551 Loss: 1.0206300491078673\n",
      "Epoch: 13 Step: 561 Loss: 1.074783866594419\n",
      "Epoch: 13 Step: 571 Loss: 1.0066567326515248\n",
      "Epoch: 13 Step: 581 Loss: 1.4247789815388174\n",
      "Epoch: 13 Step: 591 Loss: 1.1256887396861646\n",
      "Epoch: 13 Step: 601 Loss: 1.1029712794852709\n",
      "Epoch: 13 Step: 611 Loss: 0.9460211591738241\n",
      "Epoch: 13 Step: 621 Loss: 1.0834674379812965\n",
      "Epoch: 13 Step: 631 Loss: 1.0359519660942473\n",
      "Epoch: 13 Step: 641 Loss: 1.144329420534238\n",
      "Epoch: 13 Step: 651 Loss: 0.994837543820591\n",
      "Epoch: 13 Step: 661 Loss: 0.9636935826848892\n",
      "Epoch: 13 Step: 671 Loss: 1.152034474451169\n",
      "Epoch: 13 Step: 681 Loss: 1.3114288595185095\n",
      "Epoch: 13 Step: 691 Loss: 0.938704932968758\n",
      "Epoch: 13 Step: 701 Loss: 1.109595345220347\n",
      "Epoch: 13 Step: 711 Loss: 1.2003116302274013\n",
      "Epoch: 13 Step: 721 Loss: 0.7672439017463137\n",
      "Epoch: 13 Step: 731 Loss: 0.8488332172575591\n",
      "Epoch: 13 Step: 741 Loss: 1.0379955069014584\n",
      "Epoch: 13 Step: 751 Loss: 1.208276904541032\n",
      "Epoch: 13 Step: 761 Loss: 0.7877520988192966\n",
      "Epoch: 13 Step: 771 Loss: 1.2592215110035587\n",
      "Epoch: 13 Step: 781 Loss: 1.0238039907779268\n",
      "Epoch: 14 Step: 1 Loss: 1.4525963873115073\n",
      "Epoch: 14 Step: 11 Loss: 1.3155554001159222\n",
      "Epoch: 14 Step: 21 Loss: 1.4582752468492075\n",
      "Epoch: 14 Step: 31 Loss: 1.5119589543517482\n",
      "Epoch: 14 Step: 41 Loss: 1.0590187839578031\n",
      "Epoch: 14 Step: 51 Loss: 0.9374157192533502\n",
      "Epoch: 14 Step: 61 Loss: 1.2074414408435097\n",
      "Epoch: 14 Step: 71 Loss: 1.4159323884413486\n",
      "Epoch: 14 Step: 81 Loss: 1.1433745733731786\n",
      "Epoch: 14 Step: 91 Loss: 1.1637720493321815\n",
      "Epoch: 14 Step: 101 Loss: 1.0769303777214656\n",
      "Epoch: 14 Step: 111 Loss: 1.0910235325713404\n",
      "Epoch: 14 Step: 121 Loss: 1.248458034809349\n",
      "Epoch: 14 Step: 131 Loss: 1.1997504661795961\n",
      "Epoch: 14 Step: 141 Loss: 1.2677078411871379\n",
      "Epoch: 14 Step: 151 Loss: 1.1134935348875104\n",
      "Epoch: 14 Step: 161 Loss: 1.0218905692890208\n",
      "Epoch: 14 Step: 171 Loss: 0.9616886517263241\n",
      "Epoch: 14 Step: 181 Loss: 0.9026839096814325\n",
      "Epoch: 14 Step: 191 Loss: 0.9918769230319933\n",
      "Epoch: 14 Step: 201 Loss: 0.8255202286561756\n",
      "Epoch: 14 Step: 211 Loss: 0.7443844437981515\n",
      "Epoch: 14 Step: 221 Loss: 1.051405375757853\n",
      "Epoch: 14 Step: 231 Loss: 0.9114556041997852\n",
      "Epoch: 14 Step: 241 Loss: 1.1199805924875523\n",
      "Epoch: 14 Step: 251 Loss: 1.1503122477080903\n",
      "Epoch: 14 Step: 261 Loss: 1.2404166831388495\n",
      "Epoch: 14 Step: 271 Loss: 1.288608287848357\n",
      "Epoch: 14 Step: 281 Loss: 1.3823101551228658\n",
      "Epoch: 14 Step: 291 Loss: 1.0346398651591642\n",
      "Epoch: 14 Step: 301 Loss: 1.3125717178897944\n",
      "Epoch: 14 Step: 311 Loss: 0.9595176521137396\n",
      "Epoch: 14 Step: 321 Loss: 1.225986529775185\n",
      "Epoch: 14 Step: 331 Loss: 0.9778151385652226\n",
      "Epoch: 14 Step: 341 Loss: 1.1028515073496912\n",
      "Epoch: 14 Step: 351 Loss: 1.108442244340738\n",
      "Epoch: 14 Step: 361 Loss: 1.1491265964407504\n",
      "Epoch: 14 Step: 371 Loss: 0.8896937683630446\n",
      "Epoch: 14 Step: 381 Loss: 1.0757754548547822\n",
      "Epoch: 14 Step: 391 Loss: 0.8494594091553811\n",
      "Epoch: 14 Step: 401 Loss: 1.04772393351768\n",
      "Epoch: 14 Step: 411 Loss: 1.102902811046597\n",
      "Epoch: 14 Step: 421 Loss: 1.0963587953241112\n",
      "Epoch: 14 Step: 431 Loss: 1.1340165284687331\n",
      "Epoch: 14 Step: 441 Loss: 0.8690370819536073\n",
      "Epoch: 14 Step: 451 Loss: 0.9186542749604006\n",
      "Epoch: 14 Step: 461 Loss: 1.171052170819089\n",
      "Epoch: 14 Step: 471 Loss: 1.1928516137946672\n",
      "Epoch: 14 Step: 481 Loss: 1.118057613797524\n",
      "Epoch: 14 Step: 491 Loss: 1.2045113567089492\n",
      "Epoch: 14 Step: 501 Loss: 1.3846993576122988\n",
      "Epoch: 14 Step: 511 Loss: 1.0057137519425239\n",
      "Epoch: 14 Step: 521 Loss: 1.187511092770137\n",
      "Epoch: 14 Step: 531 Loss: 1.1036498997449393\n",
      "Epoch: 14 Step: 541 Loss: 1.060273581339985\n",
      "Epoch: 14 Step: 551 Loss: 1.0532814202007756\n",
      "Epoch: 14 Step: 561 Loss: 1.122458392577939\n",
      "Epoch: 14 Step: 571 Loss: 0.8638609349005448\n",
      "Epoch: 14 Step: 581 Loss: 1.2235707567876197\n",
      "Epoch: 14 Step: 591 Loss: 1.1568327098381\n",
      "Epoch: 14 Step: 601 Loss: 1.0465168532173696\n",
      "Epoch: 14 Step: 611 Loss: 1.030104955422404\n",
      "Epoch: 14 Step: 621 Loss: 1.1067993866632095\n",
      "Epoch: 14 Step: 631 Loss: 1.0094258824863522\n",
      "Epoch: 14 Step: 641 Loss: 1.0319764410073533\n",
      "Epoch: 14 Step: 651 Loss: 0.9139764643525405\n",
      "Epoch: 14 Step: 661 Loss: 0.7744654322182865\n",
      "Epoch: 14 Step: 671 Loss: 1.0469406720478198\n",
      "Epoch: 14 Step: 681 Loss: 1.2006479354983843\n",
      "Epoch: 14 Step: 691 Loss: 0.9867488892519818\n",
      "Epoch: 14 Step: 701 Loss: 0.97752175055689\n",
      "Epoch: 14 Step: 711 Loss: 1.0528169807813077\n",
      "Epoch: 14 Step: 721 Loss: 0.8021000223123416\n",
      "Epoch: 14 Step: 731 Loss: 0.7844737010329903\n",
      "Epoch: 14 Step: 741 Loss: 0.9645707101039083\n",
      "Epoch: 14 Step: 751 Loss: 1.332589982147951\n",
      "Epoch: 14 Step: 761 Loss: 0.7855466858913766\n",
      "Epoch: 14 Step: 771 Loss: 1.2108152569561739\n",
      "Epoch: 14 Step: 781 Loss: 0.9792658708666363\n",
      "Epoch: 15 Step: 1 Loss: 1.1767671990884605\n",
      "Epoch: 15 Step: 11 Loss: 1.336409752624741\n",
      "Epoch: 15 Step: 21 Loss: 1.3000256228117406\n",
      "Epoch: 15 Step: 31 Loss: 1.1922526757503793\n",
      "Epoch: 15 Step: 41 Loss: 0.8744894644407047\n",
      "Epoch: 15 Step: 51 Loss: 0.9187758823859402\n",
      "Epoch: 15 Step: 61 Loss: 1.065870156373811\n",
      "Epoch: 15 Step: 71 Loss: 1.3766180334617715\n",
      "Epoch: 15 Step: 81 Loss: 1.2379323636336754\n",
      "Epoch: 15 Step: 91 Loss: 1.0919440616077085\n",
      "Epoch: 15 Step: 101 Loss: 1.0622129599529462\n",
      "Epoch: 15 Step: 111 Loss: 0.9891731469603205\n",
      "Epoch: 15 Step: 121 Loss: 1.1649648506230288\n",
      "Epoch: 15 Step: 131 Loss: 1.034133756039936\n",
      "Epoch: 15 Step: 141 Loss: 1.3007438008592043\n",
      "Epoch: 15 Step: 151 Loss: 0.9452972618309181\n",
      "Epoch: 15 Step: 161 Loss: 1.0488064060206461\n",
      "Epoch: 15 Step: 171 Loss: 1.140232541052487\n",
      "Epoch: 15 Step: 181 Loss: 0.8621910679340299\n",
      "Epoch: 15 Step: 191 Loss: 1.0023154040166207\n",
      "Epoch: 15 Step: 201 Loss: 0.9266874155388063\n",
      "Epoch: 15 Step: 211 Loss: 0.8268478427433759\n",
      "Epoch: 15 Step: 221 Loss: 1.0939395448528337\n",
      "Epoch: 15 Step: 231 Loss: 1.0886099461176137\n",
      "Epoch: 15 Step: 241 Loss: 0.9908156495815844\n",
      "Epoch: 15 Step: 251 Loss: 1.164384588542844\n",
      "Epoch: 15 Step: 261 Loss: 1.2730516316924771\n",
      "Epoch: 15 Step: 271 Loss: 1.3264611433080384\n",
      "Epoch: 15 Step: 281 Loss: 1.0483113907494197\n",
      "Epoch: 15 Step: 291 Loss: 0.9522774199406744\n",
      "Epoch: 15 Step: 301 Loss: 1.1412729880828558\n",
      "Epoch: 15 Step: 311 Loss: 1.006056016300388\n",
      "Epoch: 15 Step: 321 Loss: 1.3046810507078908\n",
      "Epoch: 15 Step: 331 Loss: 1.0471176052868876\n",
      "Epoch: 15 Step: 341 Loss: 0.8446009076038818\n",
      "Epoch: 15 Step: 351 Loss: 1.031375095634015\n",
      "Epoch: 15 Step: 361 Loss: 1.0243407304779992\n",
      "Epoch: 15 Step: 371 Loss: 0.805947919031983\n",
      "Epoch: 15 Step: 381 Loss: 0.9989065974952949\n",
      "Epoch: 15 Step: 391 Loss: 0.7395569342241826\n",
      "Epoch: 15 Step: 401 Loss: 0.861866867822165\n",
      "Epoch: 15 Step: 411 Loss: 1.1506019459476942\n",
      "Epoch: 15 Step: 421 Loss: 1.0766491045542204\n",
      "Epoch: 15 Step: 431 Loss: 1.1026471407406786\n",
      "Epoch: 15 Step: 441 Loss: 0.8654051795600428\n",
      "Epoch: 15 Step: 451 Loss: 0.8279317945638047\n",
      "Epoch: 15 Step: 461 Loss: 1.0690022995945379\n",
      "Epoch: 15 Step: 471 Loss: 1.0794460012470783\n",
      "Epoch: 15 Step: 481 Loss: 1.1164998391217706\n",
      "Epoch: 15 Step: 491 Loss: 1.526981418421863\n",
      "Epoch: 15 Step: 501 Loss: 1.246839627867061\n",
      "Epoch: 15 Step: 511 Loss: 0.9642703011302567\n",
      "Epoch: 15 Step: 521 Loss: 1.2361231973472844\n",
      "Epoch: 15 Step: 531 Loss: 1.0891021569030122\n",
      "Epoch: 15 Step: 541 Loss: 0.9881277321715567\n",
      "Epoch: 15 Step: 551 Loss: 0.9715727719920767\n",
      "Epoch: 15 Step: 561 Loss: 1.0251536713721767\n",
      "Epoch: 15 Step: 571 Loss: 0.7300963398035629\n",
      "Epoch: 15 Step: 581 Loss: 1.107682682591813\n",
      "Epoch: 15 Step: 591 Loss: 1.04397642735727\n",
      "Epoch: 15 Step: 601 Loss: 1.040385349559438\n",
      "Epoch: 15 Step: 611 Loss: 0.9072200601910716\n",
      "Epoch: 15 Step: 621 Loss: 0.9186750018638069\n",
      "Epoch: 15 Step: 631 Loss: 0.7844372530107819\n",
      "Epoch: 15 Step: 641 Loss: 1.0794587001562623\n",
      "Epoch: 15 Step: 651 Loss: 0.8778734334590863\n",
      "Epoch: 15 Step: 661 Loss: 0.7363944796330527\n",
      "Epoch: 15 Step: 671 Loss: 1.127533207933467\n",
      "Epoch: 15 Step: 681 Loss: 1.1701387867624067\n",
      "Epoch: 15 Step: 691 Loss: 0.9094968886288826\n",
      "Epoch: 15 Step: 701 Loss: 1.0712613384388638\n",
      "Epoch: 15 Step: 711 Loss: 1.0753768244746256\n",
      "Epoch: 15 Step: 721 Loss: 0.8377934326766713\n",
      "Epoch: 15 Step: 731 Loss: 0.8384381653154255\n",
      "Epoch: 15 Step: 741 Loss: 0.9552655085462438\n",
      "Epoch: 15 Step: 751 Loss: 1.2906106463325893\n",
      "Epoch: 15 Step: 761 Loss: 0.7436486789341468\n",
      "Epoch: 15 Step: 771 Loss: 1.1016259748355837\n",
      "Epoch: 15 Step: 781 Loss: 1.1084742757996335\n",
      "Epoch: 16 Step: 1 Loss: 1.2096546243873094\n",
      "Epoch: 16 Step: 11 Loss: 1.3070063488854118\n",
      "Epoch: 16 Step: 21 Loss: 1.2215583220537451\n",
      "Epoch: 16 Step: 31 Loss: 1.078451080095959\n",
      "Epoch: 16 Step: 41 Loss: 0.8340611952722017\n",
      "Epoch: 16 Step: 51 Loss: 0.9188154417445599\n",
      "Epoch: 16 Step: 61 Loss: 0.8964448370353957\n",
      "Epoch: 16 Step: 71 Loss: 1.430096602454661\n",
      "Epoch: 16 Step: 81 Loss: 1.2058593870424361\n",
      "Epoch: 16 Step: 91 Loss: 1.0518919527874089\n",
      "Epoch: 16 Step: 101 Loss: 1.0724482052514346\n",
      "Epoch: 16 Step: 111 Loss: 1.0582613937888903\n",
      "Epoch: 16 Step: 121 Loss: 1.2544110906273893\n",
      "Epoch: 16 Step: 131 Loss: 0.829674591400979\n",
      "Epoch: 16 Step: 141 Loss: 1.1997437869472714\n",
      "Epoch: 16 Step: 151 Loss: 0.9563569468516144\n",
      "Epoch: 16 Step: 161 Loss: 1.085029272451595\n",
      "Epoch: 16 Step: 171 Loss: 1.0759399674079033\n",
      "Epoch: 16 Step: 181 Loss: 0.8678679888355267\n",
      "Epoch: 16 Step: 191 Loss: 1.0347500344893086\n",
      "Epoch: 16 Step: 201 Loss: 1.0016972555664307\n",
      "Epoch: 16 Step: 211 Loss: 0.902875029358592\n",
      "Epoch: 16 Step: 221 Loss: 1.1067696238317004\n",
      "Epoch: 16 Step: 231 Loss: 0.950241372459591\n",
      "Epoch: 16 Step: 241 Loss: 1.0200132645821485\n",
      "Epoch: 16 Step: 251 Loss: 1.008471884706244\n",
      "Epoch: 16 Step: 261 Loss: 1.139946328031968\n",
      "Epoch: 16 Step: 271 Loss: 1.116223321995089\n",
      "Epoch: 16 Step: 281 Loss: 0.9370203496423797\n",
      "Epoch: 16 Step: 291 Loss: 1.0785377949818533\n",
      "Epoch: 16 Step: 301 Loss: 1.0461397271433444\n",
      "Epoch: 16 Step: 311 Loss: 0.9554711617287243\n",
      "Epoch: 16 Step: 321 Loss: 1.5081806034614424\n",
      "Epoch: 16 Step: 331 Loss: 0.8852567924722919\n",
      "Epoch: 16 Step: 341 Loss: 0.9797531688027471\n",
      "Epoch: 16 Step: 351 Loss: 0.9717456107387877\n",
      "Epoch: 16 Step: 361 Loss: 1.0397789435670415\n",
      "Epoch: 16 Step: 371 Loss: 0.7263860554843468\n",
      "Epoch: 16 Step: 381 Loss: 0.9838674993678703\n",
      "Epoch: 16 Step: 391 Loss: 0.6514124650461828\n",
      "Epoch: 16 Step: 401 Loss: 0.8784598730966889\n",
      "Epoch: 16 Step: 411 Loss: 1.055363558210828\n",
      "Epoch: 16 Step: 421 Loss: 1.0940707750275127\n",
      "Epoch: 16 Step: 431 Loss: 1.2340594691131765\n",
      "Epoch: 16 Step: 441 Loss: 0.9013340324156784\n",
      "Epoch: 16 Step: 451 Loss: 1.0461302385482276\n",
      "Epoch: 16 Step: 461 Loss: 1.2096006318825339\n",
      "Epoch: 16 Step: 471 Loss: 1.2155387218138463\n",
      "Epoch: 16 Step: 481 Loss: 1.0327507225085935\n",
      "Epoch: 16 Step: 491 Loss: 1.1167445523544115\n",
      "Epoch: 16 Step: 501 Loss: 1.1673183334471076\n",
      "Epoch: 16 Step: 511 Loss: 0.9365616220322976\n",
      "Epoch: 16 Step: 521 Loss: 1.104918091574171\n",
      "Epoch: 16 Step: 531 Loss: 1.036152307884516\n",
      "Epoch: 16 Step: 541 Loss: 1.0422097971448179\n",
      "Epoch: 16 Step: 551 Loss: 0.9344328511389983\n",
      "Epoch: 16 Step: 561 Loss: 0.8948908493184147\n",
      "Epoch: 16 Step: 571 Loss: 0.7486268484130936\n",
      "Epoch: 16 Step: 581 Loss: 1.0906104799397456\n",
      "Epoch: 16 Step: 591 Loss: 0.9926924759295932\n",
      "Epoch: 16 Step: 601 Loss: 0.7858228349047174\n",
      "Epoch: 16 Step: 611 Loss: 0.9728904601748903\n",
      "Epoch: 16 Step: 621 Loss: 0.8095754746577057\n",
      "Epoch: 16 Step: 631 Loss: 0.8657668081175742\n",
      "Epoch: 16 Step: 641 Loss: 0.9989061533803647\n",
      "Epoch: 16 Step: 651 Loss: 0.9462406914316909\n",
      "Epoch: 16 Step: 661 Loss: 0.9940315158824791\n",
      "Epoch: 16 Step: 671 Loss: 1.1918263208358346\n",
      "Epoch: 16 Step: 681 Loss: 1.0526606074841194\n",
      "Epoch: 16 Step: 691 Loss: 1.037799564108656\n",
      "Epoch: 16 Step: 701 Loss: 1.093849750622375\n",
      "Epoch: 16 Step: 711 Loss: 1.0578814800131293\n",
      "Epoch: 16 Step: 721 Loss: 0.9158548996092262\n",
      "Epoch: 16 Step: 731 Loss: 0.6914046345535254\n",
      "Epoch: 16 Step: 741 Loss: 0.9404014322581202\n",
      "Epoch: 16 Step: 751 Loss: 1.1408052540043447\n",
      "Epoch: 16 Step: 761 Loss: 0.7877982984785807\n",
      "Epoch: 16 Step: 771 Loss: 1.0430550049946992\n",
      "Epoch: 16 Step: 781 Loss: 1.0337014040602814\n",
      "Epoch: 17 Step: 1 Loss: 1.2696498279827009\n",
      "Epoch: 17 Step: 11 Loss: 1.1782828945562236\n",
      "Epoch: 17 Step: 21 Loss: 0.9930047671085949\n",
      "Epoch: 17 Step: 31 Loss: 0.8986892557024955\n",
      "Epoch: 17 Step: 41 Loss: 0.8584156262176104\n",
      "Epoch: 17 Step: 51 Loss: 0.9161670654167272\n",
      "Epoch: 17 Step: 61 Loss: 0.8667520802424903\n",
      "Epoch: 17 Step: 71 Loss: 1.103446888462409\n",
      "Epoch: 17 Step: 81 Loss: 1.0368768027185593\n",
      "Epoch: 17 Step: 91 Loss: 1.05608008789138\n",
      "Epoch: 17 Step: 101 Loss: 0.8912158524308427\n",
      "Epoch: 17 Step: 111 Loss: 1.0009374578417958\n",
      "Epoch: 17 Step: 121 Loss: 1.1384332578975718\n",
      "Epoch: 17 Step: 131 Loss: 1.0198100752835622\n",
      "Epoch: 17 Step: 141 Loss: 1.2356302614157761\n",
      "Epoch: 17 Step: 151 Loss: 1.04462152232538\n",
      "Epoch: 17 Step: 161 Loss: 1.0203859574136016\n",
      "Epoch: 17 Step: 171 Loss: 1.2234576208245924\n",
      "Epoch: 17 Step: 181 Loss: 0.861228279693129\n",
      "Epoch: 17 Step: 191 Loss: 0.889373802547121\n",
      "Epoch: 17 Step: 201 Loss: 0.9021315146444635\n",
      "Epoch: 17 Step: 211 Loss: 0.858883220855883\n",
      "Epoch: 17 Step: 221 Loss: 1.0800647905807628\n",
      "Epoch: 17 Step: 231 Loss: 0.9719840555234222\n",
      "Epoch: 17 Step: 241 Loss: 0.86364388435791\n",
      "Epoch: 17 Step: 251 Loss: 1.0267923319251802\n",
      "Epoch: 17 Step: 261 Loss: 1.1224278703975028\n",
      "Epoch: 17 Step: 271 Loss: 1.0075057267634842\n",
      "Epoch: 17 Step: 281 Loss: 1.0578930742670687\n",
      "Epoch: 17 Step: 291 Loss: 0.9432505541938924\n",
      "Epoch: 17 Step: 301 Loss: 1.0921670165489235\n",
      "Epoch: 17 Step: 311 Loss: 0.9415793355747242\n",
      "Epoch: 17 Step: 321 Loss: 1.2611716111488307\n",
      "Epoch: 17 Step: 331 Loss: 0.9373799092515902\n",
      "Epoch: 17 Step: 341 Loss: 0.841319329037509\n",
      "Epoch: 17 Step: 351 Loss: 0.9400420648907546\n",
      "Epoch: 17 Step: 361 Loss: 1.1873022137769988\n",
      "Epoch: 17 Step: 371 Loss: 0.767503878525656\n",
      "Epoch: 17 Step: 381 Loss: 0.934257332271858\n",
      "Epoch: 17 Step: 391 Loss: 0.6748545981843215\n",
      "Epoch: 17 Step: 401 Loss: 1.062315980042038\n",
      "Epoch: 17 Step: 411 Loss: 1.2012597668114553\n",
      "Epoch: 17 Step: 421 Loss: 1.1290563154361748\n",
      "Epoch: 17 Step: 431 Loss: 1.2572190641583951\n",
      "Epoch: 17 Step: 441 Loss: 0.9813308854590318\n",
      "Epoch: 17 Step: 451 Loss: 0.9036959750663369\n",
      "Epoch: 17 Step: 461 Loss: 1.2211345083662735\n",
      "Epoch: 17 Step: 471 Loss: 1.0966126702972554\n",
      "Epoch: 17 Step: 481 Loss: 0.9837628773882309\n",
      "Epoch: 17 Step: 491 Loss: 1.2631982024101474\n",
      "Epoch: 17 Step: 501 Loss: 1.0452047997196445\n",
      "Epoch: 17 Step: 511 Loss: 1.054035111356271\n",
      "Epoch: 17 Step: 521 Loss: 1.007524298174415\n",
      "Epoch: 17 Step: 531 Loss: 1.1285534671642807\n",
      "Epoch: 17 Step: 541 Loss: 0.9145331710217035\n",
      "Epoch: 17 Step: 551 Loss: 0.8016315026223524\n",
      "Epoch: 17 Step: 561 Loss: 0.8147781295061061\n",
      "Epoch: 17 Step: 571 Loss: 0.7001850292089333\n",
      "Epoch: 17 Step: 581 Loss: 1.1251108993129397\n",
      "Epoch: 17 Step: 591 Loss: 1.026320026202654\n",
      "Epoch: 17 Step: 601 Loss: 0.7635195589664948\n",
      "Epoch: 17 Step: 611 Loss: 0.989394260969928\n",
      "Epoch: 17 Step: 621 Loss: 0.8159095718528719\n",
      "Epoch: 17 Step: 631 Loss: 0.7434662972093555\n",
      "Epoch: 17 Step: 641 Loss: 1.1034738153786305\n",
      "Epoch: 17 Step: 651 Loss: 0.8870086341324139\n",
      "Epoch: 17 Step: 661 Loss: 0.8567530479417899\n",
      "Epoch: 17 Step: 671 Loss: 1.1219208778163978\n",
      "Epoch: 17 Step: 681 Loss: 1.1993306583238805\n",
      "Epoch: 17 Step: 691 Loss: 1.0039927917635332\n",
      "Epoch: 17 Step: 701 Loss: 1.0160715793191115\n",
      "Epoch: 17 Step: 711 Loss: 1.1572458981686191\n",
      "Epoch: 17 Step: 721 Loss: 0.7866379007017482\n",
      "Epoch: 17 Step: 731 Loss: 0.7050137639035956\n",
      "Epoch: 17 Step: 741 Loss: 0.9171831942510229\n",
      "Epoch: 17 Step: 751 Loss: 1.1879295226551565\n",
      "Epoch: 17 Step: 761 Loss: 0.714561980777952\n",
      "Epoch: 17 Step: 771 Loss: 1.0377386044779568\n",
      "Epoch: 17 Step: 781 Loss: 0.8675669926992643\n",
      "Epoch: 18 Step: 1 Loss: 0.9945985950406139\n",
      "Epoch: 18 Step: 11 Loss: 1.298314894309288\n",
      "Epoch: 18 Step: 21 Loss: 1.0075198135909254\n",
      "Epoch: 18 Step: 31 Loss: 1.0325603773046201\n",
      "Epoch: 18 Step: 41 Loss: 0.7244131551707006\n",
      "Epoch: 18 Step: 51 Loss: 0.8515864146394844\n",
      "Epoch: 18 Step: 61 Loss: 0.8869469184326437\n",
      "Epoch: 18 Step: 71 Loss: 1.2264706796367086\n",
      "Epoch: 18 Step: 81 Loss: 1.060106871270702\n",
      "Epoch: 18 Step: 91 Loss: 0.8558150524754949\n",
      "Epoch: 18 Step: 101 Loss: 0.8994038420109081\n",
      "Epoch: 18 Step: 111 Loss: 1.1104276548210423\n",
      "Epoch: 18 Step: 121 Loss: 1.339682405594688\n",
      "Epoch: 18 Step: 131 Loss: 1.1427516670369873\n",
      "Epoch: 18 Step: 141 Loss: 1.3081032093677178\n",
      "Epoch: 18 Step: 151 Loss: 1.00570709922314\n",
      "Epoch: 18 Step: 161 Loss: 1.0736451343491784\n",
      "Epoch: 18 Step: 171 Loss: 0.9904472320601093\n",
      "Epoch: 18 Step: 181 Loss: 0.9163469888300364\n",
      "Epoch: 18 Step: 191 Loss: 0.7362311721171071\n",
      "Epoch: 18 Step: 201 Loss: 0.6296487378764474\n",
      "Epoch: 18 Step: 211 Loss: 0.8324067984231603\n",
      "Epoch: 18 Step: 221 Loss: 0.9431862941617108\n",
      "Epoch: 18 Step: 231 Loss: 0.8740266361634563\n",
      "Epoch: 18 Step: 241 Loss: 0.8037270141079833\n",
      "Epoch: 18 Step: 251 Loss: 0.7260253544383852\n",
      "Epoch: 18 Step: 261 Loss: 0.9747442455950904\n",
      "Epoch: 18 Step: 271 Loss: 0.9238915732755735\n",
      "Epoch: 18 Step: 281 Loss: 0.9364118870698364\n",
      "Epoch: 18 Step: 291 Loss: 0.8842191022953325\n",
      "Epoch: 18 Step: 301 Loss: 0.9814106212171456\n",
      "Epoch: 18 Step: 311 Loss: 0.8385905087676988\n",
      "Epoch: 18 Step: 321 Loss: 1.2520255354201262\n",
      "Epoch: 18 Step: 331 Loss: 0.8341499645591517\n",
      "Epoch: 18 Step: 341 Loss: 0.8992533102298583\n",
      "Epoch: 18 Step: 351 Loss: 0.8281203887443269\n",
      "Epoch: 18 Step: 361 Loss: 1.050320477944182\n",
      "Epoch: 18 Step: 371 Loss: 0.8629803901328259\n",
      "Epoch: 18 Step: 381 Loss: 1.1993052843209338\n",
      "Epoch: 18 Step: 391 Loss: 0.6787860858263115\n",
      "Epoch: 18 Step: 401 Loss: 0.9983599851267987\n",
      "Epoch: 18 Step: 411 Loss: 1.0971695997991682\n",
      "Epoch: 18 Step: 421 Loss: 1.0000008804848588\n",
      "Epoch: 18 Step: 431 Loss: 1.1880966339537737\n",
      "Epoch: 18 Step: 441 Loss: 0.943887646913787\n",
      "Epoch: 18 Step: 451 Loss: 0.7852360273141608\n",
      "Epoch: 18 Step: 461 Loss: 0.9599369941882078\n",
      "Epoch: 18 Step: 471 Loss: 1.0053241900684609\n",
      "Epoch: 18 Step: 481 Loss: 0.897611334188493\n",
      "Epoch: 18 Step: 491 Loss: 0.9093435030930126\n",
      "Epoch: 18 Step: 501 Loss: 1.1652024265350458\n",
      "Epoch: 18 Step: 511 Loss: 0.8172357528244545\n",
      "Epoch: 18 Step: 521 Loss: 0.9330930627205898\n",
      "Epoch: 18 Step: 531 Loss: 0.9799719406955167\n",
      "Epoch: 18 Step: 541 Loss: 0.9923293960810038\n",
      "Epoch: 18 Step: 551 Loss: 0.7023310527594914\n",
      "Epoch: 18 Step: 561 Loss: 0.7618459073305779\n",
      "Epoch: 18 Step: 571 Loss: 0.664598491770106\n",
      "Epoch: 18 Step: 581 Loss: 0.9683645566808428\n",
      "Epoch: 18 Step: 591 Loss: 0.8889408954153656\n",
      "Epoch: 18 Step: 601 Loss: 0.7610010110914535\n",
      "Epoch: 18 Step: 611 Loss: 0.9571872712984383\n",
      "Epoch: 18 Step: 621 Loss: 1.0307943179054524\n",
      "Epoch: 18 Step: 631 Loss: 0.7856333815466396\n",
      "Epoch: 18 Step: 641 Loss: 1.1203718519509533\n",
      "Epoch: 18 Step: 651 Loss: 0.7806910585910214\n",
      "Epoch: 18 Step: 661 Loss: 0.8311942399573038\n",
      "Epoch: 18 Step: 671 Loss: 1.100296417807693\n",
      "Epoch: 18 Step: 681 Loss: 1.104185350836893\n",
      "Epoch: 18 Step: 691 Loss: 0.8641793920182728\n",
      "Epoch: 18 Step: 701 Loss: 1.067150867920703\n",
      "Epoch: 18 Step: 711 Loss: 0.9088538587387409\n",
      "Epoch: 18 Step: 721 Loss: 0.6458420075808933\n",
      "Epoch: 18 Step: 731 Loss: 0.7705319853029124\n",
      "Epoch: 18 Step: 741 Loss: 0.8184793484228052\n",
      "Epoch: 18 Step: 751 Loss: 1.2257733087411715\n",
      "Epoch: 18 Step: 761 Loss: 0.6977534877672192\n",
      "Epoch: 18 Step: 771 Loss: 1.0689536118121319\n",
      "Epoch: 18 Step: 781 Loss: 1.0138407813844603\n",
      "Epoch: 19 Step: 1 Loss: 0.9125292665317428\n",
      "Epoch: 19 Step: 11 Loss: 1.0975118987843961\n",
      "Epoch: 19 Step: 21 Loss: 0.9142996315923932\n",
      "Epoch: 19 Step: 31 Loss: 1.0964708661349114\n",
      "Epoch: 19 Step: 41 Loss: 0.8030201456828674\n",
      "Epoch: 19 Step: 51 Loss: 0.8166422916389833\n",
      "Epoch: 19 Step: 61 Loss: 0.7642184899916297\n",
      "Epoch: 19 Step: 71 Loss: 1.1795482049423627\n",
      "Epoch: 19 Step: 81 Loss: 1.089099064805613\n",
      "Epoch: 19 Step: 91 Loss: 1.0484243279822179\n",
      "Epoch: 19 Step: 101 Loss: 1.002801223282812\n",
      "Epoch: 19 Step: 111 Loss: 0.9252421859816414\n",
      "Epoch: 19 Step: 121 Loss: 1.1680115152759625\n",
      "Epoch: 19 Step: 131 Loss: 1.0311577052870988\n",
      "Epoch: 19 Step: 141 Loss: 1.2330588957648205\n",
      "Epoch: 19 Step: 151 Loss: 0.9288794142269616\n",
      "Epoch: 19 Step: 161 Loss: 0.9788598749637811\n",
      "Epoch: 19 Step: 171 Loss: 0.9455264355055779\n",
      "Epoch: 19 Step: 181 Loss: 0.7832856829321007\n",
      "Epoch: 19 Step: 191 Loss: 0.7252411705399822\n",
      "Epoch: 19 Step: 201 Loss: 0.7280667784212383\n",
      "Epoch: 19 Step: 211 Loss: 0.6934661913634039\n",
      "Epoch: 19 Step: 221 Loss: 0.9904750585008216\n",
      "Epoch: 19 Step: 231 Loss: 0.7642428308147197\n",
      "Epoch: 19 Step: 241 Loss: 0.8279939522141169\n",
      "Epoch: 19 Step: 251 Loss: 0.8383770360083005\n",
      "Epoch: 19 Step: 261 Loss: 1.0675867096539144\n",
      "Epoch: 19 Step: 271 Loss: 1.1147027261357942\n",
      "Epoch: 19 Step: 281 Loss: 0.9255312368612987\n",
      "Epoch: 19 Step: 291 Loss: 0.8073836770241144\n",
      "Epoch: 19 Step: 301 Loss: 0.9256222491561171\n",
      "Epoch: 19 Step: 311 Loss: 1.025836304697337\n",
      "Epoch: 19 Step: 321 Loss: 1.0736812060857237\n",
      "Epoch: 19 Step: 331 Loss: 0.8988425189117646\n",
      "Epoch: 19 Step: 341 Loss: 1.0430734073467085\n",
      "Epoch: 19 Step: 351 Loss: 1.0301237157834366\n",
      "Epoch: 19 Step: 361 Loss: 1.0099234764704164\n",
      "Epoch: 19 Step: 371 Loss: 0.7162562696759299\n",
      "Epoch: 19 Step: 381 Loss: 0.8883164489665931\n",
      "Epoch: 19 Step: 391 Loss: 0.6502113807660737\n",
      "Epoch: 19 Step: 401 Loss: 0.8024426666607187\n",
      "Epoch: 19 Step: 411 Loss: 1.0085138227547388\n",
      "Epoch: 19 Step: 421 Loss: 0.8927298961402752\n",
      "Epoch: 19 Step: 431 Loss: 0.9089747222629292\n",
      "Epoch: 19 Step: 441 Loss: 0.8527795787847869\n",
      "Epoch: 19 Step: 451 Loss: 0.7528693223712366\n",
      "Epoch: 19 Step: 461 Loss: 1.0142287732687358\n",
      "Epoch: 19 Step: 471 Loss: 0.9918922816742727\n",
      "Epoch: 19 Step: 481 Loss: 0.849402943583807\n",
      "Epoch: 19 Step: 491 Loss: 0.859967484841896\n",
      "Epoch: 19 Step: 501 Loss: 1.032121193501268\n",
      "Epoch: 19 Step: 511 Loss: 0.867708871640473\n",
      "Epoch: 19 Step: 521 Loss: 0.9849157459423115\n",
      "Epoch: 19 Step: 531 Loss: 1.0208672702210682\n",
      "Epoch: 19 Step: 541 Loss: 0.9449082875552329\n",
      "Epoch: 19 Step: 551 Loss: 0.7779425752535403\n",
      "Epoch: 19 Step: 561 Loss: 0.7781577253494225\n",
      "Epoch: 19 Step: 571 Loss: 0.7775192810516479\n",
      "Epoch: 19 Step: 581 Loss: 0.9793771364276289\n",
      "Epoch: 19 Step: 591 Loss: 1.1268195334551456\n",
      "Epoch: 19 Step: 601 Loss: 0.9402577210061743\n",
      "Epoch: 19 Step: 611 Loss: 0.9786854492105921\n",
      "Epoch: 19 Step: 621 Loss: 1.089747583428689\n",
      "Epoch: 19 Step: 631 Loss: 0.8575170054842982\n",
      "Epoch: 19 Step: 641 Loss: 1.0422859688712387\n",
      "Epoch: 19 Step: 651 Loss: 0.8986037547432963\n",
      "Epoch: 19 Step: 661 Loss: 0.7279666086029497\n",
      "Epoch: 19 Step: 671 Loss: 0.9710089924239205\n",
      "Epoch: 19 Step: 681 Loss: 1.3339598691071104\n",
      "Epoch: 19 Step: 691 Loss: 0.9386480558214958\n",
      "Epoch: 19 Step: 701 Loss: 0.9542833823554742\n",
      "Epoch: 19 Step: 711 Loss: 0.8820707866692361\n",
      "Epoch: 19 Step: 721 Loss: 0.6097549414239269\n",
      "Epoch: 19 Step: 731 Loss: 0.5872235468129271\n",
      "Epoch: 19 Step: 741 Loss: 0.8773381066821682\n",
      "Epoch: 19 Step: 751 Loss: 1.177429133182955\n",
      "Epoch: 19 Step: 761 Loss: 0.6011194876660084\n",
      "Epoch: 19 Step: 771 Loss: 0.9730458248389058\n",
      "Epoch: 19 Step: 781 Loss: 1.0380989973725472\n",
      "Epoch: 20 Step: 1 Loss: 1.059052657523224\n",
      "Epoch: 20 Step: 11 Loss: 1.1876075145239464\n",
      "Epoch: 20 Step: 21 Loss: 0.9873673823785069\n",
      "Epoch: 20 Step: 31 Loss: 1.0749928810426979\n",
      "Epoch: 20 Step: 41 Loss: 0.7096573137901545\n",
      "Epoch: 20 Step: 51 Loss: 0.9384261818941909\n",
      "Epoch: 20 Step: 61 Loss: 1.0514709904852273\n",
      "Epoch: 20 Step: 71 Loss: 1.3565854400100785\n",
      "Epoch: 20 Step: 81 Loss: 0.8786856236843306\n",
      "Epoch: 20 Step: 91 Loss: 1.1096589804893568\n",
      "Epoch: 20 Step: 101 Loss: 1.0694054597056977\n",
      "Epoch: 20 Step: 111 Loss: 0.9878312381867986\n",
      "Epoch: 20 Step: 121 Loss: 0.864737842619276\n",
      "Epoch: 20 Step: 131 Loss: 0.9409729552450585\n",
      "Epoch: 20 Step: 141 Loss: 1.2921837664124398\n",
      "Epoch: 20 Step: 151 Loss: 0.8466626751066135\n",
      "Epoch: 20 Step: 161 Loss: 0.8794417311182314\n",
      "Epoch: 20 Step: 171 Loss: 0.8860358338475797\n",
      "Epoch: 20 Step: 181 Loss: 0.7289528363307134\n",
      "Epoch: 20 Step: 191 Loss: 0.7021034416300975\n",
      "Epoch: 20 Step: 201 Loss: 0.5985216866826828\n",
      "Epoch: 20 Step: 211 Loss: 0.7098964808253694\n",
      "Epoch: 20 Step: 221 Loss: 0.8643835822091102\n",
      "Epoch: 20 Step: 231 Loss: 0.7723501405465121\n",
      "Epoch: 20 Step: 241 Loss: 0.8773445516106068\n",
      "Epoch: 20 Step: 251 Loss: 0.9152779924415763\n",
      "Epoch: 20 Step: 261 Loss: 0.9261066171346954\n",
      "Epoch: 20 Step: 271 Loss: 1.0959059352719642\n",
      "Epoch: 20 Step: 281 Loss: 0.8314108246588443\n",
      "Epoch: 20 Step: 291 Loss: 0.9105200166147599\n",
      "Epoch: 20 Step: 301 Loss: 1.0934070946855987\n",
      "Epoch: 20 Step: 311 Loss: 1.0443847160320685\n",
      "Epoch: 20 Step: 321 Loss: 1.090774726539058\n",
      "Epoch: 20 Step: 331 Loss: 0.9735095159819437\n",
      "Epoch: 20 Step: 341 Loss: 0.7726785545840973\n",
      "Epoch: 20 Step: 351 Loss: 1.2444729346504628\n",
      "Epoch: 20 Step: 361 Loss: 1.109478326498547\n",
      "Epoch: 20 Step: 371 Loss: 0.7368621018529513\n",
      "Epoch: 20 Step: 381 Loss: 1.1009971135944543\n",
      "Epoch: 20 Step: 391 Loss: 0.7021943146133154\n",
      "Epoch: 20 Step: 401 Loss: 0.9881414669088213\n",
      "Epoch: 20 Step: 411 Loss: 1.0723027188131633\n",
      "Epoch: 20 Step: 421 Loss: 0.9589659953442182\n",
      "Epoch: 20 Step: 431 Loss: 0.8729470823306558\n",
      "Epoch: 20 Step: 441 Loss: 0.6962717417615301\n",
      "Epoch: 20 Step: 451 Loss: 0.8539921029557339\n",
      "Epoch: 20 Step: 461 Loss: 0.9095528591040258\n",
      "Epoch: 20 Step: 471 Loss: 0.9635459073847883\n",
      "Epoch: 20 Step: 481 Loss: 0.9255507708912374\n",
      "Epoch: 20 Step: 491 Loss: 1.2323523667114755\n",
      "Epoch: 20 Step: 501 Loss: 1.1412364545242815\n",
      "Epoch: 20 Step: 511 Loss: 0.826588056499775\n",
      "Epoch: 20 Step: 521 Loss: 1.0461860993572767\n",
      "Epoch: 20 Step: 531 Loss: 1.0297697046995327\n",
      "Epoch: 20 Step: 541 Loss: 0.8813468869428059\n",
      "Epoch: 20 Step: 551 Loss: 0.8132632461221533\n",
      "Epoch: 20 Step: 561 Loss: 1.0035395820334618\n",
      "Epoch: 20 Step: 571 Loss: 0.733186479584898\n",
      "Epoch: 20 Step: 581 Loss: 0.891130190094131\n",
      "Epoch: 20 Step: 591 Loss: 1.0441138656479703\n",
      "Epoch: 20 Step: 601 Loss: 1.018632320760139\n",
      "Epoch: 20 Step: 611 Loss: 0.8617717215021121\n",
      "Epoch: 20 Step: 621 Loss: 0.8848114343945168\n",
      "Epoch: 20 Step: 631 Loss: 0.7146258988511542\n",
      "Epoch: 20 Step: 641 Loss: 1.093588427175696\n",
      "Epoch: 20 Step: 651 Loss: 0.751019024017147\n",
      "Epoch: 20 Step: 661 Loss: 0.937723776330241\n",
      "Epoch: 20 Step: 671 Loss: 1.0304582795002348\n",
      "Epoch: 20 Step: 681 Loss: 1.1070291189613717\n",
      "Epoch: 20 Step: 691 Loss: 0.8042782491320876\n",
      "Epoch: 20 Step: 701 Loss: 0.9921166442093645\n",
      "Epoch: 20 Step: 711 Loss: 1.023181907759199\n",
      "Epoch: 20 Step: 721 Loss: 0.7482571150436478\n",
      "Epoch: 20 Step: 731 Loss: 0.7523754451450413\n",
      "Epoch: 20 Step: 741 Loss: 0.8605496989631864\n",
      "Epoch: 20 Step: 751 Loss: 1.2226531831432559\n",
      "Epoch: 20 Step: 761 Loss: 0.7246704441744035\n",
      "Epoch: 20 Step: 771 Loss: 1.1795778682407512\n",
      "Epoch: 20 Step: 781 Loss: 0.7616761798499052\n",
      "Epoch: 21 Step: 1 Loss: 0.8683841172286673\n",
      "Epoch: 21 Step: 11 Loss: 1.045419987332222\n",
      "Epoch: 21 Step: 21 Loss: 1.030703752613423\n",
      "Epoch: 21 Step: 31 Loss: 1.312319859678746\n",
      "Epoch: 21 Step: 41 Loss: 0.8476237466389318\n",
      "Epoch: 21 Step: 51 Loss: 0.7843706446694121\n",
      "Epoch: 21 Step: 61 Loss: 0.9826227618713407\n",
      "Epoch: 21 Step: 71 Loss: 1.2581260656701847\n",
      "Epoch: 21 Step: 81 Loss: 0.8936059956867394\n",
      "Epoch: 21 Step: 91 Loss: 1.0518424252863297\n",
      "Epoch: 21 Step: 101 Loss: 0.7885543698532613\n",
      "Epoch: 21 Step: 111 Loss: 0.8447813348947117\n",
      "Epoch: 21 Step: 121 Loss: 0.9730698823887745\n",
      "Epoch: 21 Step: 131 Loss: 0.7903914404776734\n",
      "Epoch: 21 Step: 141 Loss: 1.1508833955515252\n",
      "Epoch: 21 Step: 151 Loss: 0.9602083152081922\n",
      "Epoch: 21 Step: 161 Loss: 0.8227078885436454\n",
      "Epoch: 21 Step: 171 Loss: 0.7887103844715252\n",
      "Epoch: 21 Step: 181 Loss: 0.7361349566862057\n",
      "Epoch: 21 Step: 191 Loss: 0.881838731265274\n",
      "Epoch: 21 Step: 201 Loss: 0.6465203506218682\n",
      "Epoch: 21 Step: 211 Loss: 0.6888142114827893\n",
      "Epoch: 21 Step: 221 Loss: 0.9044941227575602\n",
      "Epoch: 21 Step: 231 Loss: 0.766673683926971\n",
      "Epoch: 21 Step: 241 Loss: 0.9778068035933739\n",
      "Epoch: 21 Step: 251 Loss: 0.8098890296322109\n",
      "Epoch: 21 Step: 261 Loss: 1.0799887369460972\n",
      "Epoch: 21 Step: 271 Loss: 1.1276009143027634\n",
      "Epoch: 21 Step: 281 Loss: 0.8421174180094597\n",
      "Epoch: 21 Step: 291 Loss: 0.8727926542420271\n",
      "Epoch: 21 Step: 301 Loss: 1.104446071981911\n",
      "Epoch: 21 Step: 311 Loss: 1.047293095804433\n",
      "Epoch: 21 Step: 321 Loss: 1.0060716877624591\n",
      "Epoch: 21 Step: 331 Loss: 0.9701821557830366\n",
      "Epoch: 21 Step: 341 Loss: 0.7683636613742821\n",
      "Epoch: 21 Step: 351 Loss: 0.9817606909245946\n",
      "Epoch: 21 Step: 361 Loss: 1.153478313878499\n",
      "Epoch: 21 Step: 371 Loss: 0.5312509115252148\n",
      "Epoch: 21 Step: 381 Loss: 0.6575400141312251\n",
      "Epoch: 21 Step: 391 Loss: 0.6471069323555045\n",
      "Epoch: 21 Step: 401 Loss: 0.8351986966814797\n",
      "Epoch: 21 Step: 411 Loss: 0.892036492836504\n",
      "Epoch: 21 Step: 421 Loss: 0.835865698634591\n",
      "Epoch: 21 Step: 431 Loss: 0.7312226643674622\n",
      "Epoch: 21 Step: 441 Loss: 0.6243086644283424\n",
      "Epoch: 21 Step: 451 Loss: 0.7412952726803437\n",
      "Epoch: 21 Step: 461 Loss: 1.0639888185129134\n",
      "Epoch: 21 Step: 471 Loss: 1.0425663918821357\n",
      "Epoch: 21 Step: 481 Loss: 0.7433606520602432\n",
      "Epoch: 21 Step: 491 Loss: 1.1075418156630277\n",
      "Epoch: 21 Step: 501 Loss: 1.236770774132589\n",
      "Epoch: 21 Step: 511 Loss: 1.0248150543443095\n",
      "Epoch: 21 Step: 521 Loss: 1.0319177552474645\n",
      "Epoch: 21 Step: 531 Loss: 1.0468197142031022\n",
      "Epoch: 21 Step: 541 Loss: 0.7956109319381327\n",
      "Epoch: 21 Step: 551 Loss: 0.7642403922607551\n",
      "Epoch: 21 Step: 561 Loss: 0.8770046123891061\n",
      "Epoch: 21 Step: 571 Loss: 0.6838034445926381\n",
      "Epoch: 21 Step: 581 Loss: 0.8020890945604929\n",
      "Epoch: 21 Step: 591 Loss: 1.1059298271252338\n",
      "Epoch: 21 Step: 601 Loss: 0.660613524908797\n",
      "Epoch: 21 Step: 611 Loss: 0.6886201185904739\n",
      "Epoch: 21 Step: 621 Loss: 0.8429553803391074\n",
      "Epoch: 21 Step: 631 Loss: 0.7159039743024145\n",
      "Epoch: 21 Step: 641 Loss: 0.8521424611495139\n",
      "Epoch: 21 Step: 651 Loss: 0.6974013048613863\n",
      "Epoch: 21 Step: 661 Loss: 0.772037506939147\n",
      "Epoch: 21 Step: 671 Loss: 0.880191442397739\n",
      "Epoch: 21 Step: 681 Loss: 0.9953733596641834\n",
      "Epoch: 21 Step: 691 Loss: 0.7086946656023414\n",
      "Epoch: 21 Step: 701 Loss: 1.0619948514392543\n",
      "Epoch: 21 Step: 711 Loss: 0.8901536883336484\n",
      "Epoch: 21 Step: 721 Loss: 0.6359475701628301\n",
      "Epoch: 21 Step: 731 Loss: 0.6520771819099924\n",
      "Epoch: 21 Step: 741 Loss: 0.7467326013144627\n",
      "Epoch: 21 Step: 751 Loss: 1.2147490281562663\n",
      "Epoch: 21 Step: 761 Loss: 0.7482047669963774\n",
      "Epoch: 21 Step: 771 Loss: 1.4151043552503677\n",
      "Epoch: 21 Step: 781 Loss: 0.944305369168565\n",
      "Epoch: 22 Step: 1 Loss: 0.835744562468524\n",
      "Epoch: 22 Step: 11 Loss: 0.9035090615260759\n",
      "Epoch: 22 Step: 21 Loss: 0.8722461575640327\n",
      "Epoch: 22 Step: 31 Loss: 0.8420678666675346\n",
      "Epoch: 22 Step: 41 Loss: 0.8349476564226868\n",
      "Epoch: 22 Step: 51 Loss: 0.7975258871939962\n",
      "Epoch: 22 Step: 61 Loss: 0.7872221888106237\n",
      "Epoch: 22 Step: 71 Loss: 1.0960441896666104\n",
      "Epoch: 22 Step: 81 Loss: 0.8950257425736365\n",
      "Epoch: 22 Step: 91 Loss: 0.8114634295024208\n",
      "Epoch: 22 Step: 101 Loss: 0.9238271888501401\n",
      "Epoch: 22 Step: 111 Loss: 0.7727625971643148\n",
      "Epoch: 22 Step: 121 Loss: 0.9521732123867486\n",
      "Epoch: 22 Step: 131 Loss: 0.8634004187205212\n",
      "Epoch: 22 Step: 141 Loss: 1.0986050337064803\n",
      "Epoch: 22 Step: 151 Loss: 0.7974652807791631\n",
      "Epoch: 22 Step: 161 Loss: 0.861413767868749\n",
      "Epoch: 22 Step: 171 Loss: 0.9406101532311792\n",
      "Epoch: 22 Step: 181 Loss: 0.6647517930410743\n",
      "Epoch: 22 Step: 191 Loss: 0.7228306842613595\n",
      "Epoch: 22 Step: 201 Loss: 0.6274564484184174\n",
      "Epoch: 22 Step: 211 Loss: 0.7727721141129753\n",
      "Epoch: 22 Step: 221 Loss: 0.7999271532826513\n",
      "Epoch: 22 Step: 231 Loss: 0.8669630430732169\n",
      "Epoch: 22 Step: 241 Loss: 1.1677838446793554\n",
      "Epoch: 22 Step: 251 Loss: 0.9301778283503894\n",
      "Epoch: 22 Step: 261 Loss: 0.9847978853591881\n",
      "Epoch: 22 Step: 271 Loss: 1.1539394604827136\n",
      "Epoch: 22 Step: 281 Loss: 0.8024911818640574\n",
      "Epoch: 22 Step: 291 Loss: 0.9966307014088968\n",
      "Epoch: 22 Step: 301 Loss: 0.8886979522094288\n",
      "Epoch: 22 Step: 311 Loss: 0.9562661778901865\n",
      "Epoch: 22 Step: 321 Loss: 1.0255251721844956\n",
      "Epoch: 22 Step: 331 Loss: 0.8514546278553908\n",
      "Epoch: 22 Step: 341 Loss: 0.7226781596892531\n",
      "Epoch: 22 Step: 351 Loss: 0.770457559730684\n",
      "Epoch: 22 Step: 361 Loss: 1.0165412429035312\n",
      "Epoch: 22 Step: 371 Loss: 0.6845707082883321\n",
      "Epoch: 22 Step: 381 Loss: 0.8694284015647568\n",
      "Epoch: 22 Step: 391 Loss: 0.4614192970865253\n",
      "Epoch: 22 Step: 401 Loss: 0.6743583963828306\n",
      "Epoch: 22 Step: 411 Loss: 0.8898063927251624\n",
      "Epoch: 22 Step: 421 Loss: 0.888012707660244\n",
      "Epoch: 22 Step: 431 Loss: 0.770703928119788\n",
      "Epoch: 22 Step: 441 Loss: 0.6053368474782641\n",
      "Epoch: 22 Step: 451 Loss: 0.7493586233212906\n",
      "Epoch: 22 Step: 461 Loss: 1.0959717360098544\n",
      "Epoch: 22 Step: 471 Loss: 1.0356100501195162\n",
      "Epoch: 22 Step: 481 Loss: 1.0914097822842712\n",
      "Epoch: 22 Step: 491 Loss: 1.189960363885958\n",
      "Epoch: 22 Step: 501 Loss: 1.2293622710594279\n",
      "Epoch: 22 Step: 511 Loss: 0.8302574090557582\n",
      "Epoch: 22 Step: 521 Loss: 0.876242705122751\n",
      "Epoch: 22 Step: 531 Loss: 0.9882402763934204\n",
      "Epoch: 22 Step: 541 Loss: 0.7848942989184128\n",
      "Epoch: 22 Step: 551 Loss: 0.7950378666463653\n",
      "Epoch: 22 Step: 561 Loss: 0.8215062222213528\n",
      "Epoch: 22 Step: 571 Loss: 0.648055459352072\n",
      "Epoch: 22 Step: 581 Loss: 0.819288032600433\n",
      "Epoch: 22 Step: 591 Loss: 0.7328835057071981\n",
      "Epoch: 22 Step: 601 Loss: 0.8313151107242681\n",
      "Epoch: 22 Step: 611 Loss: 0.9178522918135601\n",
      "Epoch: 22 Step: 621 Loss: 0.799175749355273\n",
      "Epoch: 22 Step: 631 Loss: 0.5825859699254302\n",
      "Epoch: 22 Step: 641 Loss: 0.8154684953941096\n",
      "Epoch: 22 Step: 651 Loss: 0.6228002793480276\n",
      "Epoch: 22 Step: 661 Loss: 0.8626042116359702\n",
      "Epoch: 22 Step: 671 Loss: 1.0980322463869587\n",
      "Epoch: 22 Step: 681 Loss: 1.0025842028062102\n",
      "Epoch: 22 Step: 691 Loss: 0.8456824406912047\n",
      "Epoch: 22 Step: 701 Loss: 1.1033250900551341\n",
      "Epoch: 22 Step: 711 Loss: 1.1282072021553968\n",
      "Epoch: 22 Step: 721 Loss: 0.6042426467435469\n",
      "Epoch: 22 Step: 731 Loss: 0.8038575190695811\n",
      "Epoch: 22 Step: 741 Loss: 0.762412129240305\n",
      "Epoch: 22 Step: 751 Loss: 1.1800232693472457\n",
      "Epoch: 22 Step: 761 Loss: 0.8174783423784148\n",
      "Epoch: 22 Step: 771 Loss: 1.157828722923763\n",
      "Epoch: 22 Step: 781 Loss: 0.8668365182252264\n",
      "Epoch: 23 Step: 1 Loss: 0.9222765329403412\n",
      "Epoch: 23 Step: 11 Loss: 1.1191749497667818\n",
      "Epoch: 23 Step: 21 Loss: 1.0710574065869518\n",
      "Epoch: 23 Step: 31 Loss: 0.7871272184987693\n",
      "Epoch: 23 Step: 41 Loss: 0.742186313548775\n",
      "Epoch: 23 Step: 51 Loss: 0.7682925829556424\n",
      "Epoch: 23 Step: 61 Loss: 0.6622956176449426\n",
      "Epoch: 23 Step: 71 Loss: 1.0494419770500918\n",
      "Epoch: 23 Step: 81 Loss: 0.7942156066731872\n",
      "Epoch: 23 Step: 91 Loss: 0.8097459309706659\n",
      "Epoch: 23 Step: 101 Loss: 0.7204533524523988\n",
      "Epoch: 23 Step: 111 Loss: 0.7568954585029939\n",
      "Epoch: 23 Step: 121 Loss: 0.9192317977462235\n",
      "Epoch: 23 Step: 131 Loss: 0.7498685478000433\n",
      "Epoch: 23 Step: 141 Loss: 1.0140535720795625\n",
      "Epoch: 23 Step: 151 Loss: 0.8474211268820431\n",
      "Epoch: 23 Step: 161 Loss: 0.7085600187512939\n",
      "Epoch: 23 Step: 171 Loss: 0.9343996300556818\n",
      "Epoch: 23 Step: 181 Loss: 0.6813669618930548\n",
      "Epoch: 23 Step: 191 Loss: 0.8344642206143013\n",
      "Epoch: 23 Step: 201 Loss: 0.7485675782725604\n",
      "Epoch: 23 Step: 211 Loss: 0.8225613062715544\n",
      "Epoch: 23 Step: 221 Loss: 0.8559614307812428\n",
      "Epoch: 23 Step: 231 Loss: 0.6825421223588044\n",
      "Epoch: 23 Step: 241 Loss: 0.7274233113926891\n",
      "Epoch: 23 Step: 251 Loss: 0.7369078525064718\n",
      "Epoch: 23 Step: 261 Loss: 0.8843266487858188\n",
      "Epoch: 23 Step: 271 Loss: 1.0161524589985726\n",
      "Epoch: 23 Step: 281 Loss: 0.6572520881549935\n",
      "Epoch: 23 Step: 291 Loss: 0.6549229634947646\n",
      "Epoch: 23 Step: 301 Loss: 0.9705873569413641\n",
      "Epoch: 23 Step: 311 Loss: 0.8389249677544295\n",
      "Epoch: 23 Step: 321 Loss: 0.9872806349467329\n",
      "Epoch: 23 Step: 331 Loss: 0.7117486702984006\n",
      "Epoch: 23 Step: 341 Loss: 0.7148671534453068\n",
      "Epoch: 23 Step: 351 Loss: 0.7667204277016602\n",
      "Epoch: 23 Step: 361 Loss: 0.8638057291647956\n",
      "Epoch: 23 Step: 371 Loss: 0.6397410830518555\n",
      "Epoch: 23 Step: 381 Loss: 0.6780523460926872\n",
      "Epoch: 23 Step: 391 Loss: 0.5331801907748899\n",
      "Epoch: 23 Step: 401 Loss: 0.61482507636469\n",
      "Epoch: 23 Step: 411 Loss: 0.8949154149993257\n",
      "Epoch: 23 Step: 421 Loss: 0.9177231571619414\n",
      "Epoch: 23 Step: 431 Loss: 0.9715412287658263\n",
      "Epoch: 23 Step: 441 Loss: 0.8239087577036794\n",
      "Epoch: 23 Step: 451 Loss: 0.8034483603332208\n",
      "Epoch: 23 Step: 461 Loss: 1.0509192141839672\n",
      "Epoch: 23 Step: 471 Loss: 0.8659187474770496\n",
      "Epoch: 23 Step: 481 Loss: 1.0361425374954856\n",
      "Epoch: 23 Step: 491 Loss: 0.9202975611845273\n",
      "Epoch: 23 Step: 501 Loss: 1.0436389866158848\n",
      "Epoch: 23 Step: 511 Loss: 0.7549330276658539\n",
      "Epoch: 23 Step: 521 Loss: 0.8453564439012176\n",
      "Epoch: 23 Step: 531 Loss: 0.8952231613916491\n",
      "Epoch: 23 Step: 541 Loss: 0.7886800974561876\n",
      "Epoch: 23 Step: 551 Loss: 0.6519657380650634\n",
      "Epoch: 23 Step: 561 Loss: 0.7186688704914799\n",
      "Epoch: 23 Step: 571 Loss: 0.6418765480675301\n",
      "Epoch: 23 Step: 581 Loss: 1.0095615731372278\n",
      "Epoch: 23 Step: 591 Loss: 0.738245491110884\n",
      "Epoch: 23 Step: 601 Loss: 0.5642125415538515\n",
      "Epoch: 23 Step: 611 Loss: 0.7643622520546881\n",
      "Epoch: 23 Step: 621 Loss: 0.7031740924844512\n",
      "Epoch: 23 Step: 631 Loss: 0.6113129521282077\n",
      "Epoch: 23 Step: 641 Loss: 0.752877893706134\n",
      "Epoch: 23 Step: 651 Loss: 0.660443251854763\n",
      "Epoch: 23 Step: 661 Loss: 0.66701872467066\n",
      "Epoch: 23 Step: 671 Loss: 1.062921203159097\n",
      "Epoch: 23 Step: 681 Loss: 0.9298290904177154\n",
      "Epoch: 23 Step: 691 Loss: 0.9469724064375824\n",
      "Epoch: 23 Step: 701 Loss: 1.2019510067038364\n",
      "Epoch: 23 Step: 711 Loss: 0.9680664533601053\n",
      "Epoch: 23 Step: 721 Loss: 0.6272616838058942\n",
      "Epoch: 23 Step: 731 Loss: 0.6602681280036471\n",
      "Epoch: 23 Step: 741 Loss: 0.8295480219536935\n",
      "Epoch: 23 Step: 751 Loss: 1.1148286237976797\n",
      "Epoch: 23 Step: 761 Loss: 0.6262990242438404\n",
      "Epoch: 23 Step: 771 Loss: 0.9716421158676382\n",
      "Epoch: 23 Step: 781 Loss: 0.8631300420575507\n",
      "Epoch: 24 Step: 1 Loss: 0.7647565717753881\n",
      "Epoch: 24 Step: 11 Loss: 0.9811869791678433\n",
      "Epoch: 24 Step: 21 Loss: 0.7417391858807836\n",
      "Epoch: 24 Step: 31 Loss: 0.9315078386924059\n",
      "Epoch: 24 Step: 41 Loss: 0.6813956792546371\n",
      "Epoch: 24 Step: 51 Loss: 0.6973901296286699\n",
      "Epoch: 24 Step: 61 Loss: 0.6206212153881394\n",
      "Epoch: 24 Step: 71 Loss: 0.9888879974971176\n",
      "Epoch: 24 Step: 81 Loss: 0.8822420466821816\n",
      "Epoch: 24 Step: 91 Loss: 0.7556801704761625\n",
      "Epoch: 24 Step: 101 Loss: 0.7789913212567435\n",
      "Epoch: 24 Step: 111 Loss: 0.8329115257448827\n",
      "Epoch: 24 Step: 121 Loss: 1.0505468872839465\n",
      "Epoch: 24 Step: 131 Loss: 0.8327467924780324\n",
      "Epoch: 24 Step: 141 Loss: 1.0474941369831277\n",
      "Epoch: 24 Step: 151 Loss: 0.8639942801239597\n",
      "Epoch: 24 Step: 161 Loss: 0.8299817293358116\n",
      "Epoch: 24 Step: 171 Loss: 0.9660188269088912\n",
      "Epoch: 24 Step: 181 Loss: 0.6663578235026413\n",
      "Epoch: 24 Step: 191 Loss: 0.6877099291117565\n",
      "Epoch: 24 Step: 201 Loss: 0.5862126026597363\n",
      "Epoch: 24 Step: 211 Loss: 0.7026366154248108\n",
      "Epoch: 24 Step: 221 Loss: 0.8020418223239287\n",
      "Epoch: 24 Step: 231 Loss: 0.738068130262711\n",
      "Epoch: 24 Step: 241 Loss: 0.6961382857876051\n",
      "Epoch: 24 Step: 251 Loss: 0.6618900856447302\n",
      "Epoch: 24 Step: 261 Loss: 0.940746085669047\n",
      "Epoch: 24 Step: 271 Loss: 0.9661694672974224\n",
      "Epoch: 24 Step: 281 Loss: 0.6996044787270269\n",
      "Epoch: 24 Step: 291 Loss: 0.7657028458136923\n",
      "Epoch: 24 Step: 301 Loss: 0.9322251900783051\n",
      "Epoch: 24 Step: 311 Loss: 0.6891986734084322\n",
      "Epoch: 24 Step: 321 Loss: 1.101181680647393\n",
      "Epoch: 24 Step: 331 Loss: 0.9839822484886387\n",
      "Epoch: 24 Step: 341 Loss: 0.733438945719236\n",
      "Epoch: 24 Step: 351 Loss: 0.6689997012664302\n",
      "Epoch: 24 Step: 361 Loss: 0.8676559100852528\n",
      "Epoch: 24 Step: 371 Loss: 0.6061555296923349\n",
      "Epoch: 24 Step: 381 Loss: 0.6617738564977931\n",
      "Epoch: 24 Step: 391 Loss: 0.539131880829546\n",
      "Epoch: 24 Step: 401 Loss: 0.7742319182555977\n",
      "Epoch: 24 Step: 411 Loss: 0.860030849163683\n",
      "Epoch: 24 Step: 421 Loss: 0.887213577623687\n",
      "Epoch: 24 Step: 431 Loss: 0.8003965145875145\n",
      "Epoch: 24 Step: 441 Loss: 0.9095642330023973\n",
      "Epoch: 24 Step: 451 Loss: 0.73756551541622\n",
      "Epoch: 24 Step: 461 Loss: 1.0541737043641608\n",
      "Epoch: 24 Step: 471 Loss: 0.95765233364329\n",
      "Epoch: 24 Step: 481 Loss: 0.9155411893873702\n",
      "Epoch: 24 Step: 491 Loss: 0.8649484136416171\n",
      "Epoch: 24 Step: 501 Loss: 1.2418902426517386\n",
      "Epoch: 24 Step: 511 Loss: 0.7125166119737107\n",
      "Epoch: 24 Step: 521 Loss: 0.8308763042409699\n",
      "Epoch: 24 Step: 531 Loss: 0.8616607102360123\n",
      "Epoch: 24 Step: 541 Loss: 0.6663616091251872\n",
      "Epoch: 24 Step: 551 Loss: 0.7139962737040806\n",
      "Epoch: 24 Step: 561 Loss: 0.7243336423432252\n",
      "Epoch: 24 Step: 571 Loss: 0.4727242366020271\n",
      "Epoch: 24 Step: 581 Loss: 0.583342183750013\n",
      "Epoch: 24 Step: 591 Loss: 0.6741517178095884\n",
      "Epoch: 24 Step: 601 Loss: 0.5752438406838359\n",
      "Epoch: 24 Step: 611 Loss: 0.8097019728104483\n",
      "Epoch: 24 Step: 621 Loss: 0.7842739079387643\n",
      "Epoch: 24 Step: 631 Loss: 0.7275113637622834\n",
      "Epoch: 24 Step: 641 Loss: 0.992469727637451\n",
      "Epoch: 24 Step: 651 Loss: 0.7330139759794447\n",
      "Epoch: 24 Step: 661 Loss: 0.744104608468134\n",
      "Epoch: 24 Step: 671 Loss: 0.9143812646278761\n",
      "Epoch: 24 Step: 681 Loss: 0.8932795212850003\n",
      "Epoch: 24 Step: 691 Loss: 0.6632300828929227\n",
      "Epoch: 24 Step: 701 Loss: 1.0173072840894104\n",
      "Epoch: 24 Step: 711 Loss: 0.6464065902554422\n",
      "Epoch: 24 Step: 721 Loss: 0.6229056940405779\n",
      "Epoch: 24 Step: 731 Loss: 0.6514947979400291\n",
      "Epoch: 24 Step: 741 Loss: 0.5899194299376642\n",
      "Epoch: 24 Step: 751 Loss: 1.3741788509618136\n",
      "Epoch: 24 Step: 761 Loss: 0.7635070079901283\n",
      "Epoch: 24 Step: 771 Loss: 0.9654442948364023\n",
      "Epoch: 24 Step: 781 Loss: 0.7063113862433033\n",
      "Epoch: 25 Step: 1 Loss: 0.7986762479822102\n",
      "Epoch: 25 Step: 11 Loss: 0.9535236081038856\n",
      "Epoch: 25 Step: 21 Loss: 0.8017020968311384\n",
      "Epoch: 25 Step: 31 Loss: 0.8775519577454349\n",
      "Epoch: 25 Step: 41 Loss: 0.6956639573336566\n",
      "Epoch: 25 Step: 51 Loss: 0.8273567873618924\n",
      "Epoch: 25 Step: 61 Loss: 0.7196688651281806\n",
      "Epoch: 25 Step: 71 Loss: 1.0019433608567534\n",
      "Epoch: 25 Step: 81 Loss: 0.8301338631238198\n",
      "Epoch: 25 Step: 91 Loss: 0.8287532946447541\n",
      "Epoch: 25 Step: 101 Loss: 0.6994081627348137\n",
      "Epoch: 25 Step: 111 Loss: 0.9941590303786407\n",
      "Epoch: 25 Step: 121 Loss: 1.0416172677272844\n",
      "Epoch: 25 Step: 131 Loss: 1.135201777876021\n",
      "Epoch: 25 Step: 141 Loss: 1.1527019228111275\n",
      "Epoch: 25 Step: 151 Loss: 0.8231083850399359\n",
      "Epoch: 25 Step: 161 Loss: 0.8595522953478552\n",
      "Epoch: 25 Step: 171 Loss: 1.0696145725165396\n",
      "Epoch: 25 Step: 181 Loss: 0.8579168039489664\n",
      "Epoch: 25 Step: 191 Loss: 0.6479028785733301\n",
      "Epoch: 25 Step: 201 Loss: 0.514333458951962\n",
      "Epoch: 25 Step: 211 Loss: 0.5668476451573702\n",
      "Epoch: 25 Step: 221 Loss: 0.8253508941826346\n",
      "Epoch: 25 Step: 231 Loss: 0.5951366672463221\n",
      "Epoch: 25 Step: 241 Loss: 0.7274856466079647\n",
      "Epoch: 25 Step: 251 Loss: 0.7624318684028648\n",
      "Epoch: 25 Step: 261 Loss: 1.0953596082678048\n",
      "Epoch: 25 Step: 271 Loss: 0.775822587924913\n",
      "Epoch: 25 Step: 281 Loss: 0.5588795207070454\n",
      "Epoch: 25 Step: 291 Loss: 0.701269261289579\n",
      "Epoch: 25 Step: 301 Loss: 1.0939753922742113\n",
      "Epoch: 25 Step: 311 Loss: 0.8137486792175892\n",
      "Epoch: 25 Step: 321 Loss: 1.082147079507361\n",
      "Epoch: 25 Step: 331 Loss: 0.8841611481340723\n",
      "Epoch: 25 Step: 341 Loss: 0.7517043448882512\n",
      "Epoch: 25 Step: 351 Loss: 0.756534938581614\n",
      "Epoch: 25 Step: 361 Loss: 1.0352084788668412\n",
      "Epoch: 25 Step: 371 Loss: 0.6288537415155665\n",
      "Epoch: 25 Step: 381 Loss: 0.8661110654530402\n",
      "Epoch: 25 Step: 391 Loss: 0.6377971525199397\n",
      "Epoch: 25 Step: 401 Loss: 0.8026735115444514\n",
      "Epoch: 25 Step: 411 Loss: 1.0411039263781143\n",
      "Epoch: 25 Step: 421 Loss: 0.780461302161733\n",
      "Epoch: 25 Step: 431 Loss: 0.8158876394571146\n",
      "Epoch: 25 Step: 441 Loss: 0.7229784132798387\n",
      "Epoch: 25 Step: 451 Loss: 0.5308793252127323\n",
      "Epoch: 25 Step: 461 Loss: 0.8128292763523058\n",
      "Epoch: 25 Step: 471 Loss: 0.9587359831429131\n",
      "Epoch: 25 Step: 481 Loss: 0.7728427238013227\n",
      "Epoch: 25 Step: 491 Loss: 0.8909080732765792\n",
      "Epoch: 25 Step: 501 Loss: 0.9610669128223338\n",
      "Epoch: 25 Step: 511 Loss: 0.5822567694717308\n",
      "Epoch: 25 Step: 521 Loss: 0.7877435562733215\n",
      "Epoch: 25 Step: 531 Loss: 0.7758832413988092\n",
      "Epoch: 25 Step: 541 Loss: 0.6747371436818776\n",
      "Epoch: 25 Step: 551 Loss: 0.4720898617739461\n",
      "Epoch: 25 Step: 561 Loss: 0.5280570035078265\n",
      "Epoch: 25 Step: 571 Loss: 0.5030668766618158\n",
      "Epoch: 25 Step: 581 Loss: 0.7304677072609781\n",
      "Epoch: 25 Step: 591 Loss: 0.6698086407674381\n",
      "Epoch: 25 Step: 601 Loss: 0.5324259774587349\n",
      "Epoch: 25 Step: 611 Loss: 0.8793592030111241\n",
      "Epoch: 25 Step: 621 Loss: 0.8996863548451299\n",
      "Epoch: 25 Step: 631 Loss: 0.6727552510343078\n",
      "Epoch: 25 Step: 641 Loss: 0.7991021210772241\n",
      "Epoch: 25 Step: 651 Loss: 0.6824213629596799\n",
      "Epoch: 25 Step: 661 Loss: 0.5554241983856794\n",
      "Epoch: 25 Step: 671 Loss: 0.89940408988689\n",
      "Epoch: 25 Step: 681 Loss: 0.8841815981089434\n",
      "Epoch: 25 Step: 691 Loss: 0.577610815677442\n",
      "Epoch: 25 Step: 701 Loss: 0.9504525140157425\n",
      "Epoch: 25 Step: 711 Loss: 0.6944520156133817\n",
      "Epoch: 25 Step: 721 Loss: 0.6356963191165397\n",
      "Epoch: 25 Step: 731 Loss: 0.43690540687717705\n",
      "Epoch: 25 Step: 741 Loss: 0.5676041640507024\n",
      "Epoch: 25 Step: 751 Loss: 0.8875616019139989\n",
      "Epoch: 25 Step: 761 Loss: 0.5043482014870572\n",
      "Epoch: 25 Step: 771 Loss: 0.8474179586160948\n",
      "Epoch: 25 Step: 781 Loss: 0.5795389660497527\n",
      "Epoch: 26 Step: 1 Loss: 0.6649702637585523\n",
      "Epoch: 26 Step: 11 Loss: 0.9268276597891516\n",
      "Epoch: 26 Step: 21 Loss: 0.769970966314304\n",
      "Epoch: 26 Step: 31 Loss: 0.8424932564344882\n",
      "Epoch: 26 Step: 41 Loss: 0.724871604990345\n",
      "Epoch: 26 Step: 51 Loss: 0.7631396438934444\n",
      "Epoch: 26 Step: 61 Loss: 0.7983530732561086\n",
      "Epoch: 26 Step: 71 Loss: 1.0039479637067776\n",
      "Epoch: 26 Step: 81 Loss: 1.0024166116837125\n",
      "Epoch: 26 Step: 91 Loss: 0.8696537186841459\n",
      "Epoch: 26 Step: 101 Loss: 0.7561806527578028\n",
      "Epoch: 26 Step: 111 Loss: 0.9012727361429017\n",
      "Epoch: 26 Step: 121 Loss: 0.8720872713721024\n",
      "Epoch: 26 Step: 131 Loss: 0.7397338616044278\n",
      "Epoch: 26 Step: 141 Loss: 1.0175200431282372\n",
      "Epoch: 26 Step: 151 Loss: 0.6176759357330596\n",
      "Epoch: 26 Step: 161 Loss: 0.7720722134360518\n",
      "Epoch: 26 Step: 171 Loss: 0.9688344539939149\n",
      "Epoch: 26 Step: 181 Loss: 0.65362847446056\n",
      "Epoch: 26 Step: 191 Loss: 0.6255227736184138\n",
      "Epoch: 26 Step: 201 Loss: 0.43440961438185927\n",
      "Epoch: 26 Step: 211 Loss: 0.4181747425826387\n",
      "Epoch: 26 Step: 221 Loss: 0.6512507551250089\n",
      "Epoch: 26 Step: 231 Loss: 0.5562437326621135\n",
      "Epoch: 26 Step: 241 Loss: 0.6012163715972585\n",
      "Epoch: 26 Step: 251 Loss: 0.7351539877038336\n",
      "Epoch: 26 Step: 261 Loss: 0.8827162650661158\n",
      "Epoch: 26 Step: 271 Loss: 0.9776250795478864\n",
      "Epoch: 26 Step: 281 Loss: 0.5178671921908147\n",
      "Epoch: 26 Step: 291 Loss: 0.7298586331270905\n",
      "Epoch: 26 Step: 301 Loss: 1.0373688062407156\n",
      "Epoch: 26 Step: 311 Loss: 0.9994977159049236\n",
      "Epoch: 26 Step: 321 Loss: 0.9941932251532886\n",
      "Epoch: 26 Step: 331 Loss: 0.7451647686245323\n",
      "Epoch: 26 Step: 341 Loss: 0.9126204626722788\n",
      "Epoch: 26 Step: 351 Loss: 0.8473577255461653\n",
      "Epoch: 26 Step: 361 Loss: 0.8321306214221277\n",
      "Epoch: 26 Step: 371 Loss: 0.809805681992233\n",
      "Epoch: 26 Step: 381 Loss: 0.6770411374212871\n",
      "Epoch: 26 Step: 391 Loss: 0.46403671818701475\n",
      "Epoch: 26 Step: 401 Loss: 0.5642817973752872\n",
      "Epoch: 26 Step: 411 Loss: 0.7876536757932447\n",
      "Epoch: 26 Step: 421 Loss: 0.7632833490305422\n",
      "Epoch: 26 Step: 431 Loss: 0.8757811349031309\n",
      "Epoch: 26 Step: 441 Loss: 0.4506822984577357\n",
      "Epoch: 26 Step: 451 Loss: 0.7895553518251716\n",
      "Epoch: 26 Step: 461 Loss: 0.6453961164213445\n",
      "Epoch: 26 Step: 471 Loss: 0.9940812162173764\n",
      "Epoch: 26 Step: 481 Loss: 0.8219273242030036\n",
      "Epoch: 26 Step: 491 Loss: 0.7020391728676578\n",
      "Epoch: 26 Step: 501 Loss: 0.9635289725700893\n",
      "Epoch: 26 Step: 511 Loss: 0.679925131156746\n",
      "Epoch: 26 Step: 521 Loss: 0.8323336110263576\n",
      "Epoch: 26 Step: 531 Loss: 0.7725470235099099\n",
      "Epoch: 26 Step: 541 Loss: 0.872714407748904\n",
      "Epoch: 26 Step: 551 Loss: 0.6529163937758947\n",
      "Epoch: 26 Step: 561 Loss: 0.6248615890787932\n",
      "Epoch: 26 Step: 571 Loss: 0.5850802817976093\n",
      "Epoch: 26 Step: 581 Loss: 0.7813614285995354\n",
      "Epoch: 26 Step: 591 Loss: 0.8821716156013215\n",
      "Epoch: 26 Step: 601 Loss: 1.0061186567073692\n",
      "Epoch: 26 Step: 611 Loss: 0.9552558671054371\n",
      "Epoch: 26 Step: 621 Loss: 0.9018150567786313\n",
      "Epoch: 26 Step: 631 Loss: 0.7481794343582475\n",
      "Epoch: 26 Step: 641 Loss: 0.6233415161742164\n",
      "Epoch: 26 Step: 651 Loss: 0.8507860720119276\n",
      "Epoch: 26 Step: 661 Loss: 0.490813656988758\n",
      "Epoch: 26 Step: 671 Loss: 0.8203474054092135\n",
      "Epoch: 26 Step: 681 Loss: 0.857640985162317\n",
      "Epoch: 26 Step: 691 Loss: 0.5946134556477465\n",
      "Epoch: 26 Step: 701 Loss: 0.773289606232987\n",
      "Epoch: 26 Step: 711 Loss: 0.5343331713547947\n",
      "Epoch: 26 Step: 721 Loss: 0.5255903517724281\n",
      "Epoch: 26 Step: 731 Loss: 0.4439320571377822\n",
      "Epoch: 26 Step: 741 Loss: 0.6295608878514553\n",
      "Epoch: 26 Step: 751 Loss: 0.8590516988793935\n",
      "Epoch: 26 Step: 761 Loss: 0.5608482051546917\n",
      "Epoch: 26 Step: 771 Loss: 0.7077351786896694\n",
      "Epoch: 26 Step: 781 Loss: 0.7829020609708637\n",
      "Epoch: 27 Step: 1 Loss: 0.9164179802384262\n",
      "Epoch: 27 Step: 11 Loss: 0.8139449725095305\n",
      "Epoch: 27 Step: 21 Loss: 0.678910984514858\n",
      "Epoch: 27 Step: 31 Loss: 0.7344202339796015\n",
      "Epoch: 27 Step: 41 Loss: 0.6704066390189027\n",
      "Epoch: 27 Step: 51 Loss: 0.859381998670475\n",
      "Epoch: 27 Step: 61 Loss: 0.9357503520879805\n",
      "Epoch: 27 Step: 71 Loss: 1.2723684014527405\n",
      "Epoch: 27 Step: 81 Loss: 0.681348157416245\n",
      "Epoch: 27 Step: 91 Loss: 0.8153141886622174\n",
      "Epoch: 27 Step: 101 Loss: 0.8234497661150899\n",
      "Epoch: 27 Step: 111 Loss: 0.8380932705205215\n",
      "Epoch: 27 Step: 121 Loss: 0.7421345512693576\n",
      "Epoch: 27 Step: 131 Loss: 0.8752689470812489\n",
      "Epoch: 27 Step: 141 Loss: 1.0952648815788701\n",
      "Epoch: 27 Step: 151 Loss: 0.7169778839501433\n",
      "Epoch: 27 Step: 161 Loss: 0.7232111410424655\n",
      "Epoch: 27 Step: 171 Loss: 0.6499311964044938\n",
      "Epoch: 27 Step: 181 Loss: 0.6542818287162233\n",
      "Epoch: 27 Step: 191 Loss: 0.781356734750203\n",
      "Epoch: 27 Step: 201 Loss: 0.660224772208666\n",
      "Epoch: 27 Step: 211 Loss: 0.65429334236458\n",
      "Epoch: 27 Step: 221 Loss: 0.724611804455331\n",
      "Epoch: 27 Step: 231 Loss: 0.5666487869489911\n",
      "Epoch: 27 Step: 241 Loss: 0.5316215023265101\n",
      "Epoch: 27 Step: 251 Loss: 0.6853833702612665\n",
      "Epoch: 27 Step: 261 Loss: 1.0027445814857145\n",
      "Epoch: 27 Step: 271 Loss: 0.9406607394924955\n",
      "Epoch: 27 Step: 281 Loss: 0.6099230762936635\n",
      "Epoch: 27 Step: 291 Loss: 0.7193201957112552\n",
      "Epoch: 27 Step: 301 Loss: 1.0641089707090927\n",
      "Epoch: 27 Step: 311 Loss: 1.044332553413296\n",
      "Epoch: 27 Step: 321 Loss: 1.0029526635957544\n",
      "Epoch: 27 Step: 331 Loss: 0.8434851491683355\n",
      "Epoch: 27 Step: 341 Loss: 0.747726470307047\n",
      "Epoch: 27 Step: 351 Loss: 0.836927187221246\n",
      "Epoch: 27 Step: 361 Loss: 0.8640784024679866\n",
      "Epoch: 27 Step: 371 Loss: 0.686826945042103\n",
      "Epoch: 27 Step: 381 Loss: 0.5382194244546886\n",
      "Epoch: 27 Step: 391 Loss: 0.5029605249647335\n",
      "Epoch: 27 Step: 401 Loss: 0.5402517094054414\n",
      "Epoch: 27 Step: 411 Loss: 0.9471838061524832\n",
      "Epoch: 27 Step: 421 Loss: 0.834874666562676\n",
      "Epoch: 27 Step: 431 Loss: 0.6029771500587056\n",
      "Epoch: 27 Step: 441 Loss: 0.46128627677064027\n",
      "Epoch: 27 Step: 451 Loss: 0.5029742312374037\n",
      "Epoch: 27 Step: 461 Loss: 0.7246464814578206\n",
      "Epoch: 27 Step: 471 Loss: 0.8837812792308335\n",
      "Epoch: 27 Step: 481 Loss: 0.857841717603228\n",
      "Epoch: 27 Step: 491 Loss: 0.858091918502086\n",
      "Epoch: 27 Step: 501 Loss: 1.0612491253552452\n",
      "Epoch: 27 Step: 511 Loss: 0.6827730149291017\n",
      "Epoch: 27 Step: 521 Loss: 0.9759659003102497\n",
      "Epoch: 27 Step: 531 Loss: 0.9378196032878461\n",
      "Epoch: 27 Step: 541 Loss: 0.8819434602018323\n",
      "Epoch: 27 Step: 551 Loss: 0.6307280094712662\n",
      "Epoch: 27 Step: 561 Loss: 0.7569881052468567\n",
      "Epoch: 27 Step: 571 Loss: 0.6449618867006484\n",
      "Epoch: 27 Step: 581 Loss: 0.6406414799397862\n",
      "Epoch: 27 Step: 591 Loss: 0.8344958008988517\n",
      "Epoch: 27 Step: 601 Loss: 0.7907923136962192\n",
      "Epoch: 27 Step: 611 Loss: 0.6203002020512047\n",
      "Epoch: 27 Step: 621 Loss: 0.7339876571358668\n",
      "Epoch: 27 Step: 631 Loss: 0.5936870088403718\n",
      "Epoch: 27 Step: 641 Loss: 0.7198607378811788\n",
      "Epoch: 27 Step: 651 Loss: 0.6376495256938282\n",
      "Epoch: 27 Step: 661 Loss: 0.5731653487914197\n",
      "Epoch: 27 Step: 671 Loss: 0.7368348567671674\n",
      "Epoch: 27 Step: 681 Loss: 0.7422451151822961\n",
      "Epoch: 27 Step: 691 Loss: 0.7725906757794347\n",
      "Epoch: 27 Step: 701 Loss: 0.813437254497134\n",
      "Epoch: 27 Step: 711 Loss: 0.7189737040092647\n",
      "Epoch: 27 Step: 721 Loss: 0.543864145173195\n",
      "Epoch: 27 Step: 731 Loss: 0.5813648880286619\n",
      "Epoch: 27 Step: 741 Loss: 0.7167564052948481\n",
      "Epoch: 27 Step: 751 Loss: 1.0468923273947872\n",
      "Epoch: 27 Step: 761 Loss: 0.5419500756309913\n",
      "Epoch: 27 Step: 771 Loss: 0.8999290323480238\n",
      "Epoch: 27 Step: 781 Loss: 0.8573115944196428\n",
      "Epoch: 28 Step: 1 Loss: 0.8006634906358776\n",
      "Epoch: 28 Step: 11 Loss: 1.0966443655146632\n",
      "Epoch: 28 Step: 21 Loss: 0.7757052600343556\n",
      "Epoch: 28 Step: 31 Loss: 0.8478813658357022\n",
      "Epoch: 28 Step: 41 Loss: 0.5664483322281662\n",
      "Epoch: 28 Step: 51 Loss: 0.8397697354287791\n",
      "Epoch: 28 Step: 61 Loss: 0.842530181582859\n",
      "Epoch: 28 Step: 71 Loss: 1.14198096406201\n",
      "Epoch: 28 Step: 81 Loss: 0.9843894430791607\n",
      "Epoch: 28 Step: 91 Loss: 0.8907369351229835\n",
      "Epoch: 28 Step: 101 Loss: 0.8566246624359547\n",
      "Epoch: 28 Step: 111 Loss: 0.6711783763484772\n",
      "Epoch: 28 Step: 121 Loss: 0.7946386199587689\n",
      "Epoch: 28 Step: 131 Loss: 0.7483145534780942\n",
      "Epoch: 28 Step: 141 Loss: 0.9115246872285181\n",
      "Epoch: 28 Step: 151 Loss: 0.8214691027370502\n",
      "Epoch: 28 Step: 161 Loss: 0.7304113348559937\n",
      "Epoch: 28 Step: 171 Loss: 0.7257649169277879\n",
      "Epoch: 28 Step: 181 Loss: 0.6182700487456024\n",
      "Epoch: 28 Step: 191 Loss: 0.7114373797376397\n",
      "Epoch: 28 Step: 201 Loss: 0.482725570208489\n",
      "Epoch: 28 Step: 211 Loss: 0.4921652011033966\n",
      "Epoch: 28 Step: 221 Loss: 0.654721085381329\n",
      "Epoch: 28 Step: 231 Loss: 0.7653190179475537\n",
      "Epoch: 28 Step: 241 Loss: 0.8117742491265427\n",
      "Epoch: 28 Step: 251 Loss: 0.5350069724773001\n",
      "Epoch: 28 Step: 261 Loss: 1.1406462777192587\n",
      "Epoch: 28 Step: 271 Loss: 0.9827795764636859\n",
      "Epoch: 28 Step: 281 Loss: 0.7509050094796149\n",
      "Epoch: 28 Step: 291 Loss: 0.802270339754579\n",
      "Epoch: 28 Step: 301 Loss: 0.8475327585517003\n",
      "Epoch: 28 Step: 311 Loss: 1.036921612499584\n",
      "Epoch: 28 Step: 321 Loss: 1.0277602112305146\n",
      "Epoch: 28 Step: 331 Loss: 0.8772709082878594\n",
      "Epoch: 28 Step: 341 Loss: 0.800706360725941\n",
      "Epoch: 28 Step: 351 Loss: 0.7470406608336837\n",
      "Epoch: 28 Step: 361 Loss: 0.9258100267081782\n",
      "Epoch: 28 Step: 371 Loss: 0.5952723819085187\n",
      "Epoch: 28 Step: 381 Loss: 0.6038013602423283\n",
      "Epoch: 28 Step: 391 Loss: 0.4202598270146459\n",
      "Epoch: 28 Step: 401 Loss: 0.5620529337225384\n",
      "Epoch: 28 Step: 411 Loss: 0.7124691076669301\n",
      "Epoch: 28 Step: 421 Loss: 0.8316867159001343\n",
      "Epoch: 28 Step: 431 Loss: 0.7455316198571444\n",
      "Epoch: 28 Step: 441 Loss: 0.4112909683222627\n",
      "Epoch: 28 Step: 451 Loss: 0.6572417217866271\n",
      "Epoch: 28 Step: 461 Loss: 0.8330426076223454\n",
      "Epoch: 28 Step: 471 Loss: 0.9563711152710653\n",
      "Epoch: 28 Step: 481 Loss: 0.8342570557354898\n",
      "Epoch: 28 Step: 491 Loss: 1.0199341363837624\n",
      "Epoch: 28 Step: 501 Loss: 1.0097309718564649\n",
      "Epoch: 28 Step: 511 Loss: 0.7434266780198033\n",
      "Epoch: 28 Step: 521 Loss: 1.111225633695068\n",
      "Epoch: 28 Step: 531 Loss: 0.9686787424782162\n",
      "Epoch: 28 Step: 541 Loss: 0.6633613540885673\n",
      "Epoch: 28 Step: 551 Loss: 0.653688062139806\n",
      "Epoch: 28 Step: 561 Loss: 0.8147154822551406\n",
      "Epoch: 28 Step: 571 Loss: 0.4691214245879898\n",
      "Epoch: 28 Step: 581 Loss: 0.600491005464549\n",
      "Epoch: 28 Step: 591 Loss: 0.6536977626415282\n",
      "Epoch: 28 Step: 601 Loss: 0.4978089290228078\n",
      "Epoch: 28 Step: 611 Loss: 0.7263347853732148\n",
      "Epoch: 28 Step: 621 Loss: 0.7626597595762737\n",
      "Epoch: 28 Step: 631 Loss: 0.5183790065554644\n",
      "Epoch: 28 Step: 641 Loss: 0.6691804403914176\n",
      "Epoch: 28 Step: 651 Loss: 0.4197303000452374\n",
      "Epoch: 28 Step: 661 Loss: 0.8640563854774365\n",
      "Epoch: 28 Step: 671 Loss: 0.6982857112975556\n",
      "Epoch: 28 Step: 681 Loss: 0.8862127880731001\n",
      "Epoch: 28 Step: 691 Loss: 0.6084112282749672\n",
      "Epoch: 28 Step: 701 Loss: 0.9352145125205791\n",
      "Epoch: 28 Step: 711 Loss: 0.8519682970359308\n",
      "Epoch: 28 Step: 721 Loss: 0.5562137675053616\n",
      "Epoch: 28 Step: 731 Loss: 0.41710825014560277\n",
      "Epoch: 28 Step: 741 Loss: 0.731860836236368\n",
      "Epoch: 28 Step: 751 Loss: 1.204649937704658\n",
      "Epoch: 28 Step: 761 Loss: 0.6163585798407294\n",
      "Epoch: 28 Step: 771 Loss: 1.1805954296537529\n",
      "Epoch: 28 Step: 781 Loss: 0.9669199760815241\n",
      "Epoch: 29 Step: 1 Loss: 0.8908807843314552\n",
      "Epoch: 29 Step: 11 Loss: 0.8885582239208776\n",
      "Epoch: 29 Step: 21 Loss: 0.7325124937323357\n",
      "Epoch: 29 Step: 31 Loss: 0.7182320280783234\n",
      "Epoch: 29 Step: 41 Loss: 0.5527755354889043\n",
      "Epoch: 29 Step: 51 Loss: 0.6276090440014841\n",
      "Epoch: 29 Step: 61 Loss: 0.7787777386887604\n",
      "Epoch: 29 Step: 71 Loss: 0.8778956529390758\n",
      "Epoch: 29 Step: 81 Loss: 0.6808637363223143\n",
      "Epoch: 29 Step: 91 Loss: 0.7794972302893852\n",
      "Epoch: 29 Step: 101 Loss: 0.6280837063597734\n",
      "Epoch: 29 Step: 111 Loss: 0.7715416936163516\n",
      "Epoch: 29 Step: 121 Loss: 0.6284666425673741\n",
      "Epoch: 29 Step: 131 Loss: 0.7297485364233649\n",
      "Epoch: 29 Step: 141 Loss: 0.7834948414040193\n",
      "Epoch: 29 Step: 151 Loss: 0.6532410632069392\n",
      "Epoch: 29 Step: 161 Loss: 0.7263993961342579\n",
      "Epoch: 29 Step: 171 Loss: 0.5886005457907846\n",
      "Epoch: 29 Step: 181 Loss: 0.60500170442802\n",
      "Epoch: 29 Step: 191 Loss: 0.6320405708232123\n",
      "Epoch: 29 Step: 201 Loss: 0.7012329198728376\n",
      "Epoch: 29 Step: 211 Loss: 0.5108802851107508\n",
      "Epoch: 29 Step: 221 Loss: 0.8282545157833199\n",
      "Epoch: 29 Step: 231 Loss: 0.6366124573550516\n",
      "Epoch: 29 Step: 241 Loss: 0.8825356545544534\n",
      "Epoch: 29 Step: 251 Loss: 0.577540717595076\n",
      "Epoch: 29 Step: 261 Loss: 0.7920657703529241\n",
      "Epoch: 29 Step: 271 Loss: 0.8929165551902514\n",
      "Epoch: 29 Step: 281 Loss: 0.7857652596748823\n",
      "Epoch: 29 Step: 291 Loss: 0.7695292175084635\n",
      "Epoch: 29 Step: 301 Loss: 0.8434961947942626\n",
      "Epoch: 29 Step: 311 Loss: 0.7512970268759083\n",
      "Epoch: 29 Step: 321 Loss: 0.9263315930417318\n",
      "Epoch: 29 Step: 331 Loss: 0.7770070427980778\n",
      "Epoch: 29 Step: 341 Loss: 0.5090462694707232\n",
      "Epoch: 29 Step: 351 Loss: 0.5907428163072315\n",
      "Epoch: 29 Step: 361 Loss: 0.8010784078580451\n",
      "Epoch: 29 Step: 371 Loss: 0.6122881560609772\n",
      "Epoch: 29 Step: 381 Loss: 0.5656744942343389\n",
      "Epoch: 29 Step: 391 Loss: 0.5311252151004632\n",
      "Epoch: 29 Step: 401 Loss: 0.5949764577162744\n",
      "Epoch: 29 Step: 411 Loss: 0.9964713598973364\n",
      "Epoch: 29 Step: 421 Loss: 0.6955353966372645\n",
      "Epoch: 29 Step: 431 Loss: 0.6809103315098184\n",
      "Epoch: 29 Step: 441 Loss: 0.6053179296099095\n",
      "Epoch: 29 Step: 451 Loss: 0.6565583964228939\n",
      "Epoch: 29 Step: 461 Loss: 0.8979238419027982\n",
      "Epoch: 29 Step: 471 Loss: 1.1558767024228476\n",
      "Epoch: 29 Step: 481 Loss: 1.0154296798382587\n",
      "Epoch: 29 Step: 491 Loss: 1.010995304638791\n",
      "Epoch: 29 Step: 501 Loss: 0.7915120179469257\n",
      "Epoch: 29 Step: 511 Loss: 0.8699966799216194\n",
      "Epoch: 29 Step: 521 Loss: 0.9024561515845511\n",
      "Epoch: 29 Step: 531 Loss: 0.753438241287957\n",
      "Epoch: 29 Step: 541 Loss: 0.7971865384443035\n",
      "Epoch: 29 Step: 551 Loss: 0.42172689426822224\n",
      "Epoch: 29 Step: 561 Loss: 0.6142445590225813\n",
      "Epoch: 29 Step: 571 Loss: 0.5902411323021352\n",
      "Epoch: 29 Step: 581 Loss: 0.5670265111125556\n",
      "Epoch: 29 Step: 591 Loss: 0.596670538575319\n",
      "Epoch: 29 Step: 601 Loss: 0.5557142043020978\n",
      "Epoch: 29 Step: 611 Loss: 0.6693230921172989\n",
      "Epoch: 29 Step: 621 Loss: 0.4688102050365221\n",
      "Epoch: 29 Step: 631 Loss: 0.4247678850192288\n",
      "Epoch: 29 Step: 641 Loss: 0.5869268945908538\n",
      "Epoch: 29 Step: 651 Loss: 0.4585104274009939\n",
      "Epoch: 29 Step: 661 Loss: 0.5802274641439311\n",
      "Epoch: 29 Step: 671 Loss: 0.5919773191230508\n",
      "Epoch: 29 Step: 681 Loss: 0.9564091786570339\n",
      "Epoch: 29 Step: 691 Loss: 0.611919082720652\n",
      "Epoch: 29 Step: 701 Loss: 0.9538204027133341\n",
      "Epoch: 29 Step: 711 Loss: 0.7659912110301182\n",
      "Epoch: 29 Step: 721 Loss: 0.520788564489505\n",
      "Epoch: 29 Step: 731 Loss: 0.5864116996938556\n",
      "Epoch: 29 Step: 741 Loss: 0.8200668543616991\n",
      "Epoch: 29 Step: 751 Loss: 0.8995911924763735\n",
      "Epoch: 29 Step: 761 Loss: 0.5838896219086485\n",
      "Epoch: 29 Step: 771 Loss: 0.8511120051196208\n",
      "Epoch: 29 Step: 781 Loss: 0.8980101654107829\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score is 0.7049055697823303\n",
      "Score is 0.5902443910256411\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "model = DenseNet(datasets='cifar_10', opt='rmsprop')\n",
    "model.datas = [data, label]\n",
    "model.train(30)\n",
    "plt.plot(np.arange(len(model.history)), model.history)\n",
    "plt.show()\n",
    "np.savetxt('/home/oneran/Downloads/rmsprop_cifar_DenseNet_history.txt', model.history)\n",
    "model.save_model('/home/oneran/机器学习课设/cifar-10/Photon/rmsprop_cifar_DenseNet.pkl')\n",
    "score, pred = model.score(X_train, Y_train)\n",
    "score, pred = model.score(X_test, Y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 0 Step: 1 Loss: 2.302228605921952\n",
      "Epoch: 0 Step: 11 Loss: 2.1087662762629336\n",
      "Epoch: 0 Step: 21 Loss: 2.1109067065281413\n",
      "Epoch: 0 Step: 31 Loss: 2.161732685350877\n",
      "Epoch: 0 Step: 41 Loss: 1.982668839775914\n",
      "Epoch: 0 Step: 51 Loss: 2.0456770062166263\n",
      "Epoch: 0 Step: 61 Loss: 2.0362046573186507\n",
      "Epoch: 0 Step: 71 Loss: 2.1565009098173955\n",
      "Epoch: 0 Step: 81 Loss: 2.0414956114243235\n",
      "Epoch: 0 Step: 91 Loss: 2.1433563760094314\n",
      "Epoch: 0 Step: 101 Loss: 2.006755673105668\n",
      "Epoch: 0 Step: 111 Loss: 1.8976900292415575\n",
      "Epoch: 0 Step: 121 Loss: 1.9402479330706885\n",
      "Epoch: 0 Step: 131 Loss: 2.0988739345169782\n",
      "Epoch: 0 Step: 141 Loss: 2.1263757060429684\n",
      "Epoch: 0 Step: 151 Loss: 1.7198300110714573\n",
      "Epoch: 0 Step: 161 Loss: 1.8746017802958772\n",
      "Epoch: 0 Step: 171 Loss: 1.918234715023806\n",
      "Epoch: 0 Step: 181 Loss: 1.8472263046874522\n",
      "Epoch: 0 Step: 191 Loss: 1.7682191581360112\n",
      "Epoch: 0 Step: 201 Loss: 1.674746827944819\n",
      "Epoch: 0 Step: 211 Loss: 1.8723123816745262\n",
      "Epoch: 0 Step: 221 Loss: 1.958796403238034\n",
      "Epoch: 0 Step: 231 Loss: 1.9619175226347456\n",
      "Epoch: 0 Step: 241 Loss: 1.9904458442365582\n",
      "Epoch: 0 Step: 251 Loss: 1.7703539493644223\n",
      "Epoch: 0 Step: 261 Loss: 1.8762056235339015\n",
      "Epoch: 0 Step: 271 Loss: 1.9576973497564891\n",
      "Epoch: 0 Step: 281 Loss: 1.8930107472297295\n",
      "Epoch: 0 Step: 291 Loss: 1.8735886522863066\n",
      "Epoch: 0 Step: 301 Loss: 1.8933957202864447\n",
      "Epoch: 0 Step: 311 Loss: 1.8453348022163882\n",
      "Epoch: 0 Step: 321 Loss: 1.8979835582555977\n",
      "Epoch: 0 Step: 331 Loss: 1.8151329473207667\n",
      "Epoch: 0 Step: 341 Loss: 1.783796707911137\n",
      "Epoch: 0 Step: 351 Loss: 1.7961590257906666\n",
      "Epoch: 0 Step: 361 Loss: 1.8211522484445015\n",
      "Epoch: 0 Step: 371 Loss: 1.7626750688690354\n",
      "Epoch: 0 Step: 381 Loss: 1.8495126646642581\n",
      "Epoch: 0 Step: 391 Loss: 1.670142555129319\n",
      "Epoch: 0 Step: 401 Loss: 1.8690869397719365\n",
      "Epoch: 0 Step: 411 Loss: 1.8984714514314673\n",
      "Epoch: 0 Step: 421 Loss: 1.8563890776491472\n",
      "Epoch: 0 Step: 431 Loss: 1.7426255983844863\n",
      "Epoch: 0 Step: 441 Loss: 1.9148031443225233\n",
      "Epoch: 0 Step: 451 Loss: 1.754387819854831\n",
      "Epoch: 0 Step: 461 Loss: 1.8099776535759178\n",
      "Epoch: 0 Step: 471 Loss: 1.7768560929029569\n",
      "Epoch: 0 Step: 481 Loss: 1.8977893734137798\n",
      "Epoch: 0 Step: 491 Loss: 2.0738529774907324\n",
      "Epoch: 0 Step: 501 Loss: 1.9369820332317078\n",
      "Epoch: 0 Step: 511 Loss: 1.8781543690231932\n",
      "Epoch: 0 Step: 521 Loss: 1.8405876171040307\n",
      "Epoch: 0 Step: 531 Loss: 1.6561161016634163\n",
      "Epoch: 0 Step: 541 Loss: 1.8101978503902219\n",
      "Epoch: 0 Step: 551 Loss: 1.6853268899866667\n",
      "Epoch: 0 Step: 561 Loss: 1.6365754363366407\n",
      "Epoch: 0 Step: 571 Loss: 1.7745241867763348\n",
      "Epoch: 0 Step: 581 Loss: 1.9414618047615073\n",
      "Epoch: 0 Step: 591 Loss: 1.8908909500325772\n",
      "Epoch: 0 Step: 601 Loss: 1.8909791076196316\n",
      "Epoch: 0 Step: 611 Loss: 1.5592436362569357\n",
      "Epoch: 0 Step: 621 Loss: 1.718876790871104\n",
      "Epoch: 0 Step: 631 Loss: 1.8836725260326008\n",
      "Epoch: 0 Step: 641 Loss: 1.8165196574516007\n",
      "Epoch: 0 Step: 651 Loss: 1.690451413283905\n",
      "Epoch: 0 Step: 661 Loss: 1.7048048515300323\n",
      "Epoch: 0 Step: 671 Loss: 1.6906054931005223\n",
      "Epoch: 0 Step: 681 Loss: 1.8540683923872288\n",
      "Epoch: 0 Step: 691 Loss: 1.6726940567509723\n",
      "Epoch: 0 Step: 701 Loss: 1.6072093210578735\n",
      "Epoch: 0 Step: 711 Loss: 1.894361600232285\n",
      "Epoch: 0 Step: 721 Loss: 1.5204715504568935\n",
      "Epoch: 0 Step: 731 Loss: 1.629438089903907\n",
      "Epoch: 0 Step: 741 Loss: 1.8035806764126001\n",
      "Epoch: 0 Step: 751 Loss: 2.0166706889364288\n",
      "Epoch: 0 Step: 761 Loss: 1.6087577335780232\n",
      "Epoch: 0 Step: 771 Loss: 1.9061986717058463\n",
      "Epoch: 0 Step: 781 Loss: 1.7637576637781407\n",
      "Epoch: 1 Step: 1 Loss: 1.7756603331148022\n",
      "Epoch: 1 Step: 11 Loss: 1.7865103842652106\n",
      "Epoch: 1 Step: 21 Loss: 1.8267371989526549\n",
      "Epoch: 1 Step: 31 Loss: 1.8088603660268667\n",
      "Epoch: 1 Step: 41 Loss: 1.5766723934442797\n",
      "Epoch: 1 Step: 51 Loss: 1.5781065203399487\n",
      "Epoch: 1 Step: 61 Loss: 1.7675218651404403\n",
      "Epoch: 1 Step: 71 Loss: 1.813247435218461\n",
      "Epoch: 1 Step: 81 Loss: 1.7629267991152728\n",
      "Epoch: 1 Step: 91 Loss: 1.790096789378161\n",
      "Epoch: 1 Step: 101 Loss: 1.624419173921978\n",
      "Epoch: 1 Step: 111 Loss: 1.7491031894898335\n",
      "Epoch: 1 Step: 121 Loss: 1.6654420168951538\n",
      "Epoch: 1 Step: 131 Loss: 1.8053696930914398\n",
      "Epoch: 1 Step: 141 Loss: 2.1334019678603453\n",
      "Epoch: 1 Step: 151 Loss: 1.530114583834935\n",
      "Epoch: 1 Step: 161 Loss: 1.7280133352928595\n",
      "Epoch: 1 Step: 171 Loss: 1.8015468432512989\n",
      "Epoch: 1 Step: 181 Loss: 1.708582539635714\n",
      "Epoch: 1 Step: 191 Loss: 1.6408953545302771\n",
      "Epoch: 1 Step: 201 Loss: 1.372888150720989\n",
      "Epoch: 1 Step: 211 Loss: 1.707646886466111\n",
      "Epoch: 1 Step: 221 Loss: 1.7714165842212013\n",
      "Epoch: 1 Step: 231 Loss: 1.7290538603638417\n",
      "Epoch: 1 Step: 241 Loss: 1.8818370842577945\n",
      "Epoch: 1 Step: 251 Loss: 1.6206537629817128\n",
      "Epoch: 1 Step: 261 Loss: 1.6521936313922543\n",
      "Epoch: 1 Step: 271 Loss: 1.7493299247869372\n",
      "Epoch: 1 Step: 281 Loss: 1.6776582972317509\n",
      "Epoch: 1 Step: 291 Loss: 1.7278289644761535\n",
      "Epoch: 1 Step: 301 Loss: 1.8100682846502816\n",
      "Epoch: 1 Step: 311 Loss: 1.6879250128852705\n",
      "Epoch: 1 Step: 321 Loss: 1.6557760524592604\n",
      "Epoch: 1 Step: 331 Loss: 1.6793868394070768\n",
      "Epoch: 1 Step: 341 Loss: 1.7311000834102392\n",
      "Epoch: 1 Step: 351 Loss: 1.677706779193187\n",
      "Epoch: 1 Step: 361 Loss: 1.7356172586089045\n",
      "Epoch: 1 Step: 371 Loss: 1.5306802231497327\n",
      "Epoch: 1 Step: 381 Loss: 1.6825300251098252\n",
      "Epoch: 1 Step: 391 Loss: 1.503343082734904\n",
      "Epoch: 1 Step: 401 Loss: 1.7692906925363667\n",
      "Epoch: 1 Step: 411 Loss: 1.8017975446812615\n",
      "Epoch: 1 Step: 421 Loss: 1.7080275202958366\n",
      "Epoch: 1 Step: 431 Loss: 1.53155066973199\n",
      "Epoch: 1 Step: 441 Loss: 1.8246538031609938\n",
      "Epoch: 1 Step: 451 Loss: 1.456038089103173\n",
      "Epoch: 1 Step: 461 Loss: 1.5409436024301248\n",
      "Epoch: 1 Step: 471 Loss: 1.5816159913487475\n",
      "Epoch: 1 Step: 481 Loss: 1.69237176937466\n",
      "Epoch: 1 Step: 491 Loss: 1.9296318455105101\n",
      "Epoch: 1 Step: 501 Loss: 1.6550992421248787\n",
      "Epoch: 1 Step: 511 Loss: 1.4942374623041186\n",
      "Epoch: 1 Step: 521 Loss: 1.5805462001923516\n",
      "Epoch: 1 Step: 531 Loss: 1.6029165516489798\n",
      "Epoch: 1 Step: 541 Loss: 1.6316513870236182\n",
      "Epoch: 1 Step: 551 Loss: 1.4332910752015706\n",
      "Epoch: 1 Step: 561 Loss: 1.5024268180853095\n",
      "Epoch: 1 Step: 571 Loss: 1.4025839625849539\n",
      "Epoch: 1 Step: 581 Loss: 1.5785927465788592\n",
      "Epoch: 1 Step: 591 Loss: 1.6039054234054289\n",
      "Epoch: 1 Step: 601 Loss: 1.7049124548361454\n",
      "Epoch: 1 Step: 611 Loss: 1.4056711022561181\n",
      "Epoch: 1 Step: 621 Loss: 1.5555082466150074\n",
      "Epoch: 1 Step: 631 Loss: 1.71384975737273\n",
      "Epoch: 1 Step: 641 Loss: 1.7217893036547118\n",
      "Epoch: 1 Step: 651 Loss: 1.6471117155850146\n",
      "Epoch: 1 Step: 661 Loss: 1.5411682545575418\n",
      "Epoch: 1 Step: 671 Loss: 1.6138700821927845\n",
      "Epoch: 1 Step: 681 Loss: 1.7699704465825956\n",
      "Epoch: 1 Step: 691 Loss: 1.6870396210518472\n",
      "Epoch: 1 Step: 701 Loss: 1.5710630370302376\n",
      "Epoch: 1 Step: 711 Loss: 1.5720550029712572\n",
      "Epoch: 1 Step: 721 Loss: 1.4532776840947275\n",
      "Epoch: 1 Step: 731 Loss: 1.4658606622429808\n",
      "Epoch: 1 Step: 741 Loss: 1.7848109526095888\n",
      "Epoch: 1 Step: 751 Loss: 1.8674946590366903\n",
      "Epoch: 1 Step: 761 Loss: 1.477265058770722\n",
      "Epoch: 1 Step: 771 Loss: 1.653781561776935\n",
      "Epoch: 1 Step: 781 Loss: 1.5545054204512097\n",
      "Epoch: 2 Step: 1 Loss: 1.8274576455608758\n",
      "Epoch: 2 Step: 11 Loss: 1.8486938396302173\n",
      "Epoch: 2 Step: 21 Loss: 1.6510207536943222\n",
      "Epoch: 2 Step: 31 Loss: 1.6963397068899186\n",
      "Epoch: 2 Step: 41 Loss: 1.5735157661476804\n",
      "Epoch: 2 Step: 51 Loss: 1.3956392661742254\n",
      "Epoch: 2 Step: 61 Loss: 1.7329303958004068\n",
      "Epoch: 2 Step: 71 Loss: 1.7729163100492793\n",
      "Epoch: 2 Step: 81 Loss: 1.8678323505629901\n",
      "Epoch: 2 Step: 91 Loss: 1.7351016804482002\n",
      "Epoch: 2 Step: 101 Loss: 1.5670963043266282\n",
      "Epoch: 2 Step: 111 Loss: 1.6429251006650505\n",
      "Epoch: 2 Step: 121 Loss: 1.6968017715026713\n",
      "Epoch: 2 Step: 131 Loss: 1.670153033133424\n",
      "Epoch: 2 Step: 141 Loss: 1.9684646375901527\n",
      "Epoch: 2 Step: 151 Loss: 1.3390330652137736\n",
      "Epoch: 2 Step: 161 Loss: 1.6392760208579045\n",
      "Epoch: 2 Step: 171 Loss: 1.600372338135958\n",
      "Epoch: 2 Step: 181 Loss: 1.4791237042636163\n",
      "Epoch: 2 Step: 191 Loss: 1.4380531851876932\n",
      "Epoch: 2 Step: 201 Loss: 1.222757432124681\n",
      "Epoch: 2 Step: 211 Loss: 1.3843068150774802\n",
      "Epoch: 2 Step: 221 Loss: 1.608383320056321\n",
      "Epoch: 2 Step: 231 Loss: 1.489867948240788\n",
      "Epoch: 2 Step: 241 Loss: 1.7131376354318024\n",
      "Epoch: 2 Step: 251 Loss: 1.4415520453402841\n",
      "Epoch: 2 Step: 261 Loss: 1.4844213491402105\n",
      "Epoch: 2 Step: 271 Loss: 1.71310431157772\n",
      "Epoch: 2 Step: 281 Loss: 1.646162068926736\n",
      "Epoch: 2 Step: 291 Loss: 1.5882613320745862\n",
      "Epoch: 2 Step: 301 Loss: 1.6871634634381047\n",
      "Epoch: 2 Step: 311 Loss: 1.571332430097785\n",
      "Epoch: 2 Step: 321 Loss: 1.592686511902096\n",
      "Epoch: 2 Step: 331 Loss: 1.566132971733111\n",
      "Epoch: 2 Step: 341 Loss: 1.673902744400409\n",
      "Epoch: 2 Step: 351 Loss: 1.7601848750074138\n",
      "Epoch: 2 Step: 361 Loss: 1.6037873306857535\n",
      "Epoch: 2 Step: 371 Loss: 1.4210378914410149\n",
      "Epoch: 2 Step: 381 Loss: 1.7257912211478512\n",
      "Epoch: 2 Step: 391 Loss: 1.4588811973816838\n",
      "Epoch: 2 Step: 401 Loss: 1.7262759900594284\n",
      "Epoch: 2 Step: 411 Loss: 1.8295811867920126\n",
      "Epoch: 2 Step: 421 Loss: 1.6863823391135533\n",
      "Epoch: 2 Step: 431 Loss: 1.5948000180248814\n",
      "Epoch: 2 Step: 441 Loss: 1.8538558400472813\n",
      "Epoch: 2 Step: 451 Loss: 1.4636418167136984\n",
      "Epoch: 2 Step: 461 Loss: 1.6470941463596054\n",
      "Epoch: 2 Step: 471 Loss: 1.4900099232491384\n",
      "Epoch: 2 Step: 481 Loss: 1.7283459002073014\n",
      "Epoch: 2 Step: 491 Loss: 1.9288465728176192\n",
      "Epoch: 2 Step: 501 Loss: 1.8173496646497453\n",
      "Epoch: 2 Step: 511 Loss: 1.6414563864274179\n",
      "Epoch: 2 Step: 521 Loss: 1.5899011595679566\n",
      "Epoch: 2 Step: 531 Loss: 1.5023796798044726\n",
      "Epoch: 2 Step: 541 Loss: 1.5799002240549616\n",
      "Epoch: 2 Step: 551 Loss: 1.4950392137571473\n",
      "Epoch: 2 Step: 561 Loss: 1.471622200098157\n",
      "Epoch: 2 Step: 571 Loss: 1.4459804169441761\n",
      "Epoch: 2 Step: 581 Loss: 1.507905186519901\n",
      "Epoch: 2 Step: 591 Loss: 1.6102244100252001\n",
      "Epoch: 2 Step: 601 Loss: 1.5673087249353095\n",
      "Epoch: 2 Step: 611 Loss: 1.3102614863509057\n",
      "Epoch: 2 Step: 621 Loss: 1.430805432509807\n",
      "Epoch: 2 Step: 631 Loss: 1.6296932134912963\n",
      "Epoch: 2 Step: 641 Loss: 1.6177862717004072\n",
      "Epoch: 2 Step: 651 Loss: 1.4888333722772518\n",
      "Epoch: 2 Step: 661 Loss: 1.4825536929276117\n",
      "Epoch: 2 Step: 671 Loss: 1.4867339271630486\n",
      "Epoch: 2 Step: 681 Loss: 1.6410422999623844\n",
      "Epoch: 2 Step: 691 Loss: 1.4870290369594188\n",
      "Epoch: 2 Step: 701 Loss: 1.34425183528876\n",
      "Epoch: 2 Step: 711 Loss: 1.4301229724148214\n",
      "Epoch: 2 Step: 721 Loss: 1.2690439448219455\n",
      "Epoch: 2 Step: 731 Loss: 1.3961494661437444\n",
      "Epoch: 2 Step: 741 Loss: 1.5848389235715754\n",
      "Epoch: 2 Step: 751 Loss: 1.9117136812121749\n",
      "Epoch: 2 Step: 761 Loss: 1.4775843101203432\n",
      "Epoch: 2 Step: 771 Loss: 1.6176553587284823\n",
      "Epoch: 2 Step: 781 Loss: 1.3697253713425623\n",
      "Epoch: 3 Step: 1 Loss: 1.7443116857197647\n",
      "Epoch: 3 Step: 11 Loss: 1.7651650370961165\n",
      "Epoch: 3 Step: 21 Loss: 1.5957646237429501\n",
      "Epoch: 3 Step: 31 Loss: 1.7276863227316082\n",
      "Epoch: 3 Step: 41 Loss: 1.4843853099224589\n",
      "Epoch: 3 Step: 51 Loss: 1.4191032480054893\n",
      "Epoch: 3 Step: 61 Loss: 1.733679490612404\n",
      "Epoch: 3 Step: 71 Loss: 1.8126274409549756\n",
      "Epoch: 3 Step: 81 Loss: 1.7548896436055357\n",
      "Epoch: 3 Step: 91 Loss: 1.5785500986668155\n",
      "Epoch: 3 Step: 101 Loss: 1.5399785425330976\n",
      "Epoch: 3 Step: 111 Loss: 1.5431625404453286\n",
      "Epoch: 3 Step: 121 Loss: 1.6244096184497052\n",
      "Epoch: 3 Step: 131 Loss: 1.5707633098481297\n",
      "Epoch: 3 Step: 141 Loss: 1.91252278208134\n",
      "Epoch: 3 Step: 151 Loss: 1.3479720026169582\n",
      "Epoch: 3 Step: 161 Loss: 1.613705914339168\n",
      "Epoch: 3 Step: 171 Loss: 1.6288452943792004\n",
      "Epoch: 3 Step: 181 Loss: 1.423428036937739\n",
      "Epoch: 3 Step: 191 Loss: 1.4016478585931988\n",
      "Epoch: 3 Step: 201 Loss: 1.2296222572372788\n",
      "Epoch: 3 Step: 211 Loss: 1.3971854334814429\n",
      "Epoch: 3 Step: 221 Loss: 1.5343651622634917\n",
      "Epoch: 3 Step: 231 Loss: 1.428039173757525\n",
      "Epoch: 3 Step: 241 Loss: 1.7134301017878204\n",
      "Epoch: 3 Step: 251 Loss: 1.422065769777993\n",
      "Epoch: 3 Step: 261 Loss: 1.4102734999089526\n",
      "Epoch: 3 Step: 271 Loss: 1.651580088097457\n",
      "Epoch: 3 Step: 281 Loss: 1.3831032463248254\n",
      "Epoch: 3 Step: 291 Loss: 1.4465541648262081\n",
      "Epoch: 3 Step: 301 Loss: 1.5507073860144152\n",
      "Epoch: 3 Step: 311 Loss: 1.4180044112019987\n",
      "Epoch: 3 Step: 321 Loss: 1.594591856717777\n",
      "Epoch: 3 Step: 331 Loss: 1.4893702838937068\n",
      "Epoch: 3 Step: 341 Loss: 1.669510704817766\n",
      "Epoch: 3 Step: 351 Loss: 1.5655225737202463\n",
      "Epoch: 3 Step: 361 Loss: 1.480591949768738\n",
      "Epoch: 3 Step: 371 Loss: 1.1421883210392776\n",
      "Epoch: 3 Step: 381 Loss: 1.6103422142257429\n",
      "Epoch: 3 Step: 391 Loss: 1.2472660078751427\n",
      "Epoch: 3 Step: 401 Loss: 1.5472196093410489\n",
      "Epoch: 3 Step: 411 Loss: 1.7165705633891684\n",
      "Epoch: 3 Step: 421 Loss: 1.5809807309703583\n",
      "Epoch: 3 Step: 431 Loss: 1.4583381946577134\n",
      "Epoch: 3 Step: 441 Loss: 1.764816522169856\n",
      "Epoch: 3 Step: 451 Loss: 1.42654253824943\n",
      "Epoch: 3 Step: 461 Loss: 1.5446532097772678\n",
      "Epoch: 3 Step: 471 Loss: 1.4772116634553534\n",
      "Epoch: 3 Step: 481 Loss: 1.7591038126235796\n",
      "Epoch: 3 Step: 491 Loss: 1.881648698497546\n",
      "Epoch: 3 Step: 501 Loss: 1.717641429136901\n",
      "Epoch: 3 Step: 511 Loss: 1.3928172403291053\n",
      "Epoch: 3 Step: 521 Loss: 1.4935508868960385\n",
      "Epoch: 3 Step: 531 Loss: 1.4655600692892716\n",
      "Epoch: 3 Step: 541 Loss: 1.4839088214127418\n",
      "Epoch: 3 Step: 551 Loss: 1.49030702526764\n",
      "Epoch: 3 Step: 561 Loss: 1.4529306928843382\n",
      "Epoch: 3 Step: 571 Loss: 1.4729318495247115\n",
      "Epoch: 3 Step: 581 Loss: 1.4625088339716332\n",
      "Epoch: 3 Step: 591 Loss: 1.6083155917578607\n",
      "Epoch: 3 Step: 601 Loss: 1.6124290108631212\n",
      "Epoch: 3 Step: 611 Loss: 1.3335802999287432\n",
      "Epoch: 3 Step: 621 Loss: 1.3856232371813781\n",
      "Epoch: 3 Step: 631 Loss: 1.558904153137386\n",
      "Epoch: 3 Step: 641 Loss: 1.5069621622452427\n",
      "Epoch: 3 Step: 651 Loss: 1.4759911961179573\n",
      "Epoch: 3 Step: 661 Loss: 1.3668804078854795\n",
      "Epoch: 3 Step: 671 Loss: 1.5499624340633167\n",
      "Epoch: 3 Step: 681 Loss: 1.6166692438330592\n",
      "Epoch: 3 Step: 691 Loss: 1.5099186376357387\n",
      "Epoch: 3 Step: 701 Loss: 1.383902321019935\n",
      "Epoch: 3 Step: 711 Loss: 1.490416102099695\n",
      "Epoch: 3 Step: 721 Loss: 1.3411812628890087\n",
      "Epoch: 3 Step: 731 Loss: 1.188333847813229\n",
      "Epoch: 3 Step: 741 Loss: 1.569187537857771\n",
      "Epoch: 3 Step: 751 Loss: 1.6909551206357143\n",
      "Epoch: 3 Step: 761 Loss: 1.4411962322805938\n",
      "Epoch: 3 Step: 771 Loss: 1.5077590562043752\n",
      "Epoch: 3 Step: 781 Loss: 1.4415977741241375\n",
      "Epoch: 4 Step: 1 Loss: 1.5006163650877724\n",
      "Epoch: 4 Step: 11 Loss: 1.566737068944791\n",
      "Epoch: 4 Step: 21 Loss: 1.4653231929843251\n",
      "Epoch: 4 Step: 31 Loss: 1.5949136147680774\n",
      "Epoch: 4 Step: 41 Loss: 1.4141418319162078\n",
      "Epoch: 4 Step: 51 Loss: 1.3193397855505835\n",
      "Epoch: 4 Step: 61 Loss: 1.4526859415860178\n",
      "Epoch: 4 Step: 71 Loss: 1.5216703701785583\n",
      "Epoch: 4 Step: 81 Loss: 1.639337097222389\n",
      "Epoch: 4 Step: 91 Loss: 1.5859885522397041\n",
      "Epoch: 4 Step: 101 Loss: 1.449865583688277\n",
      "Epoch: 4 Step: 111 Loss: 1.5187848494622758\n",
      "Epoch: 4 Step: 121 Loss: 1.5008653843266462\n",
      "Epoch: 4 Step: 131 Loss: 1.5956470804876426\n",
      "Epoch: 4 Step: 141 Loss: 1.765600266419868\n",
      "Epoch: 4 Step: 151 Loss: 1.248154585898857\n",
      "Epoch: 4 Step: 161 Loss: 1.4504831683\n",
      "Epoch: 4 Step: 171 Loss: 1.7428786417291353\n",
      "Epoch: 4 Step: 181 Loss: 1.4222712984902994\n",
      "Epoch: 4 Step: 191 Loss: 1.4886436844289235\n",
      "Epoch: 4 Step: 201 Loss: 1.187304915781435\n",
      "Epoch: 4 Step: 211 Loss: 1.4893672047301023\n",
      "Epoch: 4 Step: 221 Loss: 1.507066939670144\n",
      "Epoch: 4 Step: 231 Loss: 1.4519104818265332\n",
      "Epoch: 4 Step: 241 Loss: 1.6628907131904334\n",
      "Epoch: 4 Step: 251 Loss: 1.4099600113630157\n",
      "Epoch: 4 Step: 261 Loss: 1.5642311885811702\n",
      "Epoch: 4 Step: 271 Loss: 1.6134645532637948\n",
      "Epoch: 4 Step: 281 Loss: 1.433453858695538\n",
      "Epoch: 4 Step: 291 Loss: 1.4741055752494123\n",
      "Epoch: 4 Step: 301 Loss: 1.459724229209796\n",
      "Epoch: 4 Step: 311 Loss: 1.6265041738663553\n",
      "Epoch: 4 Step: 321 Loss: 1.5407295545581614\n",
      "Epoch: 4 Step: 331 Loss: 1.4492154537941462\n",
      "Epoch: 4 Step: 341 Loss: 1.5849782002500277\n",
      "Epoch: 4 Step: 351 Loss: 1.4850109578153772\n",
      "Epoch: 4 Step: 361 Loss: 1.477510440206093\n",
      "Epoch: 4 Step: 371 Loss: 1.1833445763011858\n",
      "Epoch: 4 Step: 381 Loss: 1.5499510892984008\n",
      "Epoch: 4 Step: 391 Loss: 1.4062782910092744\n",
      "Epoch: 4 Step: 401 Loss: 1.4022948657823409\n",
      "Epoch: 4 Step: 411 Loss: 1.4896924631038932\n",
      "Epoch: 4 Step: 421 Loss: 1.483332131122288\n",
      "Epoch: 4 Step: 431 Loss: 1.3318010526455604\n",
      "Epoch: 4 Step: 441 Loss: 1.6099319265792245\n",
      "Epoch: 4 Step: 451 Loss: 1.3175756629186575\n",
      "Epoch: 4 Step: 461 Loss: 1.6107363166702415\n",
      "Epoch: 4 Step: 471 Loss: 1.4551221563366374\n",
      "Epoch: 4 Step: 481 Loss: 1.5117274209161355\n",
      "Epoch: 4 Step: 491 Loss: 1.7872101416553163\n",
      "Epoch: 4 Step: 501 Loss: 1.6371850754913888\n",
      "Epoch: 4 Step: 511 Loss: 1.4078541586278668\n",
      "Epoch: 4 Step: 521 Loss: 1.4535393599295787\n",
      "Epoch: 4 Step: 531 Loss: 1.4131560648381216\n",
      "Epoch: 4 Step: 541 Loss: 1.4629322595941758\n",
      "Epoch: 4 Step: 551 Loss: 1.4031106585971416\n",
      "Epoch: 4 Step: 561 Loss: 1.23678320456872\n",
      "Epoch: 4 Step: 571 Loss: 1.3375788871817578\n",
      "Epoch: 4 Step: 581 Loss: 1.5035717026035393\n",
      "Epoch: 4 Step: 591 Loss: 1.5415528317296796\n",
      "Epoch: 4 Step: 601 Loss: 1.5573021582083575\n",
      "Epoch: 4 Step: 611 Loss: 1.2555784420980136\n",
      "Epoch: 4 Step: 621 Loss: 1.2497102262424635\n",
      "Epoch: 4 Step: 631 Loss: 1.6266078507548971\n",
      "Epoch: 4 Step: 641 Loss: 1.4302884541690695\n",
      "Epoch: 4 Step: 651 Loss: 1.438640793350011\n",
      "Epoch: 4 Step: 661 Loss: 1.42945462608938\n",
      "Epoch: 4 Step: 671 Loss: 1.4832262592241257\n",
      "Epoch: 4 Step: 681 Loss: 1.6960725423549676\n",
      "Epoch: 4 Step: 691 Loss: 1.5705523700473123\n",
      "Epoch: 4 Step: 701 Loss: 1.3621690563457252\n",
      "Epoch: 4 Step: 711 Loss: 1.5251536754961\n",
      "Epoch: 4 Step: 721 Loss: 1.2427671225041133\n",
      "Epoch: 4 Step: 731 Loss: 1.3349354974538263\n",
      "Epoch: 4 Step: 741 Loss: 1.6165515193461402\n",
      "Epoch: 4 Step: 751 Loss: 1.7450170149696203\n",
      "Epoch: 4 Step: 761 Loss: 1.3284696511350496\n",
      "Epoch: 4 Step: 771 Loss: 1.5136282157781131\n",
      "Epoch: 4 Step: 781 Loss: 1.3227076548478103\n",
      "Epoch: 5 Step: 1 Loss: 1.5131054386897178\n",
      "Epoch: 5 Step: 11 Loss: 1.6078649966617629\n",
      "Epoch: 5 Step: 21 Loss: 1.4628758404879714\n",
      "Epoch: 5 Step: 31 Loss: 1.6342058490165274\n",
      "Epoch: 5 Step: 41 Loss: 1.4051684768931265\n",
      "Epoch: 5 Step: 51 Loss: 1.3805352599133065\n",
      "Epoch: 5 Step: 61 Loss: 1.4192255138214063\n",
      "Epoch: 5 Step: 71 Loss: 1.6129460051399724\n",
      "Epoch: 5 Step: 81 Loss: 1.5866588411601272\n",
      "Epoch: 5 Step: 91 Loss: 1.428203462826572\n",
      "Epoch: 5 Step: 101 Loss: 1.3767863121395363\n",
      "Epoch: 5 Step: 111 Loss: 1.4429260562906747\n",
      "Epoch: 5 Step: 121 Loss: 1.4196463306987908\n",
      "Epoch: 5 Step: 131 Loss: 1.5021621298779584\n",
      "Epoch: 5 Step: 141 Loss: 1.7554390912558815\n",
      "Epoch: 5 Step: 151 Loss: 1.2621132225215845\n",
      "Epoch: 5 Step: 161 Loss: 1.3438769803949435\n",
      "Epoch: 5 Step: 171 Loss: 1.5070952881791495\n",
      "Epoch: 5 Step: 181 Loss: 1.4037155615753167\n",
      "Epoch: 5 Step: 191 Loss: 1.2357357217012481\n",
      "Epoch: 5 Step: 201 Loss: 1.1220122069323621\n",
      "Epoch: 5 Step: 211 Loss: 1.300771138682821\n",
      "Epoch: 5 Step: 221 Loss: 1.427486585176892\n",
      "Epoch: 5 Step: 231 Loss: 1.497862487914352\n",
      "Epoch: 5 Step: 241 Loss: 1.4821275363859212\n",
      "Epoch: 5 Step: 251 Loss: 1.3714528319240273\n",
      "Epoch: 5 Step: 261 Loss: 1.4385789352604186\n",
      "Epoch: 5 Step: 271 Loss: 1.5452227199824207\n",
      "Epoch: 5 Step: 281 Loss: 1.3781892913808451\n",
      "Epoch: 5 Step: 291 Loss: 1.480690354987058\n",
      "Epoch: 5 Step: 301 Loss: 1.5427267849831339\n",
      "Epoch: 5 Step: 311 Loss: 1.521932135244282\n",
      "Epoch: 5 Step: 321 Loss: 1.5158346748805158\n",
      "Epoch: 5 Step: 331 Loss: 1.3736474292126062\n",
      "Epoch: 5 Step: 341 Loss: 1.5089467913880164\n",
      "Epoch: 5 Step: 351 Loss: 1.4157336366104007\n",
      "Epoch: 5 Step: 361 Loss: 1.5850529700063738\n",
      "Epoch: 5 Step: 371 Loss: 1.129682659790117\n",
      "Epoch: 5 Step: 381 Loss: 1.5871737939320498\n",
      "Epoch: 5 Step: 391 Loss: 1.23780877945069\n",
      "Epoch: 5 Step: 401 Loss: 1.4414820027344943\n",
      "Epoch: 5 Step: 411 Loss: 1.4857760517947758\n",
      "Epoch: 5 Step: 421 Loss: 1.5428123338928807\n",
      "Epoch: 5 Step: 431 Loss: 1.3855899533964837\n",
      "Epoch: 5 Step: 441 Loss: 1.6465183805772907\n",
      "Epoch: 5 Step: 451 Loss: 1.2057553557292249\n",
      "Epoch: 5 Step: 461 Loss: 1.503733983200528\n",
      "Epoch: 5 Step: 471 Loss: 1.4969821452809309\n",
      "Epoch: 5 Step: 481 Loss: 1.569392397061283\n",
      "Epoch: 5 Step: 491 Loss: 1.6509044097276506\n",
      "Epoch: 5 Step: 501 Loss: 1.5509337137110637\n",
      "Epoch: 5 Step: 511 Loss: 1.3873058935741571\n",
      "Epoch: 5 Step: 521 Loss: 1.4700794540282156\n",
      "Epoch: 5 Step: 531 Loss: 1.406079366737405\n",
      "Epoch: 5 Step: 541 Loss: 1.373590733920694\n",
      "Epoch: 5 Step: 551 Loss: 1.3230104728617444\n",
      "Epoch: 5 Step: 561 Loss: 1.2982579106920733\n",
      "Epoch: 5 Step: 571 Loss: 1.1978902657906554\n",
      "Epoch: 5 Step: 581 Loss: 1.2932327707405817\n",
      "Epoch: 5 Step: 591 Loss: 1.4561134949305596\n",
      "Epoch: 5 Step: 601 Loss: 1.3823620430676096\n",
      "Epoch: 5 Step: 611 Loss: 1.1386173209846562\n",
      "Epoch: 5 Step: 621 Loss: 1.3432899731356958\n",
      "Epoch: 5 Step: 631 Loss: 1.3599690720718762\n",
      "Epoch: 5 Step: 641 Loss: 1.4106427524426954\n",
      "Epoch: 5 Step: 651 Loss: 1.3419062786052867\n",
      "Epoch: 5 Step: 661 Loss: 1.3836985244546915\n",
      "Epoch: 5 Step: 671 Loss: 1.286722440876056\n",
      "Epoch: 5 Step: 681 Loss: 1.7465089478091422\n",
      "Epoch: 5 Step: 691 Loss: 1.4512112466233438\n",
      "Epoch: 5 Step: 701 Loss: 1.2054808688242455\n",
      "Epoch: 5 Step: 711 Loss: 1.3865323684566888\n",
      "Epoch: 5 Step: 721 Loss: 1.3271433482495743\n",
      "Epoch: 5 Step: 731 Loss: 1.2886834286977433\n",
      "Epoch: 5 Step: 741 Loss: 1.5322064840737124\n",
      "Epoch: 5 Step: 751 Loss: 1.688061519793132\n",
      "Epoch: 5 Step: 761 Loss: 1.3026449945604814\n",
      "Epoch: 5 Step: 771 Loss: 1.5106187067674859\n",
      "Epoch: 5 Step: 781 Loss: 1.3253148103854564\n",
      "Epoch: 6 Step: 1 Loss: 1.625448162729635\n",
      "Epoch: 6 Step: 11 Loss: 1.5844617735572246\n",
      "Epoch: 6 Step: 21 Loss: 1.5506410181488348\n",
      "Epoch: 6 Step: 31 Loss: 1.5819377839861692\n",
      "Epoch: 6 Step: 41 Loss: 1.4222864972698868\n",
      "Epoch: 6 Step: 51 Loss: 1.3877261385604336\n",
      "Epoch: 6 Step: 61 Loss: 1.401468103201014\n",
      "Epoch: 6 Step: 71 Loss: 1.5273791772996717\n",
      "Epoch: 6 Step: 81 Loss: 1.7220263811634298\n",
      "Epoch: 6 Step: 91 Loss: 1.496933843162727\n",
      "Epoch: 6 Step: 101 Loss: 1.4141234107995753\n",
      "Epoch: 6 Step: 111 Loss: 1.6375269858585035\n",
      "Epoch: 6 Step: 121 Loss: 1.5558454555987753\n",
      "Epoch: 6 Step: 131 Loss: 1.4437626398832888\n",
      "Epoch: 6 Step: 141 Loss: 1.8714199063416408\n",
      "Epoch: 6 Step: 151 Loss: 1.1446561412388623\n",
      "Epoch: 6 Step: 161 Loss: 1.4806831384864445\n",
      "Epoch: 6 Step: 171 Loss: 1.5659682299648476\n",
      "Epoch: 6 Step: 181 Loss: 1.3849670503437124\n",
      "Epoch: 6 Step: 191 Loss: 1.3271240485912261\n",
      "Epoch: 6 Step: 201 Loss: 0.9970568922883816\n",
      "Epoch: 6 Step: 211 Loss: 1.2485785773406564\n",
      "Epoch: 6 Step: 221 Loss: 1.3324781147963531\n",
      "Epoch: 6 Step: 231 Loss: 1.2762141476903184\n",
      "Epoch: 6 Step: 241 Loss: 1.4410286404131507\n",
      "Epoch: 6 Step: 251 Loss: 1.3568403215891243\n",
      "Epoch: 6 Step: 261 Loss: 1.2942960901209917\n",
      "Epoch: 6 Step: 271 Loss: 1.4191970524090836\n",
      "Epoch: 6 Step: 281 Loss: 1.5300339419374327\n",
      "Epoch: 6 Step: 291 Loss: 1.4601208655043754\n",
      "Epoch: 6 Step: 301 Loss: 1.4841026473339525\n",
      "Epoch: 6 Step: 311 Loss: 1.4896756491274725\n",
      "Epoch: 6 Step: 321 Loss: 1.439453723034935\n",
      "Epoch: 6 Step: 331 Loss: 1.3962349842129802\n",
      "Epoch: 6 Step: 341 Loss: 1.4310950671459615\n",
      "Epoch: 6 Step: 351 Loss: 1.5006470427311847\n",
      "Epoch: 6 Step: 361 Loss: 1.4473545091285525\n",
      "Epoch: 6 Step: 371 Loss: 1.0394846667727589\n",
      "Epoch: 6 Step: 381 Loss: 1.600800499686399\n",
      "Epoch: 6 Step: 391 Loss: 1.2767358965822222\n",
      "Epoch: 6 Step: 401 Loss: 1.3612226187468384\n",
      "Epoch: 6 Step: 411 Loss: 1.6034784029111055\n",
      "Epoch: 6 Step: 421 Loss: 1.4868045335539026\n",
      "Epoch: 6 Step: 431 Loss: 1.4060953441158757\n",
      "Epoch: 6 Step: 441 Loss: 1.495128601690668\n",
      "Epoch: 6 Step: 451 Loss: 1.3395341171755444\n",
      "Epoch: 6 Step: 461 Loss: 1.3735249152756999\n",
      "Epoch: 6 Step: 471 Loss: 1.425929072338554\n",
      "Epoch: 6 Step: 481 Loss: 1.5065832017387202\n",
      "Epoch: 6 Step: 491 Loss: 1.7170710431645726\n",
      "Epoch: 6 Step: 501 Loss: 1.6514176120817161\n",
      "Epoch: 6 Step: 511 Loss: 1.3778074221631413\n",
      "Epoch: 6 Step: 521 Loss: 1.5236909322706986\n",
      "Epoch: 6 Step: 531 Loss: 1.395408545711734\n",
      "Epoch: 6 Step: 541 Loss: 1.455842324543557\n",
      "Epoch: 6 Step: 551 Loss: 1.3132051051534153\n",
      "Epoch: 6 Step: 561 Loss: 1.2967195072730173\n",
      "Epoch: 6 Step: 571 Loss: 1.411277074560201\n",
      "Epoch: 6 Step: 581 Loss: 1.4359028206063482\n",
      "Epoch: 6 Step: 591 Loss: 1.4085493273080685\n",
      "Epoch: 6 Step: 601 Loss: 1.4746768410388\n",
      "Epoch: 6 Step: 611 Loss: 1.2567284833962904\n",
      "Epoch: 6 Step: 621 Loss: 1.3718070595021057\n",
      "Epoch: 6 Step: 631 Loss: 1.4738200587333437\n",
      "Epoch: 6 Step: 641 Loss: 1.4272225124917557\n",
      "Epoch: 6 Step: 651 Loss: 1.3066918416433908\n",
      "Epoch: 6 Step: 661 Loss: 1.3834933055142469\n",
      "Epoch: 6 Step: 671 Loss: 1.3069697469815764\n",
      "Epoch: 6 Step: 681 Loss: 1.575157089241339\n",
      "Epoch: 6 Step: 691 Loss: 1.3983762794423278\n",
      "Epoch: 6 Step: 701 Loss: 1.290166589697006\n",
      "Epoch: 6 Step: 711 Loss: 1.3200948579770773\n",
      "Epoch: 6 Step: 721 Loss: 1.2072212144893322\n",
      "Epoch: 6 Step: 731 Loss: 0.9606904994862767\n",
      "Epoch: 6 Step: 741 Loss: 1.5743223148152767\n",
      "Epoch: 6 Step: 751 Loss: 1.588416355993016\n",
      "Epoch: 6 Step: 761 Loss: 1.1613894012494734\n",
      "Epoch: 6 Step: 771 Loss: 1.4445942375269776\n",
      "Epoch: 6 Step: 781 Loss: 1.3551370139247239\n",
      "Epoch: 7 Step: 1 Loss: 1.5281225516929844\n",
      "Epoch: 7 Step: 11 Loss: 1.5471156300258222\n",
      "Epoch: 7 Step: 21 Loss: 1.3398996412723134\n",
      "Epoch: 7 Step: 31 Loss: 1.632577122111821\n",
      "Epoch: 7 Step: 41 Loss: 1.456980200186575\n",
      "Epoch: 7 Step: 51 Loss: 1.2992301422498365\n",
      "Epoch: 7 Step: 61 Loss: 1.390429057571705\n",
      "Epoch: 7 Step: 71 Loss: 1.5692923904624163\n",
      "Epoch: 7 Step: 81 Loss: 1.6545945896136693\n",
      "Epoch: 7 Step: 91 Loss: 1.5056563334319606\n",
      "Epoch: 7 Step: 101 Loss: 1.472038318074538\n",
      "Epoch: 7 Step: 111 Loss: 1.385267637631098\n",
      "Epoch: 7 Step: 121 Loss: 1.48219496175027\n",
      "Epoch: 7 Step: 131 Loss: 1.4987452875657428\n",
      "Epoch: 7 Step: 141 Loss: 1.8812657344232782\n",
      "Epoch: 7 Step: 151 Loss: 1.2321319107095212\n",
      "Epoch: 7 Step: 161 Loss: 1.3583194161670136\n",
      "Epoch: 7 Step: 171 Loss: 1.477217949486547\n",
      "Epoch: 7 Step: 181 Loss: 1.3577155592951418\n",
      "Epoch: 7 Step: 191 Loss: 1.2702856286968296\n",
      "Epoch: 7 Step: 201 Loss: 1.0144820709811433\n",
      "Epoch: 7 Step: 211 Loss: 1.2618181917207452\n",
      "Epoch: 7 Step: 221 Loss: 1.39123819049128\n",
      "Epoch: 7 Step: 231 Loss: 1.2736095764047402\n",
      "Epoch: 7 Step: 241 Loss: 1.4876966515489194\n",
      "Epoch: 7 Step: 251 Loss: 1.324248660706322\n",
      "Epoch: 7 Step: 261 Loss: 1.4005824483784848\n",
      "Epoch: 7 Step: 271 Loss: 1.5124087108087592\n",
      "Epoch: 7 Step: 281 Loss: 1.3542946794438926\n",
      "Epoch: 7 Step: 291 Loss: 1.424676715186623\n",
      "Epoch: 7 Step: 301 Loss: 1.47504406679744\n",
      "Epoch: 7 Step: 311 Loss: 1.4741921582366873\n",
      "Epoch: 7 Step: 321 Loss: 1.3334510000653432\n",
      "Epoch: 7 Step: 331 Loss: 1.3067712665168032\n",
      "Epoch: 7 Step: 341 Loss: 1.453620416784543\n",
      "Epoch: 7 Step: 351 Loss: 1.4442340156238873\n",
      "Epoch: 7 Step: 361 Loss: 1.2970256909547275\n",
      "Epoch: 7 Step: 371 Loss: 0.983632016665647\n",
      "Epoch: 7 Step: 381 Loss: 1.615699692887408\n",
      "Epoch: 7 Step: 391 Loss: 1.1875643960086881\n",
      "Epoch: 7 Step: 401 Loss: 1.2207109244854246\n",
      "Epoch: 7 Step: 411 Loss: 1.3271180797492819\n",
      "Epoch: 7 Step: 421 Loss: 1.366405372381748\n",
      "Epoch: 7 Step: 431 Loss: 1.343743315265388\n",
      "Epoch: 7 Step: 441 Loss: 1.378850355919905\n",
      "Epoch: 7 Step: 451 Loss: 1.262791059006833\n",
      "Epoch: 7 Step: 461 Loss: 1.3816930206821953\n",
      "Epoch: 7 Step: 471 Loss: 1.4492754365174576\n",
      "Epoch: 7 Step: 481 Loss: 1.6749587373710622\n",
      "Epoch: 7 Step: 491 Loss: 1.6984985504548078\n",
      "Epoch: 7 Step: 501 Loss: 1.6771376241867593\n",
      "Epoch: 7 Step: 511 Loss: 1.3035880311543613\n",
      "Epoch: 7 Step: 521 Loss: 1.3202677265722307\n",
      "Epoch: 7 Step: 531 Loss: 1.461857220411746\n",
      "Epoch: 7 Step: 541 Loss: 1.2358056768627708\n",
      "Epoch: 7 Step: 551 Loss: 1.4015908124228005\n",
      "Epoch: 7 Step: 561 Loss: 1.2001907792105224\n",
      "Epoch: 7 Step: 571 Loss: 1.2415917474263756\n",
      "Epoch: 7 Step: 581 Loss: 1.4598841350304752\n",
      "Epoch: 7 Step: 591 Loss: 1.546329793495202\n",
      "Epoch: 7 Step: 601 Loss: 1.3900889653500286\n",
      "Epoch: 7 Step: 611 Loss: 1.2127578063210431\n",
      "Epoch: 7 Step: 621 Loss: 1.425757348192425\n",
      "Epoch: 7 Step: 631 Loss: 1.5718292148952648\n",
      "Epoch: 7 Step: 641 Loss: 1.4555311509478481\n",
      "Epoch: 7 Step: 651 Loss: 1.2733065097404295\n",
      "Epoch: 7 Step: 661 Loss: 1.3104193555566483\n",
      "Epoch: 7 Step: 671 Loss: 1.422493626883027\n",
      "Epoch: 7 Step: 681 Loss: 1.6349418121873986\n",
      "Epoch: 7 Step: 691 Loss: 1.4537829038078176\n",
      "Epoch: 7 Step: 701 Loss: 1.2944974490354577\n",
      "Epoch: 7 Step: 711 Loss: 1.3738879715348173\n",
      "Epoch: 7 Step: 721 Loss: 1.219946239132134\n",
      "Epoch: 7 Step: 731 Loss: 1.049072760621463\n",
      "Epoch: 7 Step: 741 Loss: 1.606457903455161\n",
      "Epoch: 7 Step: 751 Loss: 1.5453531791970831\n",
      "Epoch: 7 Step: 761 Loss: 1.1950093946617786\n",
      "Epoch: 7 Step: 771 Loss: 1.4044077657024736\n",
      "Epoch: 7 Step: 781 Loss: 1.3797350879287205\n",
      "Epoch: 8 Step: 1 Loss: 1.379282799452628\n",
      "Epoch: 8 Step: 11 Loss: 1.3948620352909389\n",
      "Epoch: 8 Step: 21 Loss: 1.271179525349869\n",
      "Epoch: 8 Step: 31 Loss: 1.5083078505396643\n",
      "Epoch: 8 Step: 41 Loss: 1.3293922431722462\n",
      "Epoch: 8 Step: 51 Loss: 1.2620001329708248\n",
      "Epoch: 8 Step: 61 Loss: 1.249124007675625\n",
      "Epoch: 8 Step: 71 Loss: 1.3765107364469293\n",
      "Epoch: 8 Step: 81 Loss: 1.5407336437109664\n",
      "Epoch: 8 Step: 91 Loss: 1.435164093407751\n",
      "Epoch: 8 Step: 101 Loss: 1.270974394784487\n",
      "Epoch: 8 Step: 111 Loss: 1.3834002510950798\n",
      "Epoch: 8 Step: 121 Loss: 1.417658706832675\n",
      "Epoch: 8 Step: 131 Loss: 1.3368456076270576\n",
      "Epoch: 8 Step: 141 Loss: 1.5921401144457428\n",
      "Epoch: 8 Step: 151 Loss: 1.2519191997955956\n",
      "Epoch: 8 Step: 161 Loss: 1.3996585196672255\n",
      "Epoch: 8 Step: 171 Loss: 1.3574796311083626\n",
      "Epoch: 8 Step: 181 Loss: 1.3996408462270427\n",
      "Epoch: 8 Step: 191 Loss: 1.182765293879379\n",
      "Epoch: 8 Step: 201 Loss: 0.9517993985738807\n",
      "Epoch: 8 Step: 211 Loss: 1.2278106147863899\n",
      "Epoch: 8 Step: 221 Loss: 1.4585661724722885\n",
      "Epoch: 8 Step: 231 Loss: 1.3749873170311813\n",
      "Epoch: 8 Step: 241 Loss: 1.3714921754517166\n",
      "Epoch: 8 Step: 251 Loss: 1.3451896344738419\n",
      "Epoch: 8 Step: 261 Loss: 1.4195386961428658\n",
      "Epoch: 8 Step: 271 Loss: 1.5091572648893081\n",
      "Epoch: 8 Step: 281 Loss: 1.2963458755391475\n",
      "Epoch: 8 Step: 291 Loss: 1.3800816436657624\n",
      "Epoch: 8 Step: 301 Loss: 1.5345649627552929\n",
      "Epoch: 8 Step: 311 Loss: 1.4944575520293624\n",
      "Epoch: 8 Step: 321 Loss: 1.5046728307982307\n",
      "Epoch: 8 Step: 331 Loss: 1.3924388936642202\n",
      "Epoch: 8 Step: 341 Loss: 1.4477007519487317\n",
      "Epoch: 8 Step: 351 Loss: 1.4062415438565206\n",
      "Epoch: 8 Step: 361 Loss: 1.455603733167131\n",
      "Epoch: 8 Step: 371 Loss: 1.018360439189687\n",
      "Epoch: 8 Step: 381 Loss: 1.6897120740888636\n",
      "Epoch: 8 Step: 391 Loss: 1.1616914321962792\n",
      "Epoch: 8 Step: 401 Loss: 1.3554116005792056\n",
      "Epoch: 8 Step: 411 Loss: 1.4382032102409092\n",
      "Epoch: 8 Step: 421 Loss: 1.4320484539831158\n",
      "Epoch: 8 Step: 431 Loss: 1.3158119765302845\n",
      "Epoch: 8 Step: 441 Loss: 1.4030698974774536\n",
      "Epoch: 8 Step: 451 Loss: 1.169557634928613\n",
      "Epoch: 8 Step: 461 Loss: 1.4383411244709698\n",
      "Epoch: 8 Step: 471 Loss: 1.3023944072428801\n",
      "Epoch: 8 Step: 481 Loss: 1.4462546301161416\n",
      "Epoch: 8 Step: 491 Loss: 1.5647468893275676\n",
      "Epoch: 8 Step: 501 Loss: 1.4529686562819877\n",
      "Epoch: 8 Step: 511 Loss: 1.2494047022401764\n",
      "Epoch: 8 Step: 521 Loss: 1.3597109006664088\n",
      "Epoch: 8 Step: 531 Loss: 1.2131511687709808\n",
      "Epoch: 8 Step: 541 Loss: 1.4363676285695397\n",
      "Epoch: 8 Step: 551 Loss: 1.3832638928834937\n",
      "Epoch: 8 Step: 561 Loss: 1.1391398574728073\n",
      "Epoch: 8 Step: 571 Loss: 1.2740517780236909\n",
      "Epoch: 8 Step: 581 Loss: 1.2956546451425297\n",
      "Epoch: 8 Step: 591 Loss: 1.4225555070386167\n",
      "Epoch: 8 Step: 601 Loss: 1.5595723353600608\n",
      "Epoch: 8 Step: 611 Loss: 1.2160904967478228\n",
      "Epoch: 8 Step: 621 Loss: 1.2092776910678151\n",
      "Epoch: 8 Step: 631 Loss: 1.3149276829542988\n",
      "Epoch: 8 Step: 641 Loss: 1.4926341098505693\n",
      "Epoch: 8 Step: 651 Loss: 1.3870083343351058\n",
      "Epoch: 8 Step: 661 Loss: 1.2450521040740479\n",
      "Epoch: 8 Step: 671 Loss: 1.4827722014777778\n",
      "Epoch: 8 Step: 681 Loss: 1.7133813615361344\n",
      "Epoch: 8 Step: 691 Loss: 1.4286960653282847\n",
      "Epoch: 8 Step: 701 Loss: 1.3624907582439432\n",
      "Epoch: 8 Step: 711 Loss: 1.3649501582322405\n",
      "Epoch: 8 Step: 721 Loss: 1.2174082542292988\n",
      "Epoch: 8 Step: 731 Loss: 1.2810389100156392\n",
      "Epoch: 8 Step: 741 Loss: 1.53902619591527\n",
      "Epoch: 8 Step: 751 Loss: 1.694520760279901\n",
      "Epoch: 8 Step: 761 Loss: 1.1797605279713057\n",
      "Epoch: 8 Step: 771 Loss: 1.3831313963847691\n",
      "Epoch: 8 Step: 781 Loss: 1.331514050835251\n",
      "Epoch: 9 Step: 1 Loss: 1.5124832632138845\n",
      "Epoch: 9 Step: 11 Loss: 1.5506785147402251\n",
      "Epoch: 9 Step: 21 Loss: 1.4081466588593428\n",
      "Epoch: 9 Step: 31 Loss: 1.6442520397656577\n",
      "Epoch: 9 Step: 41 Loss: 1.351711491546096\n",
      "Epoch: 9 Step: 51 Loss: 1.2097857261971816\n",
      "Epoch: 9 Step: 61 Loss: 1.3604733225109142\n",
      "Epoch: 9 Step: 71 Loss: 1.3953699723702335\n",
      "Epoch: 9 Step: 81 Loss: 1.610807358378127\n",
      "Epoch: 9 Step: 91 Loss: 1.5777094456233574\n",
      "Epoch: 9 Step: 101 Loss: 1.2955039186897128\n",
      "Epoch: 9 Step: 111 Loss: 1.3387703078294984\n",
      "Epoch: 9 Step: 121 Loss: 1.4210136504687596\n",
      "Epoch: 9 Step: 131 Loss: 1.400491845324997\n",
      "Epoch: 9 Step: 141 Loss: 1.8465374153541863\n",
      "Epoch: 9 Step: 151 Loss: 1.1972431893744921\n",
      "Epoch: 9 Step: 161 Loss: 1.2672919996544811\n",
      "Epoch: 9 Step: 171 Loss: 1.3812508359773616\n",
      "Epoch: 9 Step: 181 Loss: 1.2152038161191143\n",
      "Epoch: 9 Step: 191 Loss: 1.2318256039292867\n",
      "Epoch: 9 Step: 201 Loss: 1.0671090232793867\n",
      "Epoch: 9 Step: 211 Loss: 1.0634878029563049\n",
      "Epoch: 9 Step: 221 Loss: 1.2716268717758752\n",
      "Epoch: 9 Step: 231 Loss: 1.1187323745680484\n",
      "Epoch: 9 Step: 241 Loss: 1.2997450115986016\n",
      "Epoch: 9 Step: 251 Loss: 1.133750287658756\n",
      "Epoch: 9 Step: 261 Loss: 1.2778959320425518\n",
      "Epoch: 9 Step: 271 Loss: 1.3429366343859621\n",
      "Epoch: 9 Step: 281 Loss: 1.3441428818496415\n",
      "Epoch: 9 Step: 291 Loss: 1.3924373169468605\n",
      "Epoch: 9 Step: 301 Loss: 1.5809052368869811\n",
      "Epoch: 9 Step: 311 Loss: 1.3178322069252957\n",
      "Epoch: 9 Step: 321 Loss: 1.2928386519837152\n",
      "Epoch: 9 Step: 331 Loss: 1.4506699385700657\n",
      "Epoch: 9 Step: 341 Loss: 1.4420557436382473\n",
      "Epoch: 9 Step: 351 Loss: 1.346451504124908\n",
      "Epoch: 9 Step: 361 Loss: 1.317811953943632\n",
      "Epoch: 9 Step: 371 Loss: 1.0367302213704919\n",
      "Epoch: 9 Step: 381 Loss: 1.5203427350282563\n",
      "Epoch: 9 Step: 391 Loss: 1.135528653278577\n",
      "Epoch: 9 Step: 401 Loss: 1.2915332845606167\n",
      "Epoch: 9 Step: 411 Loss: 1.5023651502330198\n",
      "Epoch: 9 Step: 421 Loss: 1.459863018576372\n",
      "Epoch: 9 Step: 431 Loss: 1.3962823107072364\n",
      "Epoch: 9 Step: 441 Loss: 1.4710998560894444\n",
      "Epoch: 9 Step: 451 Loss: 1.2549869662807507\n",
      "Epoch: 9 Step: 461 Loss: 1.4118516823105622\n",
      "Epoch: 9 Step: 471 Loss: 1.3619422075490246\n",
      "Epoch: 9 Step: 481 Loss: 1.5531266142989235\n",
      "Epoch: 9 Step: 491 Loss: 1.5817790095641402\n",
      "Epoch: 9 Step: 501 Loss: 1.4622094662706764\n",
      "Epoch: 9 Step: 511 Loss: 1.3841360305301746\n",
      "Epoch: 9 Step: 521 Loss: 1.5415912643627627\n",
      "Epoch: 9 Step: 531 Loss: 1.4452834776153394\n",
      "Epoch: 9 Step: 541 Loss: 1.264744395875495\n",
      "Epoch: 9 Step: 551 Loss: 1.3262160790845745\n",
      "Epoch: 9 Step: 561 Loss: 1.2887118068757502\n",
      "Epoch: 9 Step: 571 Loss: 1.3593580205810878\n",
      "Epoch: 9 Step: 581 Loss: 1.3755654177971994\n",
      "Epoch: 9 Step: 591 Loss: 1.261149513205804\n",
      "Epoch: 9 Step: 601 Loss: 1.3552607878451801\n",
      "Epoch: 9 Step: 611 Loss: 1.1157711673453217\n",
      "Epoch: 9 Step: 621 Loss: 1.2904892250591624\n",
      "Epoch: 9 Step: 631 Loss: 1.3413477940193297\n",
      "Epoch: 9 Step: 641 Loss: 1.3795077539956635\n",
      "Epoch: 9 Step: 651 Loss: 1.3160662123349396\n",
      "Epoch: 9 Step: 661 Loss: 1.2614414989496168\n",
      "Epoch: 9 Step: 671 Loss: 1.3547501522279326\n",
      "Epoch: 9 Step: 681 Loss: 1.424271879596803\n",
      "Epoch: 9 Step: 691 Loss: 1.3997088537119668\n",
      "Epoch: 9 Step: 701 Loss: 1.211973075929707\n",
      "Epoch: 9 Step: 711 Loss: 1.2829611975040365\n",
      "Epoch: 9 Step: 721 Loss: 1.2031000470027364\n",
      "Epoch: 9 Step: 731 Loss: 1.1543587055685223\n",
      "Epoch: 9 Step: 741 Loss: 1.6117831601166799\n",
      "Epoch: 9 Step: 751 Loss: 1.716048100588855\n",
      "Epoch: 9 Step: 761 Loss: 1.2774453542679987\n",
      "Epoch: 9 Step: 771 Loss: 1.4119534672193277\n",
      "Epoch: 9 Step: 781 Loss: 1.2702579539793233\n",
      "Epoch: 10 Step: 1 Loss: 1.5323088613793652\n",
      "Epoch: 10 Step: 11 Loss: 1.507040361150357\n",
      "Epoch: 10 Step: 21 Loss: 1.3144565025796362\n",
      "Epoch: 10 Step: 31 Loss: 1.502295330450035\n",
      "Epoch: 10 Step: 41 Loss: 1.400136896966245\n",
      "Epoch: 10 Step: 51 Loss: 1.2743832816048057\n",
      "Epoch: 10 Step: 61 Loss: 1.278182533742131\n",
      "Epoch: 10 Step: 71 Loss: 1.5096353032482441\n",
      "Epoch: 10 Step: 81 Loss: 1.6057220982133407\n",
      "Epoch: 10 Step: 91 Loss: 1.4307626003724714\n",
      "Epoch: 10 Step: 101 Loss: 1.321206269013541\n",
      "Epoch: 10 Step: 111 Loss: 1.4227229368106862\n",
      "Epoch: 10 Step: 121 Loss: 1.4124923862130268\n",
      "Epoch: 10 Step: 131 Loss: 1.3606881528784365\n",
      "Epoch: 10 Step: 141 Loss: 1.6791142791538016\n",
      "Epoch: 10 Step: 151 Loss: 1.1057774360909196\n",
      "Epoch: 10 Step: 161 Loss: 1.3426432632921435\n",
      "Epoch: 10 Step: 171 Loss: 1.5120799959519948\n",
      "Epoch: 10 Step: 181 Loss: 1.3915270751051674\n",
      "Epoch: 10 Step: 191 Loss: 1.3149388590460604\n",
      "Epoch: 10 Step: 201 Loss: 1.0811900410085264\n",
      "Epoch: 10 Step: 211 Loss: 1.14274133849102\n",
      "Epoch: 10 Step: 221 Loss: 1.3553260080311489\n",
      "Epoch: 10 Step: 231 Loss: 1.3393245164956022\n",
      "Epoch: 10 Step: 241 Loss: 1.3363296018698043\n",
      "Epoch: 10 Step: 251 Loss: 1.201764813163888\n",
      "Epoch: 10 Step: 261 Loss: 1.2711008370591181\n",
      "Epoch: 10 Step: 271 Loss: 1.4223936582988612\n",
      "Epoch: 10 Step: 281 Loss: 1.2775418776838503\n",
      "Epoch: 10 Step: 291 Loss: 1.3359155270989136\n",
      "Epoch: 10 Step: 301 Loss: 1.4165286616567068\n",
      "Epoch: 10 Step: 311 Loss: 1.3589852427073938\n",
      "Epoch: 10 Step: 321 Loss: 1.3689923177178644\n",
      "Epoch: 10 Step: 331 Loss: 1.2450503545490608\n",
      "Epoch: 10 Step: 341 Loss: 1.388263243923816\n",
      "Epoch: 10 Step: 351 Loss: 1.4355450851433547\n",
      "Epoch: 10 Step: 361 Loss: 1.3413594374729563\n",
      "Epoch: 10 Step: 371 Loss: 1.0741040056870275\n",
      "Epoch: 10 Step: 381 Loss: 1.583481682559645\n",
      "Epoch: 10 Step: 391 Loss: 1.0516834515165852\n",
      "Epoch: 10 Step: 401 Loss: 1.287075424060558\n",
      "Epoch: 10 Step: 411 Loss: 1.4251613788340507\n",
      "Epoch: 10 Step: 421 Loss: 1.452291013657472\n",
      "Epoch: 10 Step: 431 Loss: 1.2416125624453542\n",
      "Epoch: 10 Step: 441 Loss: 1.367273697366966\n",
      "Epoch: 10 Step: 451 Loss: 1.0560180213122676\n",
      "Epoch: 10 Step: 461 Loss: 1.4482507613864155\n",
      "Epoch: 10 Step: 471 Loss: 1.314750504024642\n",
      "Epoch: 10 Step: 481 Loss: 1.3916226162176775\n",
      "Epoch: 10 Step: 491 Loss: 1.8449194013190626\n",
      "Epoch: 10 Step: 501 Loss: 1.6101262451844964\n",
      "Epoch: 10 Step: 511 Loss: 1.2199313289384754\n",
      "Epoch: 10 Step: 521 Loss: 1.5146675984181186\n",
      "Epoch: 10 Step: 531 Loss: 1.3815157962844522\n",
      "Epoch: 10 Step: 541 Loss: 1.2604060889733366\n",
      "Epoch: 10 Step: 551 Loss: 1.1774662433132201\n",
      "Epoch: 10 Step: 561 Loss: 1.1851242514832783\n",
      "Epoch: 10 Step: 571 Loss: 1.2971957426264829\n",
      "Epoch: 10 Step: 581 Loss: 1.251707812700186\n",
      "Epoch: 10 Step: 591 Loss: 1.355304391520546\n",
      "Epoch: 10 Step: 601 Loss: 1.4139315461424395\n",
      "Epoch: 10 Step: 611 Loss: 1.2665339251528311\n",
      "Epoch: 10 Step: 621 Loss: 1.2576085999038225\n",
      "Epoch: 10 Step: 631 Loss: 1.4686428025263623\n",
      "Epoch: 10 Step: 641 Loss: 1.3806620526628972\n",
      "Epoch: 10 Step: 651 Loss: 1.2094080986435114\n",
      "Epoch: 10 Step: 661 Loss: 1.220296216738867\n",
      "Epoch: 10 Step: 671 Loss: 1.4090779214697555\n",
      "Epoch: 10 Step: 681 Loss: 1.4509257314219326\n",
      "Epoch: 10 Step: 691 Loss: 1.4316807098512228\n",
      "Epoch: 10 Step: 701 Loss: 1.1933446112119706\n",
      "Epoch: 10 Step: 711 Loss: 1.303270954318223\n",
      "Epoch: 10 Step: 721 Loss: 1.097613345274072\n",
      "Epoch: 10 Step: 731 Loss: 1.0481562692580917\n",
      "Epoch: 10 Step: 741 Loss: 1.33753984228195\n",
      "Epoch: 10 Step: 751 Loss: 1.571246576665817\n",
      "Epoch: 10 Step: 761 Loss: 1.0487654890748346\n",
      "Epoch: 10 Step: 771 Loss: 1.4723192765518793\n",
      "Epoch: 10 Step: 781 Loss: 1.2848055984510445\n",
      "Epoch: 11 Step: 1 Loss: 1.3531099249680756\n",
      "Epoch: 11 Step: 11 Loss: 1.4111005138607855\n",
      "Epoch: 11 Step: 21 Loss: 1.311626108263022\n",
      "Epoch: 11 Step: 31 Loss: 1.543507859574621\n",
      "Epoch: 11 Step: 41 Loss: 1.2490697155408672\n",
      "Epoch: 11 Step: 51 Loss: 1.1633328934932021\n",
      "Epoch: 11 Step: 61 Loss: 1.2407916090948947\n",
      "Epoch: 11 Step: 71 Loss: 1.3032918545836587\n",
      "Epoch: 11 Step: 81 Loss: 1.4074241168641666\n",
      "Epoch: 11 Step: 91 Loss: 1.557850527631579\n",
      "Epoch: 11 Step: 101 Loss: 1.4137187885552946\n",
      "Epoch: 11 Step: 111 Loss: 1.4011025044496277\n",
      "Epoch: 11 Step: 121 Loss: 1.4830811344390167\n",
      "Epoch: 11 Step: 131 Loss: 1.352628549781139\n",
      "Epoch: 11 Step: 141 Loss: 1.6818785288801976\n",
      "Epoch: 11 Step: 151 Loss: 1.1862765309638228\n",
      "Epoch: 11 Step: 161 Loss: 1.348476733653148\n",
      "Epoch: 11 Step: 171 Loss: 1.2774847935377518\n",
      "Epoch: 11 Step: 181 Loss: 1.1481406984520945\n",
      "Epoch: 11 Step: 191 Loss: 1.214865187088808\n",
      "Epoch: 11 Step: 201 Loss: 0.9438490855012114\n",
      "Epoch: 11 Step: 211 Loss: 1.2026267467210343\n",
      "Epoch: 11 Step: 221 Loss: 1.1941123766952408\n",
      "Epoch: 11 Step: 231 Loss: 1.3538715434224524\n",
      "Epoch: 11 Step: 241 Loss: 1.4846231122672746\n",
      "Epoch: 11 Step: 251 Loss: 1.3992060131209954\n",
      "Epoch: 11 Step: 261 Loss: 1.3381108130799175\n",
      "Epoch: 11 Step: 271 Loss: 1.399349661116875\n",
      "Epoch: 11 Step: 281 Loss: 1.2896961690214945\n",
      "Epoch: 11 Step: 291 Loss: 1.3443220803250038\n",
      "Epoch: 11 Step: 301 Loss: 1.486290429603009\n",
      "Epoch: 11 Step: 311 Loss: 1.345976767085329\n",
      "Epoch: 11 Step: 321 Loss: 1.2090955447286285\n",
      "Epoch: 11 Step: 331 Loss: 1.3851795462521377\n",
      "Epoch: 11 Step: 341 Loss: 1.4709354864542337\n",
      "Epoch: 11 Step: 351 Loss: 1.4047056643547453\n",
      "Epoch: 11 Step: 361 Loss: 1.28097741110692\n",
      "Epoch: 11 Step: 371 Loss: 0.9340266343616301\n",
      "Epoch: 11 Step: 381 Loss: 1.482899342551578\n",
      "Epoch: 11 Step: 391 Loss: 1.0521497220530822\n",
      "Epoch: 11 Step: 401 Loss: 1.2203722186767716\n",
      "Epoch: 11 Step: 411 Loss: 1.3188536519150036\n",
      "Epoch: 11 Step: 421 Loss: 1.2720548504431548\n",
      "Epoch: 11 Step: 431 Loss: 1.194758993562659\n",
      "Epoch: 11 Step: 441 Loss: 1.2378898667359437\n",
      "Epoch: 11 Step: 451 Loss: 1.1381123079208868\n",
      "Epoch: 11 Step: 461 Loss: 1.2306147512120549\n",
      "Epoch: 11 Step: 471 Loss: 1.3409995620898232\n",
      "Epoch: 11 Step: 481 Loss: 1.368435891051894\n",
      "Epoch: 11 Step: 491 Loss: 1.556846311347538\n",
      "Epoch: 11 Step: 501 Loss: 1.344859381400675\n",
      "Epoch: 11 Step: 511 Loss: 1.2160807338055553\n",
      "Epoch: 11 Step: 521 Loss: 1.3308642916456717\n",
      "Epoch: 11 Step: 531 Loss: 1.1468014700500615\n",
      "Epoch: 11 Step: 541 Loss: 1.1691156712148696\n",
      "Epoch: 11 Step: 551 Loss: 1.306191677359152\n",
      "Epoch: 11 Step: 561 Loss: 1.1847559426850731\n",
      "Epoch: 11 Step: 571 Loss: 1.1631417585875183\n",
      "Epoch: 11 Step: 581 Loss: 1.4344593339905\n",
      "Epoch: 11 Step: 591 Loss: 1.3749498762410313\n",
      "Epoch: 11 Step: 601 Loss: 1.2998476457934303\n",
      "Epoch: 11 Step: 611 Loss: 1.3186809861965496\n",
      "Epoch: 11 Step: 621 Loss: 1.2391696360860498\n",
      "Epoch: 11 Step: 631 Loss: 1.3983086914467493\n",
      "Epoch: 11 Step: 641 Loss: 1.5064186390328054\n",
      "Epoch: 11 Step: 651 Loss: 1.3035273154525575\n",
      "Epoch: 11 Step: 661 Loss: 1.2895019597800284\n",
      "Epoch: 11 Step: 671 Loss: 1.393290483441871\n",
      "Epoch: 11 Step: 681 Loss: 1.4030952930082692\n",
      "Epoch: 11 Step: 691 Loss: 1.3983658670914703\n",
      "Epoch: 11 Step: 701 Loss: 1.2587643727864182\n",
      "Epoch: 11 Step: 711 Loss: 1.3472803529804485\n",
      "Epoch: 11 Step: 721 Loss: 1.2522386054469532\n",
      "Epoch: 11 Step: 731 Loss: 1.0895700106555681\n",
      "Epoch: 11 Step: 741 Loss: 1.5103179340199029\n",
      "Epoch: 11 Step: 751 Loss: 1.6382669018899378\n",
      "Epoch: 11 Step: 761 Loss: 1.150194458849268\n",
      "Epoch: 11 Step: 771 Loss: 1.5108922090487216\n",
      "Epoch: 11 Step: 781 Loss: 1.2599532609315014\n",
      "Epoch: 12 Step: 1 Loss: 1.3886488695287609\n",
      "Epoch: 12 Step: 11 Loss: 1.5146603345565262\n",
      "Epoch: 12 Step: 21 Loss: 1.3142602679023523\n",
      "Epoch: 12 Step: 31 Loss: 1.4734116873379146\n",
      "Epoch: 12 Step: 41 Loss: 1.3174476274840041\n",
      "Epoch: 12 Step: 51 Loss: 1.1689973400564009\n",
      "Epoch: 12 Step: 61 Loss: 1.301503476545403\n",
      "Epoch: 12 Step: 71 Loss: 1.3135135657773223\n",
      "Epoch: 12 Step: 81 Loss: 1.467161992525527\n",
      "Epoch: 12 Step: 91 Loss: 1.3215058208198127\n",
      "Epoch: 12 Step: 101 Loss: 1.2669757690486327\n",
      "Epoch: 12 Step: 111 Loss: 1.43489147903421\n",
      "Epoch: 12 Step: 121 Loss: 1.355369904916969\n",
      "Epoch: 12 Step: 131 Loss: 1.3287347096498274\n",
      "Epoch: 12 Step: 141 Loss: 1.617719382025785\n",
      "Epoch: 12 Step: 151 Loss: 1.029951453296468\n",
      "Epoch: 12 Step: 161 Loss: 1.2120241769868192\n",
      "Epoch: 12 Step: 171 Loss: 1.3520268707199434\n",
      "Epoch: 12 Step: 181 Loss: 1.150166245013422\n",
      "Epoch: 12 Step: 191 Loss: 1.1455751729160464\n",
      "Epoch: 12 Step: 201 Loss: 0.9712944476186258\n",
      "Epoch: 12 Step: 211 Loss: 1.1274484750518927\n",
      "Epoch: 12 Step: 221 Loss: 1.2473719125496374\n",
      "Epoch: 12 Step: 231 Loss: 1.2647006079825394\n",
      "Epoch: 12 Step: 241 Loss: 1.2691390095803752\n",
      "Epoch: 12 Step: 251 Loss: 1.2184347362339432\n",
      "Epoch: 12 Step: 261 Loss: 1.3474926442640043\n",
      "Epoch: 12 Step: 271 Loss: 1.4139911856276515\n",
      "Epoch: 12 Step: 281 Loss: 1.3817258469761782\n",
      "Epoch: 12 Step: 291 Loss: 1.3614181955930091\n",
      "Epoch: 12 Step: 301 Loss: 1.429001513744002\n",
      "Epoch: 12 Step: 311 Loss: 1.422264898519761\n",
      "Epoch: 12 Step: 321 Loss: 1.2315604540237706\n",
      "Epoch: 12 Step: 331 Loss: 1.2101820116462785\n",
      "Epoch: 12 Step: 341 Loss: 1.3948796432762087\n",
      "Epoch: 12 Step: 351 Loss: 1.451688520528657\n",
      "Epoch: 12 Step: 361 Loss: 1.4137234863191934\n",
      "Epoch: 12 Step: 371 Loss: 1.0309978752691618\n",
      "Epoch: 12 Step: 381 Loss: 1.5740150632723067\n",
      "Epoch: 12 Step: 391 Loss: 1.0752476715889516\n",
      "Epoch: 12 Step: 401 Loss: 1.1404589584108782\n",
      "Epoch: 12 Step: 411 Loss: 1.3265786736161804\n",
      "Epoch: 12 Step: 421 Loss: 1.41744950191987\n",
      "Epoch: 12 Step: 431 Loss: 1.2854037889620724\n",
      "Epoch: 12 Step: 441 Loss: 1.321839826117599\n",
      "Epoch: 12 Step: 451 Loss: 1.2365942785060136\n",
      "Epoch: 12 Step: 461 Loss: 1.296026012868559\n",
      "Epoch: 12 Step: 471 Loss: 1.4100689920333653\n",
      "Epoch: 12 Step: 481 Loss: 1.3488179696422242\n",
      "Epoch: 12 Step: 491 Loss: 1.5246988934433223\n",
      "Epoch: 12 Step: 501 Loss: 1.4231865038866325\n",
      "Epoch: 12 Step: 511 Loss: 1.2183199145049275\n",
      "Epoch: 12 Step: 521 Loss: 1.3501920256120359\n",
      "Epoch: 12 Step: 531 Loss: 1.3074860797546508\n",
      "Epoch: 12 Step: 541 Loss: 1.2266097628227657\n",
      "Epoch: 12 Step: 551 Loss: 1.1582256176902601\n",
      "Epoch: 12 Step: 561 Loss: 1.0046026032090811\n",
      "Epoch: 12 Step: 571 Loss: 1.2306376391716305\n",
      "Epoch: 12 Step: 581 Loss: 1.3627631118480195\n",
      "Epoch: 12 Step: 591 Loss: 1.2304969752685584\n",
      "Epoch: 12 Step: 601 Loss: 1.323284411992214\n",
      "Epoch: 12 Step: 611 Loss: 1.049196145022636\n",
      "Epoch: 12 Step: 621 Loss: 1.156976916708959\n",
      "Epoch: 12 Step: 631 Loss: 1.2439602155315448\n",
      "Epoch: 12 Step: 641 Loss: 1.3093394037015402\n",
      "Epoch: 12 Step: 651 Loss: 1.227636392290267\n",
      "Epoch: 12 Step: 661 Loss: 1.3295185977276298\n",
      "Epoch: 12 Step: 671 Loss: 1.2353219497081582\n",
      "Epoch: 12 Step: 681 Loss: 1.4758513713179504\n",
      "Epoch: 12 Step: 691 Loss: 1.4611721046406942\n",
      "Epoch: 12 Step: 701 Loss: 1.1886746233891001\n",
      "Epoch: 12 Step: 711 Loss: 1.3861763017039102\n",
      "Epoch: 12 Step: 721 Loss: 1.2537865338758207\n",
      "Epoch: 12 Step: 731 Loss: 1.148932361214609\n",
      "Epoch: 12 Step: 741 Loss: 1.5062284689134446\n",
      "Epoch: 12 Step: 751 Loss: 1.5785411622151315\n",
      "Epoch: 12 Step: 761 Loss: 1.1881716115667185\n",
      "Epoch: 12 Step: 771 Loss: 1.3297358079180952\n",
      "Epoch: 12 Step: 781 Loss: 1.2688701537336424\n",
      "Epoch: 13 Step: 1 Loss: 1.4430143669420263\n",
      "Epoch: 13 Step: 11 Loss: 1.4245196511529148\n",
      "Epoch: 13 Step: 21 Loss: 1.4691635748514438\n",
      "Epoch: 13 Step: 31 Loss: 1.4378717476778777\n",
      "Epoch: 13 Step: 41 Loss: 1.357441562624972\n",
      "Epoch: 13 Step: 51 Loss: 1.2281588807260935\n",
      "Epoch: 13 Step: 61 Loss: 1.2205023313202812\n",
      "Epoch: 13 Step: 71 Loss: 1.4396675764979683\n",
      "Epoch: 13 Step: 81 Loss: 1.5079784666050409\n",
      "Epoch: 13 Step: 91 Loss: 1.509925499805632\n",
      "Epoch: 13 Step: 101 Loss: 1.279037022323243\n",
      "Epoch: 13 Step: 111 Loss: 1.3793782167060984\n",
      "Epoch: 13 Step: 121 Loss: 1.414084925945408\n",
      "Epoch: 13 Step: 131 Loss: 1.239360558634842\n",
      "Epoch: 13 Step: 141 Loss: 1.493053504745262\n",
      "Epoch: 13 Step: 151 Loss: 1.037202041555023\n",
      "Epoch: 13 Step: 161 Loss: 1.318015470922761\n",
      "Epoch: 13 Step: 171 Loss: 1.3194888790578805\n",
      "Epoch: 13 Step: 181 Loss: 1.2992923803143324\n",
      "Epoch: 13 Step: 191 Loss: 1.2060373428046596\n",
      "Epoch: 13 Step: 201 Loss: 0.953067177360386\n",
      "Epoch: 13 Step: 211 Loss: 1.0116194670762835\n",
      "Epoch: 13 Step: 221 Loss: 1.3454557697557734\n",
      "Epoch: 13 Step: 231 Loss: 1.182118166235608\n",
      "Epoch: 13 Step: 241 Loss: 1.4017608006328248\n",
      "Epoch: 13 Step: 251 Loss: 1.005499837483768\n",
      "Epoch: 13 Step: 261 Loss: 1.3350143044119869\n",
      "Epoch: 13 Step: 271 Loss: 1.2676211226061969\n",
      "Epoch: 13 Step: 281 Loss: 1.39755209258158\n",
      "Epoch: 13 Step: 291 Loss: 1.4309799961538967\n",
      "Epoch: 13 Step: 301 Loss: 1.3233770561338902\n",
      "Epoch: 13 Step: 311 Loss: 1.3414026457345725\n",
      "Epoch: 13 Step: 321 Loss: 1.2471324250611604\n",
      "Epoch: 13 Step: 331 Loss: 1.151161678863295\n",
      "Epoch: 13 Step: 341 Loss: 1.2347926825704594\n",
      "Epoch: 13 Step: 351 Loss: 1.3872558883629384\n",
      "Epoch: 13 Step: 361 Loss: 1.1875197905163293\n",
      "Epoch: 13 Step: 371 Loss: 1.0500326618690863\n",
      "Epoch: 13 Step: 381 Loss: 1.3019075920002348\n",
      "Epoch: 13 Step: 391 Loss: 1.0969623926882686\n",
      "Epoch: 13 Step: 401 Loss: 1.2508081646124634\n",
      "Epoch: 13 Step: 411 Loss: 1.3347607760009554\n",
      "Epoch: 13 Step: 421 Loss: 1.4722893315261083\n",
      "Epoch: 13 Step: 431 Loss: 1.3518317399542452\n",
      "Epoch: 13 Step: 441 Loss: 1.3857370742056414\n",
      "Epoch: 13 Step: 451 Loss: 1.169639118827085\n",
      "Epoch: 13 Step: 461 Loss: 1.4605955585589592\n",
      "Epoch: 13 Step: 471 Loss: 1.3278291023672537\n",
      "Epoch: 13 Step: 481 Loss: 1.5579029910866335\n",
      "Epoch: 13 Step: 491 Loss: 1.6813764791857104\n",
      "Epoch: 13 Step: 501 Loss: 1.3800582164744493\n",
      "Epoch: 13 Step: 511 Loss: 1.30795146515851\n",
      "Epoch: 13 Step: 521 Loss: 1.3502184103438086\n",
      "Epoch: 13 Step: 531 Loss: 1.3644800258297014\n",
      "Epoch: 13 Step: 541 Loss: 1.2567568709203933\n",
      "Epoch: 13 Step: 551 Loss: 1.1586362764669946\n",
      "Epoch: 13 Step: 561 Loss: 1.0800592631971568\n",
      "Epoch: 13 Step: 571 Loss: 1.2856612536217489\n",
      "Epoch: 13 Step: 581 Loss: 1.3018707753104344\n",
      "Epoch: 13 Step: 591 Loss: 1.418539666627344\n",
      "Epoch: 13 Step: 601 Loss: 1.4636700785535335\n",
      "Epoch: 13 Step: 611 Loss: 1.1542625723555866\n",
      "Epoch: 13 Step: 621 Loss: 1.2479449136166414\n",
      "Epoch: 13 Step: 631 Loss: 1.2565459285266445\n",
      "Epoch: 13 Step: 641 Loss: 1.2640991576739835\n",
      "Epoch: 13 Step: 651 Loss: 1.3408725145543734\n",
      "Epoch: 13 Step: 661 Loss: 1.1609341115818115\n",
      "Epoch: 13 Step: 671 Loss: 1.1944566554378848\n",
      "Epoch: 13 Step: 681 Loss: 1.5267754609775226\n",
      "Epoch: 13 Step: 691 Loss: 1.2857827034194382\n",
      "Epoch: 13 Step: 701 Loss: 1.166544984953417\n",
      "Epoch: 13 Step: 711 Loss: 1.2487268553394162\n",
      "Epoch: 13 Step: 721 Loss: 1.0246099489706737\n",
      "Epoch: 13 Step: 731 Loss: 0.9257599769720753\n",
      "Epoch: 13 Step: 741 Loss: 1.3926717643723734\n",
      "Epoch: 13 Step: 751 Loss: 1.5113269315387736\n",
      "Epoch: 13 Step: 761 Loss: 1.1186214547785678\n",
      "Epoch: 13 Step: 771 Loss: 1.2378600536321727\n",
      "Epoch: 13 Step: 781 Loss: 1.2055973538087257\n",
      "Epoch: 14 Step: 1 Loss: 1.2947988564460782\n",
      "Epoch: 14 Step: 11 Loss: 1.2678941018285088\n",
      "Epoch: 14 Step: 21 Loss: 1.2310810717777008\n",
      "Epoch: 14 Step: 31 Loss: 1.5765318259816692\n",
      "Epoch: 14 Step: 41 Loss: 1.265644140129191\n",
      "Epoch: 14 Step: 51 Loss: 1.1778215738707827\n",
      "Epoch: 14 Step: 61 Loss: 1.274111947246948\n",
      "Epoch: 14 Step: 71 Loss: 1.3537006802862797\n",
      "Epoch: 14 Step: 81 Loss: 1.4124606212697084\n",
      "Epoch: 14 Step: 91 Loss: 1.4594632634891653\n",
      "Epoch: 14 Step: 101 Loss: 1.2724906084660197\n",
      "Epoch: 14 Step: 111 Loss: 1.3500330211599119\n",
      "Epoch: 14 Step: 121 Loss: 1.4932696956337486\n",
      "Epoch: 14 Step: 131 Loss: 1.3285806509573412\n",
      "Epoch: 14 Step: 141 Loss: 1.7337475533847129\n",
      "Epoch: 14 Step: 151 Loss: 1.0966152180426985\n",
      "Epoch: 14 Step: 161 Loss: 1.2311452730953403\n",
      "Epoch: 14 Step: 171 Loss: 1.3782872569484754\n",
      "Epoch: 14 Step: 181 Loss: 1.1237361887816122\n",
      "Epoch: 14 Step: 191 Loss: 1.2058833928287485\n",
      "Epoch: 14 Step: 201 Loss: 0.947220272250876\n",
      "Epoch: 14 Step: 211 Loss: 1.064430754427697\n",
      "Epoch: 14 Step: 221 Loss: 1.2688180213083156\n",
      "Epoch: 14 Step: 231 Loss: 1.090845486743104\n",
      "Epoch: 14 Step: 241 Loss: 1.2954672427233265\n",
      "Epoch: 14 Step: 251 Loss: 1.2371953976593506\n",
      "Epoch: 14 Step: 261 Loss: 1.354974838515966\n",
      "Epoch: 14 Step: 271 Loss: 1.2993087642067647\n",
      "Epoch: 14 Step: 281 Loss: 1.4175362115815036\n",
      "Epoch: 14 Step: 291 Loss: 1.280326680756498\n",
      "Epoch: 14 Step: 301 Loss: 1.4212979647782966\n",
      "Epoch: 14 Step: 311 Loss: 1.3727681421272924\n",
      "Epoch: 14 Step: 321 Loss: 1.2959747536064348\n",
      "Epoch: 14 Step: 331 Loss: 1.210786599560393\n",
      "Epoch: 14 Step: 341 Loss: 1.4017452812193656\n",
      "Epoch: 14 Step: 351 Loss: 1.319115185333629\n",
      "Epoch: 14 Step: 361 Loss: 1.215313155398573\n",
      "Epoch: 14 Step: 371 Loss: 0.9599186029019425\n",
      "Epoch: 14 Step: 381 Loss: 1.4529235895588153\n",
      "Epoch: 14 Step: 391 Loss: 0.9460751419982534\n",
      "Epoch: 14 Step: 401 Loss: 1.1441137633295124\n",
      "Epoch: 14 Step: 411 Loss: 1.4150641357044016\n",
      "Epoch: 14 Step: 421 Loss: 1.3604895677443944\n",
      "Epoch: 14 Step: 431 Loss: 1.173170326592363\n",
      "Epoch: 14 Step: 441 Loss: 1.252708976842468\n",
      "Epoch: 14 Step: 451 Loss: 1.1058637855407503\n",
      "Epoch: 14 Step: 461 Loss: 1.3150725965163392\n",
      "Epoch: 14 Step: 471 Loss: 1.2330623290080096\n",
      "Epoch: 14 Step: 481 Loss: 1.4704008718126902\n",
      "Epoch: 14 Step: 491 Loss: 1.6042596710109298\n",
      "Epoch: 14 Step: 501 Loss: 1.3813792282453743\n",
      "Epoch: 14 Step: 511 Loss: 1.282841796702547\n",
      "Epoch: 14 Step: 521 Loss: 1.3009150601967832\n",
      "Epoch: 14 Step: 531 Loss: 1.352267707834482\n",
      "Epoch: 14 Step: 541 Loss: 1.248219820805968\n",
      "Epoch: 14 Step: 551 Loss: 1.328196810632043\n",
      "Epoch: 14 Step: 561 Loss: 1.2027881763723383\n",
      "Epoch: 14 Step: 571 Loss: 1.337245005977321\n",
      "Epoch: 14 Step: 581 Loss: 1.267679687531594\n",
      "Epoch: 14 Step: 591 Loss: 1.3330332363043296\n",
      "Epoch: 14 Step: 601 Loss: 1.3694823968543743\n",
      "Epoch: 14 Step: 611 Loss: 1.1834901964133282\n",
      "Epoch: 14 Step: 621 Loss: 1.0579004782826487\n",
      "Epoch: 14 Step: 631 Loss: 1.3037968834427744\n",
      "Epoch: 14 Step: 641 Loss: 1.416377951810461\n",
      "Epoch: 14 Step: 651 Loss: 1.301066774383791\n",
      "Epoch: 14 Step: 661 Loss: 1.2604967090864114\n",
      "Epoch: 14 Step: 671 Loss: 1.318768327528988\n",
      "Epoch: 14 Step: 681 Loss: 1.443249900333365\n",
      "Epoch: 14 Step: 691 Loss: 1.3167977559758457\n",
      "Epoch: 14 Step: 701 Loss: 1.2093176341602234\n",
      "Epoch: 14 Step: 711 Loss: 1.3283296924125843\n",
      "Epoch: 14 Step: 721 Loss: 1.183031746404332\n",
      "Epoch: 14 Step: 731 Loss: 0.9796586176138341\n",
      "Epoch: 14 Step: 741 Loss: 1.486090250306386\n",
      "Epoch: 14 Step: 751 Loss: 1.5344843838314393\n",
      "Epoch: 14 Step: 761 Loss: 1.0303629736395772\n",
      "Epoch: 14 Step: 771 Loss: 1.329252889439498\n",
      "Epoch: 14 Step: 781 Loss: 1.126720330272077\n",
      "Epoch: 15 Step: 1 Loss: 1.4658906347925778\n",
      "Epoch: 15 Step: 11 Loss: 1.279390466051322\n",
      "Epoch: 15 Step: 21 Loss: 1.2554858617669709\n",
      "Epoch: 15 Step: 31 Loss: 1.3879205458491626\n",
      "Epoch: 15 Step: 41 Loss: 1.1213098606075937\n",
      "Epoch: 15 Step: 51 Loss: 1.0898341973914083\n",
      "Epoch: 15 Step: 61 Loss: 1.2742275841606334\n",
      "Epoch: 15 Step: 71 Loss: 1.2554804429383182\n",
      "Epoch: 15 Step: 81 Loss: 1.424568612334043\n",
      "Epoch: 15 Step: 91 Loss: 1.3043127587333816\n",
      "Epoch: 15 Step: 101 Loss: 1.1469340620736972\n",
      "Epoch: 15 Step: 111 Loss: 1.2648901687079568\n",
      "Epoch: 15 Step: 121 Loss: 1.360945844952166\n",
      "Epoch: 15 Step: 131 Loss: 1.2965980382068447\n",
      "Epoch: 15 Step: 141 Loss: 1.517898004462206\n",
      "Epoch: 15 Step: 151 Loss: 1.1392367255481095\n",
      "Epoch: 15 Step: 161 Loss: 1.1393059805591474\n",
      "Epoch: 15 Step: 171 Loss: 1.4012841525040074\n",
      "Epoch: 15 Step: 181 Loss: 1.23205429761629\n",
      "Epoch: 15 Step: 191 Loss: 1.1759021987032514\n",
      "Epoch: 15 Step: 201 Loss: 0.9607079096786095\n",
      "Epoch: 15 Step: 211 Loss: 1.1332232941881941\n",
      "Epoch: 15 Step: 221 Loss: 1.2379732656397877\n",
      "Epoch: 15 Step: 231 Loss: 1.18599413745034\n",
      "Epoch: 15 Step: 241 Loss: 1.160096339289785\n",
      "Epoch: 15 Step: 251 Loss: 1.1274319086202644\n",
      "Epoch: 15 Step: 261 Loss: 1.3874825211239048\n",
      "Epoch: 15 Step: 271 Loss: 1.414037686853518\n",
      "Epoch: 15 Step: 281 Loss: 1.328915495755132\n",
      "Epoch: 15 Step: 291 Loss: 1.3325282139981196\n",
      "Epoch: 15 Step: 301 Loss: 1.404918861226884\n",
      "Epoch: 15 Step: 311 Loss: 1.38626332691368\n",
      "Epoch: 15 Step: 321 Loss: 1.298286952158436\n",
      "Epoch: 15 Step: 331 Loss: 1.1653280568637807\n",
      "Epoch: 15 Step: 341 Loss: 1.4028138090752929\n",
      "Epoch: 15 Step: 351 Loss: 1.3846822584731378\n",
      "Epoch: 15 Step: 361 Loss: 1.315469314798198\n",
      "Epoch: 15 Step: 371 Loss: 0.939219285134461\n",
      "Epoch: 15 Step: 381 Loss: 1.4325495675257665\n",
      "Epoch: 15 Step: 391 Loss: 1.063428571079045\n",
      "Epoch: 15 Step: 401 Loss: 1.2017425771478325\n",
      "Epoch: 15 Step: 411 Loss: 1.4494680397685706\n",
      "Epoch: 15 Step: 421 Loss: 1.2742701666877567\n",
      "Epoch: 15 Step: 431 Loss: 1.381415237988313\n",
      "Epoch: 15 Step: 441 Loss: 1.2700581424196424\n",
      "Epoch: 15 Step: 451 Loss: 1.286230368804811\n",
      "Epoch: 15 Step: 461 Loss: 1.3087145353444378\n",
      "Epoch: 15 Step: 471 Loss: 1.2510925657752292\n",
      "Epoch: 15 Step: 481 Loss: 1.3410378332214095\n",
      "Epoch: 15 Step: 491 Loss: 1.3129588540266228\n",
      "Epoch: 15 Step: 501 Loss: 1.410112704555866\n",
      "Epoch: 15 Step: 511 Loss: 1.128549731557996\n",
      "Epoch: 15 Step: 521 Loss: 1.2292403566788677\n",
      "Epoch: 15 Step: 531 Loss: 1.1770588825053927\n",
      "Epoch: 15 Step: 541 Loss: 1.1298207903801178\n",
      "Epoch: 15 Step: 551 Loss: 1.1331333989673102\n",
      "Epoch: 15 Step: 561 Loss: 1.0380385709333062\n",
      "Epoch: 15 Step: 571 Loss: 1.0957178189492278\n",
      "Epoch: 15 Step: 581 Loss: 1.386339395129981\n",
      "Epoch: 15 Step: 591 Loss: 1.2514962797743507\n",
      "Epoch: 15 Step: 601 Loss: 1.256739297888226\n",
      "Epoch: 15 Step: 611 Loss: 1.1470029637475978\n",
      "Epoch: 15 Step: 621 Loss: 1.2439410007393759\n",
      "Epoch: 15 Step: 631 Loss: 1.5097496415163136\n",
      "Epoch: 15 Step: 641 Loss: 1.406581157627401\n",
      "Epoch: 15 Step: 651 Loss: 1.3279463121309\n",
      "Epoch: 15 Step: 661 Loss: 1.1878417008010338\n",
      "Epoch: 15 Step: 671 Loss: 1.246322879075731\n",
      "Epoch: 15 Step: 681 Loss: 1.4480094124439145\n",
      "Epoch: 15 Step: 691 Loss: 1.3592139159031011\n",
      "Epoch: 15 Step: 701 Loss: 1.342288015649885\n",
      "Epoch: 15 Step: 711 Loss: 1.1939083110183368\n",
      "Epoch: 15 Step: 721 Loss: 1.095059013099307\n",
      "Epoch: 15 Step: 731 Loss: 1.1612787888284246\n",
      "Epoch: 15 Step: 741 Loss: 1.3278084979891664\n",
      "Epoch: 15 Step: 751 Loss: 1.6370196611816976\n",
      "Epoch: 15 Step: 761 Loss: 1.2168757615414976\n",
      "Epoch: 15 Step: 771 Loss: 1.495658880063763\n",
      "Epoch: 15 Step: 781 Loss: 1.1910586699365782\n",
      "Epoch: 16 Step: 1 Loss: 1.371324856246499\n",
      "Epoch: 16 Step: 11 Loss: 1.359583411626242\n",
      "Epoch: 16 Step: 21 Loss: 1.1808198681306017\n",
      "Epoch: 16 Step: 31 Loss: 1.4998474589023936\n",
      "Epoch: 16 Step: 41 Loss: 1.237722180624711\n",
      "Epoch: 16 Step: 51 Loss: 1.287579143475181\n",
      "Epoch: 16 Step: 61 Loss: 1.2102464969624782\n",
      "Epoch: 16 Step: 71 Loss: 1.293157104321602\n",
      "Epoch: 16 Step: 81 Loss: 1.3666896302998055\n",
      "Epoch: 16 Step: 91 Loss: 1.270374060913896\n",
      "Epoch: 16 Step: 101 Loss: 1.3141422382110433\n",
      "Epoch: 16 Step: 111 Loss: 1.313068273910058\n",
      "Epoch: 16 Step: 121 Loss: 1.3883354337575948\n",
      "Epoch: 16 Step: 131 Loss: 1.318375976621371\n",
      "Epoch: 16 Step: 141 Loss: 1.5980351080703552\n",
      "Epoch: 16 Step: 151 Loss: 0.9848261976989041\n",
      "Epoch: 16 Step: 161 Loss: 1.1678411557376682\n",
      "Epoch: 16 Step: 171 Loss: 1.1847119265759096\n",
      "Epoch: 16 Step: 181 Loss: 1.1956184622960842\n",
      "Epoch: 16 Step: 191 Loss: 1.1035668729854324\n",
      "Epoch: 16 Step: 201 Loss: 0.8845512688401473\n",
      "Epoch: 16 Step: 211 Loss: 1.0184553144054833\n",
      "Epoch: 16 Step: 221 Loss: 1.1693727975730985\n",
      "Epoch: 16 Step: 231 Loss: 1.024835440185016\n",
      "Epoch: 16 Step: 241 Loss: 1.1634781150048126\n",
      "Epoch: 16 Step: 251 Loss: 1.1025864788632784\n",
      "Epoch: 16 Step: 261 Loss: 1.1994227301496219\n",
      "Epoch: 16 Step: 271 Loss: 1.4245080127163305\n",
      "Epoch: 16 Step: 281 Loss: 1.348909977238395\n",
      "Epoch: 16 Step: 291 Loss: 1.2094866400629907\n",
      "Epoch: 16 Step: 301 Loss: 1.4152409071360332\n",
      "Epoch: 16 Step: 311 Loss: 1.2754333579188595\n",
      "Epoch: 16 Step: 321 Loss: 1.2319743008663804\n",
      "Epoch: 16 Step: 331 Loss: 1.2778235424833646\n",
      "Epoch: 16 Step: 341 Loss: 1.4322528861182668\n",
      "Epoch: 16 Step: 351 Loss: 1.1975510237286877\n",
      "Epoch: 16 Step: 361 Loss: 1.2302768324092679\n",
      "Epoch: 16 Step: 371 Loss: 0.9502724691197534\n",
      "Epoch: 16 Step: 381 Loss: 1.4224183005217417\n",
      "Epoch: 16 Step: 391 Loss: 1.0054476377026886\n",
      "Epoch: 16 Step: 401 Loss: 1.1529493924593566\n",
      "Epoch: 16 Step: 411 Loss: 1.386647426408828\n",
      "Epoch: 16 Step: 421 Loss: 1.3224963665659042\n",
      "Epoch: 16 Step: 431 Loss: 1.252164221067268\n",
      "Epoch: 16 Step: 441 Loss: 1.3838969797432965\n",
      "Epoch: 16 Step: 451 Loss: 1.2382683571520974\n",
      "Epoch: 16 Step: 461 Loss: 1.3393855640629273\n",
      "Epoch: 16 Step: 471 Loss: 1.2907617758619085\n",
      "Epoch: 16 Step: 481 Loss: 1.4135264123814824\n",
      "Epoch: 16 Step: 491 Loss: 1.584290829725598\n",
      "Epoch: 16 Step: 501 Loss: 1.377035238914841\n",
      "Epoch: 16 Step: 511 Loss: 1.2050035880917536\n",
      "Epoch: 16 Step: 521 Loss: 1.3484417201423593\n",
      "Epoch: 16 Step: 531 Loss: 1.234551000606628\n",
      "Epoch: 16 Step: 541 Loss: 1.2379424930329184\n",
      "Epoch: 16 Step: 551 Loss: 1.264762015984844\n",
      "Epoch: 16 Step: 561 Loss: 1.1341436834740524\n",
      "Epoch: 16 Step: 571 Loss: 1.1375106058132505\n",
      "Epoch: 16 Step: 581 Loss: 1.283073728450893\n",
      "Epoch: 16 Step: 591 Loss: 1.1735084482878357\n",
      "Epoch: 16 Step: 601 Loss: 1.2212170285696429\n",
      "Epoch: 16 Step: 611 Loss: 1.1174626271866237\n",
      "Epoch: 16 Step: 621 Loss: 1.0342100948460438\n",
      "Epoch: 16 Step: 631 Loss: 1.142005843249053\n",
      "Epoch: 16 Step: 641 Loss: 1.2419847866492173\n",
      "Epoch: 16 Step: 651 Loss: 1.1454777890565775\n",
      "Epoch: 16 Step: 661 Loss: 1.1295849738524328\n",
      "Epoch: 16 Step: 671 Loss: 1.2341773689794113\n",
      "Epoch: 16 Step: 681 Loss: 1.368212710773242\n",
      "Epoch: 16 Step: 691 Loss: 1.192606823964037\n",
      "Epoch: 16 Step: 701 Loss: 1.0957259761611946\n",
      "Epoch: 16 Step: 711 Loss: 1.0870119353112089\n",
      "Epoch: 16 Step: 721 Loss: 1.0799897077019334\n",
      "Epoch: 16 Step: 731 Loss: 0.9123774656075815\n",
      "Epoch: 16 Step: 741 Loss: 1.385715883344402\n",
      "Epoch: 16 Step: 751 Loss: 1.5303164836691365\n",
      "Epoch: 16 Step: 761 Loss: 1.1093127142024752\n",
      "Epoch: 16 Step: 771 Loss: 1.3579404105319899\n",
      "Epoch: 16 Step: 781 Loss: 1.2993966847442102\n",
      "Epoch: 17 Step: 1 Loss: 1.3166833537359337\n",
      "Epoch: 17 Step: 11 Loss: 1.4913142423033459\n",
      "Epoch: 17 Step: 21 Loss: 1.3531601358614256\n",
      "Epoch: 17 Step: 31 Loss: 1.5807587870581163\n",
      "Epoch: 17 Step: 41 Loss: 1.2679628962570404\n",
      "Epoch: 17 Step: 51 Loss: 1.1394934982960874\n",
      "Epoch: 17 Step: 61 Loss: 1.1593447976813003\n",
      "Epoch: 17 Step: 71 Loss: 1.369061866779288\n",
      "Epoch: 17 Step: 81 Loss: 1.4931960393790829\n",
      "Epoch: 17 Step: 91 Loss: 1.2460141449230702\n",
      "Epoch: 17 Step: 101 Loss: 1.163031647013984\n",
      "Epoch: 17 Step: 111 Loss: 1.3291017365395927\n",
      "Epoch: 17 Step: 121 Loss: 1.6465558089148575\n",
      "Epoch: 17 Step: 131 Loss: 1.328335616122883\n",
      "Epoch: 17 Step: 141 Loss: 1.6853272435661855\n",
      "Epoch: 17 Step: 151 Loss: 1.0475117386865467\n",
      "Epoch: 17 Step: 161 Loss: 1.1637510364388262\n",
      "Epoch: 17 Step: 171 Loss: 1.3092102893571675\n",
      "Epoch: 17 Step: 181 Loss: 1.1976346534574838\n",
      "Epoch: 17 Step: 191 Loss: 1.2590136331665147\n",
      "Epoch: 17 Step: 201 Loss: 0.9244777150694345\n",
      "Epoch: 17 Step: 211 Loss: 1.0417311605492379\n",
      "Epoch: 17 Step: 221 Loss: 1.1939789199603572\n",
      "Epoch: 17 Step: 231 Loss: 1.1334335439708316\n",
      "Epoch: 17 Step: 241 Loss: 1.2937166591613012\n",
      "Epoch: 17 Step: 251 Loss: 1.2802880986163307\n",
      "Epoch: 17 Step: 261 Loss: 1.261960701146804\n",
      "Epoch: 17 Step: 271 Loss: 1.2429215311042414\n",
      "Epoch: 17 Step: 281 Loss: 1.2497370570948392\n",
      "Epoch: 17 Step: 291 Loss: 1.2322536481805049\n",
      "Epoch: 17 Step: 301 Loss: 1.426763143949535\n",
      "Epoch: 17 Step: 311 Loss: 1.2420377001898961\n",
      "Epoch: 17 Step: 321 Loss: 1.1722035503168595\n",
      "Epoch: 17 Step: 331 Loss: 1.1422990205190646\n",
      "Epoch: 17 Step: 341 Loss: 1.2956415653144948\n",
      "Epoch: 17 Step: 351 Loss: 1.2513520470995707\n",
      "Epoch: 17 Step: 361 Loss: 1.2076811197980404\n",
      "Epoch: 17 Step: 371 Loss: 0.9636157801634223\n",
      "Epoch: 17 Step: 381 Loss: 1.4195348215764154\n",
      "Epoch: 17 Step: 391 Loss: 0.9662715049742788\n",
      "Epoch: 17 Step: 401 Loss: 1.2199562255094594\n",
      "Epoch: 17 Step: 411 Loss: 1.3267907266269006\n",
      "Epoch: 17 Step: 421 Loss: 1.4577717755117336\n",
      "Epoch: 17 Step: 431 Loss: 1.3140473274129103\n",
      "Epoch: 17 Step: 441 Loss: 1.1331428152283887\n",
      "Epoch: 17 Step: 451 Loss: 1.1306193988955426\n",
      "Epoch: 17 Step: 461 Loss: 1.270435904117239\n",
      "Epoch: 17 Step: 471 Loss: 1.2531495524106326\n",
      "Epoch: 17 Step: 481 Loss: 1.2375950941974572\n",
      "Epoch: 17 Step: 491 Loss: 1.5543226548113473\n",
      "Epoch: 17 Step: 501 Loss: 1.3675788499415753\n",
      "Epoch: 17 Step: 511 Loss: 1.1692949820325222\n",
      "Epoch: 17 Step: 521 Loss: 1.21920570449053\n",
      "Epoch: 17 Step: 531 Loss: 1.214822207861037\n",
      "Epoch: 17 Step: 541 Loss: 1.2178578000551963\n",
      "Epoch: 17 Step: 551 Loss: 1.3649329324245785\n",
      "Epoch: 17 Step: 561 Loss: 1.057235502052551\n",
      "Epoch: 17 Step: 571 Loss: 1.2040658580099224\n",
      "Epoch: 17 Step: 581 Loss: 1.2230162686732435\n",
      "Epoch: 17 Step: 591 Loss: 1.2888123049359321\n",
      "Epoch: 17 Step: 601 Loss: 1.3147773123048636\n",
      "Epoch: 17 Step: 611 Loss: 1.1605071442437995\n",
      "Epoch: 17 Step: 621 Loss: 1.1794017496297582\n",
      "Epoch: 17 Step: 631 Loss: 1.1882700488605829\n",
      "Epoch: 17 Step: 641 Loss: 1.422500838890028\n",
      "Epoch: 17 Step: 651 Loss: 1.200610889641384\n",
      "Epoch: 17 Step: 661 Loss: 1.1728949153777624\n",
      "Epoch: 17 Step: 671 Loss: 1.2832582563352846\n",
      "Epoch: 17 Step: 681 Loss: 1.44473693247993\n",
      "Epoch: 17 Step: 691 Loss: 1.2914583179889823\n",
      "Epoch: 17 Step: 701 Loss: 1.0978106395729617\n",
      "Epoch: 17 Step: 711 Loss: 1.2579654637489563\n",
      "Epoch: 17 Step: 721 Loss: 0.9613293790099586\n",
      "Epoch: 17 Step: 731 Loss: 0.8815736875546994\n",
      "Epoch: 17 Step: 741 Loss: 1.3958627368936143\n",
      "Epoch: 17 Step: 751 Loss: 1.3383433421175792\n",
      "Epoch: 17 Step: 761 Loss: 1.0094245194720286\n",
      "Epoch: 17 Step: 771 Loss: 1.3693499659849881\n",
      "Epoch: 17 Step: 781 Loss: 1.197676876187652\n",
      "Epoch: 18 Step: 1 Loss: 1.2510302078860733\n",
      "Epoch: 18 Step: 11 Loss: 1.2308020601219631\n",
      "Epoch: 18 Step: 21 Loss: 1.1860519977675354\n",
      "Epoch: 18 Step: 31 Loss: 1.3679726803038235\n",
      "Epoch: 18 Step: 41 Loss: 1.0058374984824106\n",
      "Epoch: 18 Step: 51 Loss: 1.0581475527171826\n",
      "Epoch: 18 Step: 61 Loss: 1.1239123488678382\n",
      "Epoch: 18 Step: 71 Loss: 1.227424052746172\n",
      "Epoch: 18 Step: 81 Loss: 1.4617876207101967\n",
      "Epoch: 18 Step: 91 Loss: 1.30864320760039\n",
      "Epoch: 18 Step: 101 Loss: 1.3142462194436684\n",
      "Epoch: 18 Step: 111 Loss: 1.4859027718674818\n",
      "Epoch: 18 Step: 121 Loss: 1.4156914276609038\n",
      "Epoch: 18 Step: 131 Loss: 1.191180413291852\n",
      "Epoch: 18 Step: 141 Loss: 1.4894490282154722\n",
      "Epoch: 18 Step: 151 Loss: 1.0805146443801263\n",
      "Epoch: 18 Step: 161 Loss: 1.1271237539744545\n",
      "Epoch: 18 Step: 171 Loss: 1.239394540238675\n",
      "Epoch: 18 Step: 181 Loss: 1.3995949037248465\n",
      "Epoch: 18 Step: 191 Loss: 1.1691566898425543\n",
      "Epoch: 18 Step: 201 Loss: 0.918297761843015\n",
      "Epoch: 18 Step: 211 Loss: 1.102224076028588\n",
      "Epoch: 18 Step: 221 Loss: 1.161110852637258\n",
      "Epoch: 18 Step: 231 Loss: 1.2422775800483508\n",
      "Epoch: 18 Step: 241 Loss: 1.0427436516285278\n",
      "Epoch: 18 Step: 251 Loss: 1.130612849028018\n",
      "Epoch: 18 Step: 261 Loss: 1.2955401896289662\n",
      "Epoch: 18 Step: 271 Loss: 1.2745671734098043\n",
      "Epoch: 18 Step: 281 Loss: 1.278036578208381\n",
      "Epoch: 18 Step: 291 Loss: 1.151241333468552\n",
      "Epoch: 18 Step: 301 Loss: 1.290701946753654\n",
      "Epoch: 18 Step: 311 Loss: 1.245996940818337\n",
      "Epoch: 18 Step: 321 Loss: 1.1377259047076123\n",
      "Epoch: 18 Step: 331 Loss: 1.1712163278995713\n",
      "Epoch: 18 Step: 341 Loss: 1.2899761651464596\n",
      "Epoch: 18 Step: 351 Loss: 1.2454771652336512\n",
      "Epoch: 18 Step: 361 Loss: 1.2802934509824513\n",
      "Epoch: 18 Step: 371 Loss: 0.9357580627114157\n",
      "Epoch: 18 Step: 381 Loss: 1.332769720508363\n",
      "Epoch: 18 Step: 391 Loss: 0.9417146178968112\n",
      "Epoch: 18 Step: 401 Loss: 1.143826626616769\n",
      "Epoch: 18 Step: 411 Loss: 1.1506422256253759\n",
      "Epoch: 18 Step: 421 Loss: 1.3180631407912435\n",
      "Epoch: 18 Step: 431 Loss: 1.097215725369432\n",
      "Epoch: 18 Step: 441 Loss: 1.129911867253149\n",
      "Epoch: 18 Step: 451 Loss: 1.202174777716779\n",
      "Epoch: 18 Step: 461 Loss: 1.2315743319845414\n",
      "Epoch: 18 Step: 471 Loss: 1.2291610073098285\n",
      "Epoch: 18 Step: 481 Loss: 1.3300742805017456\n",
      "Epoch: 18 Step: 491 Loss: 1.4629255283626765\n",
      "Epoch: 18 Step: 501 Loss: 1.3535334922841402\n",
      "Epoch: 18 Step: 511 Loss: 1.1308197828649942\n",
      "Epoch: 18 Step: 521 Loss: 1.1722140068772766\n",
      "Epoch: 18 Step: 531 Loss: 1.3750161457445764\n",
      "Epoch: 18 Step: 541 Loss: 1.1966958223305966\n",
      "Epoch: 18 Step: 551 Loss: 1.2855850907353141\n",
      "Epoch: 18 Step: 561 Loss: 1.0754900642047063\n",
      "Epoch: 18 Step: 571 Loss: 1.087734488608385\n",
      "Epoch: 18 Step: 581 Loss: 1.4655363513203254\n",
      "Epoch: 18 Step: 591 Loss: 1.1906366772371861\n",
      "Epoch: 18 Step: 601 Loss: 1.3493599712989908\n",
      "Epoch: 18 Step: 611 Loss: 1.0461916381046712\n",
      "Epoch: 18 Step: 621 Loss: 1.0751417268032786\n",
      "Epoch: 18 Step: 631 Loss: 1.3255335918998121\n",
      "Epoch: 18 Step: 641 Loss: 1.3280790832269729\n",
      "Epoch: 18 Step: 651 Loss: 1.1712493352093558\n",
      "Epoch: 18 Step: 661 Loss: 1.196242290826795\n",
      "Epoch: 18 Step: 671 Loss: 1.2039058031107404\n",
      "Epoch: 18 Step: 681 Loss: 1.3142440579869201\n",
      "Epoch: 18 Step: 691 Loss: 1.3779428323603145\n",
      "Epoch: 18 Step: 701 Loss: 1.232470513045639\n",
      "Epoch: 18 Step: 711 Loss: 1.1118774121734625\n",
      "Epoch: 18 Step: 721 Loss: 1.109078480375469\n",
      "Epoch: 18 Step: 731 Loss: 0.9281674554462893\n",
      "Epoch: 18 Step: 741 Loss: 1.2818638946646888\n",
      "Epoch: 18 Step: 751 Loss: 1.4253848594128478\n",
      "Epoch: 18 Step: 761 Loss: 1.1238537359144252\n",
      "Epoch: 18 Step: 771 Loss: 1.297645062375555\n",
      "Epoch: 18 Step: 781 Loss: 1.125360670388941\n",
      "Epoch: 19 Step: 1 Loss: 1.3167409473905125\n",
      "Epoch: 19 Step: 11 Loss: 1.3656164004760947\n",
      "Epoch: 19 Step: 21 Loss: 1.228377019760524\n",
      "Epoch: 19 Step: 31 Loss: 1.5415392105037373\n",
      "Epoch: 19 Step: 41 Loss: 1.2261426102973156\n",
      "Epoch: 19 Step: 51 Loss: 1.1238293382903874\n",
      "Epoch: 19 Step: 61 Loss: 1.2495676498828998\n",
      "Epoch: 19 Step: 71 Loss: 1.2426552222393585\n",
      "Epoch: 19 Step: 81 Loss: 1.420335898589519\n",
      "Epoch: 19 Step: 91 Loss: 1.2575108690210213\n",
      "Epoch: 19 Step: 101 Loss: 1.147159807642125\n",
      "Epoch: 19 Step: 111 Loss: 1.0957152407743098\n",
      "Epoch: 19 Step: 121 Loss: 1.3289538047789087\n",
      "Epoch: 19 Step: 131 Loss: 1.3796953091857782\n",
      "Epoch: 19 Step: 141 Loss: 1.5844000072948448\n",
      "Epoch: 19 Step: 151 Loss: 0.870370477975579\n",
      "Epoch: 19 Step: 161 Loss: 1.0822181652233946\n",
      "Epoch: 19 Step: 171 Loss: 1.456855150052426\n",
      "Epoch: 19 Step: 181 Loss: 1.2685459324571466\n",
      "Epoch: 19 Step: 191 Loss: 1.24978541109911\n",
      "Epoch: 19 Step: 201 Loss: 0.9467861577884014\n",
      "Epoch: 19 Step: 211 Loss: 0.9964500000623787\n",
      "Epoch: 19 Step: 221 Loss: 1.1503689499356171\n",
      "Epoch: 19 Step: 231 Loss: 1.1237762561317581\n",
      "Epoch: 19 Step: 241 Loss: 1.1302644211303754\n",
      "Epoch: 19 Step: 251 Loss: 1.1021626854741444\n",
      "Epoch: 19 Step: 261 Loss: 1.2493028596250912\n",
      "Epoch: 19 Step: 271 Loss: 1.3783441791101185\n",
      "Epoch: 19 Step: 281 Loss: 1.2677348180339019\n",
      "Epoch: 19 Step: 291 Loss: 1.2119698450916914\n",
      "Epoch: 19 Step: 301 Loss: 1.3888143970026265\n",
      "Epoch: 19 Step: 311 Loss: 1.069610994868572\n",
      "Epoch: 19 Step: 321 Loss: 1.3717040051503138\n",
      "Epoch: 19 Step: 331 Loss: 1.3002168698900474\n",
      "Epoch: 19 Step: 341 Loss: 1.3606876884332946\n",
      "Epoch: 19 Step: 351 Loss: 1.351228228877967\n",
      "Epoch: 19 Step: 361 Loss: 1.1529234922923766\n",
      "Epoch: 19 Step: 371 Loss: 0.913869290666228\n",
      "Epoch: 19 Step: 381 Loss: 1.6780782992660401\n",
      "Epoch: 19 Step: 391 Loss: 1.0904795146378832\n",
      "Epoch: 19 Step: 401 Loss: 1.13179503908362\n",
      "Epoch: 19 Step: 411 Loss: 1.1992170681317482\n",
      "Epoch: 19 Step: 421 Loss: 1.3829489013713538\n",
      "Epoch: 19 Step: 431 Loss: 1.2544286728525134\n",
      "Epoch: 19 Step: 441 Loss: 1.168706706996216\n",
      "Epoch: 19 Step: 451 Loss: 0.9690411200901179\n",
      "Epoch: 19 Step: 461 Loss: 1.2108907935657753\n",
      "Epoch: 19 Step: 471 Loss: 1.2250375773072988\n",
      "Epoch: 19 Step: 481 Loss: 1.3503913220958765\n",
      "Epoch: 19 Step: 491 Loss: 1.4436203446928073\n",
      "Epoch: 19 Step: 501 Loss: 1.4319599354908736\n",
      "Epoch: 19 Step: 511 Loss: 1.187343167067574\n",
      "Epoch: 19 Step: 521 Loss: 1.3088549762407902\n",
      "Epoch: 19 Step: 531 Loss: 1.1692605844096828\n",
      "Epoch: 19 Step: 541 Loss: 1.2984711111878364\n",
      "Epoch: 19 Step: 551 Loss: 1.0809652124730806\n",
      "Epoch: 19 Step: 561 Loss: 1.019169511493097\n",
      "Epoch: 19 Step: 571 Loss: 1.1108291814509297\n",
      "Epoch: 19 Step: 581 Loss: 1.2675640085418398\n",
      "Epoch: 19 Step: 591 Loss: 1.1432791729968295\n",
      "Epoch: 19 Step: 601 Loss: 1.2150414644736682\n",
      "Epoch: 19 Step: 611 Loss: 1.0578959154526797\n",
      "Epoch: 19 Step: 621 Loss: 1.1088614856412218\n",
      "Epoch: 19 Step: 631 Loss: 1.154726289936606\n",
      "Epoch: 19 Step: 641 Loss: 1.1447963752076835\n",
      "Epoch: 19 Step: 651 Loss: 1.1971761520686983\n",
      "Epoch: 19 Step: 661 Loss: 1.0686386501576244\n",
      "Epoch: 19 Step: 671 Loss: 1.132933283884852\n",
      "Epoch: 19 Step: 681 Loss: 1.3269074754015908\n",
      "Epoch: 19 Step: 691 Loss: 1.311756771247389\n",
      "Epoch: 19 Step: 701 Loss: 1.2007117886937695\n",
      "Epoch: 19 Step: 711 Loss: 1.2924972874522318\n",
      "Epoch: 19 Step: 721 Loss: 1.14005453849239\n",
      "Epoch: 19 Step: 731 Loss: 0.9496547182484044\n",
      "Epoch: 19 Step: 741 Loss: 1.4372417437100125\n",
      "Epoch: 19 Step: 751 Loss: 1.4443161328414762\n",
      "Epoch: 19 Step: 761 Loss: 1.1573276289911854\n",
      "Epoch: 19 Step: 771 Loss: 1.4031341431317075\n",
      "Epoch: 19 Step: 781 Loss: 1.155236923233241\n",
      "Epoch: 20 Step: 1 Loss: 1.2510233046614943\n",
      "Epoch: 20 Step: 11 Loss: 1.3043580413369904\n",
      "Epoch: 20 Step: 21 Loss: 1.1734173413969065\n",
      "Epoch: 20 Step: 31 Loss: 1.5164513355757074\n",
      "Epoch: 20 Step: 41 Loss: 1.0947812552579586\n",
      "Epoch: 20 Step: 51 Loss: 1.2005396204815266\n",
      "Epoch: 20 Step: 61 Loss: 1.3784718244654623\n",
      "Epoch: 20 Step: 71 Loss: 1.3436046370134385\n",
      "Epoch: 20 Step: 81 Loss: 1.3748024290002834\n",
      "Epoch: 20 Step: 91 Loss: 1.3086692065067744\n",
      "Epoch: 20 Step: 101 Loss: 1.1944132094076796\n",
      "Epoch: 20 Step: 111 Loss: 1.2504375953948235\n",
      "Epoch: 20 Step: 121 Loss: 1.267299238893309\n",
      "Epoch: 20 Step: 131 Loss: 1.4372450058236188\n",
      "Epoch: 20 Step: 141 Loss: 1.572958811239555\n",
      "Epoch: 20 Step: 151 Loss: 0.9466202199519629\n",
      "Epoch: 20 Step: 161 Loss: 1.1551941122585314\n",
      "Epoch: 20 Step: 171 Loss: 1.1420393986376114\n",
      "Epoch: 20 Step: 181 Loss: 1.1075745038775309\n",
      "Epoch: 20 Step: 191 Loss: 1.2379034883957256\n",
      "Epoch: 20 Step: 201 Loss: 0.8965604822464092\n",
      "Epoch: 20 Step: 211 Loss: 1.0073249222480372\n",
      "Epoch: 20 Step: 221 Loss: 1.249936503360575\n",
      "Epoch: 20 Step: 231 Loss: 1.1972604666626079\n",
      "Epoch: 20 Step: 241 Loss: 1.129305986148462\n",
      "Epoch: 20 Step: 251 Loss: 1.014864512151457\n",
      "Epoch: 20 Step: 261 Loss: 1.1695731518058663\n",
      "Epoch: 20 Step: 271 Loss: 1.2283272718569456\n",
      "Epoch: 20 Step: 281 Loss: 1.2231948955687237\n",
      "Epoch: 20 Step: 291 Loss: 1.1336723995823594\n",
      "Epoch: 20 Step: 301 Loss: 1.3567913391917714\n",
      "Epoch: 20 Step: 311 Loss: 1.2371996674144143\n",
      "Epoch: 20 Step: 321 Loss: 1.2692115578392362\n",
      "Epoch: 20 Step: 331 Loss: 1.2926299439524502\n",
      "Epoch: 20 Step: 341 Loss: 1.2580264372938323\n",
      "Epoch: 20 Step: 351 Loss: 1.2251653878400024\n",
      "Epoch: 20 Step: 361 Loss: 1.1392482513002404\n",
      "Epoch: 20 Step: 371 Loss: 0.9229850955794492\n",
      "Epoch: 20 Step: 381 Loss: 1.2227925919790976\n",
      "Epoch: 20 Step: 391 Loss: 1.1192800077716178\n",
      "Epoch: 20 Step: 401 Loss: 1.254719138170442\n",
      "Epoch: 20 Step: 411 Loss: 1.2586586728749798\n",
      "Epoch: 20 Step: 421 Loss: 1.315564613044589\n",
      "Epoch: 20 Step: 431 Loss: 1.2101956017681934\n",
      "Epoch: 20 Step: 441 Loss: 1.3401431078341428\n",
      "Epoch: 20 Step: 451 Loss: 1.1832299748558768\n",
      "Epoch: 20 Step: 461 Loss: 1.3554993629168217\n",
      "Epoch: 20 Step: 471 Loss: 1.1886427087656504\n",
      "Epoch: 20 Step: 481 Loss: 1.215668581285735\n",
      "Epoch: 20 Step: 491 Loss: 1.5635892692503004\n",
      "Epoch: 20 Step: 501 Loss: 1.273180421778719\n",
      "Epoch: 20 Step: 511 Loss: 1.1378998638454942\n",
      "Epoch: 20 Step: 521 Loss: 1.2482712712086008\n",
      "Epoch: 20 Step: 531 Loss: 1.2087127198549252\n",
      "Epoch: 20 Step: 541 Loss: 1.166907855445006\n",
      "Epoch: 20 Step: 551 Loss: 1.0445476605700603\n",
      "Epoch: 20 Step: 561 Loss: 1.0850473944586598\n",
      "Epoch: 20 Step: 571 Loss: 1.0144073831678089\n",
      "Epoch: 20 Step: 581 Loss: 1.1966943561375984\n",
      "Epoch: 20 Step: 591 Loss: 1.2793758665760813\n",
      "Epoch: 20 Step: 601 Loss: 1.2434932355990433\n",
      "Epoch: 20 Step: 611 Loss: 1.1934446112805737\n",
      "Epoch: 20 Step: 621 Loss: 1.0773494435675692\n",
      "Epoch: 20 Step: 631 Loss: 1.1422686860090407\n",
      "Epoch: 20 Step: 641 Loss: 1.2219147858959367\n",
      "Epoch: 20 Step: 651 Loss: 1.161460228667828\n",
      "Epoch: 20 Step: 661 Loss: 1.2023944947680336\n",
      "Epoch: 20 Step: 671 Loss: 1.2510492270341378\n",
      "Epoch: 20 Step: 681 Loss: 1.2812964601527481\n",
      "Epoch: 20 Step: 691 Loss: 1.1634113674383078\n",
      "Epoch: 20 Step: 701 Loss: 1.0299668417399606\n",
      "Epoch: 20 Step: 711 Loss: 1.1596471521387053\n",
      "Epoch: 20 Step: 721 Loss: 0.952309362920517\n",
      "Epoch: 20 Step: 731 Loss: 0.8691096866442716\n",
      "Epoch: 20 Step: 741 Loss: 1.188603262441089\n",
      "Epoch: 20 Step: 751 Loss: 1.352322723922672\n",
      "Epoch: 20 Step: 761 Loss: 1.0328877571934463\n",
      "Epoch: 20 Step: 771 Loss: 1.1620792287864676\n",
      "Epoch: 20 Step: 781 Loss: 1.1547574840972752\n",
      "Epoch: 21 Step: 1 Loss: 1.2065892196758239\n",
      "Epoch: 21 Step: 11 Loss: 1.181118235703227\n",
      "Epoch: 21 Step: 21 Loss: 1.2544390768503897\n",
      "Epoch: 21 Step: 31 Loss: 1.3942588659205684\n",
      "Epoch: 21 Step: 41 Loss: 1.2019952355560477\n",
      "Epoch: 21 Step: 51 Loss: 1.1177139740712676\n",
      "Epoch: 21 Step: 61 Loss: 1.215795423911732\n",
      "Epoch: 21 Step: 71 Loss: 1.3331447296215895\n",
      "Epoch: 21 Step: 81 Loss: 1.5189501900728568\n",
      "Epoch: 21 Step: 91 Loss: 1.2312649738397925\n",
      "Epoch: 21 Step: 101 Loss: 1.3029090951481712\n",
      "Epoch: 21 Step: 111 Loss: 1.376897787003205\n",
      "Epoch: 21 Step: 121 Loss: 1.3410107470805497\n",
      "Epoch: 21 Step: 131 Loss: 1.1886314254980417\n",
      "Epoch: 21 Step: 141 Loss: 1.5481555657053114\n",
      "Epoch: 21 Step: 151 Loss: 0.9631059849629446\n",
      "Epoch: 21 Step: 161 Loss: 1.164247468610015\n",
      "Epoch: 21 Step: 171 Loss: 1.3107119169937338\n",
      "Epoch: 21 Step: 181 Loss: 1.0853518370842454\n",
      "Epoch: 21 Step: 191 Loss: 1.2737545434712372\n",
      "Epoch: 21 Step: 201 Loss: 0.844681854058884\n",
      "Epoch: 21 Step: 211 Loss: 0.9945379764945023\n",
      "Epoch: 21 Step: 221 Loss: 1.1020244575541867\n",
      "Epoch: 21 Step: 231 Loss: 1.1928724752900097\n",
      "Epoch: 21 Step: 241 Loss: 1.2966725950223497\n",
      "Epoch: 21 Step: 251 Loss: 1.0732940017003538\n",
      "Epoch: 21 Step: 261 Loss: 1.1352073210006846\n",
      "Epoch: 21 Step: 271 Loss: 1.3457540798429717\n",
      "Epoch: 21 Step: 281 Loss: 1.2544498110734421\n",
      "Epoch: 21 Step: 291 Loss: 1.1929505374307512\n",
      "Epoch: 21 Step: 301 Loss: 1.5081703535714874\n",
      "Epoch: 21 Step: 311 Loss: 1.2527228607793086\n",
      "Epoch: 21 Step: 321 Loss: 1.2016822815595884\n",
      "Epoch: 21 Step: 331 Loss: 1.1693619541744282\n",
      "Epoch: 21 Step: 341 Loss: 1.2734606375820632\n",
      "Epoch: 21 Step: 351 Loss: 1.1398687059391377\n",
      "Epoch: 21 Step: 361 Loss: 1.208732289958645\n",
      "Epoch: 21 Step: 371 Loss: 0.8715894711631436\n",
      "Epoch: 21 Step: 381 Loss: 1.4108363837787055\n",
      "Epoch: 21 Step: 391 Loss: 0.9549230963558231\n",
      "Epoch: 21 Step: 401 Loss: 0.9658413246777882\n",
      "Epoch: 21 Step: 411 Loss: 1.162568958157347\n",
      "Epoch: 21 Step: 421 Loss: 1.221478745965026\n",
      "Epoch: 21 Step: 431 Loss: 1.148705975459193\n",
      "Epoch: 21 Step: 441 Loss: 1.0206281442347678\n",
      "Epoch: 21 Step: 451 Loss: 0.90832202476382\n",
      "Epoch: 21 Step: 461 Loss: 1.3406792620822734\n",
      "Epoch: 21 Step: 471 Loss: 1.2522874240651247\n",
      "Epoch: 21 Step: 481 Loss: 1.2388667510761389\n",
      "Epoch: 21 Step: 491 Loss: 1.3814493477045038\n",
      "Epoch: 21 Step: 501 Loss: 1.2463439370625828\n",
      "Epoch: 21 Step: 511 Loss: 1.0974811930349297\n",
      "Epoch: 21 Step: 521 Loss: 1.2335046526788966\n",
      "Epoch: 21 Step: 531 Loss: 1.0661996024211091\n",
      "Epoch: 21 Step: 541 Loss: 1.0749791094253318\n",
      "Epoch: 21 Step: 551 Loss: 1.1787579951458076\n",
      "Epoch: 21 Step: 561 Loss: 1.0820416728825846\n",
      "Epoch: 21 Step: 571 Loss: 1.0384310339013054\n",
      "Epoch: 21 Step: 581 Loss: 1.4449373580351514\n",
      "Epoch: 21 Step: 591 Loss: 1.171294394814581\n",
      "Epoch: 21 Step: 601 Loss: 1.2822068321845568\n",
      "Epoch: 21 Step: 611 Loss: 1.0163523106363916\n",
      "Epoch: 21 Step: 621 Loss: 1.217136725504639\n",
      "Epoch: 21 Step: 631 Loss: 1.3979138320758342\n",
      "Epoch: 21 Step: 641 Loss: 1.380189535414357\n",
      "Epoch: 21 Step: 651 Loss: 1.3084276859350294\n",
      "Epoch: 21 Step: 661 Loss: 1.196867003109786\n",
      "Epoch: 21 Step: 671 Loss: 1.2948317346237896\n",
      "Epoch: 21 Step: 681 Loss: 1.288575928399143\n",
      "Epoch: 21 Step: 691 Loss: 1.3406901436681091\n",
      "Epoch: 21 Step: 701 Loss: 1.1469252810569368\n",
      "Epoch: 21 Step: 711 Loss: 1.1766909393887568\n",
      "Epoch: 21 Step: 721 Loss: 1.1869517970764702\n",
      "Epoch: 21 Step: 731 Loss: 1.015622072792486\n",
      "Epoch: 21 Step: 741 Loss: 1.2872701872326435\n",
      "Epoch: 21 Step: 751 Loss: 1.301605753811296\n",
      "Epoch: 21 Step: 761 Loss: 1.0472882952479887\n",
      "Epoch: 21 Step: 771 Loss: 1.4275436726420199\n",
      "Epoch: 21 Step: 781 Loss: 1.019484079562619\n",
      "Epoch: 22 Step: 1 Loss: 1.2253129970092647\n",
      "Epoch: 22 Step: 11 Loss: 1.160594679701123\n",
      "Epoch: 22 Step: 21 Loss: 1.2288202555632282\n",
      "Epoch: 22 Step: 31 Loss: 1.403288100351249\n",
      "Epoch: 22 Step: 41 Loss: 0.992458342945624\n",
      "Epoch: 22 Step: 51 Loss: 1.127883520368938\n",
      "Epoch: 22 Step: 61 Loss: 1.058050372605703\n",
      "Epoch: 22 Step: 71 Loss: 1.2283073712701988\n",
      "Epoch: 22 Step: 81 Loss: 1.2013571881365126\n",
      "Epoch: 22 Step: 91 Loss: 1.128534991602824\n",
      "Epoch: 22 Step: 101 Loss: 1.200017584253093\n",
      "Epoch: 22 Step: 111 Loss: 1.266648490670216\n",
      "Epoch: 22 Step: 121 Loss: 1.291113461460502\n",
      "Epoch: 22 Step: 131 Loss: 1.0986918072624747\n",
      "Epoch: 22 Step: 141 Loss: 1.502059968117611\n",
      "Epoch: 22 Step: 151 Loss: 0.9243019867025379\n",
      "Epoch: 22 Step: 161 Loss: 1.224588160698182\n",
      "Epoch: 22 Step: 171 Loss: 1.2103446960782664\n",
      "Epoch: 22 Step: 181 Loss: 1.0767544944475378\n",
      "Epoch: 22 Step: 191 Loss: 1.2792931644567105\n",
      "Epoch: 22 Step: 201 Loss: 0.8642725899437305\n",
      "Epoch: 22 Step: 211 Loss: 0.9880056280850203\n",
      "Epoch: 22 Step: 221 Loss: 1.1339847185297163\n",
      "Epoch: 22 Step: 231 Loss: 1.037443600517517\n",
      "Epoch: 22 Step: 241 Loss: 1.172137971919557\n",
      "Epoch: 22 Step: 251 Loss: 1.110474093571021\n",
      "Epoch: 22 Step: 261 Loss: 1.1995271509326686\n",
      "Epoch: 22 Step: 271 Loss: 1.3177692048675622\n",
      "Epoch: 22 Step: 281 Loss: 1.4287456734645239\n",
      "Epoch: 22 Step: 291 Loss: 1.27989242541911\n",
      "Epoch: 22 Step: 301 Loss: 1.1774403214223357\n",
      "Epoch: 22 Step: 311 Loss: 1.3712924110069866\n",
      "Epoch: 22 Step: 321 Loss: 1.1484292741098838\n",
      "Epoch: 22 Step: 331 Loss: 1.1187131227427933\n",
      "Epoch: 22 Step: 341 Loss: 1.1992424964294786\n",
      "Epoch: 22 Step: 351 Loss: 1.1678987852412197\n",
      "Epoch: 22 Step: 361 Loss: 1.1117365590260426\n",
      "Epoch: 22 Step: 371 Loss: 0.9039796970111527\n",
      "Epoch: 22 Step: 381 Loss: 1.374440804346581\n",
      "Epoch: 22 Step: 391 Loss: 0.9769528004921236\n",
      "Epoch: 22 Step: 401 Loss: 1.1523890279517732\n",
      "Epoch: 22 Step: 411 Loss: 1.2950637681963717\n",
      "Epoch: 22 Step: 421 Loss: 1.2643059812620365\n",
      "Epoch: 22 Step: 431 Loss: 1.181233437767105\n",
      "Epoch: 22 Step: 441 Loss: 1.2198157437700217\n",
      "Epoch: 22 Step: 451 Loss: 1.0597938609292947\n",
      "Epoch: 22 Step: 461 Loss: 1.2693938872614206\n",
      "Epoch: 22 Step: 471 Loss: 1.2774803858347854\n",
      "Epoch: 22 Step: 481 Loss: 1.2891130263572732\n",
      "Epoch: 22 Step: 491 Loss: 1.2886348305419109\n",
      "Epoch: 22 Step: 501 Loss: 1.2424048571149213\n",
      "Epoch: 22 Step: 511 Loss: 1.042353824992194\n",
      "Epoch: 22 Step: 521 Loss: 1.1629460736442487\n",
      "Epoch: 22 Step: 531 Loss: 1.2653356915407215\n",
      "Epoch: 22 Step: 541 Loss: 1.172572600646375\n",
      "Epoch: 22 Step: 551 Loss: 1.2381793025683463\n",
      "Epoch: 22 Step: 561 Loss: 0.9885223640935056\n",
      "Epoch: 22 Step: 571 Loss: 1.1248639755929595\n",
      "Epoch: 22 Step: 581 Loss: 1.3236341571710484\n",
      "Epoch: 22 Step: 591 Loss: 1.1534869282229754\n",
      "Epoch: 22 Step: 601 Loss: 1.3294076020995989\n",
      "Epoch: 22 Step: 611 Loss: 1.021710520438209\n",
      "Epoch: 22 Step: 621 Loss: 1.0793096876409978\n",
      "Epoch: 22 Step: 631 Loss: 1.0822878855321214\n",
      "Epoch: 22 Step: 641 Loss: 1.3245553515562993\n",
      "Epoch: 22 Step: 651 Loss: 1.1889032967753037\n",
      "Epoch: 22 Step: 661 Loss: 1.1537781303812045\n",
      "Epoch: 22 Step: 671 Loss: 1.2961534827519452\n",
      "Epoch: 22 Step: 681 Loss: 1.2895751449978443\n",
      "Epoch: 22 Step: 691 Loss: 1.2662577362422769\n",
      "Epoch: 22 Step: 701 Loss: 1.1929058129628047\n",
      "Epoch: 22 Step: 711 Loss: 1.3115655265237947\n",
      "Epoch: 22 Step: 721 Loss: 1.1509547342109046\n",
      "Epoch: 22 Step: 731 Loss: 0.9483172473135234\n",
      "Epoch: 22 Step: 741 Loss: 1.27770944992227\n",
      "Epoch: 22 Step: 751 Loss: 1.4554807612473275\n",
      "Epoch: 22 Step: 761 Loss: 1.162326280440591\n",
      "Epoch: 22 Step: 771 Loss: 1.134657507429289\n",
      "Epoch: 22 Step: 781 Loss: 1.2291865868492169\n",
      "Epoch: 23 Step: 1 Loss: 1.0775864985016672\n",
      "Epoch: 23 Step: 11 Loss: 1.3343727696538612\n",
      "Epoch: 23 Step: 21 Loss: 1.218196529679774\n",
      "Epoch: 23 Step: 31 Loss: 1.3551581240565993\n",
      "Epoch: 23 Step: 41 Loss: 0.962577776340925\n",
      "Epoch: 23 Step: 51 Loss: 1.1816109846423748\n",
      "Epoch: 23 Step: 61 Loss: 1.2032546302026277\n",
      "Epoch: 23 Step: 71 Loss: 1.2332580625230465\n",
      "Epoch: 23 Step: 81 Loss: 1.3259544928795703\n",
      "Epoch: 23 Step: 91 Loss: 1.4908020235398083\n",
      "Epoch: 23 Step: 101 Loss: 1.2370879193908877\n",
      "Epoch: 23 Step: 111 Loss: 1.2260681432619458\n",
      "Epoch: 23 Step: 121 Loss: 1.2634124093576147\n",
      "Epoch: 23 Step: 131 Loss: 1.2196017663959844\n",
      "Epoch: 23 Step: 141 Loss: 1.4621789689837514\n",
      "Epoch: 23 Step: 151 Loss: 0.8802867754031727\n",
      "Epoch: 23 Step: 161 Loss: 1.0138080222461356\n",
      "Epoch: 23 Step: 171 Loss: 1.2044852139949909\n",
      "Epoch: 23 Step: 181 Loss: 1.0106815282404988\n",
      "Epoch: 23 Step: 191 Loss: 0.9768970354233243\n",
      "Epoch: 23 Step: 201 Loss: 0.8194218182328985\n",
      "Epoch: 23 Step: 211 Loss: 0.8647891569115558\n",
      "Epoch: 23 Step: 221 Loss: 1.1605717465858354\n",
      "Epoch: 23 Step: 231 Loss: 0.9952356003605712\n",
      "Epoch: 23 Step: 241 Loss: 1.0276801569417737\n",
      "Epoch: 23 Step: 251 Loss: 0.9055234247507772\n",
      "Epoch: 23 Step: 261 Loss: 1.137285731643773\n",
      "Epoch: 23 Step: 271 Loss: 1.2772715455760424\n",
      "Epoch: 23 Step: 281 Loss: 1.1318281774083228\n",
      "Epoch: 23 Step: 291 Loss: 1.1555285644957745\n",
      "Epoch: 23 Step: 301 Loss: 1.4466771539453362\n",
      "Epoch: 23 Step: 311 Loss: 1.351236659014995\n",
      "Epoch: 23 Step: 321 Loss: 1.088435247989784\n",
      "Epoch: 23 Step: 331 Loss: 1.2134665677940162\n",
      "Epoch: 23 Step: 341 Loss: 1.2851250073049503\n",
      "Epoch: 23 Step: 351 Loss: 1.2033181983997627\n",
      "Epoch: 23 Step: 361 Loss: 1.0267955669931992\n",
      "Epoch: 23 Step: 371 Loss: 0.8148106732216689\n",
      "Epoch: 23 Step: 381 Loss: 1.3977816836970964\n",
      "Epoch: 23 Step: 391 Loss: 0.9089706344402115\n",
      "Epoch: 23 Step: 401 Loss: 1.2030162700605542\n",
      "Epoch: 23 Step: 411 Loss: 1.3964271919406208\n",
      "Epoch: 23 Step: 421 Loss: 1.3911148298035187\n",
      "Epoch: 23 Step: 431 Loss: 1.2089457007824436\n",
      "Epoch: 23 Step: 441 Loss: 1.2343804546362473\n",
      "Epoch: 23 Step: 451 Loss: 1.2562215822607092\n",
      "Epoch: 23 Step: 461 Loss: 1.0749078896303739\n",
      "Epoch: 23 Step: 471 Loss: 1.204610383146061\n",
      "Epoch: 23 Step: 481 Loss: 1.2880051830750954\n",
      "Epoch: 23 Step: 491 Loss: 1.536445528041909\n",
      "Epoch: 23 Step: 501 Loss: 1.4527542353281278\n",
      "Epoch: 23 Step: 511 Loss: 1.1229770744145964\n",
      "Epoch: 23 Step: 521 Loss: 1.2203461327288763\n",
      "Epoch: 23 Step: 531 Loss: 1.2478809836858225\n",
      "Epoch: 23 Step: 541 Loss: 1.3022241198199889\n",
      "Epoch: 23 Step: 551 Loss: 1.076369139623416\n",
      "Epoch: 23 Step: 561 Loss: 1.0165285937506843\n",
      "Epoch: 23 Step: 571 Loss: 1.034088346575462\n",
      "Epoch: 23 Step: 581 Loss: 1.172501287771993\n",
      "Epoch: 23 Step: 591 Loss: 1.0974371452749057\n",
      "Epoch: 23 Step: 601 Loss: 1.151380659888243\n",
      "Epoch: 23 Step: 611 Loss: 1.0995616305880822\n",
      "Epoch: 23 Step: 621 Loss: 1.238195920480972\n",
      "Epoch: 23 Step: 631 Loss: 1.0781557830697368\n",
      "Epoch: 23 Step: 641 Loss: 1.2497326079716946\n",
      "Epoch: 23 Step: 651 Loss: 1.1741436755567287\n",
      "Epoch: 23 Step: 661 Loss: 0.9438457572068264\n",
      "Epoch: 23 Step: 671 Loss: 1.217727567948482\n",
      "Epoch: 23 Step: 681 Loss: 1.2331512480980433\n",
      "Epoch: 23 Step: 691 Loss: 1.2406401994527079\n",
      "Epoch: 23 Step: 701 Loss: 1.0459363286629588\n",
      "Epoch: 23 Step: 711 Loss: 1.169000266934838\n",
      "Epoch: 23 Step: 721 Loss: 0.9751933519315514\n",
      "Epoch: 23 Step: 731 Loss: 0.9908611097720522\n",
      "Epoch: 23 Step: 741 Loss: 1.3398271416493022\n",
      "Epoch: 23 Step: 751 Loss: 1.576482080504936\n",
      "Epoch: 23 Step: 761 Loss: 1.004348659173504\n",
      "Epoch: 23 Step: 771 Loss: 1.4261160635281702\n",
      "Epoch: 23 Step: 781 Loss: 1.1644527044206252\n",
      "Epoch: 24 Step: 1 Loss: 1.1369047650682667\n",
      "Epoch: 24 Step: 11 Loss: 1.4031521365092474\n",
      "Epoch: 24 Step: 21 Loss: 1.1917702937768722\n",
      "Epoch: 24 Step: 31 Loss: 1.5323117469555654\n",
      "Epoch: 24 Step: 41 Loss: 1.1193465940309442\n",
      "Epoch: 24 Step: 51 Loss: 1.0082957744968941\n",
      "Epoch: 24 Step: 61 Loss: 1.1182927978395392\n",
      "Epoch: 24 Step: 71 Loss: 1.3100727622239001\n",
      "Epoch: 24 Step: 81 Loss: 1.603508851954345\n",
      "Epoch: 24 Step: 91 Loss: 1.3156970902307272\n",
      "Epoch: 24 Step: 101 Loss: 1.0778329780181424\n",
      "Epoch: 24 Step: 111 Loss: 1.2587934309795725\n",
      "Epoch: 24 Step: 121 Loss: 1.4465323792380942\n",
      "Epoch: 24 Step: 131 Loss: 1.210276656749914\n",
      "Epoch: 24 Step: 141 Loss: 1.5387812745947838\n",
      "Epoch: 24 Step: 151 Loss: 0.9134219112959501\n",
      "Epoch: 24 Step: 161 Loss: 1.0967379051803725\n",
      "Epoch: 24 Step: 171 Loss: 1.212351695882846\n",
      "Epoch: 24 Step: 181 Loss: 1.0846406675427716\n",
      "Epoch: 24 Step: 191 Loss: 1.1491151760717955\n",
      "Epoch: 24 Step: 201 Loss: 0.8507645408416086\n",
      "Epoch: 24 Step: 211 Loss: 1.0562331267884657\n",
      "Epoch: 24 Step: 221 Loss: 1.269556587738021\n",
      "Epoch: 24 Step: 231 Loss: 1.127813285314391\n",
      "Epoch: 24 Step: 241 Loss: 1.13510968064435\n",
      "Epoch: 24 Step: 251 Loss: 1.0355559081432337\n",
      "Epoch: 24 Step: 261 Loss: 1.0838604693374498\n",
      "Epoch: 24 Step: 271 Loss: 1.2619467019161736\n",
      "Epoch: 24 Step: 281 Loss: 1.264696407315001\n",
      "Epoch: 24 Step: 291 Loss: 1.0763470843487872\n",
      "Epoch: 24 Step: 301 Loss: 1.276891354662113\n",
      "Epoch: 24 Step: 311 Loss: 1.1675631810311489\n",
      "Epoch: 24 Step: 321 Loss: 1.1616655034064607\n",
      "Epoch: 24 Step: 331 Loss: 1.0076946042286252\n",
      "Epoch: 24 Step: 341 Loss: 1.0895463941197714\n",
      "Epoch: 24 Step: 351 Loss: 1.3092685668513284\n",
      "Epoch: 24 Step: 361 Loss: 1.1218776108236113\n",
      "Epoch: 24 Step: 371 Loss: 0.8712510876210764\n",
      "Epoch: 24 Step: 381 Loss: 1.367934392407145\n",
      "Epoch: 24 Step: 391 Loss: 0.8082231505537109\n",
      "Epoch: 24 Step: 401 Loss: 1.1209433506365274\n",
      "Epoch: 24 Step: 411 Loss: 1.2510250059035628\n",
      "Epoch: 24 Step: 421 Loss: 1.3924095873957607\n",
      "Epoch: 24 Step: 431 Loss: 1.1444253731256417\n",
      "Epoch: 24 Step: 441 Loss: 1.241745936035587\n",
      "Epoch: 24 Step: 451 Loss: 1.0196904818271557\n",
      "Epoch: 24 Step: 461 Loss: 1.2722659996132308\n",
      "Epoch: 24 Step: 471 Loss: 1.0024713212788214\n",
      "Epoch: 24 Step: 481 Loss: 1.3983258676444774\n",
      "Epoch: 24 Step: 491 Loss: 1.4285431029675695\n",
      "Epoch: 24 Step: 501 Loss: 1.3570058082949867\n",
      "Epoch: 24 Step: 511 Loss: 0.982456119734836\n",
      "Epoch: 24 Step: 521 Loss: 1.2484544572266674\n",
      "Epoch: 24 Step: 531 Loss: 1.227407520356781\n",
      "Epoch: 24 Step: 541 Loss: 1.111059955702006\n",
      "Epoch: 24 Step: 551 Loss: 1.1347929855019112\n",
      "Epoch: 24 Step: 561 Loss: 1.1079872269569346\n",
      "Epoch: 24 Step: 571 Loss: 1.0344401000031702\n",
      "Epoch: 24 Step: 581 Loss: 1.204837580893253\n",
      "Epoch: 24 Step: 591 Loss: 1.2072622814583776\n",
      "Epoch: 24 Step: 601 Loss: 1.299141464416369\n",
      "Epoch: 24 Step: 611 Loss: 1.0881866333798365\n",
      "Epoch: 24 Step: 621 Loss: 1.0698369003658534\n",
      "Epoch: 24 Step: 631 Loss: 1.041014768262694\n",
      "Epoch: 24 Step: 641 Loss: 1.366386635916693\n",
      "Epoch: 24 Step: 651 Loss: 1.187772109936797\n",
      "Epoch: 24 Step: 661 Loss: 1.0896054286978054\n",
      "Epoch: 24 Step: 671 Loss: 1.269081030579588\n",
      "Epoch: 24 Step: 681 Loss: 1.4723960587927594\n",
      "Epoch: 24 Step: 691 Loss: 1.171359976000283\n",
      "Epoch: 24 Step: 701 Loss: 1.0741749417988156\n",
      "Epoch: 24 Step: 711 Loss: 1.198258566721827\n",
      "Epoch: 24 Step: 721 Loss: 1.032624840778866\n",
      "Epoch: 24 Step: 731 Loss: 0.8837050595788127\n",
      "Epoch: 24 Step: 741 Loss: 1.2708636310428567\n",
      "Epoch: 24 Step: 751 Loss: 1.4515005237613248\n",
      "Epoch: 24 Step: 761 Loss: 0.9115620058698048\n",
      "Epoch: 24 Step: 771 Loss: 1.1292316984745598\n",
      "Epoch: 24 Step: 781 Loss: 1.0350638172208624\n",
      "Epoch: 25 Step: 1 Loss: 1.1986047525039298\n",
      "Epoch: 25 Step: 11 Loss: 1.116428174378965\n",
      "Epoch: 25 Step: 21 Loss: 1.291663436222999\n",
      "Epoch: 25 Step: 31 Loss: 1.4114560653743302\n",
      "Epoch: 25 Step: 41 Loss: 1.0026261298474803\n",
      "Epoch: 25 Step: 51 Loss: 1.1267038202641642\n",
      "Epoch: 25 Step: 61 Loss: 1.1486639156384655\n",
      "Epoch: 25 Step: 71 Loss: 1.0452791100597378\n",
      "Epoch: 25 Step: 81 Loss: 1.4045221768027718\n",
      "Epoch: 25 Step: 91 Loss: 1.1450406691913184\n",
      "Epoch: 25 Step: 101 Loss: 1.130056700113957\n",
      "Epoch: 25 Step: 111 Loss: 1.1293835929551803\n",
      "Epoch: 25 Step: 121 Loss: 1.399404149743574\n",
      "Epoch: 25 Step: 131 Loss: 1.107665474791232\n",
      "Epoch: 25 Step: 141 Loss: 1.6545848648605648\n",
      "Epoch: 25 Step: 151 Loss: 0.9527606475626622\n",
      "Epoch: 25 Step: 161 Loss: 1.0334380226235822\n",
      "Epoch: 25 Step: 171 Loss: 1.066229023629563\n",
      "Epoch: 25 Step: 181 Loss: 1.1126582504575637\n",
      "Epoch: 25 Step: 191 Loss: 1.1039145156457506\n",
      "Epoch: 25 Step: 201 Loss: 0.9643524525735951\n",
      "Epoch: 25 Step: 211 Loss: 0.8502651896757094\n",
      "Epoch: 25 Step: 221 Loss: 1.230178950901762\n",
      "Epoch: 25 Step: 231 Loss: 1.1158667504675348\n",
      "Epoch: 25 Step: 241 Loss: 1.2660738540815015\n",
      "Epoch: 25 Step: 251 Loss: 1.1129326289432102\n",
      "Epoch: 25 Step: 261 Loss: 1.1928699930562743\n",
      "Epoch: 25 Step: 271 Loss: 1.2515424171655012\n",
      "Epoch: 25 Step: 281 Loss: 1.3015142508005635\n",
      "Epoch: 25 Step: 291 Loss: 1.2583303713738454\n",
      "Epoch: 25 Step: 301 Loss: 1.2581586207043949\n",
      "Epoch: 25 Step: 311 Loss: 1.327739309013278\n",
      "Epoch: 25 Step: 321 Loss: 1.4139035464643215\n",
      "Epoch: 25 Step: 331 Loss: 1.0292369339206426\n",
      "Epoch: 25 Step: 341 Loss: 1.257650418615666\n",
      "Epoch: 25 Step: 351 Loss: 1.2730170326585766\n",
      "Epoch: 25 Step: 361 Loss: 1.1074624688486454\n",
      "Epoch: 25 Step: 371 Loss: 0.8891627293607718\n",
      "Epoch: 25 Step: 381 Loss: 1.3721204505485476\n",
      "Epoch: 25 Step: 391 Loss: 0.997027970523677\n",
      "Epoch: 25 Step: 401 Loss: 1.0078653081195885\n",
      "Epoch: 25 Step: 411 Loss: 1.266503522240145\n",
      "Epoch: 25 Step: 421 Loss: 1.2421545659688036\n",
      "Epoch: 25 Step: 431 Loss: 1.1677531664476495\n",
      "Epoch: 25 Step: 441 Loss: 1.1482881820534039\n",
      "Epoch: 25 Step: 451 Loss: 0.9631480317127614\n",
      "Epoch: 25 Step: 461 Loss: 1.169817990487833\n",
      "Epoch: 25 Step: 471 Loss: 1.2097380512180131\n",
      "Epoch: 25 Step: 481 Loss: 1.101224608311077\n",
      "Epoch: 25 Step: 491 Loss: 1.4775189077766908\n",
      "Epoch: 25 Step: 501 Loss: 1.2241312037591139\n",
      "Epoch: 25 Step: 511 Loss: 1.1415564000284943\n",
      "Epoch: 25 Step: 521 Loss: 1.1357335347348727\n",
      "Epoch: 25 Step: 531 Loss: 1.3036993840231785\n",
      "Epoch: 25 Step: 541 Loss: 1.2175864691066498\n",
      "Epoch: 25 Step: 551 Loss: 1.1806954328863957\n",
      "Epoch: 25 Step: 561 Loss: 0.9954063004294396\n",
      "Epoch: 25 Step: 571 Loss: 0.8830490182124869\n",
      "Epoch: 25 Step: 581 Loss: 1.3472199820117856\n",
      "Epoch: 25 Step: 591 Loss: 1.1289436495179208\n",
      "Epoch: 25 Step: 601 Loss: 1.1759044700177184\n",
      "Epoch: 25 Step: 611 Loss: 1.170506526662907\n",
      "Epoch: 25 Step: 621 Loss: 1.0983216592943945\n",
      "Epoch: 25 Step: 631 Loss: 1.290379630943858\n",
      "Epoch: 25 Step: 641 Loss: 1.2715053926787616\n",
      "Epoch: 25 Step: 651 Loss: 1.0671207112745542\n",
      "Epoch: 25 Step: 661 Loss: 1.251609317856715\n",
      "Epoch: 25 Step: 671 Loss: 1.2225435947551375\n",
      "Epoch: 25 Step: 681 Loss: 1.3732269272660158\n",
      "Epoch: 25 Step: 691 Loss: 1.2280660126729146\n",
      "Epoch: 25 Step: 701 Loss: 1.1121735660332202\n",
      "Epoch: 25 Step: 711 Loss: 1.1827564510984967\n",
      "Epoch: 25 Step: 721 Loss: 0.9265626780589016\n",
      "Epoch: 25 Step: 731 Loss: 0.9197114151219394\n",
      "Epoch: 25 Step: 741 Loss: 1.2476071876037609\n",
      "Epoch: 25 Step: 751 Loss: 1.2353648970576616\n",
      "Epoch: 25 Step: 761 Loss: 1.0048699132162944\n",
      "Epoch: 25 Step: 771 Loss: 1.3388985450913173\n",
      "Epoch: 25 Step: 781 Loss: 1.0595757465919902\n",
      "Epoch: 26 Step: 1 Loss: 1.263634789102432\n",
      "Epoch: 26 Step: 11 Loss: 1.2117948996659953\n",
      "Epoch: 26 Step: 21 Loss: 1.3702287747731057\n",
      "Epoch: 26 Step: 31 Loss: 1.5614479635686909\n",
      "Epoch: 26 Step: 41 Loss: 0.9415542563122277\n",
      "Epoch: 26 Step: 51 Loss: 1.0007748626141284\n",
      "Epoch: 26 Step: 61 Loss: 1.1605560948757656\n",
      "Epoch: 26 Step: 71 Loss: 1.2550396588592112\n",
      "Epoch: 26 Step: 81 Loss: 1.4663807258112942\n",
      "Epoch: 26 Step: 91 Loss: 1.0678063981895425\n",
      "Epoch: 26 Step: 101 Loss: 1.1535770157825884\n",
      "Epoch: 26 Step: 111 Loss: 1.2354439866222617\n",
      "Epoch: 26 Step: 121 Loss: 1.3058630166343443\n",
      "Epoch: 26 Step: 131 Loss: 1.1474942054358348\n",
      "Epoch: 26 Step: 141 Loss: 1.34815497424403\n",
      "Epoch: 26 Step: 151 Loss: 0.7678898751602138\n",
      "Epoch: 26 Step: 161 Loss: 1.011766745211804\n",
      "Epoch: 26 Step: 171 Loss: 1.0420244332539128\n",
      "Epoch: 26 Step: 181 Loss: 1.1013700317823663\n",
      "Epoch: 26 Step: 191 Loss: 1.0923495187213113\n",
      "Epoch: 26 Step: 201 Loss: 0.8139544617690854\n",
      "Epoch: 26 Step: 211 Loss: 0.996935762026347\n",
      "Epoch: 26 Step: 221 Loss: 1.0493284504212983\n",
      "Epoch: 26 Step: 231 Loss: 1.0661172569870443\n",
      "Epoch: 26 Step: 241 Loss: 1.0145886554643706\n",
      "Epoch: 26 Step: 251 Loss: 1.1486271217261894\n",
      "Epoch: 26 Step: 261 Loss: 1.1769751333714553\n",
      "Epoch: 26 Step: 271 Loss: 1.2241718905425132\n",
      "Epoch: 26 Step: 281 Loss: 1.1550390909318895\n",
      "Epoch: 26 Step: 291 Loss: 1.0212377095859657\n",
      "Epoch: 26 Step: 301 Loss: 1.2904426446190314\n",
      "Epoch: 26 Step: 311 Loss: 1.1911296302703662\n",
      "Epoch: 26 Step: 321 Loss: 1.1313882329586544\n",
      "Epoch: 26 Step: 331 Loss: 1.0308677760085927\n",
      "Epoch: 26 Step: 341 Loss: 1.4036519028061571\n",
      "Epoch: 26 Step: 351 Loss: 1.202673782568381\n",
      "Epoch: 26 Step: 361 Loss: 1.173594429353721\n",
      "Epoch: 26 Step: 371 Loss: 0.8331715540238727\n",
      "Epoch: 26 Step: 381 Loss: 1.4678421503548722\n",
      "Epoch: 26 Step: 391 Loss: 0.993812061634469\n",
      "Epoch: 26 Step: 401 Loss: 1.1787128303556698\n",
      "Epoch: 26 Step: 411 Loss: 1.1651355332589635\n",
      "Epoch: 26 Step: 421 Loss: 1.2872778902690591\n",
      "Epoch: 26 Step: 431 Loss: 1.2554804187822206\n",
      "Epoch: 26 Step: 441 Loss: 1.1733382707772901\n",
      "Epoch: 26 Step: 451 Loss: 0.940086472713689\n",
      "Epoch: 26 Step: 461 Loss: 1.2560094527550723\n",
      "Epoch: 26 Step: 471 Loss: 1.2051713716830283\n",
      "Epoch: 26 Step: 481 Loss: 1.3859607734055972\n",
      "Epoch: 26 Step: 491 Loss: 1.4631309648391888\n",
      "Epoch: 26 Step: 501 Loss: 1.0970871032225937\n",
      "Epoch: 26 Step: 511 Loss: 1.01920068182512\n",
      "Epoch: 26 Step: 521 Loss: 1.3216296080511039\n",
      "Epoch: 26 Step: 531 Loss: 1.182180040476163\n",
      "Epoch: 26 Step: 541 Loss: 1.0824730046690547\n",
      "Epoch: 26 Step: 551 Loss: 1.1105345843628565\n",
      "Epoch: 26 Step: 561 Loss: 0.922121619968579\n",
      "Epoch: 26 Step: 571 Loss: 0.9459571137506645\n",
      "Epoch: 26 Step: 581 Loss: 1.040822954503371\n",
      "Epoch: 26 Step: 591 Loss: 1.0553582998304427\n",
      "Epoch: 26 Step: 601 Loss: 1.179448799764348\n",
      "Epoch: 26 Step: 611 Loss: 1.1104292892430183\n",
      "Epoch: 26 Step: 621 Loss: 1.0028353719088234\n",
      "Epoch: 26 Step: 631 Loss: 1.0392341273441585\n",
      "Epoch: 26 Step: 641 Loss: 1.2469525343818182\n",
      "Epoch: 26 Step: 651 Loss: 1.2607354222362805\n",
      "Epoch: 26 Step: 661 Loss: 1.1879428831122176\n",
      "Epoch: 26 Step: 671 Loss: 1.2029780250531017\n",
      "Epoch: 26 Step: 681 Loss: 1.294762202750294\n",
      "Epoch: 26 Step: 691 Loss: 1.2326217913256285\n",
      "Epoch: 26 Step: 701 Loss: 1.1398829297825837\n",
      "Epoch: 26 Step: 711 Loss: 1.2544789459493264\n",
      "Epoch: 26 Step: 721 Loss: 1.061669236173528\n",
      "Epoch: 26 Step: 731 Loss: 0.8737091010636815\n",
      "Epoch: 26 Step: 741 Loss: 1.526549442948334\n",
      "Epoch: 26 Step: 751 Loss: 1.444173027157976\n",
      "Epoch: 26 Step: 761 Loss: 1.1475586622239002\n",
      "Epoch: 26 Step: 771 Loss: 1.1508536831489398\n",
      "Epoch: 26 Step: 781 Loss: 1.1716105919777888\n",
      "Epoch: 27 Step: 1 Loss: 1.2949458787724304\n",
      "Epoch: 27 Step: 11 Loss: 1.1095161750532152\n",
      "Epoch: 27 Step: 21 Loss: 1.1254996051572326\n",
      "Epoch: 27 Step: 31 Loss: 1.3530751087675117\n",
      "Epoch: 27 Step: 41 Loss: 1.0954989273750062\n",
      "Epoch: 27 Step: 51 Loss: 1.1155602373871558\n",
      "Epoch: 27 Step: 61 Loss: 1.0974632341943846\n",
      "Epoch: 27 Step: 71 Loss: 1.2226410657279974\n",
      "Epoch: 27 Step: 81 Loss: 1.3590724207516867\n",
      "Epoch: 27 Step: 91 Loss: 1.2757827109005606\n",
      "Epoch: 27 Step: 101 Loss: 1.1663120616385485\n",
      "Epoch: 27 Step: 111 Loss: 1.174230280413726\n",
      "Epoch: 27 Step: 121 Loss: 1.3876822673052114\n",
      "Epoch: 27 Step: 131 Loss: 1.171205172213201\n",
      "Epoch: 27 Step: 141 Loss: 1.6677596823717424\n",
      "Epoch: 27 Step: 151 Loss: 0.8221890407688333\n",
      "Epoch: 27 Step: 161 Loss: 0.9087957006873404\n",
      "Epoch: 27 Step: 171 Loss: 1.192165684933568\n",
      "Epoch: 27 Step: 181 Loss: 0.9496376723642967\n",
      "Epoch: 27 Step: 191 Loss: 1.1410148515900451\n",
      "Epoch: 27 Step: 201 Loss: 0.8987290068449469\n",
      "Epoch: 27 Step: 211 Loss: 0.9572128144052335\n",
      "Epoch: 27 Step: 221 Loss: 1.035493425461372\n",
      "Epoch: 27 Step: 231 Loss: 0.9589668832951926\n",
      "Epoch: 27 Step: 241 Loss: 1.0413132986088824\n",
      "Epoch: 27 Step: 251 Loss: 0.9913381105995875\n",
      "Epoch: 27 Step: 261 Loss: 1.012357395218941\n",
      "Epoch: 27 Step: 271 Loss: 1.2067571449697727\n",
      "Epoch: 27 Step: 281 Loss: 1.0421909230384976\n",
      "Epoch: 27 Step: 291 Loss: 1.2032110140010506\n",
      "Epoch: 27 Step: 301 Loss: 1.5545497999116735\n",
      "Epoch: 27 Step: 311 Loss: 1.1401883283634864\n",
      "Epoch: 27 Step: 321 Loss: 1.1445013417900307\n",
      "Epoch: 27 Step: 331 Loss: 1.0660907274130427\n",
      "Epoch: 27 Step: 341 Loss: 1.208880214333138\n",
      "Epoch: 27 Step: 351 Loss: 1.1450664015926253\n",
      "Epoch: 27 Step: 361 Loss: 1.1535692100431942\n",
      "Epoch: 27 Step: 371 Loss: 0.8708507159840806\n",
      "Epoch: 27 Step: 381 Loss: 1.441612023422149\n",
      "Epoch: 27 Step: 391 Loss: 1.0694703550439904\n",
      "Epoch: 27 Step: 401 Loss: 1.0526523117622244\n",
      "Epoch: 27 Step: 411 Loss: 1.1267086770745556\n",
      "Epoch: 27 Step: 421 Loss: 1.2503556712616355\n",
      "Epoch: 27 Step: 431 Loss: 1.2174302398229184\n",
      "Epoch: 27 Step: 441 Loss: 1.2521819043433047\n",
      "Epoch: 27 Step: 451 Loss: 1.1412966974851972\n",
      "Epoch: 27 Step: 461 Loss: 1.201405526992084\n",
      "Epoch: 27 Step: 471 Loss: 1.1249523654058065\n",
      "Epoch: 27 Step: 481 Loss: 1.3369158527546126\n",
      "Epoch: 27 Step: 491 Loss: 1.4109174449111985\n",
      "Epoch: 27 Step: 501 Loss: 1.2223766788726118\n",
      "Epoch: 27 Step: 511 Loss: 1.0960513491854225\n",
      "Epoch: 27 Step: 521 Loss: 1.1672776943665397\n",
      "Epoch: 27 Step: 531 Loss: 1.1402575737972134\n",
      "Epoch: 27 Step: 541 Loss: 1.0532315951885436\n",
      "Epoch: 27 Step: 551 Loss: 0.9580941374519457\n",
      "Epoch: 27 Step: 561 Loss: 1.0192585761613628\n",
      "Epoch: 27 Step: 571 Loss: 1.1372738317174012\n",
      "Epoch: 27 Step: 581 Loss: 0.991212990189686\n",
      "Epoch: 27 Step: 591 Loss: 1.1699946971479094\n",
      "Epoch: 27 Step: 601 Loss: 1.1743094957597198\n",
      "Epoch: 27 Step: 611 Loss: 1.074266515195081\n",
      "Epoch: 27 Step: 621 Loss: 0.880855383142604\n",
      "Epoch: 27 Step: 631 Loss: 1.2012175779539138\n",
      "Epoch: 27 Step: 641 Loss: 1.2956720016156522\n",
      "Epoch: 27 Step: 651 Loss: 1.0686936617064837\n",
      "Epoch: 27 Step: 661 Loss: 1.0817848323625823\n",
      "Epoch: 27 Step: 671 Loss: 1.0939624084162\n",
      "Epoch: 27 Step: 681 Loss: 1.3962577139703591\n",
      "Epoch: 27 Step: 691 Loss: 1.139629626920343\n",
      "Epoch: 27 Step: 701 Loss: 1.0987160066249817\n",
      "Epoch: 27 Step: 711 Loss: 1.01659318885704\n",
      "Epoch: 27 Step: 721 Loss: 0.9912371798481954\n",
      "Epoch: 27 Step: 731 Loss: 0.8274536412592982\n",
      "Epoch: 27 Step: 741 Loss: 1.1478742454771116\n",
      "Epoch: 27 Step: 751 Loss: 1.3560313792973555\n",
      "Epoch: 27 Step: 761 Loss: 1.0051061149413658\n",
      "Epoch: 27 Step: 771 Loss: 1.1118049706904964\n",
      "Epoch: 27 Step: 781 Loss: 1.1660849412764158\n",
      "Epoch: 28 Step: 1 Loss: 1.072499834846692\n",
      "Epoch: 28 Step: 11 Loss: 1.1222598669691595\n",
      "Epoch: 28 Step: 21 Loss: 1.14918521274687\n",
      "Epoch: 28 Step: 31 Loss: 1.3654687634382023\n",
      "Epoch: 28 Step: 41 Loss: 0.9410098116515243\n",
      "Epoch: 28 Step: 51 Loss: 1.014241678584932\n",
      "Epoch: 28 Step: 61 Loss: 1.1310915816859202\n",
      "Epoch: 28 Step: 71 Loss: 1.3077675955944006\n",
      "Epoch: 28 Step: 81 Loss: 1.4455905257080326\n",
      "Epoch: 28 Step: 91 Loss: 1.1402886145583249\n",
      "Epoch: 28 Step: 101 Loss: 1.4585687464691475\n",
      "Epoch: 28 Step: 111 Loss: 1.2228860273062019\n",
      "Epoch: 28 Step: 121 Loss: 1.2346480507552857\n",
      "Epoch: 28 Step: 131 Loss: 1.269147818510599\n",
      "Epoch: 28 Step: 141 Loss: 1.4292557107812693\n",
      "Epoch: 28 Step: 151 Loss: 0.8210903442428845\n",
      "Epoch: 28 Step: 161 Loss: 1.168696707235183\n",
      "Epoch: 28 Step: 171 Loss: 1.1720003392935214\n",
      "Epoch: 28 Step: 181 Loss: 1.0337595312528816\n",
      "Epoch: 28 Step: 191 Loss: 1.1868560856320955\n",
      "Epoch: 28 Step: 201 Loss: 0.719816371686207\n",
      "Epoch: 28 Step: 211 Loss: 0.9747554486816733\n",
      "Epoch: 28 Step: 221 Loss: 1.069387596224303\n",
      "Epoch: 28 Step: 231 Loss: 1.0986601123376474\n",
      "Epoch: 28 Step: 241 Loss: 1.1000121213481548\n",
      "Epoch: 28 Step: 251 Loss: 1.058752750295079\n",
      "Epoch: 28 Step: 261 Loss: 1.2041662559121526\n",
      "Epoch: 28 Step: 271 Loss: 1.25800433475658\n",
      "Epoch: 28 Step: 281 Loss: 0.9995160283714335\n",
      "Epoch: 28 Step: 291 Loss: 1.0490396258152752\n",
      "Epoch: 28 Step: 301 Loss: 1.3460249305239143\n",
      "Epoch: 28 Step: 311 Loss: 1.2763534718583636\n",
      "Epoch: 28 Step: 321 Loss: 1.246297009985631\n",
      "Epoch: 28 Step: 331 Loss: 1.0489140159098214\n",
      "Epoch: 28 Step: 341 Loss: 1.1673993358569188\n",
      "Epoch: 28 Step: 351 Loss: 1.1010925070108897\n",
      "Epoch: 28 Step: 361 Loss: 1.045556927868424\n",
      "Epoch: 28 Step: 371 Loss: 0.6849384770230458\n",
      "Epoch: 28 Step: 381 Loss: 1.262998742515998\n",
      "Epoch: 28 Step: 391 Loss: 0.8900808618983491\n",
      "Epoch: 28 Step: 401 Loss: 0.9632446392944475\n",
      "Epoch: 28 Step: 411 Loss: 1.2113436208861716\n",
      "Epoch: 28 Step: 421 Loss: 1.3026662207668305\n",
      "Epoch: 28 Step: 431 Loss: 1.0758515350344982\n",
      "Epoch: 28 Step: 441 Loss: 1.1812499408959969\n",
      "Epoch: 28 Step: 451 Loss: 0.8636194063697875\n",
      "Epoch: 28 Step: 461 Loss: 1.1555040075487653\n",
      "Epoch: 28 Step: 471 Loss: 1.1731150242076054\n",
      "Epoch: 28 Step: 481 Loss: 1.301605973957742\n",
      "Epoch: 28 Step: 491 Loss: 1.4694336064793294\n",
      "Epoch: 28 Step: 501 Loss: 1.26297966305644\n",
      "Epoch: 28 Step: 511 Loss: 1.1978448177743282\n",
      "Epoch: 28 Step: 521 Loss: 1.1299165941719356\n",
      "Epoch: 28 Step: 531 Loss: 1.173466536615035\n",
      "Epoch: 28 Step: 541 Loss: 1.035681607976529\n",
      "Epoch: 28 Step: 551 Loss: 1.3109398996909376\n",
      "Epoch: 28 Step: 561 Loss: 0.9670222084077265\n",
      "Epoch: 28 Step: 571 Loss: 1.0194008371127914\n",
      "Epoch: 28 Step: 581 Loss: 1.227030057579169\n",
      "Epoch: 28 Step: 591 Loss: 1.1789539415919021\n",
      "Epoch: 28 Step: 601 Loss: 1.2603179560601014\n",
      "Epoch: 28 Step: 611 Loss: 1.0214963250762095\n",
      "Epoch: 28 Step: 621 Loss: 1.091837539748485\n",
      "Epoch: 28 Step: 631 Loss: 1.1696447294635384\n",
      "Epoch: 28 Step: 641 Loss: 1.2179099820495554\n",
      "Epoch: 28 Step: 651 Loss: 0.9735061332740748\n",
      "Epoch: 28 Step: 661 Loss: 1.1705547385687083\n",
      "Epoch: 28 Step: 671 Loss: 1.0257993236116412\n",
      "Epoch: 28 Step: 681 Loss: 1.3766256404590347\n",
      "Epoch: 28 Step: 691 Loss: 1.2264354590959183\n",
      "Epoch: 28 Step: 701 Loss: 1.0930014215006696\n",
      "Epoch: 28 Step: 711 Loss: 1.0604327135553882\n",
      "Epoch: 28 Step: 721 Loss: 0.8046377977288924\n",
      "Epoch: 28 Step: 731 Loss: 0.9984667373967474\n",
      "Epoch: 28 Step: 741 Loss: 1.3144213186720572\n",
      "Epoch: 28 Step: 751 Loss: 1.410396062237786\n",
      "Epoch: 28 Step: 761 Loss: 0.9046139718381447\n",
      "Epoch: 28 Step: 771 Loss: 1.1946966006721553\n",
      "Epoch: 28 Step: 781 Loss: 1.0705702897090912\n",
      "Epoch: 29 Step: 1 Loss: 1.2041701128546345\n",
      "Epoch: 29 Step: 11 Loss: 1.1554672767488177\n",
      "Epoch: 29 Step: 21 Loss: 1.1569757818050554\n",
      "Epoch: 29 Step: 31 Loss: 1.2936213178597735\n",
      "Epoch: 29 Step: 41 Loss: 0.7776253466090058\n",
      "Epoch: 29 Step: 51 Loss: 0.9965070639752683\n",
      "Epoch: 29 Step: 61 Loss: 1.0541467444138317\n",
      "Epoch: 29 Step: 71 Loss: 1.129871348766952\n",
      "Epoch: 29 Step: 81 Loss: 1.1966784821748742\n",
      "Epoch: 29 Step: 91 Loss: 1.0752540563485755\n",
      "Epoch: 29 Step: 101 Loss: 1.0065657073306955\n",
      "Epoch: 29 Step: 111 Loss: 1.135376402717427\n",
      "Epoch: 29 Step: 121 Loss: 1.3166620325866816\n",
      "Epoch: 29 Step: 131 Loss: 1.0299131109424864\n",
      "Epoch: 29 Step: 141 Loss: 1.3889531145231522\n",
      "Epoch: 29 Step: 151 Loss: 0.8289101473521772\n",
      "Epoch: 29 Step: 161 Loss: 1.0693381644657372\n",
      "Epoch: 29 Step: 171 Loss: 1.179277544042315\n",
      "Epoch: 29 Step: 181 Loss: 1.0572034749282704\n",
      "Epoch: 29 Step: 191 Loss: 1.1326397133170496\n",
      "Epoch: 29 Step: 201 Loss: 0.9379100627565364\n",
      "Epoch: 29 Step: 211 Loss: 0.9429903478599839\n",
      "Epoch: 29 Step: 221 Loss: 1.0959268167577123\n",
      "Epoch: 29 Step: 231 Loss: 1.083107127994522\n",
      "Epoch: 29 Step: 241 Loss: 1.0375691625011259\n",
      "Epoch: 29 Step: 251 Loss: 1.042005592320257\n",
      "Epoch: 29 Step: 261 Loss: 1.0286439975265598\n",
      "Epoch: 29 Step: 271 Loss: 1.234497130183785\n",
      "Epoch: 29 Step: 281 Loss: 1.219037500399248\n",
      "Epoch: 29 Step: 291 Loss: 1.223900450470417\n",
      "Epoch: 29 Step: 301 Loss: 1.443636465182998\n",
      "Epoch: 29 Step: 311 Loss: 1.058895154327474\n",
      "Epoch: 29 Step: 321 Loss: 1.136635281161312\n",
      "Epoch: 29 Step: 331 Loss: 1.1630383926480925\n",
      "Epoch: 29 Step: 341 Loss: 1.1985819830141686\n",
      "Epoch: 29 Step: 351 Loss: 1.1337022236230467\n",
      "Epoch: 29 Step: 361 Loss: 1.1130690087114536\n",
      "Epoch: 29 Step: 371 Loss: 0.9147532395124001\n",
      "Epoch: 29 Step: 381 Loss: 1.3295940871134038\n",
      "Epoch: 29 Step: 391 Loss: 0.9686496626193927\n",
      "Epoch: 29 Step: 401 Loss: 0.9415217928646267\n",
      "Epoch: 29 Step: 411 Loss: 1.1038330333242152\n",
      "Epoch: 29 Step: 421 Loss: 1.185050901701996\n",
      "Epoch: 29 Step: 431 Loss: 1.0461097879907344\n",
      "Epoch: 29 Step: 441 Loss: 1.1827305515519617\n",
      "Epoch: 29 Step: 451 Loss: 1.0377903539056546\n",
      "Epoch: 29 Step: 461 Loss: 1.0871246775901402\n",
      "Epoch: 29 Step: 471 Loss: 1.3134423213427406\n",
      "Epoch: 29 Step: 481 Loss: 1.184769668198323\n",
      "Epoch: 29 Step: 491 Loss: 1.4059088508360875\n",
      "Epoch: 29 Step: 501 Loss: 1.1472854429633412\n",
      "Epoch: 29 Step: 511 Loss: 0.9789221659345471\n",
      "Epoch: 29 Step: 521 Loss: 1.1570961247100273\n",
      "Epoch: 29 Step: 531 Loss: 1.1089921671109817\n",
      "Epoch: 29 Step: 541 Loss: 1.0463494811471166\n",
      "Epoch: 29 Step: 551 Loss: 1.0976856080228248\n",
      "Epoch: 29 Step: 561 Loss: 0.9850045657168495\n",
      "Epoch: 29 Step: 571 Loss: 0.9783956409172575\n",
      "Epoch: 29 Step: 581 Loss: 1.2358528119894143\n",
      "Epoch: 29 Step: 591 Loss: 1.1012915297746757\n",
      "Epoch: 29 Step: 601 Loss: 1.2040696917027702\n",
      "Epoch: 29 Step: 611 Loss: 1.0356268930445274\n",
      "Epoch: 29 Step: 621 Loss: 0.9837768713731738\n",
      "Epoch: 29 Step: 631 Loss: 1.151195060034414\n",
      "Epoch: 29 Step: 641 Loss: 1.2106289329616318\n",
      "Epoch: 29 Step: 651 Loss: 1.0122380057075229\n",
      "Epoch: 29 Step: 661 Loss: 0.9277695899104712\n",
      "Epoch: 29 Step: 671 Loss: 1.0939210914963176\n",
      "Epoch: 29 Step: 681 Loss: 1.2477915047232253\n",
      "Epoch: 29 Step: 691 Loss: 1.1728791040518434\n",
      "Epoch: 29 Step: 701 Loss: 1.1176102360860358\n",
      "Epoch: 29 Step: 711 Loss: 1.1690524496022814\n",
      "Epoch: 29 Step: 721 Loss: 0.9832765641894259\n",
      "Epoch: 29 Step: 731 Loss: 0.8535731112428584\n",
      "Epoch: 29 Step: 741 Loss: 1.49258558091064\n",
      "Epoch: 29 Step: 751 Loss: 1.3304718999595035\n",
      "Epoch: 29 Step: 761 Loss: 0.8715617629937549\n",
      "Epoch: 29 Step: 771 Loss: 1.243739541407989\n",
      "Epoch: 29 Step: 781 Loss: 1.1268283123516927\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Score is 0.5936299615877081\n",
      "Score is 0.49048477564102566\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# model = ConvNet()\n",
    "# model.load_model('/home/oneran/机器学习课设/cifar-10/Photon/rmsprop_cifar_ConvNet.pkl')\n",
    "# score, pred = model.score(X_train, Y_train)\n",
    "# score, pred = model.score(X_test, Y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# model = ResNet()\n",
    "# model.load_model('/home/oneran/机器学习课设/cifar-10/Photon/rmsprop_cifar_ResNet.pkl')\n",
    "# score, pred = model.score(X_train, Y_train)\n",
    "# score, pred = model.score(X_test, Y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# model = DenseNet('cifar_10')\n",
    "# model.load_model('/home/oneran/机器学习课设/cifar-10/Photon/rmsprop_cifar_DenseNet.pkl')\n",
    "# score, pred = model.score(X_train, Y_train)\n",
    "# score, pred = model.score(X_test, Y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# import seaborn as sns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# confu_mat = confusion_matrix(Y_test[:len(pred)].flatten(), np.array(pred).flatten())\n",
    "# np.sum(confu_mat * np.eye(10)) / len(pred)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# sns.heatmap(confu_mat)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.10.1",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.10.1 64-bit"
  },
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}